(function(f){if(typeof exports==="object"&&typeof module!=="undefined"){module.exports=f()}else if(typeof define==="function"&&define.amd){define([],f)}else{var g;if(typeof window!=="undefined"){g=window}else if(typeof global!=="undefined"){g=global}else if(typeof self!=="undefined"){g=self}else{g=this}g.rdfsig = f()}})(function(){var define,module,exports;return (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const stream = require('@graphy/core.iso.stream');
const factory = require('@graphy/core.data.factory');

const RT_ABSOLUTE_IRI_VALID = /^[a-z][a-z0-9+\-.]*:(?:[^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_ABSOLUTE_IRI_ESCAPELESS_VALID = /^[a-z][a-z0-9+\-.]*:[^\0-\x20<>"{}|^`]*$/;
const RT_NAMED_NODE_VALID = /^([^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_NAMED_NODE_ESCAPELESS_VALID = /^([^\0-\x20<>"{}|^`])*$/;

const R_UNICODE_ANY = /\\u([0-9A-Fa-f]{4})|\\U([0-9A-Fa-f]{8})/g;

const F_REPLACE_UNICODE_ANY = 	(s_, s_4, s_8) => String.fromCodePoint(parseInt(s_4 || s_8, 16));


const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_CLEAN_COMMENTS = /\s*(#[^\n]*\n\s*)*\s*/y;
const RT_HAS_ESCAPES = /[\\]/;
const R_EOL = /[^\n]+\n/y;

// eslint-disable-next-line no-misleading-character-class
const RT_BLANK_NODE_LABEL_VALID = /^(?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_0-9])(?:(?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.])*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?$/u;
const RT_LANGUAGE_VALID = /^[a-z]+(-[a-z0-9]+)*$/;

const R_WS = /\s*/y;
const R_HWS = /[ \t]*/y;
const R_LANGTAG = /@([A-Za-z]+(?:-[A-Za-z0-9-]+)*)(?:\s+|(?=[.,;\])#]))/y;

const R_IRIREF = /<([^>]*)>\s*/y;



const F_REPLACE_STRLIT_CONTENTS = (s_, s_whitespace, s_auto, s_4, s_8, s_invalid) => {
	if(s_whitespace) {
		switch(s_whitespace) {
			case 't': return '\t';
			case 'n': return '\n';
			case 'r': return '\r';
			case 'f': return '\f';
			case 'b': return '\b';
			default: {
				console.assert(`bad regex escape char mapping: '${s_whitespace}'`);
			}
		}
	}
	else if(s_auto) {
		return s_auto;
	}
	else if(s_4) {
		return String.fromCodePoint(parseInt(s_4, 16));
	}
	else if(s_8) {
		return String.fromCodePoint(parseInt(s_8, 16));
	}
	else if(s_invalid) {
		// pointless escape
		if('\\' === s_invalid[0]) {
				// // relaxed
				// return s_invalid[1];
			// if relaxed then return s_invalid, otherwise throw:
			throw new Error(`expected string_literal but invalid escape sequence within contents: '${s_invalid}'. failed to parse a valid token`);
		}
		// bad character
		else {
			throw new Error(`expected string_literal but invalid whitespace character within contents: ${JSON.stringify(s_invalid)}. failed to parse a valid token`);
		}
	}
	else {
		console.assert(`unexpected no match branch in escape sequence replace callback`);
	}
};


const R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\.))/g;
const R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_short_hard = s_literal => s_literal
	.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_short_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};

// lookbehind regexes
const [
	R_STRLIT_ESCAPE_INCOMPLETE,
	R_STRLIT_SHORT_DOUBLE_TERM,
] = (() => {
	function RegExp_$lookbehind_polyfill(s_input) {
		let m_match = RegExp.prototype.exec.call(this, s_input);

		if(m_match) {
			let i_start = m_match[0].length - m_match[1].length;
			m_match.index += i_start;
			m_match[0] = m_match[0].slice(i_start);
		}

		return m_match;
	}
	let mk_lookbehind_regex = (() => {
		try {
			new RegExp('(?<!h)i');  // eslint-disable-line no-new
		}
		catch(e_compile) {
			return (f_lookbehind, r_polyfill, f_polyfill) => {
				r_polyfill.exec = f_polyfill;
				return r_polyfill;
			};
		}
		return f_lookbehind => f_lookbehind();
	})();
	return [
		// R_STRLIT_ESCAPE_INCOMPLETE
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\\\\(|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7})$'),
			/^(?:(?:[^\\]|\\.)*)(\\(?:|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7}))$/,
			function RegExp_$lookbehind_polyfill_n(s_input) {
				let m_match = RegExp.prototype.exec.call(this, s_input);
				if(m_match) {
					m_match.index += m_match[0].length - m_match[1].length;
				}

				return m_match;
			},
		),
		// R_STRLIT_SHORT_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"\\s*', 'g'),
			/(?:[^\\"]|\\.)*("\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

	];
})();



const R_QUAD_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^\x20\t<]+))[\x20\t]*<([^\\>]*)>[\x20\t]*(?:(?:(<[^\\>]*)>|_:([^\x20\t<]+))[\x20\t]*(?:<([^\\>]*)>|_:([^\x20\t<]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+|"([^"\\]*)(?:(")(?:\^\^<([^\\>]*)>|@([^\x20\t.]+)|)[\x20\t]*(?:<([^\\>]*)>|_:([^\x20\t<]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+)?)/y;
const R_QUAD = /(?:<([^>]*)>|_:([^\x20\t<]+))[\x20\t]*<([^>]*)>[\x20\t]*(?:(?:(<[^>]*)>|_:([^\x20\t<]+))[\x20\t]*(?:<([^>]*)>|_:([^\x20\t<]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+|"((?:[^"\\]|\\.)*)(?:(")(?:\^\^<([^>]*)>|@([^\x20\t.]+)|)[\x20\t]*(?:<([^>]*)>|_:([^\x20\t<]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+)?)/y;
const R_BLANK_NODE = /_:([^\x20\t<]+)/y;



class NQuads_Reader extends stream.Transform {
	constructor(g_impls) {
		super({
			// do not decode strings into buffers
			decodeStrings: false,

			// accept strings as input on writable side
			writableObjectMode: false,

			// output quad objects on readable side
			readableObjectMode: true,

			// implementations
			flush: g_impls.flush,
			transform: g_impls.transform,
		});

		// when the writable side is piped into
		this.on('pipe', (ds_input) => {
			this._ds_input = ds_input;

			// input stream has encoding option; ensure stream encoding is utf8
			if('function' === typeof ds_input.setEncoding) {
				ds_input.setEncoding('utf8');
			}
		});
	}

	// intercept pipe
	pipe(ds_out) {
		let ds_dst = ds_out;

		// non-object mode
		if(!ds_dst._writableState.objectMode) {
			// transform to JSON
			ds_out = stream.quads_to_json();
		}
		// yet object mode and graphy writable
		else if(ds_out.isGraphyWritable) {
			// transform to quad-stream
			ds_out = stream.quads_to_writable();
		}

		// interim stream created
		if(ds_out !== ds_dst) {
			// forward output to super
			super.pipe(ds_out);

			// pipe outpu to destination
			return ds_out.pipe(ds_dst);
		}
		// forward as-is to super
		else {
			return super.pipe(ds_dst);
		}
	}
}

class Reader {
	constructor(g_config) {
		let {
			// input medium
			input: g_input=null,

			// relax validation
			relax: b_relax=false,

			// debug
			debug: b_debug=false,
		} = g_config;

		// allow relative iris flag
		let b_allow_relative_iris = g_config.allow_relative_iris || g_config.allowRelativeIRIs || g_config.allowRelativeIris || false;

		// adopt factory
		let dc_factory = this._dc_factory = factory.adopt(g_config.dataFactory || g_config.data_factory || factory.unfiltered);

		let f_quad = this._f_quad = dc_factory.quad;

		// fields
		Object.assign(this, {
			// string buffer, accept left-over string from previous data chunk
			s: g_config.prepend || '',

			// string buffer length
			n: 0,

			_b_debug: b_debug,

			_b_relax: b_relax,

			_b_destroyed: false,

			_b_trim_start: true,

			_f_state: this.statement,

			_kt_subject: null,
			_kt_predicate: null,
			_kt_object: null,

			_s_literal: '',
		});

		this._kt_default_graph = dc_factory.defaultGraph();
		this._kt_rdfs_lang_string = dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString');

		// clean regex
		let r_clean = this._r_clean = R_CLEAN;

		if(g_config.relaxed) {
			console.warn((new Error(`no such option 'relaxed'; did you mean 'relax' ?`)).stack.replace(/^Error:/, 'Warning:'));
		}
		if('validate' in g_config) {
			console.warn((new Error(`option 'validate' has been removed and validation is now on by default. Use 'relax' option if you wish to disable validation.`)).stack.replace(/^Error:/, 'Warning:'));
		}

		let namedNode = dc_factory.namedNode;
		let blankNode = dc_factory.blankNode;
		let languagedLiteral = dc_factory.languagedLiteral;

		// test for valid named node
		let rt_named_node_valid = b_allow_relative_iris? RT_NAMED_NODE_VALID: RT_ABSOLUTE_IRI_VALID;

		// test for valid named node escapeless
		let rt_named_node_valid_escapeless = b_allow_relative_iris? RT_NAMED_NODE_ESCAPELESS_VALID: RT_ABSOLUTE_IRI_ESCAPELESS_VALID;

		// validation
		let k_self = this;
		Object.assign(this, !b_relax
			? {
				create_named_node(p_iri) {
					if(!rt_named_node_valid.test(p_iri)) return k_self._error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				create_named_node_escapeless(p_iri) {
					if(!rt_named_node_valid_escapeless.test(p_iri)) return k_self._error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				create_blank_node(s_label) {
					if(!RT_BLANK_NODE_LABEL_VALID.test(s_label)) return k_self._error(`Invalid blank node label: "${s_label}"`);
					return blankNode(s_label);
				},

				create_languaged_literal(s_contents, s_language) {
					if(!RT_LANGUAGE_VALID.test(s_language)) {
						return k_self._error(`Invalid literal language tag: ${s_language}`);
					}

					return languagedLiteral(s_contents, s_language);
				},
			}
			: {
				create_named_node: namedNode,

				create_named_node_escapeless: namedNode,

				create_blank_node: blankNode,

				create_languaged_literal: languagedLiteral,
			});

		// transform stream
		let ds_transform;

		// whether or not data has been received before
		let b_init = false;

		// create transform
		ds_transform = this.transform = new NQuads_Reader({
			// on data event
			transform: (s_chunk, s_encoding, fk_chunk) => {
				// first transform
				if(!b_init) {
					// notify that data will begin
					ds_transform.emit('ready');

					// do not emit 'ready' event again
					b_init = false;
				}

				// concatenate current chunk to previous chunk
				let s = this.s += s_chunk;

				// remove whitespace & comments from beginning
				if(this._b_trim_start) {
					r_clean.lastIndex = 0;
					let m_clean = r_clean.exec(s);
					if(this.emit_comments) {
						this.emit_comments(m_clean[1]);
					}

					// update index and prepare to match statement
					this.i = r_clean.lastIndex;
				}
				// do not remove whitespace; reset index
				else {
					this.i = 0;
				}

				// cache chunk length
				this.n = s.length;

				// resume parsing
				try {
					this.parse(true);
				}
				// read error occurred; emit and destroy stream
				catch(e_read) {
					return ds_transform.destroy(e_read);
				}

				// emit progress event updates
				ds_transform.emit('progress', s_chunk.length);

				// done transforming this chunk
				fk_chunk();
			},

			// once there's no more data to consume, invoke eof
			flush: (fk_flush) => {
				// there is still unparsed data
				if(this.s.length) {
					// append newline to end so we can match token
					this.s += '\n';

					// remove whitespace & comments from beginning
					if(this._b_trim_start) {
						r_clean.lastIndex = 0;
						let m_clean = r_clean.exec(this.s);
						if(this.emit_comments) {
							this.emit_comments(m_clean[1]);
						}

						// update index and prepare to match statement
						this.i = r_clean.lastIndex;
					}
					// do not remove whitespace; reset index
					else {
						this.i = 0;
					}

					// parse
					try {
						this.parse();
					}
					// read error occurred; pass to flush errback and exit method
					catch(e_read) {
						// destroying during flush means overriding push
						return ds_transform.demolish(e_read);
					}

					// still unparsed characters; pass to flush errback and exit method
					if(this.s.length) {
						return ds_transform.demolish(new Error(`parsing error occurred in state: statement\n  ${this.s.substr(0, 50)}\n  ^ starting here`));
					}
				}

				// invalid state
				if(this._f_state !== this.statement) {
					return ds_transform.demolish(new Error(`parsing error occurred in state: ${this._f_state.name}\n  ${this.s.substr(0, 50)}\n  ^ starting here`));
				}

				// make buffer's alloc eligible for gc
				this.s = null;

				// final progress update: no additional bytes were read
				ds_transform.emit('progress', 0);

				// call end event listener
				ds_transform.emit('eof');

				// done flushing, close read stream
				fk_flush();
			},
		});

		// destroy
		ds_transform._destroy = (...a_args) => {
			this.destroy(...a_args);
		};

		// data quad
		this._f_data_quad = (kt_subject, kt_predicate, kt_object, kt_graph) => ds_transform.push(f_quad(kt_subject, kt_predicate, kt_object, kt_graph));

		// new listener added
		ds_transform.on('newListener', (s_event) => {
			// comment
			if('comment' === s_event) {
				r_clean = R_CLEAN_COMMENTS;
				this.emit_comments = (s_captured) => {
					if(!s_captured) return;
					let a_comments = s_captured.slice(1).replace(/\n\s+$/, '').split(/\n+\s*#/g);

					for(let s_comment of a_comments) {
						ds_transform.emit('comment', s_comment);
					}
				};
			}
		});

		// bind events to transform stream
		this.bind(g_config);

		// input given
		if(g_input) {
			// input is stream
			if(g_input.stream) {
				let ds_input = g_input.stream;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_input.pipe(ds_transform);
				});
			}
			// string
			else if('string' === typeof g_input.string) {
				let s_input = g_input.string;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_transform.end(s_input, 'utf8');
				});
			}
			// invalid arg
			else {
				throw new TypeError(`Invalid argument for input parameter: ${'object' === typeof g_input? JSON.stringify(g_input): g_input}`);
			}
		}

		ds_transform._graphy_reader = this;
	}

	_error(s_message) {
		this._b_destroyed = true;
		throw new Error(s_message);
	}



	bind(g_config) {
		let ds_transform = this.transform;
		if(g_config.error) ds_transform.on('error', g_config.error);
		if(g_config.comment) ds_transform.on('comment', g_config.comment);
		if(g_config.read) ds_transform.once('read', g_config.read);
		if(g_config.progress) ds_transform.on('progress', g_config.progress);
		if(g_config.eof) ds_transform.once('eof', g_config.eof);
		if(g_config.end) ds_transform.once('end', g_config.end);
		if(g_config.finish) ds_transform.once('finish', g_config.finish);
		if(g_config.data) ds_transform.on('data', g_config.data);
	}

	// begin parsing, keep applying until no more stack bail-outs
	parse() {
		let f_sync = this._f_state();
		while('function' === typeof f_sync) {
			f_sync = f_sync.apply(this);
		}
	}

	statement() {
		let s = this.s;
		let n = this.n;
		let i = this.i;
		let f_data_quad = this._f_data_quad;
		let create_named_node = this.create_named_node;
		let create_named_node_escapeless = this.create_named_node_escapeless;
		let create_languaged_literal = this.create_languaged_literal;
		let create_blank_node = this.create_blank_node;
		let simpleLiteral = this._dc_factory.simpleLiteral;
		let datatypedLiteral = this._dc_factory.datatypedLiteral;
		let kt_default_graph = this._kt_default_graph;

		// match triples/quads
		for(;;) {
			// prepare sticky regex index
			R_QUAD_ESCAPELESS_SP.lastIndex = i;
			// execute regex
			let m_statement_e_sp = R_QUAD_ESCAPELESS_SP.exec(s);

			// regex was a match
			if(m_statement_e_sp) {
				// advance index
				i = R_QUAD_ESCAPELESS_SP.lastIndex;

				// prep object term
				let kt_object;
				// where to find the graph component
				let b_graph_late = false;

				// object term type is named node
				if(m_statement_e_sp[4]) {
					let p_object = m_statement_e_sp[4].slice(1);
					kt_object = create_named_node_escapeless(p_object);
				}
				// object term type is blank node
				else if(m_statement_e_sp[5]) {
					kt_object = create_blank_node(m_statement_e_sp[5]);
				}
				// object term type is literal
				else {
					// graph is in late capture group
					b_graph_late = true;

					// contents
					let s_contents = m_statement_e_sp[9];
					// string terminator
					if(m_statement_e_sp[10]) {
						// datatype is present
						if(m_statement_e_sp[11]) {
							// create datatype term
							let kt_datatype = this.create_named_node_escapeless(m_statement_e_sp[11]);
							// create object term
							kt_object = datatypedLiteral(s_contents, kt_datatype);
						}
						// language tag is present
						else if(m_statement_e_sp[12]) {
							// normalize language
							let s_language = m_statement_e_sp[12].toLowerCase();
							// create object term
							kt_object = create_languaged_literal(s_contents, s_language);
						}
						// simple literal
						else {
							kt_object = simpleLiteral(s_contents);
						}
					}
					// no string terminator
					else {
						// save contents
						this._s_literal = s_contents;
						// update index
						this.i = i;
						// save subject
						{
							let s_subject = m_statement_e_sp[1];
							// named node
							if(s_subject || 'string' === typeof s_subject) {
								this._kt_subject = create_named_node_escapeless(s_subject);
							}
							// blank node
							else {
								this._kt_subject = create_blank_node(m_statement_e_sp[2]);
							}
						}
						// save predicate
						this._kt_predicate = create_named_node_escapeless(m_statement_e_sp[3]);
						// parse contents
						let z_bail = this.strlit_contents();
						// bail out of stack
						if(z_bail && this.statement !== z_bail) {
							return z_bail;
						}
						// statement completed
						else {
							// clean
							let r_clean = this._r_clean;
							r_clean.lastIndex = this.i;
							let m_clean = r_clean.exec(s);
							if(this.emit_comments) {
								this.emit_comments(m_clean[1]);
							}
							// update local index and prepare to match next statement
							i = r_clean.lastIndex;
							// resume
							continue;
						}
					}
				}
				let kt_graph = kt_default_graph;

				// graph after literal
				if(b_graph_late) {
					// ref capture group
					let s_graph = m_statement_e_sp[13];

					// named node
					if(s_graph || 'string' === typeof s_graph) {
						kt_graph = create_named_node_escapeless(s_graph);
					}
					// blank node
					else if(m_statement_e_sp[14]) {
						kt_graph = create_blank_node(m_statement_e_sp[14]);
					}
				}
				// graph after node
				else {
					// ref capture group
					let s_graph = m_statement_e_sp[6];

					// named node
					if(s_graph || 'string' === typeof s_graph) {
						kt_graph = create_named_node_escapeless(s_graph);
					}
					// blank node
					else if(m_statement_e_sp[7]) {
						kt_graph = create_blank_node(m_statement_e_sp[7]);
					}
				}

				let kt_subject;
				{
					let s_subject = m_statement_e_sp[1];
					// named node
					if(s_subject || 'string' === typeof s_subject) {
						kt_subject = create_named_node_escapeless(s_subject);
					}
					// blank node
					else {
						kt_subject = create_blank_node(m_statement_e_sp[2]);
					}
				}
				let s_predicate = m_statement_e_sp[3];
				// emit data event
				f_data_quad(
					kt_subject,
					create_named_node_escapeless(s_predicate),
					kt_object,
					kt_graph,
				);
				// comments
				if(this.emit_comments) {
					this.emit_comments(m_statement_e_sp[8] || m_statement_e_sp[15]);
				}
			}
			else {
				// prepare sticky regex index
				R_QUAD.lastIndex = i;
				// execute regex
				let m_statement = R_QUAD.exec(s);

				// regex was a match
				if(m_statement) {
					// advance index
					i = R_QUAD.lastIndex;

					// prep object term
					let kt_object;
					// where to find the graph component
					let b_graph_late = false;

					// object term type is named node
					if(m_statement[4]) {
						let p_object = m_statement[4].slice(1);
						kt_object = create_named_node(RT_HAS_ESCAPES.test(p_object)? p_object.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): p_object);
					}
					// object term type is blank node
					else if(m_statement[5]) {
						kt_object = create_blank_node(RT_HAS_ESCAPES.test(m_statement[5])? m_statement[5].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): m_statement[5]);
					}
					// object term type is literal
					else {
						// graph is in late capture group
						b_graph_late = true;

						// contents
						let s_contents = m_statement[9];
						// string terminator
						if(m_statement[10]) {
							// unescape contents
							s_contents = unescape_literal_short_hard(s_contents);

							// datatype is present
							if(m_statement[11]) {
								// create datatype term
								let kt_datatype = this.create_named_node(m_statement[11]);
								// create object term
								kt_object = datatypedLiteral(s_contents, kt_datatype);
							}
							// language tag is present
							else if(m_statement[12]) {
								// normalize language
								let s_language = m_statement[12].toLowerCase();
								// create object term
								kt_object = create_languaged_literal(s_contents, s_language);
							}
							// simple literal
							else {
								kt_object = simpleLiteral(s_contents);
							}
						}
						// no string terminator
						else {
							// save contents
							this._s_literal = s_contents;
							// update index
							this.i = i;
							// save subject
							{
								let s_subject = m_statement[1];
								// named node
								if(s_subject || 'string' === typeof s_subject) {
									this._kt_subject = create_named_node(RT_HAS_ESCAPES.test(s_subject)? s_subject.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_subject);
								}
								// blank node
								else {
									this._kt_subject = create_blank_node(m_statement[2]);
								}
							}
							// save predicate
							this._kt_predicate = create_named_node(RT_HAS_ESCAPES.test(m_statement[3])? m_statement[3].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): m_statement[3]);
							// parse contents
							let z_bail = this.strlit_contents();
							// bail out of stack
							if(z_bail && this.statement !== z_bail) {
								return z_bail;
							}
							// statement completed
							else {
								// clean
								let r_clean = this._r_clean;
								r_clean.lastIndex = this.i;
								let m_clean = r_clean.exec(s);
								if(this.emit_comments) {
									this.emit_comments(m_clean[1]);
								}
								// update local index and prepare to match next statement
								i = r_clean.lastIndex;
								// resume
								continue;
							}
						}
					}
					let kt_graph = kt_default_graph;

					// graph after literal
					if(b_graph_late) {
						// ref capture group
						let s_graph = m_statement[13];

						// named node
						if(s_graph || 'string' === typeof s_graph) {
							kt_graph = create_named_node(RT_HAS_ESCAPES.test(s_graph)? s_graph.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_graph);
						}
						// blank node
						else if(m_statement[14]) {
							kt_graph = create_blank_node(m_statement[14]);
						}
					}
					// graph after node
					else {
						// ref capture group
						let s_graph = m_statement[6];

						// named node
						if(s_graph || 'string' === typeof s_graph) {
							kt_graph = create_named_node(RT_HAS_ESCAPES.test(s_graph)? s_graph.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_graph);
						}
						// blank node
						else if(m_statement[7]) {
							kt_graph = create_blank_node(m_statement[7]);
						}
					}

					let kt_subject;
					{
						let s_subject = m_statement[1];
						// named node
						if(s_subject || 'string' === typeof s_subject) {
							kt_subject = create_named_node(RT_HAS_ESCAPES.test(s_subject)? s_subject.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_subject);
						}
						// blank node
						else {
							kt_subject = create_blank_node(m_statement[2]);
						}
					}
					let s_predicate = m_statement[3];
					// emit data event
					f_data_quad(
						kt_subject,
						create_named_node(RT_HAS_ESCAPES.test(s_predicate)? s_predicate.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_predicate),
						kt_object,
						kt_graph,
					);
					// comments
					if(this.emit_comments) {
						this.emit_comments(m_statement[8] || m_statement[15]);
					}
				}
				else {
					// prepare sticky regex index
					R_EOL.lastIndex = i;

					if(R_EOL.exec(s)) {
						// advance index
						i = R_EOL.lastIndex;
						this._error(`Failed to read statement:\n\`${s.substr(i, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		} // end of while

		// update unparsed data string
		this.s = s.substr(i);

		// resume here
		this._f_state = this.statement;

		// exit
		return 1;
	}


	strlit_contents() {
		let {s, n, i} = this;

		// try to find end
		R_STRLIT_SHORT_DOUBLE_TERM.lastIndex = i;
		let m_term = R_STRLIT_SHORT_DOUBLE_TERM.exec(s);

		// end is in this chunk
		if(m_term) {
			// index of terminator
			let i_term = m_term.index;

			// extract dirty potion
			let s_dirty = s.slice(i, i_term);

			// clean and save
			this._s_literal += unescape_literal_short_hard(s_dirty);

			// advance index beyond terminator
			this.i = i_term + m_term[0].length;

			// resume eating whitespace at start of next chunk
			this._b_trim_start = true;

			// proceed with datatype_or_lang, then bail out of stack or resume parsing
			return this.datatype_or_langtag() || this.statement;
		}
		// end is not in this chunk
		else {
			// extract whole portion
			let s_dirty = s.slice(i);

			// unescape to clean part
			let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

			// save
			this._s_literal += s_clean;

			// set unparsed index
			this.i = i = n - s_incomplete.length;

			// do not eat whitespace at start of next chunk
			this._b_trim_start = false;
		}

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('strlit_contents');
				}
			}
		}

		// resume here
		this._f_state = this.strlit_contents;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}



	// parse state for datatype_or_langtag
	datatype_or_langtag() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// ref character
		let x = s[i];

		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// datatype
			if('^' === x) {
				// enough to speculate datatype
				if((i+2) < n) {
					// correct token
					if('^' === s[i+1]) {
						// advance index beyond token
						R_IRIREF.lastIndex = i + 2;

						// execute regex
						let m_iriref = R_IRIREF.exec(s);

						// regex was a match
						if(m_iriref) {
							// advance index
							this.i = R_IRIREF.lastIndex;

							// prepare iri
							let p_datatype = m_iriref[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);

							// create datatype term
							let kt_datatype = this.create_named_node(p_datatype);

							// create object term
							this._kt_object = this._dc_factory.datatypedLiteral(this._s_literal, kt_datatype);

							// free literal string
							this._s_literal = '';

							// graph state
							return this.post_object();
						}
						// failed to match; try again next chunk
						else {
							break;
						}
					}
					// invalid
					else {
						this._error(`Failed to read token after literal:\n\`${s.substr(i+1, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);
					}
				}
				// not enough to speculate; try again next chunk
				else {
					break;
				}
			}
			// language tag
			else if('@' === x) {
				// prepare sticky regex index
				R_LANGTAG.lastIndex = i;
				// execute regex
				let m_langtag = R_LANGTAG.exec(s);

				// regex was a match
				if(m_langtag) {
					// advance index
					this.i = R_LANGTAG.lastIndex;

					// use direct factory method since regex is validation
					this._kt_object = this._dc_factory.languagedLiteral(this._s_literal, m_langtag[1]);

					// free literal string
					this._s_literal = '';

					// graph state
					return this.post_object();
				}
				// interrupted by eos; try again next chunk
				else {
					break;
				}
			}
			// graph component
			else if('<' === x || '_' === x) {
				// save simple literal
				this._kt_object = this._dc_factory.simpleLiteral(this._s_literal);

				// free literal string
				this._s_literal = '';

				// continue parsing graph component
				return this.graph();
			}
			// triple terminator
			else if('.' === x) {
				// save simple literal
				let kt_object = this._dc_factory.simpleLiteral(this._s_literal);

				// free literal string
				this._s_literal = '';

				// advance index beyond terminator
				this.i = i + 1;

				// emit data event
				this._f_data_quad(this._kt_subject, this._kt_predicate, kt_object, this._kt_default_graph);

				// reset state
				return this.statement;

				// // consume whitespace (and incidentally reset index)
				// R_WS.lastIndex = i + 1;
				// R_WS.exec(s);
				// this.i = R_WS.lastIndex;

				// // done
				// return;
			}
			// other
			else {
				break;
			}
		}

		// ran out of characters
		// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype_or_langtag');
				}
			}
		}

		// resume here
		this._f_state = this.datatype_or_langtag;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}

	statement_term() {
		let {s, n, i} = this;

		// find full stop
		let i_stop = s.indexOf('.', i);

		// found
		if(i_stop > -1) {
			// consume whitespace again
			this._b_trim_start = true;

			// advance beyond token
			this.i = i_stop + 1;

			// reset state
			return this.statement;
		}
		// anything other than whitespace
		else if(!/^\s*$/.test(s.slice(i))) {
			this.parse_error('statement_term');
		}

		// do not consume whitespace
		this._b_trim_start = false;

		// resume here
		this._f_state = this.statement_term;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}

	post_object() {
		let {s, n, i} = this;

		// eat horizontal whitespace
		R_HWS.lastIndex = i;
		R_HWS.exec(s);
		i = R_HWS.lastIndex;

		// ran out of characters
		if(i >= n) {
			// resume here
			this._f_state = this.post_object;

			// store what is unparsed
			this.s = s.slice(i);

			// if we're not parsing a stream, then this is an error
			if(this.eos) this.eos();
			return 1;
		}

		// depending on char
		switch(s[i]) {
			// statement term
			case '.': {
				// advance index beyond terminator
				this.i = i + 1;

				// emit data event
				this._f_data_quad(this._kt_subject, this._kt_predicate, this._kt_object, this._kt_default_graph);

				// reset state
				return this.statement;
			}

			// graph
			case '<':
			case '_': {
				// save index
				this.i = i;

				// consume graph component
				return this.graph();
			}

			// invalid
			default: {
				// save index
				this.i = i;

				// emit parsing error
				this.parse_error('post_object');
			}
		}
	}

	graph() {
		let {s, n, i} = this;


		// prepare sticky regex index
		R_IRIREF.lastIndex = i;
		// execute regex
		let m_iriref = R_IRIREF.exec(s);

		// regex was a match
		if(m_iriref) {
			// advance index
			this.i = R_IRIREF.lastIndex;
			// create graph term
			let kt_graph = this.create_named_node(m_iriref[1]);

			// emit data event
			this._f_data_quad(this._kt_subject, this._kt_predicate, this._kt_object, kt_graph);

			// complete with statement_term
			return this.statement_term();
		}
		else {
			// prepare sticky regex index
			R_BLANK_NODE.lastIndex = i;
			// execute regex
			let m_blank = R_BLANK_NODE.exec(s);

			// regex was a match
			if(m_blank) {
				// advance index
				this.i = R_BLANK_NODE.lastIndex;
				// create graph term
				let kt_graph = this._dc_factory.blankNode(m_blank[1]);

				// emit data event
				this._f_data_quad(this._kt_subject, this._kt_predicate, this._kt_object, kt_graph);

				// complete with statement_term
				return this.statement_term();
			}
		} // brace #1


		// resume here
		this._f_state = this.graph;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}

	parse_error(s_state) {
		return this._error(`Failed to read ${s_state}:\n\`${this.s.substr(this.i, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);
	}

	destroy(e_destroy) {
		this._f_data_quad = () => {};

		if(!e_destroy && this._ds_input) {
			this._ds_input.destroy(e_destroy);
		}

		this.transform.demolish(e_destroy);
	}
}


module.exports = function(...a_args) {
	let g_config = {};

	// at least one argument
	if(a_args.length) {
		let z_arg_0 = a_args[0];

		// input given unspecified
		if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
			z_arg_0 = z_arg_0.input;
		}

		// string
		if('string' === typeof z_arg_0) {
			g_config.input = {string:z_arg_0};
		}
		// null
		else if(null === z_arg_0) {
			g_config.input = null;
		}
		// node stream
		else if('function' === typeof z_arg_0.setEncoding) {
			g_config.input = {stream:z_arg_0};
		}
		// whatwg stream
		else if('function' === typeof z_arg_0.pipeTo) {
			throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
		// g_config.input = {stream:z_arg_0};
		}
		// config struct
		else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
			g_config = z_arg_0;

			// more args; invalid
			if(a_args.length > 1) {
				throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
			}
		}
		// unknown
		else {
			throw new TypeError(`unexpected input type: ${z_arg_0}`);
		}

		// more args
		if(a_args.length > 1) {
			// copy onto struct
			Object.assign(g_config, a_args[1]);

			// more args
			if(a_args.length > 2) {
				throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
			}
		}
	}

	// create reader, return transform stream
	return (new Reader(g_config)).transform;
};

},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21}],2:[function(require,module,exports){
(function (Buffer,setImmediate){(function (){

const run = sjx_eval => eval(sjx_eval);

// iiaf to isolate scope from eval
(function() {
	// queueMicrotask shim
	{
		// not defined or not a function
		if('function' !== typeof queueMicrotask) {
			// create resolved promise
			let dp_resolve = Promise.resolve();

			// try to redefine
			try {
				// eslint-disable-next-line no-global-assign
				queueMicrotask = fk => dp_resolve.then(fk)
					.catch(e_callback => setTimeout(() => {
						throw e_callback;
					}, 0));
			}
			// oh well, at least we tried
			catch(e_define) {}
		}
	}



	const events = require('events');
	const path = require('path');
	const stream = require('@graphy/core.iso.stream');
	const reader = require('@graphy/content.nq.read');
	const master = require('@graphy/core.iso.threads').master;
	const {StringDecoder} = require('string_decoder');
	const H_PRESET_TASKS = require('./task-presets.js');

	// fast 4 byte writer from bkit
	const f_writer_uintle32 = (at, ib, x) => {
		at[ib] = x & 0xff;
		at[ib+1] = (x >>> 8) & 0xff;
		at[ib+2] = (x >>> 16) & 0xff;
		at[ib+3] = (x / 0x1000000) & 0xff;
		return at;
	};

	const N_DEFAULT_SLOTS_PER_WORKER = 3;



	// adapted from https://www.npmjs.com/package/physical-cpu-count
	let NL_WORKERS_ADVISE = (() => {
		const cp = require('child_process');
		const os = require('os');

		const exec = s_cmd => cp.execSync(s_cmd, {encoding:'utf8'});

		switch(os.platform()) {
			case 'linux': {
				let s_out = exec(/* syntax: shell */ `lscpu -p | egrep -v "^#" | sort -u -t, -k 2,4 | wc -l`);
				return parseInt(s_out.trim(), 10);
			}

			case 'darwin': {
				let s_out = exec(/* syntax: shell */ `sysctl -n hw.physicalcpu_max`);
				return parseInt(s_out.trim(), 10);
			}

			case 'windows': {
				let s_out = exec(/* syntax: shell */ `WMIC CPU Get NumberOfCores`);
				return s_out.split(os.EOL)
					.map(s => parseInt(s))
					.filter(n => !isNaN(n))
					.reduce((c_out, n) => c_out + n, 0);
			}

			default: {
				return os.cpus().filter((g_cpu, i_cpu) => {
					let b_hyperthreading = g_cpu.model.includes('Intel');
					let b_odd = 1 === (i_cpu % 2);
					return !b_hyperthreading || b_odd;
				}).length;
			}
		}
	})() - 1;



	function Scanner$handle_worker_message(k_self, i_worker) {
		return (g_msg) => {
			switch(g_msg.type) {
				// update
				case 'update': {
					// ref message payload
					let w_value = g_msg.value;

					// sync receive update transform
					if(k_self._f_receive_update) w_value = k_self._f_receive_update(w_value, i_worker);

					// apply update handler
					k_self._f_update(w_value, i_worker);
					break;
				}

				// submit
				case 'submit': {
// console.log(`received result from worker ${i_worker}: ${g_msg.value}; ${a_reports.length+1} results`);

					// ref message payload
					let w_value = g_msg.value;

					// sync receive submit transform
					if(k_self._f_receive_submit) w_value = k_self._f_receive_submit(w_value, i_worker);

					// reduce
					k_self._w_reduced = k_self._f_reduce(k_self._w_reduced, w_value);

					// all results have been collected
					if(k_self._nl_workers === ++k_self._c_reports) {
						if(k_self._b_eofed) {
							k_self._f_report(k_self._w_reduced);
						}
						else {
							k_self._b_collected = true;
						}
					}

					break;
				}

				// error
				case 'error': {
					// error struct
					let g_error = g_msg.value;

					// reconstruct error
					let e_throw = new Error(g_error.message);
					e_throw.stack = g_error.stack;

					// kill workers and throw error
					return k_self._kill(e_throw, i_worker);
				}

				// throw
				case 'throw': {
					// ref error struct
					let z_throw = g_msg.value;

					// issue warning
					console.warn(`WARNING: Your code (or some library) on the worker is throwing an object which is not an instance of Error. I am going to put it into an Error for you now, but please fix this. The object.toString() is: "${z_throw}"`);

					// construct error
					let e_wrap = new Error(z_throw+'');

					// kill workers and throw error
					return k_self._kill(e_wrap, i_worker);
				}

				// clone error
				case 'clone-error': {
					// ref error struct
					let g_clone = g_msg.value;

					// construct error
					let e_clone = new Error(`You are trying to call '${g_clone.info}' on some object from within one of the workers, but that object is not serializable using the structured clone algorithm. The object.toString() is: "${g_clone.obejct}"... the error about the worker failing to send the original error to the master thread is:\n${g_clone.error}`);

					// kill workers and throw error
					return k_self._kill(e_clone, i_worker);
				}


				// other
				default: {
					console.assert(`invalid worker message type: ${g_msg.type}`);
				}
			}
		};
	}


	// fill open slots with next chunk from input stream
	function Scanner$fill_slots(k_self) {
		let ds_input = k_self._ds_input;
		let a_slots_open = k_self._a_slots_open;
		let nb_high_water_mark = k_self._nb_high_water_mark;
		let nb_slot = k_self._nb_slot;
		let atu8_data = k_self._atu8_data;
		let atu8_slot_owners = k_self._atu8_slot_owners;
		let at32_indicators = k_self._at32_indicators;
		let a_slot_states = k_self._a_slot_states;
		let ab_prev = k_self._ab_prev;
		let ds_reader = k_self._ds_reader;

		// prep chunk placeholder
		let ab_chunk;

		// while there are open slots
		while(a_slots_open.length) {
			// read chunk from input stream
			ab_chunk = ds_input.read();

			// buffer is drained; break read loop
			if(null === ab_chunk) break;

			// chunk size exceeds high water mark
			if(ab_chunk.length > nb_high_water_mark) {
				// unshift remainder back into internal buffer
				let ab_unshift = ab_chunk.slice(nb_high_water_mark);

				// pick limit part for this chunk
				ab_chunk = ab_chunk.slice(0, nb_high_water_mark);

				// unshift
				ds_input.unshift(ab_unshift);
			}

			// read head/tail
			let ib_head = ab_chunk.indexOf(0x0a) + 1;
			let ib_tail = ab_chunk.lastIndexOf(0x0a) + 1;

			// take next open slot
			let i_slot = a_slots_open.shift();

			// slot position
			let ib_slot = i_slot * nb_slot;

			// payload size
			let nb_payload = ib_tail - ib_head;
			f_writer_uintle32(atu8_data, ib_slot, nb_payload);

			// fill it
			ab_chunk.copy(atu8_data, ib_slot+4, ib_head, ib_tail);

			// mark slot ready
			atu8_slot_owners[i_slot] = 255;

			// set indicator & notice
			at32_indicators[0] += 1;
			let n_awoke = Atomics.notify(at32_indicators, 0);
// log(`woke ${n_awoke} sleeping threads}`);

			// set slot state
			a_slot_states[i_slot] = 1;

			// join head with prev
			let ab_head = ab_chunk.slice(0, ib_head);
			let ab_write = Buffer.concat([ab_prev, ab_head], ab_prev.length+ab_head.length);

			let s_write = ab_write.toString('utf8');

			// write to reader
			ds_reader.write(s_write);

			// save tail to prev
			ab_prev = ab_chunk.slice(ib_tail);
		}

		// update prev chunk value
		k_self._ab_prev = ab_prev;

		// buffer is drained
		if(0 === ds_input.readableLength) {
			// but did not reach null
			if(null !== ab_chunk) {
				// trigger
				let z_read = ds_input.read();

				// assert null
				if(null !== z_read) {
					throw new Error(`expected to reach null in paused stream readable but received ${z_read? 'chunk data instad': 'skipped event'}`);
				}
			}

			// await readable
			return true;
		}

		// have not consumed everything
		return false;
	}

	// drain returned slots
	function Scanner$drain_slots(k_self) {
		let nl_slots = k_self._nl_slots;
		let atu8_slot_owners = k_self._atu8_slot_owners;
		let a_slot_states = k_self._a_slot_states;
		let a_slots_open = k_self._a_slots_open;

		let c_drained = 0;

		// read results
		for(let i_slot=0; i_slot<nl_slots; i_slot++) {
			// slot returned
			if(0 === atu8_slot_owners[i_slot] && 1 === a_slot_states[i_slot]) {
				// update slot state
				a_slot_states[i_slot] = 0;

				// mark slot as open
				a_slots_open.push(i_slot);

				// number of slots drained
				c_drained += 1;
			}
		}

		return c_drained;
	}


	function Scanner$attach_readable(k_self) {
		let ds_input = k_self._ds_input;
		let nl_workers = k_self._nl_workers;
		let at32_indicators = k_self._at32_indicators;

		// each time the input stream emits readable (this switches to paused mode)
		ds_input.on('readable', () => {
			k_self._tick();
		});

		// no workers
		if(0 === nl_workers) {
			// override tick function
			k_self._tick = Scanner$_tick_master_only;

			// presume worker reports collected
			k_self._b_collected = true;

			// end
			ds_input.on('end', () => {
				// final chunk
				let s_final = k_self._d_string_decoder.end();

				// end writable side of content reader
				k_self._ds_reader.end(s_final);
			});
		}
		// yes workers
		else {
			// end
			ds_input.on('end', () => {
				// set indicator and notify
				at32_indicators[0] = -1;
				let c_notified = Atomics.notify(at32_indicators, 0);

				// reassign tick function
				k_self._tick = () => {};

				// final chunk
				let s_final = k_self._ab_prev.toString('utf8');

				// end writable side of content reader
				k_self._ds_reader.end(s_final);
			});
		}
	}

	// special tick function if no workers
	function Scanner$_tick_master_only() {
		let ds_input = this._ds_input;
		let ds_reader = this._ds_reader;
		let d_string_decoder = this._d_string_decoder;

		let ab_chunk;
		while(null !== (ab_chunk=ds_input.read())) {
			ds_reader.write(d_string_decoder.write(ab_chunk));
		}
	}


	class NQuads_Scanner extends stream.Readable {
		constructor(gc_scanner) {
			super();

			// worker and slot settings
			let nl_workers = this._nl_workers = (gc_scanner.threads || (NL_WORKERS_ADVISE+1)) - 1;
			this._n_slots_per_worker = gc_scanner.slots_per_worker || gc_scanner.slotsPerWorker || N_DEFAULT_SLOTS_PER_WORKER;

			// flags
			this._b_eofed = false;
			this._b_collected = false;

			// report count
			this._c_reports = 0;

			// list of workers
			this._a_workers = [];

			// queue of open slots
			this._a_slots_open = [];

			// slot states
			this._a_slot_states = [];

			// previous chunk fragment
			this._ab_prev = Buffer.allocUnsafe(0);

			// string decoder
			this._d_string_decoder = new StringDecoder();

			// open slot resolve
			this._f_resolve_open_slot = null;

			// reader ready resolve
			this._f_resolve_reader_ready = null;

			if(gc_scanner.error) this.on('error', gc_scanner.error);
			if(gc_scanner.update) this.on('update', gc_scanner.update);
			if(gc_scanner.report) this.once('report', gc_scanner.report);


			// semaphores
			this.b_ready_pipe = null;
			this.b_ready_reader = false;
			this.b_unpiped_self = false;

			// default preset config
			let g_preset = {};

			// preset given
			if(gc_scanner.preset) {
				let si_preset = gc_scanner.preset;

				// no such preset name
				if(!H_PRESET_TASKS[si_preset]) {
					throw new Error(`No such NQuads_Scanner preset named '${si_preset}'`);
				}

				// generate preset config
				g_preset = H_PRESET_TASKS[gc_scanner.preset]({
					...gc_scanner,

					// auto-populate format
					format: 'nq',
				});
			}

			// task config
			let g_task = {
				...g_preset,
				...(gc_scanner.task || {}),
				...gc_scanner,
			};

			// run function
			let sjx_run = this._sjx_run = g_task.run;

			// missing run function
			if('string' !== typeof sjx_run || !sjx_run) {
				throw new TypeError('Invalid \'.run\' property supplied to NQuads_Scanner constructor; must be a non-empty string.');
			}

			// try creating run function
			let f_run;
			try {
				// f_run = (new Function(`return (${sjx_run})`))();  // eslint-disable-line no-new-func
				f_run = run(`(${sjx_run})`);  // eslint-disable-line no-eval
			}
			catch(e_eval) {
				throw new Error(`Failed to evaluate the '.run' property supplied to NQuads_Scanner constructor as JavaScript code: """\n${sjx_run}"""\n${e_eval.stack || e_eval}`);
			}

			// reduce property supplied
			if(g_task.reduce) {
				let f_reduce = g_task.reduce;

				// invalid reduce property
				if('function' !== typeof f_reduce) {
					throw new TypeError('Invalid \'.reduce\' property supplied to NQuads_Scanner constructor; if present, it must be a function.');
				}

				// set reduce function
				this._f_reduce = f_reduce;

				// initial value also present
				if('undefined' !== typeof g_task.initial) {
					this._w_initial = g_task.initial;
				}
				// no initial value; set master as initial
				else {
					this._f_submit_master = w_value => this._w_reduced = w_value;
				}
			}
			// initial value present
			else if('undefined' !== typeof g_task.initial) {
				throw new TypeError('The \'.initial\' property was supplied to NQuads_Scanner constructor but you also need to specify a \'.reduce\' function.');
			}

			// user property
			let z_user = g_task.user;

			// callback function; save
			if('function' === typeof z_user) {
				this._f_spawn = z_user;
			}
			// other
			else {
				this._f_spawn = () => z_user;
			}

			// receive handler(s)
			let z_receive = g_task.receive;

			// receive function
			if('function' === typeof z_receive) {
				this._f_receive_update = this._f_receive_submit = z_receive;
			}
			// different handlers for update and submit events
			else if(z_receive) {
				// update handler supplied
				if(z_receive.update) {
					this._f_receive_update = z_receive.update;
				}

				// submit handler supplied
				if(z_receive.submit) {
					this._f_receive_submit = z_receive.submit;
				}
			}


			let k_self = this;

			// create content reader
			(async() => {
				let ds_reader = this._ds_reader = await f_run(reader, ...[
					// handle errors
					function err(z_what) {
						// proper error instance
						if(z_what instanceof Error) {
							// kill workers and handle error
							k_self._kill(z_what, 0);
						}
						// invalid error type
						else {
							// issue warning
							console.warn(`WARNING: Your code (or some library) on the main thread is throwing an object which is not an instance of Error. I am going to put it into an Error for you now, but please fix this. The object.toString() is: "${z_what}"`);

							// construct error
							let e_wrap = new Error(z_what+'');

							// kill workers and throw error
							k_self._kill(e_wrap, 0);
						}
					},

					// 'update' with some info
					function update(w_msg) {
						k_self._f_update(w_msg, 0);
					},

					// 'submit' results
					function submit(w_value) {
						k_self._f_submit_master(w_value);
					},

					// user data
					this._f_spawn(0),

					// not a worker
					false,
				]);

				// attach automatic error handler to kill workers
				ds_reader.on('error', (e_read) => {
					this._kill(e_read, 0);
				});

				// once main thread content reader has finished
				ds_reader.once('eof', () => {
					// all results collected from workers
					if(this._b_collected) {
						this._f_report(this._w_reduced);
					}
					// set flag that we eof'd
					else {
						this._b_eofed = true;
					}
				});

				// input has been imported
				if(this._b_ready_input) {
					Scanner$attach_readable(this);
				}
			})();

			// input given
			let g_input = gc_scanner.input;
			if(g_input) {
				// stream
				if(g_input.stream) {
					this.import(g_input.stream);
				}
				// string
				else if(g_input.string) {
					// ref input string
					let s_input = g_input.string;

					// cache its length
					let nl_input = s_input.length;

					// read position
					let i_read = 0;

					// import
					this.import(new stream.Readable({
						highWaterMark: 0x10000,

						_read() {
							// end of read range position
							let i_next = i_read + 0x10000;

							// reach end of string; push eof signal
							if(i_next >= nl_input) {
								this.push(null);
							}
							// still data
							else {
								// convert string to buffer
								this.push(Buffer.from(s_input.slice(i_read, i_next)));

								// update read position
								i_read = i_next;
							}
						},
					}));
				}
				// other
				else {
					throw new Error(`NQuads_Scanner: Invalid option supplied to '.input' property "${g_input}"`);
				}
			}
		}

		_kill(e_reason, i_thread) {
			// destroy callbacks
			this._f_report = this._f_update = this._kill = () => {};

			// kill all workers
			Promise.all(this._a_workers.map(d => d.terminate()))
				.then(() => queueMicrotask(() => {
					this.emit('error', e_reason, i_thread);
				}));
		}

		import(ds_input) {
			// input has already been imported
			if(this._b_ready_input) {
				throw new Error(`More than one input was imported to NQuads_Scanner; only a single input source can be imported and only once.`);
			}

			// mark input ready
			this._b_ready_input = true;

			// save input
			this._ds_input = ds_input;

			// byte size ofhigh water mark
			let nb_high_water_mark = this._nb_high_water_mark = Math.max(0x10000, ds_input.readableHighWaterMark);

			let nl_workers = this._nl_workers;

			let nl_slots = this._nl_slots = this._n_slots_per_worker * nl_workers;

			let nb_slot = this._nb_slot = 4 + nb_high_water_mark;

			let nl_indicators = 2;
			let nb_indicators = nl_indicators * 4;

			let nb_slot_owners = nl_slots * 1;
			let nb_region = (nb_indicators)  // indicators
			+ (nb_slot_owners)  // slot owners
			+ (nb_slot * nl_slots);  // slot data

			// create shared memory region
			let ab_share = new SharedArrayBuffer(nb_region);

			// indicators
			let at32_indicators = this._at32_indicators = new Int32Array(ab_share, 0, nl_indicators);

			// slot owner and data byte positions
			let ib_slots = 0 + nb_indicators;
			let ib_data = ib_slots + (nb_slot_owners);

			// slot owners
			let atu8_slot_owners = this._atu8_slot_owners = new Uint8Array(ab_share, ib_slots, nl_slots);

			// slot data
			let atu8_data = this._atu8_data = new Uint8Array(ab_share, ib_data);


			// initially, all slots are claimed by master thread
			for(let i_slot=0; i_slot<nl_slots; i_slot++) {
				// set slot owner to master thread
				atu8_slot_owners[i_slot] = 0;
// a_slot_owners_internal.push(XC_SLOT_OWNER_MASTER);

				// push open slot to queue
				this._a_slots_open.push(i_slot);

				// set initial slot state
				this._a_slot_states.push(0);
			}


			// spawn workers
			{
				let a_workers = this._a_workers;

				let g_worker_data = {
					sjx_run: this._sjx_run,
					// ab_share,
					nl_workers,
					nl_slots,
					nb_slot,
					at32_indicators,
					// nb_region,
					atu8_slot_owners,
					atu8_data,
				};

				// ref spawn (and then call without context)
				let f_spawn = this._f_spawn;

				// each worker
				for(let i_worker=1; i_worker<=nl_workers; i_worker++) {
					// spawn
					let d_worker = new master.Worker('./worker.js', {
						__dirname,

						workerData: {
							...g_worker_data,
							i_worker,
							w_user: f_spawn(i_worker),
						},

						// on message event
						message: Scanner$handle_worker_message(this, i_worker),

						// inherit resource limits from main
						resourceLimits: 'inherit',
					});

// d_worker.on('message', );

					// push to worker list
					a_workers.push(d_worker);
				}
			}

			// reader is ready; attach readable event listener
			if(this._b_ready_reader) {
				Scanner$attach_readable(this);
			}
		}

		_tick(b_softlock) {
			let at32_indicators = this._at32_indicators;

			// grab indicator
			let xc_indicator_reclaim = Atomics.load(at32_indicators, 1);

			// fill slots, return value indicates exitting due to slots being full
			let b_await_readable = Scanner$fill_slots(this);

			// drain slots
			let n_drained = Scanner$drain_slots(this);

			// need to explicitly recall tick
			if(!b_await_readable) {
				// something drained (or no workers)
				if(n_drained) {
					// retick, avoiding recursion
					queueMicrotask(() => {
						this._tick();
					});
				}
				else {
					// avoid recursion; use setImmediate (need event loop to process messages from worker)
					setImmediate(() => {
						// await change
						let s_status = Atomics.wait(at32_indicators, 1, xc_indicator_reclaim, 2000);

						// awaiting lock timed out
						if('timed-out' === s_status) {
							// this could be a softlock
							if(b_softlock) {
								console.warn(`WARNING: NQuads_Scanner main thread waited more than 2000ms for a response from one of its ${this._nl_workers} worker(s); now escaping potential softlock`);
							}

							// set indicator and notify
							at32_indicators[0] += 1;
							Atomics.notify(at32_indicators, 0);

							// tick next
							return this._tick(true);
						}
					// else if('not-equal' === s_status) {
					// 	log(`awaited indicator: ${s_status}; ${Atomics.load(at32_indicators, 1)}`);
// }

						// retick
						this._tick();
					});
				}
			}
		}
	}

	Object.assign(NQuads_Scanner.prototype, {
		// initial value
		_w_initial: [],

		// default reduce function
		_f_reduce: (a_out, w_value) => [...a_out, w_value],

		// update handler
		_f_update(w_report, i_thread) {
			if(!this.emit('update', w_report, i_thread)) {
				console.warn(`WARNING: NQuads_Scanner emitted an 'update' event but no listener function is attached`);
			}
		},

		// report handler
		_f_report(w_report) {
			if(!this.emit('report', w_report)) {
				console.warn(`WARNING: NQuads_Scanner emitted a 'report' event but no listener function is attached`);
			}

		// // emit end event
		// queueMicrotask(() => {
		// 	this.emit('end');
		// });
		},

		// receive handlers
		_f_receive_update: null,
		_f_receive_submit: null,

		// submit master
		_f_submit_master(w_report) {
			this._w_reduced = this._f_reduce(this._w_initial, w_report);
		},

		// spawn function
		_f_spawn: () => {},
	});



	module.exports = function(...a_args) {
		let g_config = {};

		// at least one argument
		if(a_args.length) {
			let z_arg_0 = a_args[0];

			// input given unspecified
			if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
				z_arg_0 = z_arg_0.input;
			}

			// string
			if('string' === typeof z_arg_0) {
				g_config.input = {string:z_arg_0};
			}
			// null
			else if(null === z_arg_0) {
				g_config.input = null;
			}
			// node stream
			else if('function' === typeof z_arg_0.setEncoding) {
				g_config.input = {stream:z_arg_0};
			}
			// whatwg stream
			else if('function' === typeof z_arg_0.pipeTo) {
				throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
			// g_config.input = {stream:z_arg_0};
			}
			// config struct
			else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
				g_config = z_arg_0;

				// more args; invalid
				if(a_args.length > 1) {
					throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
				}
			}
			// unknown
			else {
				throw new TypeError(`unexpected input type: ${z_arg_0}`);
			}

			// more args
			if(a_args.length > 1) {
				// copy onto struct
				Object.assign(g_config, a_args[1]);

				// more args
				if(a_args.length > 2) {
					throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
				}
			}
		}

		// create reader, return transform stream
		return (new NQuads_Scanner(g_config));
	};
})();

}).call(this)}).call(this,require("buffer").Buffer,require("timers").setImmediate)
},{"./task-presets.js":3,"@graphy/content.nq.read":1,"@graphy/core.iso.stream":21,"@graphy/core.iso.threads":22,"buffer":74,"child_process":73,"events":118,"os":166,"path":172,"string_decoder":76,"timers":228}],3:[function(require,module,exports){

module.exports = {
	count: gc_scan => ({
		reduce: (c_quads_a, c_quads_b) => c_quads_a + c_quads_b,

		run: /* syntax: js */ `
			(read, err, update, submit) => {
				let c_quads = 0;

				return read({
					relax: ${gc_scan.relax? 'true': 'false'},

					data() {
						c_quads += 1;
					},

					error(e_read) {
						err(e_read);
					},

					eof() {
						submit(c_quads);
					},
				});
			}
		`,
	}),

	// tree: gc_scan => ({
	// 	// receive: abs_dump => dataset.fromArrayBuffer(abs_dump),
// 	// receive: h_import => dataset.from(h_import),

// 	reduce: (k_tree_a, k_tree_b) => k_tree_a.union(k_tree_b),

	// 	run: /* syntax: js */ `
	// 		(read, err, update, submit, user={}, isWorker=false) => {
// 			let k_dataset = require('@graphy/memory.dataset.fast')();

	// 			return read({
	// 				relax: ${gc_scan.relax? 'true': 'false'},

	// 				pipe: k_dataset.on('finish', () => {
	// 					if(isWorker) {
	// 						// let abs_dump = k_dataset.dump({shared:true});
	// 						// submit(abs_dump, [abs_dump]);
	// 						submit(k_dataset.export());
	// 					}
	// 					else {
	// 						submit(k_dataset);
	// 					}
	// 				}),

	// 				error(e_read) {
	// 					err(e_read);
	// 				},
	// 			});
	// 		}
	// 	`,

	// 	report(k_tree) {
	// 		console.log(k_tree.size);
	// 	},
	// }),

	scribe: gc_scan => ({
		run: /* syntax: js */ `
			async(read, err, update, submit, user={}, isWorker=false) => {
				// prep buffer string
				let s_buffer = '';

				// create scriber
				let ds_scriber = require('@graphy/content.ttl.scribe')({
					prefixes: user.prefixes,

					// capture scriber output
					data(s_write) {
						s_buffer += s_write;
					},

					// once scriber ends
					end() {
						submit();
					},
				});

				// create reader
				let ds_reader = read({
					relax: ${gc_scan.relax? 'true': 'false'},

					// error while reading
					error(e_read) {
						err(e_read);
					},
				});

				// worker
				if(isWorker) {
					// on reader progress
					ds_reader.on('progress', () => {
						// buffer is not empty
						if(s_buffer) {
							// clean scriber output buffer before sending
							ds_scriber.rinse();

							// convert string -> Buffer -> ArrayBuffer
							let db_chunk = Buffer.from(s_buffer);
							let ab_chunk = db_chunk.buffer.slice(db_chunk.byteOffset, db_chunk.byteOffset+db_chunk.byteLength);

							// send to master
							update(ab_chunk, [ab_chunk]);

							// reset buffer
							s_buffer = '';
						}
					});
				}
				// master
				else {
					// on reader progress
					ds_reader.on('progress', () => {
						// scriber output buffer is not empty
						if(s_buffer) {
							// clean scriber output buffer before sending
							ds_scriber.rinse();

							// empty buffer
							update(s_buffer);

							// reset buffer
							s_buffer = '';
						}
					});
				}

				// pipe reader to scriber
				ds_reader.pipe(ds_scriber);

				// return reader instance
				return ds_reader;
			}
		`,
	}),

	ndjson: gc_scan => ({
		run: /* syntax: js */ `
			async(read, err, update, submit, user={}, isWorker=false) => {
				// prep buffer string
				let s_buffer = '';

				// create reader
				let ds_reader = read({
					relax: ${gc_scan.relax? 'true': 'false'},

					error(e_read) {
						err(e_read);
					},

					data(g_quad) {
						s_buffer += JSON.stringify(g_quad.isolate())+'\\n';
					},

					eof() {
						submit();
					},
				});

				// worker
				if(isWorker) {
					// on reader progress
					ds_reader.on('progress', () => {
						// buffer is not empty
						if(s_buffer) {
							// convert string -> Buffer -> ArrayBuffer
							let db_chunk = Buffer.from(s_buffer);
							let ab_chunk = db_chunk.buffer.slice(db_chunk.byteOffset, db_chunk.byteOffset+db_chunk.byteLength);

							// send to master
							update(ab_chunk, [ab_chunk]);

							// reset buffer
							s_buffer = '';
						}
					});
				}
				// master
				else {
					// on reader progress
					ds_reader.on('progress', () => {
						// scriber output buffer is not empty
						if(s_buffer) {
							// empty buffer
							update(s_buffer);

							// reset buffer
							s_buffer = '';
						}
					});
				}

				// return reader instance
				return ds_reader;
			}
		`,
	}),

	// 'distinct-quads': gc_scan => ({
	// 	reduce: (k_dataset_a, k_dataset_b) => k_dataset_a.union(k_dataset_b),

	// 	run: /* syntax: js */ `
	// 		(read, err, update, submit, user) => {
	// 			const dataset = require('@graphy/memory.dataset.fast');
	// 			let k_dataset = dataset();

	// 			k_dataset.on('finish', () => {
	// 				submit(k_dataset.export());
// 			});

	// 			let ds_reader = read({
	// 				relax: ${gc_scan.relax? 'true': 'false'},
// 			});

// 			ds_reader.pipe(k_dataset);

	// 			return ds_reader;
	// 		}
	// 	`,
	// }),
};

},{}],4:[function(require,module,exports){



const Scribable = require('@graphy/core.class.scribable');

const factory = require('@graphy/core.data.factory');
const {
	c1_to_nt,
	clean_iri,
} = factory;


function verbose_s(yt_subject) {
	if('NamedNode' === yt_subject.termType) {
		return '<'+clean_iri(yt_subject.value)+'>';
	}
	else {
		return '_:'+yt_subject.value;
	}
}


function verbose_g(yt_subject) {
	switch(yt_subject.termType) {
		// default graph
		case 'DefaultGraph': return '';

		// named node
		case 'NamedNode': return '<'+clean_iri(yt_subject.value)+'>';

		// blank node
		default: return '_:'+yt_subject.value;
	}
}


const verbose_p = yt_predicate => '<'+clean_iri(yt_predicate.value)+'>';

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function verbose_o(yt_object) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return '<'+clean_iri(yt_object.value)+'>';

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^<'+clean_iri(yt_object.datatype.value)+'>';
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}


class NQuads_Scriber extends Scribable {
	constructor(gc_scriber={}) {
		super(gc_scriber);

		// prefixes given
		if(gc_scriber.prefixes) {
			// update prefixes
			this._update_prefixes(gc_scriber.prefixes);
		}
	}

	_serialize_c4r(hc4r_quads) {
		let h_prefixes = this._h_prefixes;
		let sv_build = '';

		// each graph in quads hash
		for(let sc1_graph in hc4r_quads) {
			// quick convert graph from concise term to verbose
			let sv1_graph = c1_to_nt(sc1_graph, h_prefixes, true);

			// graph string
			let sv_graph = sv1_graph? ' '+sv1_graph: '';

			// each subject
			let hc3r_triples = hc4r_quads[sc1_graph];
			for(let sc1_subject in hc3r_triples) {
				// quick convert subject from concise term to verbose
				let sv1_subject = c1_to_nt(sc1_subject, h_prefixes, true);

				// not a term; skip
				if(!sv1_subject) continue;

				// each predicate
				let hc2r_pairs = hc3r_triples[sc1_subject];
				for(let sc1_predicate in hc2r_pairs) {
					// quick convert predicate from concise term to verbose
					let sv1_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);

					// not a term; skip
					if(!sv1_predicate) continue;

					// opening string
					let sv_opening = sv1_subject+' '+sv1_predicate+' ';

					// each object
					for(let sc1_object of hc2r_pairs[sc1_predicate]) {
						// quick convert object from concise term to verbose
						let sv1_object = c1_to_nt(sc1_object, h_prefixes, true);

						// not a term; skip
						if(!sv1_object) continue;

						sv_build += sv_opening+sv1_object+sv_graph+' .\n';
					}
				}
			}
		}

		return sv_build;
	}

	_serialize_c3r(hc3r_triples) {
		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// string building
		let sv_build = '';

		for(let sc1_subject in hc3r_triples) {
			// quick convert subject from concise term to verbose
			let sv1_subject = c1_to_nt(sc1_subject, h_prefixes, true);

			// not a term; skip
			if(!sv1_subject) continue;

			// each predicate
			let hc2r_pairs = hc3r_triples[sc1_subject];
			for(let sc1_predicate in hc2r_pairs) {
				// quick convert predicate from concise term to verbose
				let sv1_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);

				// not a term; skip
				if(!sv1_predicate) continue;

				// opening string
				let sv_opening = sv1_subject+' '+sv1_predicate+' ';

				// each object
				for(let sc1_object of hc2r_pairs[sc1_predicate]) {
					// quick convert object from concise term to verbose
					let sv1_object = c1_to_nt(sc1_object, h_prefixes, true);

					// not a term; skip
					if(!sv1_object) continue;

					sv_build += sv_opening+sv1_object+' .\n';
				}
			}
		}

		return sv_build;
	}

	_serialize_quad(g_quad) {
		let {
			subject: yt_subject,
			predicate: yt_predicate,
			object: yt_object,
			graph: yt_graph,
		} = g_quad;

		// write quad
		this._s_push += verbose_s(yt_subject)
			+' '+verbose_p(yt_predicate)
			+' '+verbose_o(yt_object)
			+' '+verbose_g(yt_graph)
			+' .\n';
	}
}

Object.assign(NQuads_Scriber.prototype, {
	_serialize_comment: Scribable.prototype._serialize_hash_comment,
});

module.exports = function(g_config) {
	return new NQuads_Scriber(g_config);
};

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],5:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Writable = require('@graphy/core.class.writable');

const {
	c1_to_nt,
	clean_iri,
} = factory;

const N_MAX_STRING_BUFFER = 1 << 12;


function verbose_s(yt_subject) {
	if('NamedNode' === yt_subject.termType) {
		return '<'+clean_iri(yt_subject.value)+'>';
	}
	else {
		return '_:'+yt_subject.value;
	}
}


function verbose_g(yt_subject) {
	switch(yt_subject.termType) {
		// default graph
		case 'DefaultGraph': return '';

		// named node
		case 'NamedNode': return '<'+clean_iri(yt_subject.value)+'>';

		// blank node
		default: return '_:'+yt_subject.value;
	}
}


const verbose_p = yt_predicate => '<'+clean_iri(yt_predicate.value)+'>';

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function verbose_o(yt_object) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return '<'+clean_iri(yt_object.value)+'>';

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^<'+clean_iri(yt_object.datatype.value)+'>';
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}

class NQuads_Writer extends Writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			style: gc_style=null,
		} = gc_writer;

		Object.assign(this, {
			_xc_state: 2,
		});
	}



	// serialize c3 hash
	_serialize_c3(hc3_triples) {
		let {
			_h_prefixes: h_prefixes,
		} = this;
		let s_write = '';

		// post component
		let st_post = ' .\n';

		// subject exit listener
		let f_exit_subject = null;
		// each subject
		for(let sc1_subject in hc3_triples) {
			// directive; serialize it
			if('`' === sc1_subject[0]) {
				let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
				// write data
				if(g_apply.write) s_write += g_apply.write;
				// save exit listener
				if(g_apply.exit) f_exit_subject = g_apply.exit;
				continue;
			}
			// subject-pre component
			let st_pre = c1_to_nt(sc1_subject, h_prefixes, true)+' ';
			// pair indent & terminator
			let s_indent_pairs = '';
			let s_term_pairs = '';
			// ref pairs
			let hc2_pairs = hc3_triples[sc1_subject];
			// predicate exit listener
			let f_exit_predicate = null;
			// each predicate
			for(let sc1_predicate in hc2_pairs) {
				// directive; serialize it
				if('`' === sc1_predicate[0]) {
					let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// write data
					if(g_apply.write) s_write += g_apply.write;
					// save exit listener
					if(g_apply.exit) f_exit_predicate = g_apply.exit;
					continue;
				}
				// predicate component
				let st_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);
				// ref objects
				let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
				s_write += this._encode_objects(st_pre+st_predicate+' ', z_objects, st_post);
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
			}
			// call exit predicate listener
			if(f_exit_predicate) f_exit_predicate();
		}
		// call exit subject listener
		if(f_exit_subject) f_exit_subject();

		return s_write;
	}


	// serialize c4 hash
	_serialize_c4(hc4_quads) {
		let {
			_h_prefixes: h_prefixes,
		} = this;
		let s_write = '';
		// graph exit listener
		let f_exit_graph = null;

		// each graph
		for(let sc1_graph in hc4_quads) {
			// directive
			if('`' === sc1_graph[0]) {
				let g_apply = this._apply_directive(sc1_graph, hc4_quads[sc1_graph]);

				// write data
				if(g_apply.write) s_write += g_apply.write;

				// save exit listener
				if(g_apply.exit) f_exit_graph = g_apply.exit;
				continue;
			}

			// graph component
			let kt_graph = factory.c1(sc1_graph, h_prefixes);

			// post component
			let st_post = (kt_graph.isDefaultGraph? '': ' '+kt_graph.verbose())+' .\n';

			// ref triples
			let hc3_triples = hc4_quads[sc1_graph];

			// subject exit listener
			let f_exit_subject = null;
			// each subject
			for(let sc1_subject in hc3_triples) {
				// directive; serialize it
				if('`' === sc1_subject[0]) {
					let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
					// write data
					if(g_apply.write) s_write += g_apply.write;
					// save exit listener
					if(g_apply.exit) f_exit_subject = g_apply.exit;
					continue;
				}
				// subject-pre component
				let st_pre = c1_to_nt(sc1_subject, h_prefixes, true)+' ';
				// pair indent & terminator
				let s_indent_pairs = '';
				let s_term_pairs = '';
				// ref pairs
				let hc2_pairs = hc3_triples[sc1_subject];
				// predicate exit listener
				let f_exit_predicate = null;
				// each predicate
				for(let sc1_predicate in hc2_pairs) {
					// directive; serialize it
					if('`' === sc1_predicate[0]) {
						let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
						// write data
						if(g_apply.write) s_write += g_apply.write;
						// save exit listener
						if(g_apply.exit) f_exit_predicate = g_apply.exit;
						continue;
					}
					// predicate component
					let st_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);
					// ref objects
					let z_objects = hc2_pairs[sc1_predicate];
					// serialize objects
					s_write += this._encode_objects(st_pre+st_predicate+' ', z_objects, st_post);
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
				}
				// call exit predicate listener
				if(f_exit_predicate) f_exit_predicate();
			}
			// call exit subject listener
			if(f_exit_subject) f_exit_subject();
		}

		// call exit graph listener
		if(f_exit_graph) f_exit_graph();

		return s_write;
	}


	// write objects
	_encode_objects(s_pre, z_objects, s_post, n_nest_level=1) {
		let {
			_h_prefixes: h_prefixes,
			_hm_coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return s_pre+factory.c1(z_objects, h_prefixes).verbose()+s_post;

			// numeric type
			case 'number': return s_pre+factory.number(z_objects).verbose()+s_post;

			// boolean type
			case 'boolean': return s_pre+factory.boolean(z_objects).verbose()+s_post;

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; write list
						if(Array.isArray(z_item)) {
							// transcode list
							let hc2_list = this._transcode_list(z_item);

							// serialize transcoded list
							s_write += this._encode_objects(s_pre, hc2_list, s_post, n_nest_level);
						}
						// non-array; recurse on item
						else {
							s_write += this._encode_objects(s_pre, z_item, s_post, n_nest_level);
						}
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// new blank node
					let st_blank = factory.blankNode();

					// start with incoming triple
					let s_write = s_pre+st_blank+s_post;

					// object exit listener
					let f_exit_object = null;

					// each pair
					for(let sc1_predicate in z_objects) {
						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							let g_apply = this._apply_directive(sc1_predicate, z_objects[sc1_predicate]);

							// write data
							if(g_apply.write) s_write += g_apply.write;

							// save exit listener
							if(g_apply.exit) f_exit_object = g_apply.exit;
							continue;
						}

						// pre-string for nested triples
						let s_pre_nest = st_blank+' '+c1_to_nt(sc1_predicate, h_prefixes, true)+' ';

						// recurse
						s_write += this._encode_objects(s_pre_nest, z_objects[sc1_predicate], s_post, n_nest_level+1);
					}

					// call exit object listener
					if(f_exit_object) f_exit_object();

					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return s_pre+kt_converted.verbose(h_prefixes)+s_post;
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return s_pre+z_objects.verbose()+s_post;
				}
				// RDFJS term
				else if(z_objects.termType) {
					return s_pre+factory.from.term(z_objects).verbose()+s_post;
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// rdfjs quad
	_serialize_quad(g_quad) {
		// serialize quad
		this._s_push += (2 !== this._xc_state? '\n': '')
			+verbose_s(g_quad.subject)
			+' '+verbose_p(g_quad.predicate)
			+' '+verbose_o(g_quad.object)
			+('DefaultGraph' === g_quad.graph.termType? '': ' '+verbose_g(g_quad.graph))
			+' .\n';

		// update state
		this._xc_state = 2;
	}
}

Object.assign(NQuads_Writer.prototype, {
	_serialize_c3r: NQuads_Writer.prototype._serialize_c3,
	_serialize_c4r: NQuads_Writer.prototype._serialize_c4,
	_serialize_comment: Writable.prototype._serialize_hash_comment,
});

module.exports = function(gc_writer) {
	return new NQuads_Writer(gc_writer);
};

},{"@graphy/core.class.writable":19,"@graphy/core.data.factory":20}],6:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const stream = require('@graphy/core.iso.stream');
const factory = require('@graphy/core.data.factory');

const RT_ABSOLUTE_IRI_VALID = /^[a-z][a-z0-9+\-.]*:(?:[^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_ABSOLUTE_IRI_ESCAPELESS_VALID = /^[a-z][a-z0-9+\-.]*:[^\0-\x20<>"{}|^`]*$/;
const RT_NAMED_NODE_VALID = /^([^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_NAMED_NODE_ESCAPELESS_VALID = /^([^\0-\x20<>"{}|^`])*$/;

const R_UNICODE_ANY = /\\u([0-9A-Fa-f]{4})|\\U([0-9A-Fa-f]{8})/g;

const F_REPLACE_UNICODE_ANY = 	(s_, s_4, s_8) => String.fromCodePoint(parseInt(s_4 || s_8, 16));


const R_CLEAN = /\s*(?:#[^\n]*\n\s*)*\s*/y;
const R_CLEAN_COMMENTS = /\s*(#[^\n]*\n\s*)*\s*/y;
const RT_HAS_ESCAPES = /[\\]/;
const R_EOL = /[^\n]+\n/y;

// eslint-disable-next-line no-misleading-character-class
const RT_BLANK_NODE_LABEL_VALID = /^(?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_0-9])(?:(?:[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.])*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?$/u;
const RT_LANGUAGE_VALID = /^[a-z]+(-[a-z0-9]+)*$/;

const R_WS = /\s*/y;
const R_HWS = /[ \t]*/y;
const R_LANGTAG = /@([A-Za-z]+(?:-[A-Za-z0-9-]+)*)(?:\s+|(?=[.,;\])#]))/y;

const R_IRIREF = /<([^>]*)>\s*/y;



const F_REPLACE_STRLIT_CONTENTS = (s_, s_whitespace, s_auto, s_4, s_8, s_invalid) => {
	if(s_whitespace) {
		switch(s_whitespace) {
			case 't': return '\t';
			case 'n': return '\n';
			case 'r': return '\r';
			case 'f': return '\f';
			case 'b': return '\b';
			default: {
				console.assert(`bad regex escape char mapping: '${s_whitespace}'`);
			}
		}
	}
	else if(s_auto) {
		return s_auto;
	}
	else if(s_4) {
		return String.fromCodePoint(parseInt(s_4, 16));
	}
	else if(s_8) {
		return String.fromCodePoint(parseInt(s_8, 16));
	}
	else if(s_invalid) {
		// pointless escape
		if('\\' === s_invalid[0]) {
				// // relaxed
				// return s_invalid[1];
			// if relaxed then return s_invalid, otherwise throw:
			throw new Error(`expected string_literal but invalid escape sequence within contents: '${s_invalid}'. failed to parse a valid token`);
		}
		// bad character
		else {
			throw new Error(`expected string_literal but invalid whitespace character within contents: ${JSON.stringify(s_invalid)}. failed to parse a valid token`);
		}
	}
	else {
		console.assert(`unexpected no match branch in escape sequence replace callback`);
	}
};


const R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\.))/g;
const R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_short_hard = s_literal => s_literal
	.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_short_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};

// lookbehind regexes
const [
	R_STRLIT_ESCAPE_INCOMPLETE,
	R_STRLIT_SHORT_DOUBLE_TERM,
] = (() => {
	function RegExp_$lookbehind_polyfill(s_input) {
		let m_match = RegExp.prototype.exec.call(this, s_input);

		if(m_match) {
			let i_start = m_match[0].length - m_match[1].length;
			m_match.index += i_start;
			m_match[0] = m_match[0].slice(i_start);
		}

		return m_match;
	}
	let mk_lookbehind_regex = (() => {
		try {
			new RegExp('(?<!h)i');  // eslint-disable-line no-new
		}
		catch(e_compile) {
			return (f_lookbehind, r_polyfill, f_polyfill) => {
				r_polyfill.exec = f_polyfill;
				return r_polyfill;
			};
		}
		return f_lookbehind => f_lookbehind();
	})();
	return [
		// R_STRLIT_ESCAPE_INCOMPLETE
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\\\\(|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7})$'),
			/^(?:(?:[^\\]|\\.)*)(\\(?:|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7}))$/,
			function RegExp_$lookbehind_polyfill_n(s_input) {
				let m_match = RegExp.prototype.exec.call(this, s_input);
				if(m_match) {
					m_match.index += m_match[0].length - m_match[1].length;
				}

				return m_match;
			},
		),
		// R_STRLIT_SHORT_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"\\s*', 'g'),
			/(?:[^\\"]|\\.)*("\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

	];
})();



const R_TRIPLE_ESCAPELESS_SP = /(?:<([^\\>]*)>|_:([^\x20\t<]+))[\x20\t]*<([^\\>]*)>[\x20\t]*(?:(?:(<[^\\>]*)>|_:([^\x20\t<]+))[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+|"([^"\\]*)(?:(")(?:\^\^<([^\\>]*)>|@([^\x20\t.]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+)?)/y;
const R_TRIPLE = /(?:<([^>]*)>|_:([^\x20\t<]+))[\x20\t]*<([^>]*)>[\x20\t]*(?:(?:(<[^>]*)>|_:([^\x20\t<]+))[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+|"((?:[^"\\]|\\.)*)(?:(")(?:\^\^<([^>]*)>|@([^\x20\t.]+)|)[\x20\t]*\.\s*(#[^\n]*\n\s*|\n\s*)+)?)/y;



class NTriples_Reader extends stream.Transform {
	constructor(g_impls) {
		super({
			// do not decode strings into buffers
			decodeStrings: false,

			// accept strings as input on writable side
			writableObjectMode: false,

			// output quad objects on readable side
			readableObjectMode: true,

			// implementations
			flush: g_impls.flush,
			transform: g_impls.transform,
		});

		// when the writable side is piped into
		this.on('pipe', (ds_input) => {
			this._ds_input = ds_input;

			// input stream has encoding option; ensure stream encoding is utf8
			if('function' === typeof ds_input.setEncoding) {
				ds_input.setEncoding('utf8');
			}
		});
	}

	// intercept pipe
	pipe(ds_out) {
		let ds_dst = ds_out;

		// non-object mode
		if(!ds_dst._writableState.objectMode) {
			// transform to JSON
			ds_out = stream.quads_to_json();
		}
		// yet object mode and graphy writable
		else if(ds_out.isGraphyWritable) {
			// transform to quad-stream
			ds_out = stream.quads_to_writable();
		}

		// interim stream created
		if(ds_out !== ds_dst) {
			// forward output to super
			super.pipe(ds_out);

			// pipe outpu to destination
			return ds_out.pipe(ds_dst);
		}
		// forward as-is to super
		else {
			return super.pipe(ds_dst);
		}
	}
}

class Reader {
	constructor(g_config) {
		let {
			// input medium
			input: g_input=null,

			// relax validation
			relax: b_relax=false,

			// debug
			debug: b_debug=false,
		} = g_config;

		// allow relative iris flag
		let b_allow_relative_iris = g_config.allow_relative_iris || g_config.allowRelativeIRIs || g_config.allowRelativeIris || false;

		// adopt factory
		let dc_factory = this._dc_factory = factory.adopt(g_config.dataFactory || g_config.data_factory || factory.unfiltered);

		let f_quad = this._f_quad = dc_factory.quad;

		// fields
		Object.assign(this, {
			// string buffer, accept left-over string from previous data chunk
			s: g_config.prepend || '',

			// string buffer length
			n: 0,

			_b_debug: b_debug,

			_b_relax: b_relax,

			_b_destroyed: false,

			_b_trim_start: true,

			_f_state: this.statement,

			_kt_subject: null,
			_kt_predicate: null,

			_s_literal: '',
		});

		this._kt_default_graph = dc_factory.defaultGraph();
		this._kt_rdfs_lang_string = dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString');

		// clean regex
		let r_clean = this._r_clean = R_CLEAN;

		if(g_config.relaxed) {
			console.warn((new Error(`no such option 'relaxed'; did you mean 'relax' ?`)).stack.replace(/^Error:/, 'Warning:'));
		}
		if('validate' in g_config) {
			console.warn((new Error(`option 'validate' has been removed and validation is now on by default. Use 'relax' option if you wish to disable validation.`)).stack.replace(/^Error:/, 'Warning:'));
		}

		let namedNode = dc_factory.namedNode;
		let blankNode = dc_factory.blankNode;
		let languagedLiteral = dc_factory.languagedLiteral;

		// test for valid named node
		let rt_named_node_valid = b_allow_relative_iris? RT_NAMED_NODE_VALID: RT_ABSOLUTE_IRI_VALID;

		// test for valid named node escapeless
		let rt_named_node_valid_escapeless = b_allow_relative_iris? RT_NAMED_NODE_ESCAPELESS_VALID: RT_ABSOLUTE_IRI_ESCAPELESS_VALID;

		// validation
		let k_self = this;
		Object.assign(this, !b_relax
			? {
				create_named_node(p_iri) {
					if(!rt_named_node_valid.test(p_iri)) return k_self._error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				create_named_node_escapeless(p_iri) {
					if(!rt_named_node_valid_escapeless.test(p_iri)) return k_self._error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				create_blank_node(s_label) {
					if(!RT_BLANK_NODE_LABEL_VALID.test(s_label)) return k_self._error(`Invalid blank node label: "${s_label}"`);
					return blankNode(s_label);
				},

				create_languaged_literal(s_contents, s_language) {
					if(!RT_LANGUAGE_VALID.test(s_language)) {
						return k_self._error(`Invalid literal language tag: ${s_language}`);
					}

					return languagedLiteral(s_contents, s_language);
				},
			}
			: {
				create_named_node: namedNode,

				create_named_node_escapeless: namedNode,

				create_blank_node: blankNode,

				create_languaged_literal: languagedLiteral,
			});

		// transform stream
		let ds_transform;

		// whether or not data has been received before
		let b_init = false;

		// create transform
		ds_transform = this.transform = new NTriples_Reader({
			// on data event
			transform: (s_chunk, s_encoding, fk_chunk) => {
				// first transform
				if(!b_init) {
					// notify that data will begin
					ds_transform.emit('ready');

					// do not emit 'ready' event again
					b_init = false;
				}

				// concatenate current chunk to previous chunk
				let s = this.s += s_chunk;

				// remove whitespace & comments from beginning
				if(this._b_trim_start) {
					r_clean.lastIndex = 0;
					let m_clean = r_clean.exec(s);
					if(this.emit_comments) {
						this.emit_comments(m_clean[1]);
					}

					// update index and prepare to match statement
					this.i = r_clean.lastIndex;
				}
				// do not remove whitespace; reset index
				else {
					this.i = 0;
				}

				// cache chunk length
				this.n = s.length;

				// resume parsing
				try {
					this.parse(true);
				}
				// read error occurred; emit and destroy stream
				catch(e_read) {
					return ds_transform.destroy(e_read);
				}

				// emit progress event updates
				ds_transform.emit('progress', s_chunk.length);

				// done transforming this chunk
				fk_chunk();
			},

			// once there's no more data to consume, invoke eof
			flush: (fk_flush) => {
				// there is still unparsed data
				if(this.s.length) {
					// append newline to end so we can match token
					this.s += '\n';

					// remove whitespace & comments from beginning
					if(this._b_trim_start) {
						r_clean.lastIndex = 0;
						let m_clean = r_clean.exec(this.s);
						if(this.emit_comments) {
							this.emit_comments(m_clean[1]);
						}

						// update index and prepare to match statement
						this.i = r_clean.lastIndex;
					}
					// do not remove whitespace; reset index
					else {
						this.i = 0;
					}

					// parse
					try {
						this.parse();
					}
					// read error occurred; pass to flush errback and exit method
					catch(e_read) {
						// destroying during flush means overriding push
						return ds_transform.demolish(e_read);
					}

					// still unparsed characters; pass to flush errback and exit method
					if(this.s.length) {
						return ds_transform.demolish(new Error(`parsing error occurred in state: statement\n  ${this.s.substr(0, 50)}\n  ^ starting here`));
					}
				}

				// invalid state
				if(this._f_state !== this.statement) {
					return ds_transform.demolish(new Error(`parsing error occurred in state: ${this._f_state.name}\n  ${this.s.substr(0, 50)}\n  ^ starting here`));
				}

				// make buffer's alloc eligible for gc
				this.s = null;

				// final progress update: no additional bytes were read
				ds_transform.emit('progress', 0);

				// call end event listener
				ds_transform.emit('eof');

				// done flushing, close read stream
				fk_flush();
			},
		});

		// destroy
		ds_transform._destroy = (...a_args) => {
			this.destroy(...a_args);
		};

		// data quad
		this._f_data_quad = (kt_subject, kt_predicate, kt_object, kt_graph) => ds_transform.push(f_quad(kt_subject, kt_predicate, kt_object, kt_graph));

		// new listener added
		ds_transform.on('newListener', (s_event) => {
			// comment
			if('comment' === s_event) {
				r_clean = R_CLEAN_COMMENTS;
				this.emit_comments = (s_captured) => {
					if(!s_captured) return;
					let a_comments = s_captured.slice(1).replace(/\n\s+$/, '').split(/\n+\s*#/g);

					for(let s_comment of a_comments) {
						ds_transform.emit('comment', s_comment);
					}
				};
			}
		});

		// bind events to transform stream
		this.bind(g_config);

		// input given
		if(g_input) {
			// input is stream
			if(g_input.stream) {
				let ds_input = g_input.stream;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_input.pipe(ds_transform);
				});
			}
			// string
			else if('string' === typeof g_input.string) {
				let s_input = g_input.string;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_transform.end(s_input, 'utf8');
				});
			}
			// invalid arg
			else {
				throw new TypeError(`Invalid argument for input parameter: ${'object' === typeof g_input? JSON.stringify(g_input): g_input}`);
			}
		}

		ds_transform._graphy_reader = this;
	}

	_error(s_message) {
		this._b_destroyed = true;
		throw new Error(s_message);
	}



	bind(g_config) {
		let ds_transform = this.transform;
		if(g_config.error) ds_transform.on('error', g_config.error);
		if(g_config.comment) ds_transform.on('comment', g_config.comment);
		if(g_config.read) ds_transform.once('read', g_config.read);
		if(g_config.progress) ds_transform.on('progress', g_config.progress);
		if(g_config.eof) ds_transform.once('eof', g_config.eof);
		if(g_config.end) ds_transform.once('end', g_config.end);
		if(g_config.finish) ds_transform.once('finish', g_config.finish);
		if(g_config.data) ds_transform.on('data', g_config.data);
	}

	// begin parsing, keep applying until no more stack bail-outs
	parse() {
		let f_sync = this._f_state();
		while('function' === typeof f_sync) {
			f_sync = f_sync.apply(this);
		}
	}

	statement() {
		let s = this.s;
		let n = this.n;
		let i = this.i;
		let f_data_quad = this._f_data_quad;
		let create_named_node = this.create_named_node;
		let create_named_node_escapeless = this.create_named_node_escapeless;
		let create_languaged_literal = this.create_languaged_literal;
		let create_blank_node = this.create_blank_node;
		let simpleLiteral = this._dc_factory.simpleLiteral;
		let datatypedLiteral = this._dc_factory.datatypedLiteral;
		let kt_default_graph = this._kt_default_graph;

		// match triples/quads
		for(;;) {
			// prepare sticky regex index
			R_TRIPLE_ESCAPELESS_SP.lastIndex = i;
			// execute regex
			let m_statement_e_sp = R_TRIPLE_ESCAPELESS_SP.exec(s);

			// regex was a match
			if(m_statement_e_sp) {
				// advance index
				i = R_TRIPLE_ESCAPELESS_SP.lastIndex;

				// prep object term
				let kt_object;

				// object term type is named node
				if(m_statement_e_sp[4]) {
					let p_object = m_statement_e_sp[4].slice(1);
					kt_object = create_named_node_escapeless(p_object);
				}
				// object term type is blank node
				else if(m_statement_e_sp[5]) {
					kt_object = create_blank_node(m_statement_e_sp[5]);
				}
				// object term type is literal
				else {
					// contents
					let s_contents = m_statement_e_sp[7];
					// string terminator
					if(m_statement_e_sp[8]) {
						// datatype is present
						if(m_statement_e_sp[9]) {
							// create datatype term
							let kt_datatype = this.create_named_node_escapeless(m_statement_e_sp[9]);
							// create object term
							kt_object = datatypedLiteral(s_contents, kt_datatype);
						}
						// language tag is present
						else if(m_statement_e_sp[10]) {
							// normalize language
							let s_language = m_statement_e_sp[10].toLowerCase();
							// create object term
							kt_object = create_languaged_literal(s_contents, s_language);
						}
						// simple literal
						else {
							kt_object = simpleLiteral(s_contents);
						}
					}
					// no string terminator
					else {
						// save contents
						this._s_literal = s_contents;
						// update index
						this.i = i;
						// save subject
						{
							let s_subject = m_statement_e_sp[1];
							// named node
							if(s_subject || 'string' === typeof s_subject) {
								this._kt_subject = create_named_node_escapeless(s_subject);
							}
							// blank node
							else {
								this._kt_subject = create_blank_node(m_statement_e_sp[2]);
							}
						}
						// save predicate
						this._kt_predicate = create_named_node_escapeless(m_statement_e_sp[3]);
						// parse contents
						let z_bail = this.strlit_contents();
						// bail out of stack
						if(z_bail && this.statement !== z_bail) {
							return z_bail;
						}
						// statement completed
						else {
							// clean
							let r_clean = this._r_clean;
							r_clean.lastIndex = this.i;
							let m_clean = r_clean.exec(s);
							if(this.emit_comments) {
								this.emit_comments(m_clean[1]);
							}
							// update local index and prepare to match next statement
							i = r_clean.lastIndex;
							// resume
							continue;
						}
					}
				}

				let kt_subject;
				{
					let s_subject = m_statement_e_sp[1];
					// named node
					if(s_subject || 'string' === typeof s_subject) {
						kt_subject = create_named_node_escapeless(s_subject);
					}
					// blank node
					else {
						kt_subject = create_blank_node(m_statement_e_sp[2]);
					}
				}
				let s_predicate = m_statement_e_sp[3];
				// emit data event
				f_data_quad(
					kt_subject,
					create_named_node_escapeless(s_predicate),
					kt_object,
					kt_default_graph,
				);
				// comments
				if(this.emit_comments) {
					this.emit_comments(m_statement_e_sp[6] || m_statement_e_sp[11]);
				}
			}
			else {
				// prepare sticky regex index
				R_TRIPLE.lastIndex = i;
				// execute regex
				let m_statement = R_TRIPLE.exec(s);

				// regex was a match
				if(m_statement) {
					// advance index
					i = R_TRIPLE.lastIndex;

					// prep object term
					let kt_object;

					// object term type is named node
					if(m_statement[4]) {
						let p_object = m_statement[4].slice(1);
						kt_object = create_named_node(RT_HAS_ESCAPES.test(p_object)? p_object.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): p_object);
					}
					// object term type is blank node
					else if(m_statement[5]) {
						kt_object = create_blank_node(RT_HAS_ESCAPES.test(m_statement[5])? m_statement[5].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): m_statement[5]);
					}
					// object term type is literal
					else {
						// contents
						let s_contents = m_statement[7];
						// string terminator
						if(m_statement[8]) {
							// unescape contents
							s_contents = unescape_literal_short_hard(s_contents);

							// datatype is present
							if(m_statement[9]) {
								// create datatype term
								let kt_datatype = this.create_named_node(m_statement[9]);
								// create object term
								kt_object = datatypedLiteral(s_contents, kt_datatype);
							}
							// language tag is present
							else if(m_statement[10]) {
								// normalize language
								let s_language = m_statement[10].toLowerCase();
								// create object term
								kt_object = create_languaged_literal(s_contents, s_language);
							}
							// simple literal
							else {
								kt_object = simpleLiteral(s_contents);
							}
						}
						// no string terminator
						else {
							// save contents
							this._s_literal = s_contents;
							// update index
							this.i = i;
							// save subject
							{
								let s_subject = m_statement[1];
								// named node
								if(s_subject || 'string' === typeof s_subject) {
									this._kt_subject = create_named_node(RT_HAS_ESCAPES.test(s_subject)? s_subject.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_subject);
								}
								// blank node
								else {
									this._kt_subject = create_blank_node(m_statement[2]);
								}
							}
							// save predicate
							this._kt_predicate = create_named_node(RT_HAS_ESCAPES.test(m_statement[3])? m_statement[3].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): m_statement[3]);
							// parse contents
							let z_bail = this.strlit_contents();
							// bail out of stack
							if(z_bail && this.statement !== z_bail) {
								return z_bail;
							}
							// statement completed
							else {
								// clean
								let r_clean = this._r_clean;
								r_clean.lastIndex = this.i;
								let m_clean = r_clean.exec(s);
								if(this.emit_comments) {
									this.emit_comments(m_clean[1]);
								}
								// update local index and prepare to match next statement
								i = r_clean.lastIndex;
								// resume
								continue;
							}
						}
					}

					let kt_subject;
					{
						let s_subject = m_statement[1];
						// named node
						if(s_subject || 'string' === typeof s_subject) {
							kt_subject = create_named_node(RT_HAS_ESCAPES.test(s_subject)? s_subject.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_subject);
						}
						// blank node
						else {
							kt_subject = create_blank_node(m_statement[2]);
						}
					}
					let s_predicate = m_statement[3];
					// emit data event
					f_data_quad(
						kt_subject,
						create_named_node(RT_HAS_ESCAPES.test(s_predicate)? s_predicate.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY): s_predicate),
						kt_object,
						kt_default_graph,
					);
					// comments
					if(this.emit_comments) {
						this.emit_comments(m_statement[6] || m_statement[11]);
					}
				}
				else {
					// prepare sticky regex index
					R_EOL.lastIndex = i;

					if(R_EOL.exec(s)) {
						// advance index
						i = R_EOL.lastIndex;
						this._error(`Failed to read statement:\n\`${s.substr(i, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		} // end of while

		// update unparsed data string
		this.s = s.substr(i);

		// resume here
		this._f_state = this.statement;

		// exit
		return 1;
	}


	strlit_contents() {
		let {s, n, i} = this;

		// try to find end
		R_STRLIT_SHORT_DOUBLE_TERM.lastIndex = i;
		let m_term = R_STRLIT_SHORT_DOUBLE_TERM.exec(s);

		// end is in this chunk
		if(m_term) {
			// index of terminator
			let i_term = m_term.index;

			// extract dirty potion
			let s_dirty = s.slice(i, i_term);

			// clean and save
			this._s_literal += unescape_literal_short_hard(s_dirty);

			// advance index beyond terminator
			this.i = i_term + m_term[0].length;

			// resume eating whitespace at start of next chunk
			this._b_trim_start = true;

			// proceed with datatype_or_lang, then bail out of stack or resume parsing
			return this.datatype_or_langtag() || this.statement;
		}
		// end is not in this chunk
		else {
			// extract whole portion
			let s_dirty = s.slice(i);

			// unescape to clean part
			let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

			// save
			this._s_literal += s_clean;

			// set unparsed index
			this.i = i = n - s_incomplete.length;

			// do not eat whitespace at start of next chunk
			this._b_trim_start = false;
		}

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('strlit_contents');
				}
			}
		}

		// resume here
		this._f_state = this.strlit_contents;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}



	// parse state for datatype_or_langtag
	datatype_or_langtag() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// ref character
		let x = s[i];

		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// datatype
			if('^' === x) {
				// enough to speculate datatype
				if((i+2) < n) {
					// correct token
					if('^' === s[i+1]) {
						// advance index beyond token
						R_IRIREF.lastIndex = i + 2;

						// execute regex
						let m_iriref = R_IRIREF.exec(s);

						// regex was a match
						if(m_iriref) {
							// advance index
							this.i = R_IRIREF.lastIndex;

							// prepare iri
							let p_datatype = m_iriref[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);

							// create datatype term
							let kt_datatype = this.create_named_node(p_datatype);

							// create object term
							let kt_object = this._dc_factory.datatypedLiteral(this._s_literal, kt_datatype);

							// free literal string
							this._s_literal = '';


							// emit data event
							this._f_data_quad(this._kt_subject, this._kt_predicate, kt_object, this._kt_default_graph);

							// complete with statement_term
							return this.statement_term();
						}
						// failed to match; try again next chunk
						else {
							break;
						}
					}
					// invalid
					else {
						this._error(`Failed to read token after literal:\n\`${s.substr(i+1, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);
					}
				}
				// not enough to speculate; try again next chunk
				else {
					break;
				}
			}
			// language tag
			else if('@' === x) {
				// prepare sticky regex index
				R_LANGTAG.lastIndex = i;
				// execute regex
				let m_langtag = R_LANGTAG.exec(s);

				// regex was a match
				if(m_langtag) {
					// advance index
					this.i = R_LANGTAG.lastIndex;

					// use direct factory method since regex is validation
					let kt_object = this._dc_factory.languagedLiteral(this._s_literal, m_langtag[1]);

					// free literal string
					this._s_literal = '';


					// emit data event
					this._f_data_quad(this._kt_subject, this._kt_predicate, kt_object, this._kt_default_graph);

					// complete with statement_term
					return this.statement_term();
				}
				// interrupted by eos; try again next chunk
				else {
					break;
				}
			}
			// triple terminator
			else if('.' === x) {
				// save simple literal
				let kt_object = this._dc_factory.simpleLiteral(this._s_literal);

				// free literal string
				this._s_literal = '';

				// advance index beyond terminator
				this.i = i + 1;

				// emit data event
				this._f_data_quad(this._kt_subject, this._kt_predicate, kt_object, this._kt_default_graph);

				// reset state
				return this.statement;

				// // consume whitespace (and incidentally reset index)
				// R_WS.lastIndex = i + 1;
				// R_WS.exec(s);
				// this.i = R_WS.lastIndex;

				// // done
				// return;
			}
			// other
			else {
				break;
			}
		}

		// ran out of characters
		// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype_or_langtag');
				}
			}
		}

		// resume here
		this._f_state = this.datatype_or_langtag;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}

	statement_term() {
		let {s, n, i} = this;

		// find full stop
		let i_stop = s.indexOf('.', i);

		// found
		if(i_stop > -1) {
			// consume whitespace again
			this._b_trim_start = true;

			// advance beyond token
			this.i = i_stop + 1;

			// reset state
			return this.statement;
		}
		// anything other than whitespace
		else if(!/^\s*$/.test(s.slice(i))) {
			this.parse_error('statement_term');
		}

		// do not consume whitespace
		this._b_trim_start = false;

		// resume here
		this._f_state = this.statement_term;

		// store what is unparsed
		this.s = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return 1;
	}


	parse_error(s_state) {
		return this._error(`Failed to read ${s_state}:\n\`${this.s.substr(this.i, 80).replace(/\n/g, '\u23CE')} [...]\`\n ^ starting here`);
	}

	destroy(e_destroy) {
		this._f_data_quad = () => {};

		if(!e_destroy && this._ds_input) {
			this._ds_input.destroy(e_destroy);
		}

		this.transform.demolish(e_destroy);
	}
}


module.exports = function(...a_args) {
	let g_config = {};

	// at least one argument
	if(a_args.length) {
		let z_arg_0 = a_args[0];

		// input given unspecified
		if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
			z_arg_0 = z_arg_0.input;
		}

		// string
		if('string' === typeof z_arg_0) {
			g_config.input = {string:z_arg_0};
		}
		// null
		else if(null === z_arg_0) {
			g_config.input = null;
		}
		// node stream
		else if('function' === typeof z_arg_0.setEncoding) {
			g_config.input = {stream:z_arg_0};
		}
		// whatwg stream
		else if('function' === typeof z_arg_0.pipeTo) {
			throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
		// g_config.input = {stream:z_arg_0};
		}
		// config struct
		else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
			g_config = z_arg_0;

			// more args; invalid
			if(a_args.length > 1) {
				throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
			}
		}
		// unknown
		else {
			throw new TypeError(`unexpected input type: ${z_arg_0}`);
		}

		// more args
		if(a_args.length > 1) {
			// copy onto struct
			Object.assign(g_config, a_args[1]);

			// more args
			if(a_args.length > 2) {
				throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
			}
		}
	}

	// create reader, return transform stream
	return (new Reader(g_config)).transform;
};

},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21}],7:[function(require,module,exports){
(function (Buffer,setImmediate){(function (){

const run = sjx_eval => eval(sjx_eval);

// iiaf to isolate scope from eval
(function() {
	// queueMicrotask shim
	{
		// not defined or not a function
		if('function' !== typeof queueMicrotask) {
			// create resolved promise
			let dp_resolve = Promise.resolve();

			// try to redefine
			try {
				// eslint-disable-next-line no-global-assign
				queueMicrotask = fk => dp_resolve.then(fk)
					.catch(e_callback => setTimeout(() => {
						throw e_callback;
					}, 0));
			}
			// oh well, at least we tried
			catch(e_define) {}
		}
	}



	const events = require('events');
	const path = require('path');
	const stream = require('@graphy/core.iso.stream');
	const reader = require('@graphy/content.nt.read');
	const master = require('@graphy/core.iso.threads').master;
	const {StringDecoder} = require('string_decoder');
	const H_PRESET_TASKS = require('./task-presets.js');

	// fast 4 byte writer from bkit
	const f_writer_uintle32 = (at, ib, x) => {
		at[ib] = x & 0xff;
		at[ib+1] = (x >>> 8) & 0xff;
		at[ib+2] = (x >>> 16) & 0xff;
		at[ib+3] = (x / 0x1000000) & 0xff;
		return at;
	};

	const N_DEFAULT_SLOTS_PER_WORKER = 3;



	// adapted from https://www.npmjs.com/package/physical-cpu-count
	let NL_WORKERS_ADVISE = (() => {
		const cp = require('child_process');
		const os = require('os');

		const exec = s_cmd => cp.execSync(s_cmd, {encoding:'utf8'});

		switch(os.platform()) {
			case 'linux': {
				let s_out = exec(/* syntax: shell */ `lscpu -p | egrep -v "^#" | sort -u -t, -k 2,4 | wc -l`);
				return parseInt(s_out.trim(), 10);
			}

			case 'darwin': {
				let s_out = exec(/* syntax: shell */ `sysctl -n hw.physicalcpu_max`);
				return parseInt(s_out.trim(), 10);
			}

			case 'windows': {
				let s_out = exec(/* syntax: shell */ `WMIC CPU Get NumberOfCores`);
				return s_out.split(os.EOL)
					.map(s => parseInt(s))
					.filter(n => !isNaN(n))
					.reduce((c_out, n) => c_out + n, 0);
			}

			default: {
				return os.cpus().filter((g_cpu, i_cpu) => {
					let b_hyperthreading = g_cpu.model.includes('Intel');
					let b_odd = 1 === (i_cpu % 2);
					return !b_hyperthreading || b_odd;
				}).length;
			}
		}
	})() - 1;



	function Scanner$handle_worker_message(k_self, i_worker) {
		return (g_msg) => {
			switch(g_msg.type) {
				// update
				case 'update': {
					// ref message payload
					let w_value = g_msg.value;

					// sync receive update transform
					if(k_self._f_receive_update) w_value = k_self._f_receive_update(w_value, i_worker);

					// apply update handler
					k_self._f_update(w_value, i_worker);
					break;
				}

				// submit
				case 'submit': {
// console.log(`received result from worker ${i_worker}: ${g_msg.value}; ${a_reports.length+1} results`);

					// ref message payload
					let w_value = g_msg.value;

					// sync receive submit transform
					if(k_self._f_receive_submit) w_value = k_self._f_receive_submit(w_value, i_worker);

					// reduce
					k_self._w_reduced = k_self._f_reduce(k_self._w_reduced, w_value);

					// all results have been collected
					if(k_self._nl_workers === ++k_self._c_reports) {
						if(k_self._b_eofed) {
							k_self._f_report(k_self._w_reduced);
						}
						else {
							k_self._b_collected = true;
						}
					}

					break;
				}

				// error
				case 'error': {
					// error struct
					let g_error = g_msg.value;

					// reconstruct error
					let e_throw = new Error(g_error.message);
					e_throw.stack = g_error.stack;

					// kill workers and throw error
					return k_self._kill(e_throw, i_worker);
				}

				// throw
				case 'throw': {
					// ref error struct
					let z_throw = g_msg.value;

					// issue warning
					console.warn(`WARNING: Your code (or some library) on the worker is throwing an object which is not an instance of Error. I am going to put it into an Error for you now, but please fix this. The object.toString() is: "${z_throw}"`);

					// construct error
					let e_wrap = new Error(z_throw+'');

					// kill workers and throw error
					return k_self._kill(e_wrap, i_worker);
				}

				// clone error
				case 'clone-error': {
					// ref error struct
					let g_clone = g_msg.value;

					// construct error
					let e_clone = new Error(`You are trying to call '${g_clone.info}' on some object from within one of the workers, but that object is not serializable using the structured clone algorithm. The object.toString() is: "${g_clone.obejct}"... the error about the worker failing to send the original error to the master thread is:\n${g_clone.error}`);

					// kill workers and throw error
					return k_self._kill(e_clone, i_worker);
				}


				// other
				default: {
					console.assert(`invalid worker message type: ${g_msg.type}`);
				}
			}
		};
	}


	// fill open slots with next chunk from input stream
	function Scanner$fill_slots(k_self) {
		let ds_input = k_self._ds_input;
		let a_slots_open = k_self._a_slots_open;
		let nb_high_water_mark = k_self._nb_high_water_mark;
		let nb_slot = k_self._nb_slot;
		let atu8_data = k_self._atu8_data;
		let atu8_slot_owners = k_self._atu8_slot_owners;
		let at32_indicators = k_self._at32_indicators;
		let a_slot_states = k_self._a_slot_states;
		let ab_prev = k_self._ab_prev;
		let ds_reader = k_self._ds_reader;

		// prep chunk placeholder
		let ab_chunk;

		// while there are open slots
		while(a_slots_open.length) {
			// read chunk from input stream
			ab_chunk = ds_input.read();

			// buffer is drained; break read loop
			if(null === ab_chunk) break;

			// chunk size exceeds high water mark
			if(ab_chunk.length > nb_high_water_mark) {
				// unshift remainder back into internal buffer
				let ab_unshift = ab_chunk.slice(nb_high_water_mark);

				// pick limit part for this chunk
				ab_chunk = ab_chunk.slice(0, nb_high_water_mark);

				// unshift
				ds_input.unshift(ab_unshift);
			}

			// read head/tail
			let ib_head = ab_chunk.indexOf(0x0a) + 1;
			let ib_tail = ab_chunk.lastIndexOf(0x0a) + 1;

			// take next open slot
			let i_slot = a_slots_open.shift();

			// slot position
			let ib_slot = i_slot * nb_slot;

			// payload size
			let nb_payload = ib_tail - ib_head;
			f_writer_uintle32(atu8_data, ib_slot, nb_payload);

			// fill it
			ab_chunk.copy(atu8_data, ib_slot+4, ib_head, ib_tail);

			// mark slot ready
			atu8_slot_owners[i_slot] = 255;

			// set indicator & notice
			at32_indicators[0] += 1;
			let n_awoke = Atomics.notify(at32_indicators, 0);
// log(`woke ${n_awoke} sleeping threads}`);

			// set slot state
			a_slot_states[i_slot] = 1;

			// join head with prev
			let ab_head = ab_chunk.slice(0, ib_head);
			let ab_write = Buffer.concat([ab_prev, ab_head], ab_prev.length+ab_head.length);

			let s_write = ab_write.toString('utf8');

			// write to reader
			ds_reader.write(s_write);

			// save tail to prev
			ab_prev = ab_chunk.slice(ib_tail);
		}

		// update prev chunk value
		k_self._ab_prev = ab_prev;

		// buffer is drained
		if(0 === ds_input.readableLength) {
			// but did not reach null
			if(null !== ab_chunk) {
				// trigger
				let z_read = ds_input.read();

				// assert null
				if(null !== z_read) {
					throw new Error(`expected to reach null in paused stream readable but received ${z_read? 'chunk data instad': 'skipped event'}`);
				}
			}

			// await readable
			return true;
		}

		// have not consumed everything
		return false;
	}

	// drain returned slots
	function Scanner$drain_slots(k_self) {
		let nl_slots = k_self._nl_slots;
		let atu8_slot_owners = k_self._atu8_slot_owners;
		let a_slot_states = k_self._a_slot_states;
		let a_slots_open = k_self._a_slots_open;

		let c_drained = 0;

		// read results
		for(let i_slot=0; i_slot<nl_slots; i_slot++) {
			// slot returned
			if(0 === atu8_slot_owners[i_slot] && 1 === a_slot_states[i_slot]) {
				// update slot state
				a_slot_states[i_slot] = 0;

				// mark slot as open
				a_slots_open.push(i_slot);

				// number of slots drained
				c_drained += 1;
			}
		}

		return c_drained;
	}


	function Scanner$attach_readable(k_self) {
		let ds_input = k_self._ds_input;
		let nl_workers = k_self._nl_workers;
		let at32_indicators = k_self._at32_indicators;

		// each time the input stream emits readable (this switches to paused mode)
		ds_input.on('readable', () => {
			k_self._tick();
		});

		// no workers
		if(0 === nl_workers) {
			// override tick function
			k_self._tick = Scanner$_tick_master_only;

			// presume worker reports collected
			k_self._b_collected = true;

			// end
			ds_input.on('end', () => {
				// final chunk
				let s_final = k_self._d_string_decoder.end();

				// end writable side of content reader
				k_self._ds_reader.end(s_final);
			});
		}
		// yes workers
		else {
			// end
			ds_input.on('end', () => {
				// set indicator and notify
				at32_indicators[0] = -1;
				let c_notified = Atomics.notify(at32_indicators, 0);

				// reassign tick function
				k_self._tick = () => {};

				// final chunk
				let s_final = k_self._ab_prev.toString('utf8');

				// end writable side of content reader
				k_self._ds_reader.end(s_final);
			});
		}
	}

	// special tick function if no workers
	function Scanner$_tick_master_only() {
		let ds_input = this._ds_input;
		let ds_reader = this._ds_reader;
		let d_string_decoder = this._d_string_decoder;

		let ab_chunk;
		while(null !== (ab_chunk=ds_input.read())) {
			ds_reader.write(d_string_decoder.write(ab_chunk));
		}
	}


	class NTriples_Scanner extends stream.Readable {
		constructor(gc_scanner) {
			super();

			// worker and slot settings
			let nl_workers = this._nl_workers = (gc_scanner.threads || (NL_WORKERS_ADVISE+1)) - 1;
			this._n_slots_per_worker = gc_scanner.slots_per_worker || gc_scanner.slotsPerWorker || N_DEFAULT_SLOTS_PER_WORKER;

			// flags
			this._b_eofed = false;
			this._b_collected = false;

			// report count
			this._c_reports = 0;

			// list of workers
			this._a_workers = [];

			// queue of open slots
			this._a_slots_open = [];

			// slot states
			this._a_slot_states = [];

			// previous chunk fragment
			this._ab_prev = Buffer.allocUnsafe(0);

			// string decoder
			this._d_string_decoder = new StringDecoder();

			// open slot resolve
			this._f_resolve_open_slot = null;

			// reader ready resolve
			this._f_resolve_reader_ready = null;

			if(gc_scanner.error) this.on('error', gc_scanner.error);
			if(gc_scanner.update) this.on('update', gc_scanner.update);
			if(gc_scanner.report) this.once('report', gc_scanner.report);


			// semaphores
			this.b_ready_pipe = null;
			this.b_ready_reader = false;
			this.b_unpiped_self = false;

			// default preset config
			let g_preset = {};

			// preset given
			if(gc_scanner.preset) {
				let si_preset = gc_scanner.preset;

				// no such preset name
				if(!H_PRESET_TASKS[si_preset]) {
					throw new Error(`No such NTriples_Scanner preset named '${si_preset}'`);
				}

				// generate preset config
				g_preset = H_PRESET_TASKS[gc_scanner.preset]({
					...gc_scanner,

					// auto-populate format
					format: 'nt',
				});
			}

			// task config
			let g_task = {
				...g_preset,
				...(gc_scanner.task || {}),
				...gc_scanner,
			};

			// run function
			let sjx_run = this._sjx_run = g_task.run;

			// missing run function
			if('string' !== typeof sjx_run || !sjx_run) {
				throw new TypeError('Invalid \'.run\' property supplied to NTriples_Scanner constructor; must be a non-empty string.');
			}

			// try creating run function
			let f_run;
			try {
				// f_run = (new Function(`return (${sjx_run})`))();  // eslint-disable-line no-new-func
				f_run = run(`(${sjx_run})`);  // eslint-disable-line no-eval
			}
			catch(e_eval) {
				throw new Error(`Failed to evaluate the '.run' property supplied to NTriples_Scanner constructor as JavaScript code: """\n${sjx_run}"""\n${e_eval.stack || e_eval}`);
			}

			// reduce property supplied
			if(g_task.reduce) {
				let f_reduce = g_task.reduce;

				// invalid reduce property
				if('function' !== typeof f_reduce) {
					throw new TypeError('Invalid \'.reduce\' property supplied to NTriples_Scanner constructor; if present, it must be a function.');
				}

				// set reduce function
				this._f_reduce = f_reduce;

				// initial value also present
				if('undefined' !== typeof g_task.initial) {
					this._w_initial = g_task.initial;
				}
				// no initial value; set master as initial
				else {
					this._f_submit_master = w_value => this._w_reduced = w_value;
				}
			}
			// initial value present
			else if('undefined' !== typeof g_task.initial) {
				throw new TypeError('The \'.initial\' property was supplied to NTriples_Scanner constructor but you also need to specify a \'.reduce\' function.');
			}

			// user property
			let z_user = g_task.user;

			// callback function; save
			if('function' === typeof z_user) {
				this._f_spawn = z_user;
			}
			// other
			else {
				this._f_spawn = () => z_user;
			}

			// receive handler(s)
			let z_receive = g_task.receive;

			// receive function
			if('function' === typeof z_receive) {
				this._f_receive_update = this._f_receive_submit = z_receive;
			}
			// different handlers for update and submit events
			else if(z_receive) {
				// update handler supplied
				if(z_receive.update) {
					this._f_receive_update = z_receive.update;
				}

				// submit handler supplied
				if(z_receive.submit) {
					this._f_receive_submit = z_receive.submit;
				}
			}


			let k_self = this;

			// create content reader
			(async() => {
				let ds_reader = this._ds_reader = await f_run(reader, ...[
					// handle errors
					function err(z_what) {
						// proper error instance
						if(z_what instanceof Error) {
							// kill workers and handle error
							k_self._kill(z_what, 0);
						}
						// invalid error type
						else {
							// issue warning
							console.warn(`WARNING: Your code (or some library) on the main thread is throwing an object which is not an instance of Error. I am going to put it into an Error for you now, but please fix this. The object.toString() is: "${z_what}"`);

							// construct error
							let e_wrap = new Error(z_what+'');

							// kill workers and throw error
							k_self._kill(e_wrap, 0);
						}
					},

					// 'update' with some info
					function update(w_msg) {
						k_self._f_update(w_msg, 0);
					},

					// 'submit' results
					function submit(w_value) {
						k_self._f_submit_master(w_value);
					},

					// user data
					this._f_spawn(0),

					// not a worker
					false,
				]);

				// attach automatic error handler to kill workers
				ds_reader.on('error', (e_read) => {
					this._kill(e_read, 0);
				});

				// once main thread content reader has finished
				ds_reader.once('eof', () => {
					// all results collected from workers
					if(this._b_collected) {
						this._f_report(this._w_reduced);
					}
					// set flag that we eof'd
					else {
						this._b_eofed = true;
					}
				});

				// input has been imported
				if(this._b_ready_input) {
					Scanner$attach_readable(this);
				}
			})();

			// input given
			let g_input = gc_scanner.input;
			if(g_input) {
				// stream
				if(g_input.stream) {
					this.import(g_input.stream);
				}
				// string
				else if(g_input.string) {
					// ref input string
					let s_input = g_input.string;

					// cache its length
					let nl_input = s_input.length;

					// read position
					let i_read = 0;

					// import
					this.import(new stream.Readable({
						highWaterMark: 0x10000,

						_read() {
							// end of read range position
							let i_next = i_read + 0x10000;

							// reach end of string; push eof signal
							if(i_next >= nl_input) {
								this.push(null);
							}
							// still data
							else {
								// convert string to buffer
								this.push(Buffer.from(s_input.slice(i_read, i_next)));

								// update read position
								i_read = i_next;
							}
						},
					}));
				}
				// other
				else {
					throw new Error(`NTriples_Scanner: Invalid option supplied to '.input' property "${g_input}"`);
				}
			}
		}

		_kill(e_reason, i_thread) {
			// destroy callbacks
			this._f_report = this._f_update = this._kill = () => {};

			// kill all workers
			Promise.all(this._a_workers.map(d => d.terminate()))
				.then(() => queueMicrotask(() => {
					this.emit('error', e_reason, i_thread);
				}));
		}

		import(ds_input) {
			// input has already been imported
			if(this._b_ready_input) {
				throw new Error(`More than one input was imported to NTriples_Scanner; only a single input source can be imported and only once.`);
			}

			// mark input ready
			this._b_ready_input = true;

			// save input
			this._ds_input = ds_input;

			// byte size ofhigh water mark
			let nb_high_water_mark = this._nb_high_water_mark = Math.max(0x10000, ds_input.readableHighWaterMark);

			let nl_workers = this._nl_workers;

			let nl_slots = this._nl_slots = this._n_slots_per_worker * nl_workers;

			let nb_slot = this._nb_slot = 4 + nb_high_water_mark;

			let nl_indicators = 2;
			let nb_indicators = nl_indicators * 4;

			let nb_slot_owners = nl_slots * 1;
			let nb_region = (nb_indicators)  // indicators
			+ (nb_slot_owners)  // slot owners
			+ (nb_slot * nl_slots);  // slot data

			// create shared memory region
			let ab_share = new SharedArrayBuffer(nb_region);

			// indicators
			let at32_indicators = this._at32_indicators = new Int32Array(ab_share, 0, nl_indicators);

			// slot owner and data byte positions
			let ib_slots = 0 + nb_indicators;
			let ib_data = ib_slots + (nb_slot_owners);

			// slot owners
			let atu8_slot_owners = this._atu8_slot_owners = new Uint8Array(ab_share, ib_slots, nl_slots);

			// slot data
			let atu8_data = this._atu8_data = new Uint8Array(ab_share, ib_data);


			// initially, all slots are claimed by master thread
			for(let i_slot=0; i_slot<nl_slots; i_slot++) {
				// set slot owner to master thread
				atu8_slot_owners[i_slot] = 0;
// a_slot_owners_internal.push(XC_SLOT_OWNER_MASTER);

				// push open slot to queue
				this._a_slots_open.push(i_slot);

				// set initial slot state
				this._a_slot_states.push(0);
			}


			// spawn workers
			{
				let a_workers = this._a_workers;

				let g_worker_data = {
					sjx_run: this._sjx_run,
					// ab_share,
					nl_workers,
					nl_slots,
					nb_slot,
					at32_indicators,
					// nb_region,
					atu8_slot_owners,
					atu8_data,
				};

				// ref spawn (and then call without context)
				let f_spawn = this._f_spawn;

				// each worker
				for(let i_worker=1; i_worker<=nl_workers; i_worker++) {
					// spawn
					let d_worker = new master.Worker('./worker.js', {
						__dirname,

						workerData: {
							...g_worker_data,
							i_worker,
							w_user: f_spawn(i_worker),
						},

						// on message event
						message: Scanner$handle_worker_message(this, i_worker),

						// inherit resource limits from main
						resourceLimits: 'inherit',
					});

// d_worker.on('message', );

					// push to worker list
					a_workers.push(d_worker);
				}
			}

			// reader is ready; attach readable event listener
			if(this._b_ready_reader) {
				Scanner$attach_readable(this);
			}
		}

		_tick(b_softlock) {
			let at32_indicators = this._at32_indicators;

			// grab indicator
			let xc_indicator_reclaim = Atomics.load(at32_indicators, 1);

			// fill slots, return value indicates exitting due to slots being full
			let b_await_readable = Scanner$fill_slots(this);

			// drain slots
			let n_drained = Scanner$drain_slots(this);

			// need to explicitly recall tick
			if(!b_await_readable) {
				// something drained (or no workers)
				if(n_drained) {
					// retick, avoiding recursion
					queueMicrotask(() => {
						this._tick();
					});
				}
				else {
					// avoid recursion; use setImmediate (need event loop to process messages from worker)
					setImmediate(() => {
						// await change
						let s_status = Atomics.wait(at32_indicators, 1, xc_indicator_reclaim, 2000);

						// awaiting lock timed out
						if('timed-out' === s_status) {
							// this could be a softlock
							if(b_softlock) {
								console.warn(`WARNING: NTriples_Scanner main thread waited more than 2000ms for a response from one of its ${this._nl_workers} worker(s); now escaping potential softlock`);
							}

							// set indicator and notify
							at32_indicators[0] += 1;
							Atomics.notify(at32_indicators, 0);

							// tick next
							return this._tick(true);
						}
					// else if('not-equal' === s_status) {
					// 	log(`awaited indicator: ${s_status}; ${Atomics.load(at32_indicators, 1)}`);
// }

						// retick
						this._tick();
					});
				}
			}
		}
	}

	Object.assign(NTriples_Scanner.prototype, {
		// initial value
		_w_initial: [],

		// default reduce function
		_f_reduce: (a_out, w_value) => [...a_out, w_value],

		// update handler
		_f_update(w_report, i_thread) {
			if(!this.emit('update', w_report, i_thread)) {
				console.warn(`WARNING: NTriples_Scanner emitted an 'update' event but no listener function is attached`);
			}
		},

		// report handler
		_f_report(w_report) {
			if(!this.emit('report', w_report)) {
				console.warn(`WARNING: NTriples_Scanner emitted a 'report' event but no listener function is attached`);
			}

		// // emit end event
		// queueMicrotask(() => {
		// 	this.emit('end');
		// });
		},

		// receive handlers
		_f_receive_update: null,
		_f_receive_submit: null,

		// submit master
		_f_submit_master(w_report) {
			this._w_reduced = this._f_reduce(this._w_initial, w_report);
		},

		// spawn function
		_f_spawn: () => {},
	});



	module.exports = function(...a_args) {
		let g_config = {};

		// at least one argument
		if(a_args.length) {
			let z_arg_0 = a_args[0];

			// input given unspecified
			if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
				z_arg_0 = z_arg_0.input;
			}

			// string
			if('string' === typeof z_arg_0) {
				g_config.input = {string:z_arg_0};
			}
			// null
			else if(null === z_arg_0) {
				g_config.input = null;
			}
			// node stream
			else if('function' === typeof z_arg_0.setEncoding) {
				g_config.input = {stream:z_arg_0};
			}
			// whatwg stream
			else if('function' === typeof z_arg_0.pipeTo) {
				throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
			// g_config.input = {stream:z_arg_0};
			}
			// config struct
			else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
				g_config = z_arg_0;

				// more args; invalid
				if(a_args.length > 1) {
					throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
				}
			}
			// unknown
			else {
				throw new TypeError(`unexpected input type: ${z_arg_0}`);
			}

			// more args
			if(a_args.length > 1) {
				// copy onto struct
				Object.assign(g_config, a_args[1]);

				// more args
				if(a_args.length > 2) {
					throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
				}
			}
		}

		// create reader, return transform stream
		return (new NTriples_Scanner(g_config));
	};
})();

}).call(this)}).call(this,require("buffer").Buffer,require("timers").setImmediate)
},{"./task-presets.js":8,"@graphy/content.nt.read":6,"@graphy/core.iso.stream":21,"@graphy/core.iso.threads":22,"buffer":74,"child_process":73,"events":118,"os":166,"path":172,"string_decoder":76,"timers":228}],8:[function(require,module,exports){
arguments[4][3][0].apply(exports,arguments)
},{"dup":3}],9:[function(require,module,exports){



const Scribable = require('@graphy/core.class.scribable');

const factory = require('@graphy/core.data.factory');
const {
	c1_to_nt,
	clean_iri,
} = factory;


function verbose_s(yt_subject) {
	if('NamedNode' === yt_subject.termType) {
		return '<'+clean_iri(yt_subject.value)+'>';
	}
	else {
		return '_:'+yt_subject.value;
	}
}



const verbose_p = yt_predicate => '<'+clean_iri(yt_predicate.value)+'>';

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function verbose_o(yt_object) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return '<'+clean_iri(yt_object.value)+'>';

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^<'+clean_iri(yt_object.datatype.value)+'>';
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}


class NTriples_Scriber extends Scribable {
	constructor(gc_scriber={}) {
		super(gc_scriber);

		// prefixes given
		if(gc_scriber.prefixes) {
			// update prefixes
			this._update_prefixes(gc_scriber.prefixes);
		}
	}


	_serialize_c3r(hc3r_triples) {
		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// string building
		let sv_build = '';

		for(let sc1_subject in hc3r_triples) {
			// quick convert subject from concise term to verbose
			let sv1_subject = c1_to_nt(sc1_subject, h_prefixes, true);

			// not a term; skip
			if(!sv1_subject) continue;

			// each predicate
			let hc2r_pairs = hc3r_triples[sc1_subject];
			for(let sc1_predicate in hc2r_pairs) {
				// quick convert predicate from concise term to verbose
				let sv1_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);

				// not a term; skip
				if(!sv1_predicate) continue;

				// opening string
				let sv_opening = sv1_subject+' '+sv1_predicate+' ';

				// each object
				for(let sc1_object of hc2r_pairs[sc1_predicate]) {
					// quick convert object from concise term to verbose
					let sv1_object = c1_to_nt(sc1_object, h_prefixes, true);

					// not a term; skip
					if(!sv1_object) continue;

					sv_build += sv_opening+sv1_object+' .\n';
				}
			}
		}

		return sv_build;
	}

	_serialize_quad(g_quad) {
		let {
			subject: yt_subject,
			predicate: yt_predicate,
			object: yt_object,
		} = g_quad;

		// write triple
		this._s_push += verbose_s(yt_subject)
			+' '+verbose_p(yt_predicate)
			+' '+verbose_o(yt_object)

			+' .\n';
	}
}

Object.assign(NTriples_Scriber.prototype, {
	_serialize_comment: Scribable.prototype._serialize_hash_comment,
});

module.exports = function(g_config) {
	return new NTriples_Scriber(g_config);
};

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],10:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Writable = require('@graphy/core.class.writable');

const {
	c1_to_nt,
	clean_iri,
} = factory;

const N_MAX_STRING_BUFFER = 1 << 12;


function verbose_s(yt_subject) {
	if('NamedNode' === yt_subject.termType) {
		return '<'+clean_iri(yt_subject.value)+'>';
	}
	else {
		return '_:'+yt_subject.value;
	}
}



const verbose_p = yt_predicate => '<'+clean_iri(yt_predicate.value)+'>';

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function verbose_o(yt_object) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return '<'+clean_iri(yt_object.value)+'>';

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^<'+clean_iri(yt_object.datatype.value)+'>';
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}

class NTriples_Writer extends Writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			style: gc_style=null,
		} = gc_writer;

		Object.assign(this, {
			_xc_state: 2,
		});
	}



	// serialize c3 hash
	_serialize_c3(hc3_triples) {
		let {
			_h_prefixes: h_prefixes,
		} = this;
		let s_write = '';

		// post component
		let st_post = ' .\n';

		// subject exit listener
		let f_exit_subject = null;
		// each subject
		for(let sc1_subject in hc3_triples) {
			// directive; serialize it
			if('`' === sc1_subject[0]) {
				let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
				// write data
				if(g_apply.write) s_write += g_apply.write;
				// save exit listener
				if(g_apply.exit) f_exit_subject = g_apply.exit;
				continue;
			}
			// subject-pre component
			let st_pre = c1_to_nt(sc1_subject, h_prefixes, true)+' ';
			// pair indent & terminator
			let s_indent_pairs = '';
			let s_term_pairs = '';
			// ref pairs
			let hc2_pairs = hc3_triples[sc1_subject];
			// predicate exit listener
			let f_exit_predicate = null;
			// each predicate
			for(let sc1_predicate in hc2_pairs) {
				// directive; serialize it
				if('`' === sc1_predicate[0]) {
					let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// write data
					if(g_apply.write) s_write += g_apply.write;
					// save exit listener
					if(g_apply.exit) f_exit_predicate = g_apply.exit;
					continue;
				}
				// predicate component
				let st_predicate = c1_to_nt(sc1_predicate, h_prefixes, true);
				// ref objects
				let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
				s_write += this._encode_objects(st_pre+st_predicate+' ', z_objects, st_post);
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
			}
			// call exit predicate listener
			if(f_exit_predicate) f_exit_predicate();
		}
		// call exit subject listener
		if(f_exit_subject) f_exit_subject();

		return s_write;
	}



	// write objects
	_encode_objects(s_pre, z_objects, s_post, n_nest_level=1) {
		let {
			_h_prefixes: h_prefixes,
			_hm_coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return s_pre+factory.c1(z_objects, h_prefixes).verbose()+s_post;

			// numeric type
			case 'number': return s_pre+factory.number(z_objects).verbose()+s_post;

			// boolean type
			case 'boolean': return s_pre+factory.boolean(z_objects).verbose()+s_post;

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; write list
						if(Array.isArray(z_item)) {
							// transcode list
							let hc2_list = this._transcode_list(z_item);

							// serialize transcoded list
							s_write += this._encode_objects(s_pre, hc2_list, s_post, n_nest_level);
						}
						// non-array; recurse on item
						else {
							s_write += this._encode_objects(s_pre, z_item, s_post, n_nest_level);
						}
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// new blank node
					let st_blank = factory.blankNode();

					// start with incoming triple
					let s_write = s_pre+st_blank+s_post;

					// object exit listener
					let f_exit_object = null;

					// each pair
					for(let sc1_predicate in z_objects) {
						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							let g_apply = this._apply_directive(sc1_predicate, z_objects[sc1_predicate]);

							// write data
							if(g_apply.write) s_write += g_apply.write;

							// save exit listener
							if(g_apply.exit) f_exit_object = g_apply.exit;
							continue;
						}

						// pre-string for nested triples
						let s_pre_nest = st_blank+' '+c1_to_nt(sc1_predicate, h_prefixes, true)+' ';

						// recurse
						s_write += this._encode_objects(s_pre_nest, z_objects[sc1_predicate], s_post, n_nest_level+1);
					}

					// call exit object listener
					if(f_exit_object) f_exit_object();

					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return s_pre+kt_converted.verbose(h_prefixes)+s_post;
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return s_pre+z_objects.verbose()+s_post;
				}
				// RDFJS term
				else if(z_objects.termType) {
					return s_pre+factory.from.term(z_objects).verbose()+s_post;
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// rdfjs quad
	_serialize_quad(g_quad) {
		// serialize quad
		this._s_push += (2 !== this._xc_state? '\n': '')
			+verbose_s(g_quad.subject)
			+' '+verbose_p(g_quad.predicate)
			+' '+verbose_o(g_quad.object)

			+' .\n';

		// update state
		this._xc_state = 2;
	}
}

Object.assign(NTriples_Writer.prototype, {
	_serialize_c3r: NTriples_Writer.prototype._serialize_c3,
	_serialize_comment: Writable.prototype._serialize_hash_comment,
});

module.exports = function(gc_writer) {
	return new NTriples_Writer(gc_writer);
};

},{"@graphy/core.class.writable":19,"@graphy/core.data.factory":20}],11:[function(require,module,exports){
(function (Buffer){(function (){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const uri = require('uri-js');
const string_decoder = require('string_decoder');

const stream = require('@graphy/core.iso.stream');
const factory = require('@graphy/core.data.factory');
const quad = k => factory.quad(k._kt_subject, k._kt_predicate, k._kt_object, k._kt_graph);

// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_NAMESPACE_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?)?$/u;
// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_LOCAL_NAME_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_:0-9]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%])(([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.:]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%])*([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}:]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%]))?$/u;
// eslint-disable-next-line no-misleading-character-class
const RT_BLANK_NODE_VALID = /^[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_0-9]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?$/u;
const RT_NAMED_NODE_VALID = /^([^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_NAMED_NODE_ESCAPELESS_VALID = /^([^\0-\x20<>"{}|^`])*$/;

const RT_LITERAL_CONTENTS_VALID = /^(?:[^\\]|\\[tbnrf"'\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;

const R_UNICODE_ANY = /\\u([0-9A-Fa-f]{4})|\\U([0-9A-Fa-f]{8})/g;

const F_REPLACE_UNICODE_ANY = 	(s_, s_4, s_8) => String.fromCodePoint(parseInt(s_4 || s_8, 16));

const OPHOP = Object.prototype.hasOwnProperty;



const R_PREFIXED_NAME_QUICK = /([A-Za-z][A-Za-z0-9_-]*)?:([A-Za-z_0-9:][A-Za-z0-9_:-]*)(?:\s+|(?=\.?[<[("';,)\]#{}]|\.[\s\0]))/y;


const R_PREFIXED_NAME_ESCAPELESS = /([^\s#@<[("':_{}][^\s#@<[("':{}]*)?:((?:[^\s#@<[("'.;,{})\]\\](?:[^\s#@<[("';,{})\]\\]*[^\s#@<[("'.;,{})\]\\])?)?)(?:\s+|(?=\.?[<[("';,)\]#{}]|\.[\s\0]))/y;



const R_PREFIXED_NAME = /([^\s#@<[("':_{}][^\s#@<[("':{}]*)?:((?:(?:[^\s#@<[("'.;,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))(?:(?:[^\s#@<[("';,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))*(?:[^\s#@<[("'.;,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"])))?)?)(?:\s+|(?=\.?[<[("';,)\]#{}]|\.[\s\0]))/y;

const R_PN_LOCAL_ESCAPES = /\\(.)/g;


const R_BLANK_NODE_LABEL = /_:(.(?:[^\s:<;,)\]#}]*[^\s:<.;,)\]#}])?)(?:\s+|(?=[<:{,;\])#]))/y;
const R_BLANK_NODE_LABEL_TERMINAL = /_:(.(?:[^\s:<;,)\]#}]*[^\s:<.;,)\]#}])?)(?:\s+|(?=\.?[<:{,;\])#])|(?=\.[\s@#<({[}]))/y;

const R_IRIREF_ESCAPELESS = /<([^\\>]*)>\s*/y;
const R_IRIREF = /<([^>]*)>\s*/y;

const R_NUMERIC_LITERAL = /([+-]?(?:[0-9]+(\.[0-9]+)?|(\.[0-9]+))(\.?[eE][+-]?[0-9]+)?)(?:\s+|(?=\.[^eE0-9]|[;,)\]]))/y;
const R_BOOLEAN_LITERAL = /(?:(true|TRUE)|false|FALSE)\s*/y;
const R_A = /a(?:\s+|(?=[[("'<#]))/y;

const R_DOUBLE_CARET = /\^\^/y;
const R_WS = /\s*/y;
const R_LANGTAG = /@([A-Za-z]+(?:-[A-Za-z0-9-]+)*)(?:\s+|(?=[.},;\])#]))/y;

const R_PREFIX_KEYWORD = /(?:(@prefix)|[pP][rR][eE][fF][iI][xX])\s*/y;
const R_PREFIX_ID = /([^#:]*):\s*/iy;
const R_BASE_KEYWORD = /(?:(@base)|[bB][aA][sS][eE])\s*/y;

const R_GRAPH_IRI_ESCAPELESS = /(?:graph)?\s*<([^\\>]*)>\s*\{\s*/iy;
const R_GRAPH_PREFIXED_NAME = /(?:graph)?\s*([^\s#@<[("':_{}][^\s#@<[("':{}]*)?:((?:(?:[^\s#@<[("'.;,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))(?:(?:[^\s#@<[("';,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))*(?:[^\s#@<[("'.;,{})\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"])))?)?)\s*\{\s*/iy;
const R_GRAPH_LABELED_BLANK_NODE = /(?:graph)?\s*_:(.(?:[^\s:<;,)\]#}]*[^\s:<.;,)\]#}])?)\s*\{\s*/iy;
const R_GRAPH_ANONYMOUS_BLANK_NODE = /(?:graph)?\s*\[\s*\]\s*\{\s*/iy;
const R_GRAPH_IRI = /(?:graph)?\s*<([^>]*)>\s*\{\s*/iy;
const R_GRAPH = /graph(?:\s+|(?=[#<[{]))/iy;

const R_COMMENT = /(#[^\n]*\n\s*)+/y;

const RT_IRI_ABSOLUTE = /^[A-Za-z][A-Za-z0-9.\-+]*:/;
const R_RELATIVE_URI = /^(\/[^?#]+)([?#].*)?$/;
const R_BASE_IRI = /^((([A-Za-z0-9.\-+]*:\/)?\/[^/>]*)?(\/(?:[^/>]*\/)*)?[^>]*)$/;

const R_ANONYMOUS_BLANK_NODE = /\[\s*\]\s*/y;
const R_CHAR_BLANK_NODE = /\[(?:\s+|(?=[^\]]))/y;
const R_CHAR_COLLECTION = /\(\s*/y;

const R_CHAR_KET = /\]\s*/y;

const R_CHAR_OPEN = /\{\s*/y;
const R_CHAR_CLOSE = /\}\s*/y;

const R_CHAR_STOP = /\.\s*/y;



const R_STRLIT_SHORT_DOUBLE_BREAK = /[\\"\r\n]/g;
const R_STRLIT_SHORT_SINGLE_BREAK = /[\\'\r\n]/g;

const R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM = /"{1,2}$/g;
const R_STRLIT_LONG_SINGLE_UNFINISHED_TERM = /'{1,2}$/g;

const R_STRLIT_LONG_DOUBLE_BREAK = /(\\|""")/g;
const R_STRLIT_LONG_SINGLE_BREAK = /(\\|''')/g;


const F_REPLACE_STRLIT_CONTENTS = (s_, s_whitespace, s_auto, s_4, s_8, s_invalid) => {
	if(s_whitespace) {
		switch(s_whitespace) {
			case 't': return '\t';
			case 'n': return '\n';
			case 'r': return '\r';
			case 'f': return '\f';
			case 'b': return '\b';
			default: {
				console.assert(`bad regex escape char mapping: '${s_whitespace}'`);
			}
		}
	}
	else if(s_auto) {
		return s_auto;
	}
	else if(s_4) {
		return String.fromCodePoint(parseInt(s_4, 16));
	}
	else if(s_8) {
		return String.fromCodePoint(parseInt(s_8, 16));
	}
	else if(s_invalid) {
		// pointless escape
		if('\\' === s_invalid[0]) {
				// // relaxed
				// return s_invalid[1];
			// if relaxed then return s_invalid, otherwise throw:
			throw new Error(`expected string_literal but invalid escape sequence within contents: '${s_invalid}'. failed to parse a valid token`);
		}
		// bad character
		else {
			throw new Error(`expected string_literal but invalid whitespace character within contents: ${JSON.stringify(s_invalid)}. failed to parse a valid token`);
		}
	}
	else {
		console.assert(`unexpected no match branch in escape sequence replace callback`);
	}
};


const R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\.))/g;
const R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_short_hard = s_literal => s_literal
	.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_short_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};


const R_STRLIT_LONG_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|(\\.))/g;
const R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|(\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_long_hard = s_literal => s_literal
	.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_long_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};

// lookbehind regexes
const [
	R_STRLIT_ESCAPE_INCOMPLETE,
	R_STRLIT_SHORT_DOUBLE_TERM,
	R_STRLIT_SHORT_SINGLE_TERM,
	R_STRLIT_LONG_DOUBLE_TERM,
	R_STRLIT_LONG_SINGLE_TERM,
] = (() => {
	function RegExp_$lookbehind_polyfill(s_input) {
		let m_match = RegExp.prototype.exec.call(this, s_input);

		if(m_match) {
			let i_start = m_match[0].length - m_match[1].length;
			m_match.index += i_start;
			m_match[0] = m_match[0].slice(i_start);
		}

		return m_match;
	}
	let mk_lookbehind_regex = (() => {
		try {
			new RegExp('(?<!h)i');  // eslint-disable-line no-new
		}
		catch(e_compile) {
			return (f_lookbehind, r_polyfill, f_polyfill) => {
				r_polyfill.exec = f_polyfill;
				return r_polyfill;
			};
		}
		return f_lookbehind => f_lookbehind();
	})();
	return [
		// R_STRLIT_ESCAPE_INCOMPLETE
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\\\\(|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7})$'),
			/^(?:(?:[^\\]|\\.)*)(\\(?:|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7}))$/,
			function RegExp_$lookbehind_polyfill_n(s_input) {
				let m_match = RegExp.prototype.exec.call(this, s_input);
				if(m_match) {
					m_match.index += m_match[0].length - m_match[1].length;
				}

				return m_match;
			},
		),
		// R_STRLIT_SHORT_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"\\s*', 'g'),
			/(?:[^\\"]|\\.)*("\s*)/y,
			RegExp_$lookbehind_polyfill,
		),
		// R_STRLIT_SHORT_SINGLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\'\\s*', 'g'),
			/(?:[^\\']|\\.)*('\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

		// R_STRLIT_LONG_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"""\\s*', 'g'),
			/(?:[^\\"]|\\.|""?(?!"))*("""\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

		// R_STRLIT_LONG_SINGLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\'\'\'\\s*', 'g'),
			/(?:[^\\']|\\.|''?(?!'))*('''\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

	];
})();

const match_prefixed_name_quick = (s, i) => {
	R_PREFIXED_NAME_QUICK.lastIndex = i;
	return [R_PREFIXED_NAME_QUICK.exec(s), R_PREFIXED_NAME_QUICK.lastIndex];
};

const match_prefixed_name_escapeless = (s, i) => {
	R_PREFIXED_NAME_ESCAPELESS.lastIndex = i;
	return [R_PREFIXED_NAME_ESCAPELESS.exec(s), R_PREFIXED_NAME_ESCAPELESS.lastIndex];
};

const match_prefixed_name = (s, i) => {
	R_PREFIXED_NAME.lastIndex = i;
	return [R_PREFIXED_NAME.exec(s), R_PREFIXED_NAME.lastIndex];
};



function Reader$syntax_error(k_self, i, si_state, s_info) {
	let i_off = Math.min(i, Math.abs(i-15));

	let s = k_self.s;

	return k_self.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
		+` ${' '.repeat(i-i_off)}^\n`
		+`expected ${si_state} ${s_info || ''}.  failed to parse a valid token starting at ${s[i]? '"'+s[i]+'"': '<<EOF>>'}`);
}



class TriG_Reader extends stream.Transform {
	constructor(g_impls) {
		super({
			// do not decode strings into buffers
			decodeStrings: false,

			// accept strings as input on writable side
			writableObjectMode: false,

			// output quad objects on readable side
			readableObjectMode: true,

			// implementations
			flush: g_impls.flush,
			transform: g_impls.transform,
		});
	}

	// intercept pipe
	pipe(ds_out) {
		let ds_dst = ds_out;

		// non-object mode
		if(!ds_dst._writableState.objectMode) {
			// transform to JSON
			ds_out = stream.quads_to_json();
		}
		// yet object mode and graphy writable
		else if(ds_out.isGraphyWritable) {
			// transform to writable data events
			ds_out = stream.quads_to_writable();
		}

		// interim stream created
		if(ds_out !== ds_dst) {
			// forward output to super
			super.pipe(ds_out);

			// pipe outpu to destination
			return ds_out.pipe(ds_dst);
		}
		// forward as-is to super
		else {
			return super.pipe(ds_dst);
		}
	}
}


class Reader {
	constructor(g_config={}) {
		// impl-specific configs
		let {
			// input medium
			input: g_input=null,

			// a state to inherit
			state: g_state={},
		} = g_config;

		// inherit state from creator
		let {
			// index for anonymous blank node labels
			blank_node_index: i_anon=0,

			// prefix map
			prefixes: h_prefixes={},

			// blank node label map
			labels: h_labels={},
		} = g_state;


		let dc_factory = factory.adopt(g_config.dataFactory || g_config.data_factory || factory.unfiltered);

		let kt_default_graph = dc_factory.defaultGraph();

		// if data factory is not graphy, it might be returning the same object on each call to .defaultGraph()
		if(dc_factory !== factory.unfiltered) {
			// do not trust it, create a new object
			kt_default_graph = Object.create(kt_default_graph);
		}

		let kt_rdf_first = dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#first');

		let blankNode = dc_factory.blankNode;
		let namedNode = dc_factory.namedNode;

		this.emit_data = factory.unfiltered === dc_factory
			? function() {
				ds_transform.push(quad(this));
			}
			: function() {
				let g_quad = dc_factory.quad(this._kt_subject, this._kt_predicate, this._kt_object, this._kt_graph);
				ds_transform.push(g_quad);
			};

		// fields
		Object.assign(this, {
			// read index
			i: 0,

			// string buffer
			s: '',

			// string buffer length
			n: 0,

			// left-over string from previous data chunk
			pre: g_config.prepend || '',

			// debug state
			_b_debug: g_config.debug || false,

			// relax
			_b_relax: g_config.relax || false,

			// factory
			_dc_factory: dc_factory,

			// current reader state
			_f_state: this.block,

			// map of current prefix ids => iris
			_h_prefixes: h_prefixes,


			// reader was destroyed by an error
			_b_destroyed: false,

			// current @base url
			_s_base_url: '',
			_s_base_url_scheme: '',
			_s_base_url_root: '',
			_s_base_url_path: '',

			// current data
			_kt_subject: null,
			_kt_predicate: kt_rdf_first,
			_kt_object: null,
			_kt_graph: kt_default_graph,
			_s_literal: '',

			// static terms
			_kt_rdf_type: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'),
			_kt_rdf_first: kt_rdf_first,
			_kt_rdf_rest: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#rest'),
			_kt_rdf_nil: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#nil'),
			_kt_default_graph: kt_default_graph,

			// queue of nested subject, predicate, state for blanknodes and collections
			_a_nested: [],

			// hash to keep track of all blank node labels in use
			_h_labels: h_labels,

			// event routing
			event: this.emit,
			data: this.emit_data,

			// for restoring the original event callback when resuming paused stream
			restore_data: this.emit_data,

			// keep a queue of data events to hold onto until stream resumes (only happens in rare conditions)
			_a_queue_event: [],

			// helper states
			_b_expecting_full_stop: false,
			_s_temp_prefix_id: null,
			_b_trim_start: true,

			anonymous_blank_node: s_label => blankNode(s_label, true),

			// finds the next non-conflicting blank node label
			next_label() {
				let s_label = '';
				do {
					s_label = 'g'+(i_anon++);
				} while(this._h_labels[s_label]);

				// claim this label, and remember that we invented it
				this._h_labels[s_label] = 2;

				// return the label
				return s_label;
			},

			// what to do when reach eos
			eos: null,

			// which state to go to after end of statement
			after_end_of_statement: this.post_object,

			// maximum length of a token: defaults to 2048 => http://stackoverflow.com/a/417184/1641160
			_n_max_token_length: g_config.max_token_length || g_config.maxTokenLength || 2048,

			// maximum length of a string (overrides max_token_length): defaults to Infinity
			_n_max_string_length: g_config.max_string_length || g_config.maxStringLength || Infinity,

			// byte tracking
			_b_byte_tracking: g_config.byte_tracking || g_config.byteTracking || false,
			_nb_seen: 0,
			_nb_last: 0,
			_nb_curr: 0,
		});

		if(g_config.relaxed) {
			console.warn((new Error(`no such option 'relaxed'; did you mean 'relax' ?`)).stack.replace(/^Error:/, 'Warning:'));
		}
		if('validate' in g_config) {
			console.warn((new Error(`option 'validate' has been deprecated. Validation is now enabled by default. Use the 'relax' option if you wish to disable validation.`)).stack.replace(/^Error:/, 'Warning:'));
		}



		// term constructors
		Object.assign(this, !g_config.relax
			? {
				blank_node(s_label) {
					// test valid blank node label
					if(!RT_BLANK_NODE_VALID.test(s_label)) return this.error(`invalid blank node label: "${s_label}"`);

					// not first time use of label
					let z_label_state = this._h_labels[s_label];
					if(z_label_state) {
						// label was used previously by document and has no conflict
						if(1 === z_label_state) {}  // eslint-disable-line no-empty
						// label is in use by invention, this would cause a conflict
						else if(2 === z_label_state) {
							// so create a redirect mapping for this actual label & use it instead
							s_label = this._h_labels[s_label] = this.next_label();
						}
						// label already has a redirect mapping
						else {
							// use redirected label
							s_label = this._h_labels[s_label];
						}
					}
					// first time use of label
					else {
						// store label in hash so we avoid future collisions
						this._h_labels[s_label] = 1;
					}

					// make term
					return blankNode(s_label);
				},

				check_named_node(p_iri) {
					if(!RT_NAMED_NODE_VALID.test(p_iri)) return this.error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				check_named_node_escapeless(p_iri) {
					if(!RT_NAMED_NODE_ESCAPELESS_VALID.test(p_iri)) return this.error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				match_prefixed_name_quick(s, i) {
					R_PREFIXED_NAME_QUICK.lastIndex = i;
					return [R_PREFIXED_NAME_QUICK.exec(s), R_PREFIXED_NAME_QUICK.lastIndex];
				},

				match_prefixed_name_escapeless(s, i) {
					let [m_prefixed_name_e, im_prefixed_name_e] = match_prefixed_name_escapeless(s, i);
					if(m_prefixed_name_e) {
						// invalid local name
						if(!RT_PREFIXED_NAME_LOCAL_NAME_VALID.test(m_prefixed_name_e[2]) && m_prefixed_name_e[2]) {
							this.error(`invalid prefixed name local name: "${m_prefixed_name_e[2]}:"`);
							return;
						}
					}

					return [m_prefixed_name_e, im_prefixed_name_e];
				},

				match_prefixed_name(s, i) {
					let [m_prefixed_name, im_prefixed_name] = match_prefixed_name(s, i);
					if(m_prefixed_name) {
						// invalid local name
						if(!RT_PREFIXED_NAME_LOCAL_NAME_VALID.test(m_prefixed_name[2])) {
							this.error(`invalid prefixed name local name: "${m_prefixed_name[2]}:"`);
							return;
						}
					}

					return [m_prefixed_name, im_prefixed_name];
				},
			}
			: {
				// term constructors
				blank_node(s_label) {
					// not first time use of label
					let z_label_state = this._h_labels[s_label];
					if(z_label_state) {
						// label was used previously by document and has no conflict
						if(1 === z_label_state) {}  // eslint-disable-line no-empty
						// label is in use by invention, this would cause a conflict
						else if(2 === z_label_state) {
							// so create a redirect mapping for this actual label & use it instead
							s_label = this._h_labels[s_label] = this.next_label();
						}
						// label already has a redirect mapping
						else {
							// use redirected label
							s_label = this._h_labels[s_label];
						}
					}
					// first time use of label
					else {
						// store label in hash so we avoid future collisions
						this._h_labels[s_label] = 1;
					}

					// make term
					return blankNode(s_label);
				},

				check_named_node: namedNode,

				check_named_node_escapeless: namedNode,

				match_prefixed_name_escapeless,

				match_prefixed_name,
			});


		this.named_node = namedNode;

		this.prefixed_name = function(si_prefix, s_suffix) {
			return namedNode(h_prefixes[si_prefix] + s_suffix);
		};


		// oops -- user passed string into `base`
		if('string' === typeof g_config.base) {
			throw new TypeError(`invalid type 'string' was given for 'base' event listener: '${g_config.base}'\n`
				+`did you mean to use the 'base_uri' key instead?`);
		}

		// base uri
		let p_set_base_uri = g_config.base_uri || g_config.baseUri || g_config.baseURI || g_config.base_iri || g_config.baseIri || g_config.baseIRI;
		if(p_set_base_uri) {
			let m_base_iri = R_BASE_IRI.exec(p_set_base_uri);
			this._s_base_url = m_base_iri[1];
			this._s_base_url_root = m_base_iri[2] || '';
			this._s_base_url_scheme = m_base_iri[3] || '';
			this._s_base_url_path = m_base_iri[4] || '';
		}
		// not set; 'url' variant is
		else if(g_config.base_url || g_config.baseUrl || g_config.baseURL) {
			throw new Error(`invalid option: .base${g_config.base_url? '_url': g_config.baseUrl? 'Url': g_config.baseURL? 'URL': ''}; use the '.base_uri' key instead`);
		}

		// transform stream
		let ds_transform = this.transform = new TriG_Reader({
			// on data event
			transform: (s_chunk, s_encoding, fke_chunk) => {
				// concatenate current chunk to previous chunk
				let s = this.s = this.pre + s_chunk;

				// cache chunk length
				this.n = s.length;

				// eat whitespace before token and reset index
				if(this._b_trim_start) {
					// consume whitespace (and incidentally reset index)
					R_WS.lastIndex = 0;
					R_WS.exec(s);
					this.i = R_WS.lastIndex;
				}
				// do not eat whitespace; start at beginning
				else {
					this.i = 0;
				}

				// resume parsing; no errors
				if(this.safe_parse(true)) {
					// emit progress event updates
					ds_transform.emit('progress', s_chunk.length);

					// done transforming this chunk
					fke_chunk();
				}
			},

			// once there's no more data to consume, invoke eof
			flush: (fke_flush) => {
				// now that input stream has ended, clean up remainder
				try {
					this.eof(1);
				}
				// read error occurred
				catch(e_eof) {
					// destroy self and stream
					this.destroy(e_eof);

					// exit gracefully
					return;
				}

				// no errors. done flushing, close read stream
				fke_flush();
			},
		});

		// when the writable side is piped into
		ds_transform.on('pipe', (ds_input) => {
			this._ds_input = ds_input;

			let b_byte_tracking = this._b_byte_tracking;

			// byte-tracking is disable & input stream has encoding option; ensure stream encoding is utf8
			if(!b_byte_tracking && 'function' === typeof ds_input.setEncoding) {
				ds_input.setEncoding('utf8');
			}
			// set decoding on write
			else {
				let f_write = ds_transform.write;
				let d_decoder = new string_decoder.StringDecoder('utf8');

				let f_write_track = (s_chunk, s_encoding, fk_write) => {
					// TODO: optimize by testing for multibyte chars and using string length instead?
					let nb_chunk = Buffer.from(s_chunk, 'utf8').length;
					this._nb_seen += nb_chunk;
					this._nb_last = nb_chunk;
					return f_write.call(ds_transform, s_chunk, s_encoding, fk_write);
				};

				let f_decode_write_track = (ab_chunk, s_encoding, fk_write) => {
					let nb_chunk = this._nb_last = ab_chunk.length;
					this._nb_seen += nb_chunk;
					return f_write.call(ds_transform, d_decoder.write(ab_chunk), s_encoding, fk_write);
				};

				let f_decode_write = (ab_chunk, s_encoding, fk_write) => f_write.call(ds_transform, d_decoder.write(ab_chunk), s_encoding, fk_write);

				ds_transform.write = function(z_chunk, s_encoding, fk_write) {
					// not null
					if(null !== z_chunk) {
						// chunk is string; adapt by resetting method to original
						if('string' === typeof z_chunk) {
							ds_transform.write = b_byte_tracking? f_write_track: f_write;
						}
						// chunk is buffer; adapt by setting decoder write method
						else {
							ds_transform.write = b_byte_tracking? f_decode_write_track: f_decode_write;
						}

						// use set method
						return ds_transform.write(z_chunk, s_encoding, fk_write);
					}

					// null, use parent
					return f_write.call(ds_transform, z_chunk, s_encoding, fk_write);
				};

				// byte tracking is enabled
				if(b_byte_tracking) {
					// overwrite emit_data method
					this.emit_data = this.data = this.restore_data = function() {
						let g_quad = this._dc_factory.quad(this._kt_subject, this._kt_predicate, this._kt_object, this._kt_graph);
						let nb_post = Buffer.from(this.s.slice(this.i)).length;
						let ib_post = this._nb_seen - nb_post;
						g_quad.byteRange = [this._nb_curr, ib_post];
						this._nb_curr = ib_post;
						this.transform.push(g_quad);
					};
				}
			}
		});

		// new listener added
		ds_transform.on('newListener', (s_event) => {
			// comment
			if('comment' === s_event) {
				this.emit_comments = (s_captured) => {
					let a_comments = s_captured.slice(1).replace(/\n\s+$/, '').split(/\n+\s*#/g);

					for(let s_comment of a_comments) {
						ds_transform.emit('comment', s_comment);
					}
				};
			}
		});

		// destroy
		ds_transform._destroy = (...a_args) => {
			this.destroy(...a_args);
		};

		// bind events to transform stream
		this.bind(g_config);

		// input given
		if(g_input) {
			// input is stream
			if(g_input.stream) {
				let ds_input = g_input.stream;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_input.pipe(ds_transform);
				});
			}
			// string
			else if('string' === typeof g_input.string) {
				let s_input = g_input.string;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_transform.end(s_input, 'utf8');
				});
			}
			// invalid arg
			else {
				throw new TypeError(`Invalid argument for input parameter: ${'object' === typeof g_input? JSON.stringify(g_input): g_input}`);
			}
		}
	}

	// begin parsing, keep applying until no more stack bail-outs
	safe_parse() {
		try {
			let f_sync = this._f_state();
			while('function' === typeof f_sync) {
				f_sync = f_sync.apply(this);
			}
		}
		// read error occurred
		catch(e_read) {
			// destroy self and stream
			this.destroy(e_read);

			// failure
			return false;
		}

		// okay
		return true;
	}


	emit(s_event, ...a_args) {
		this.transform.emit(s_event, ...a_args);
	}

	queue(s_event, ...a_args) {
		this._a_queue_event.push({
			event: s_event,
			args: a_args,
		});
	}

	error(s_message) {
		// bail out
		throw new Error(s_message);
	}

	// parse_error (not meant to be an event callback)
	parse_error(s_expected, b_eof=false) {
		let i = this.i;

		let i_off = Math.min(i, Math.abs(i-15));

		let s = this.s;

		return this.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
			+` ${' '.repeat(i-i_off)}^\n`
			+`expected ${s_expected} ${b_eof? 'but encountered <<EOF>>': ''}.  failed to parse a valid token starting at ${s[i]? '"'+s[i]+'"': '<<EOF>>'}`);
	}

	info_error(s_message) {
		let i = this.i;

		let i_off = Math.min(i, Math.abs(i-15));

		let s = this.s;

		this.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
			+` ${' '.repeat(i-i_off)}^\n`
			+s_message);
	}

	// end of file
	eof() {
		// there are events queued
		if(this._a_queue_event.length) {
			let a_queue = this._a_queue_event;

			// drain event queue
			while(a_queue.length) {
				// remove event from front of queue
				let h_event = a_queue.shift();

				// make event callback
				this[h_event.event](h_event.data);
			}
		}

		// invalid parsing state
		if(this.block !== this._f_state) {
			// append EOF char
			this.s += '\0';

			// exit "flowing" mode
			this.n = this.s.length;

			// resume parsing; no errors
			if(this.safe_parse()) {
				// eof has occurred under safe parse
				if(null === this.s) return;

				// still invalid parsing state
				if(this.block !== this._f_state) {
					return this.parse_error(this._f_state.name, true);
				}
			}
		}

		// there are still unparsed characters
		if(this.i < this.n) {
			// consume whitespace and comments
			let s = this.s;
			let i = this.i;
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i;
			R_WS.exec(s);
			i = R_WS.lastIndex;
			R_COMMENT.lastIndex = i;
			let m_comment = R_COMMENT.exec(s);

			// advance beyond comment
			if(R_COMMENT.lastIndex > i) {
				this.i = i = R_COMMENT.lastIndex;
				if(this.emit_comments) this.emit_comments(m_comment[0]);
			}

			// still unparsed characters
			if(i < this.n) {
				// not EOF
				if(!(i === this.n - 1 && '\0' === s[i])) {
					// bad input; parse error
					return this.parse_error(this._f_state.name);
				}
			}
		}

		// make buffer's alloc eligible for gc
		this.s = null;

		// transform stream
		let ds_transform = this.transform;

		// final progress update: no additional bytes were read
		ds_transform.emit('progress', 0);

		// call end event listener
		ds_transform.emit('eof', this._h_prefixes);

		// close write stream (EOF-signaling)
		ds_transform.push(null);
	}



	// bind event listeners to transform stream
	bind(g_config) {
		let ds_transform = this.transform;
		if(g_config.base) ds_transform.on('base', g_config.base);
		if(g_config.prefix) ds_transform.on('prefix', g_config.prefix);
		if(g_config.enter) ds_transform.on('enter', g_config.enter);
		if(g_config.exit) ds_transform.on('exit', g_config.exit);
		if(g_config.comment) ds_transform.on('comment', g_config.comment);
		if(g_config.error) ds_transform.on('error', g_config.error);
		if(g_config.read) ds_transform.once('read', g_config.read);
		if(g_config.progress) ds_transform.on('progress', g_config.progress);
		if(g_config.eof) ds_transform.once('eof', g_config.eof);
		if(g_config.end) ds_transform.once('end', g_config.end);
		if(g_config.finish) ds_transform.once('finish', g_config.finish);
		if(g_config.data) ds_transform.on('data', g_config.data);
	}

	// after a blank node subject (either property-list or colleciton)
	post_blank_subject() {
		let {s, i} = this;
		if('.' === s[i]) {
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i+1;
			R_WS.exec(s);
			this.i = R_WS.lastIndex;

			// not inside block
			if(this._kt_default_graph === this._kt_graph) {
				return this.block();
			}
			// inside block
			else {
				return this.statement();
			}
		}
		else {
			// prepare sticky regex index
			R_CHAR_CLOSE.lastIndex = i;

			if(R_CHAR_CLOSE.exec(s)) {
				// advance index
				this.i = R_CHAR_CLOSE.lastIndex;
				// empty collection
				if(this._kt_rdf_nil.equals(this._kt_subject)) {
					return this.error('empty collection');
				}

				// emit graph_close event
				this.emit('exit', this._kt_graph);

				// reset graph
				this._kt_graph = this._kt_default_graph;

				// goto block state
				return this.block();
			}
		} // brace #1

		return this.pairs();
	}



	// parse state for statement
	statement() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefixed name quick

			// prepare sticky regex index
			R_PREFIXED_NAME_QUICK.lastIndex = i;
			// execute regex
			let m_pnq_subject = R_PREFIXED_NAME_QUICK.exec(s);

			// regex was a match
			if(m_pnq_subject) {
				// advance index
				this.i = R_PREFIXED_NAME_QUICK.lastIndex;
				// check valid prefix
				let s_prefix_id = m_pnq_subject[1] || '';
				// invalid prefix
				if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


				// commit subject iri from resolve prefixed name
				this._kt_subject = this.prefixed_name(s_prefix_id, m_pnq_subject[2]);

				// predicate-object pairs state
				return this.pairs();

			// iriref
			}
			else {
				// prepare sticky regex index
				R_IRIREF_ESCAPELESS.lastIndex = i;
				// execute regex
				let m_iriref_e_subject = R_IRIREF_ESCAPELESS.exec(s);

				// regex was a match
				if(m_iriref_e_subject) {
					// advance index
					this.i = R_IRIREF_ESCAPELESS.lastIndex;

					// ref iri
					let s_iri = m_iriref_e_subject[1];
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set subject
						this._kt_subject = this.check_named_node_escapeless(s_iri);
					}
					// relative iri
					else {
						this._kt_subject = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
					}

					// predicate-object pairs state
					return this.pairs();



				// prefixed name
				}
				else {
					// try match
					let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
					// stack bail out
					if(!aw_valid_this_match_prefixed_name_escapeless) return true;
					let [m_prefixed_named_e_subject, im_prefixed_named_e_subject] = aw_valid_this_match_prefixed_name_escapeless;
					if(m_prefixed_named_e_subject) {
						// advance index
						this.i = im_prefixed_named_e_subject;

						// check valid prefix
						let s_prefix_id = m_prefixed_named_e_subject[1] || '';
						// invalid prefix
						if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


						// make subject key
						this._kt_subject = this.prefixed_name(s_prefix_id, m_prefixed_named_e_subject[2]);

						// predicate-object pairs state
						return this.pairs();

					// blank node label
					}
					else {
						// prepare sticky regex index
						R_BLANK_NODE_LABEL.lastIndex = i;
						// execute regex
						let m_blank_node_label_subject = R_BLANK_NODE_LABEL.exec(s);

						// regex was a match
						if(m_blank_node_label_subject) {
							// advance index
							this.i = R_BLANK_NODE_LABEL.lastIndex;
							// extract label
							let s_label = m_blank_node_label_subject[1];

							// make subject key
							this._kt_subject = this.blank_node(s_label);

							// predicate-object pairs state
							return this.pairs();

						// anonymous blank node subject
						}
						else {
							// prepare sticky regex index
							R_ANONYMOUS_BLANK_NODE.lastIndex = i;

							if(R_ANONYMOUS_BLANK_NODE.exec(s)) {
								// advance index
								this.i = R_ANONYMOUS_BLANK_NODE.lastIndex;
								// set new blank node as subject
								this._kt_subject = this.anonymous_blank_node(this.next_label());

								// goto pairs state for inside property list
								return this.pairs();

							// anonymous blank node property list subject
							}
							else {
								// prepare sticky regex index
								R_CHAR_BLANK_NODE.lastIndex = i;

								if(R_CHAR_BLANK_NODE.exec(s)) {
									// advance index
									this.i = R_CHAR_BLANK_NODE.lastIndex;
									// enter blank node
									this._kt_subject = this.anonymous_blank_node(this.next_label());

									// how to resume when we pop state
									this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_blank_subject']);

									// goto pairs state for inside property list
									return this.pairs();

								// rdf collection
								}
								else {
									// prepare sticky regex index
									R_CHAR_COLLECTION.lastIndex = i;

									if(R_CHAR_COLLECTION.exec(s)) {
										// advance index
										this.i = R_CHAR_COLLECTION.lastIndex;
										// indicate that collection subject should emit an initial statement
										this._kt_subject = null;

// (don't push state, we don't have a subject yet)

										// goto collection-subject state
										return this.collection_subject();


									// closing graph '}'
									}
									else {
										// prepare sticky regex index
										R_CHAR_CLOSE.lastIndex = i;

										if(R_CHAR_CLOSE.exec(s)) {
											// advance index
											this.i = R_CHAR_CLOSE.lastIndex;
											// emit graph_close event
											this.emit('exit', this._kt_graph);

											// reset graph
											this._kt_graph = this._kt_default_graph;

											// goto block state
											return this.block();

										// iriref
										}
										else {
											// prepare sticky regex index
											R_IRIREF.lastIndex = i;
											// execute regex
											let m_iriref_subject = R_IRIREF.exec(s);

											// regex was a match
											if(m_iriref_subject) {
												// advance index
												this.i = R_IRIREF.lastIndex;

												// ref iri
												let s_iri = m_iriref_subject[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
												// absolute iri
												if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
													// set subject
													this._kt_subject = this.check_named_node(s_iri);
												}
												// relative iri
												else {
													this._kt_subject = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
												}

												// predicate-object pairs state
												return this.pairs();

											// prefixed name
											}
											else {
												// try match
												let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
												// stack bail out
												if(!aw_valid_this_match_prefixed_name) return true;
												let [m_prefixed_named_subject, im_prefixed_named_subject] = aw_valid_this_match_prefixed_name;
												if(m_prefixed_named_subject) {
													// advance index
													this.i = im_prefixed_named_subject;
													// check valid prefix
													let s_prefix_id = m_prefixed_named_subject[1] || '';
													// invalid prefix
													if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


													// escape local escapes
													let s_suffix = m_prefixed_named_subject[2]
														.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
														.replace(R_PN_LOCAL_ESCAPES, '$1');

													// make subject key
													this._kt_subject = this.prefixed_name(s_prefix_id, s_suffix);

													// predicate-object pairs state
													return this.pairs();


												// comment
												}
												else {
													// prepare sticky regex index
													R_COMMENT.lastIndex = i;
													// execute regex
													let m_comment = R_COMMENT.exec(s);

													// regex was a match
													if(m_comment) {
														// advance index
														i = R_COMMENT.lastIndex;
														if(this.emit_comments) this.emit_comments(m_comment[0]);
														continue;

			// not iriref, not prefixed name, not blank node label, not prefix id, not base
			// match counter: 10
													}
													else {
														// break loop to retry on next chunk if eos
														break;
													}
												} // brace #10
											} // brace #9
										} // brace #8
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('statement');
				}
			}
		}

		// save state before pausing
		this._f_state = this.statement;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for block
	block() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// prepare sticky regex index
			R_GRAPH_IRI_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_graph_iriref_e_graph = R_GRAPH_IRI_ESCAPELESS.exec(s);

			// regex was a match
			if(m_graph_iriref_e_graph) {
				// advance index
				this.i = R_GRAPH_IRI_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_graph_iriref_e_graph[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set graph
					this._kt_graph = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_graph = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

				this.emit('enter', this._kt_graph);

				// statement state
				return this.statement();
			}
			else {
				// prepare sticky regex index
				R_GRAPH_PREFIXED_NAME.lastIndex = i;
				// execute regex
				let m_graph_prefixed_name = R_GRAPH_PREFIXED_NAME.exec(s);

				// regex was a match
				if(m_graph_prefixed_name) {
					// advance index
					this.i = R_GRAPH_PREFIXED_NAME.lastIndex;
					// check valid prefix
					let s_prefix_id = m_graph_prefixed_name[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// make subject key
					this._kt_graph = this.prefixed_name(s_prefix_id, m_graph_prefixed_name[2]);

					this.emit('enter', this._kt_graph);

					// statement state
					return this.statement();
				}
				else {
					// prepare sticky regex index
					R_CHAR_OPEN.lastIndex = i;

					if(R_CHAR_OPEN.exec(s)) {
						// advance index
						this.i = R_CHAR_OPEN.lastIndex;
						// make new default graph
						this._kt_graph = this._dc_factory.defaultGraph();

						this.emit('enter', this._kt_graph);

						// goto statement state
						return this.statement();
					}
					else {
						// prepare sticky regex index
						R_GRAPH_ANONYMOUS_BLANK_NODE.lastIndex = i;
						// execute regex
						let m_graph_anonymous_blank_node = R_GRAPH_ANONYMOUS_BLANK_NODE.exec(s);

						// regex was a match
						if(m_graph_anonymous_blank_node) {
							// advance index
							this.i = R_GRAPH_ANONYMOUS_BLANK_NODE.lastIndex;
							// make new label & set graph to blank node
							this._kt_graph = this.anonymous_blank_node(this.next_label());

							this.emit('enter', this._kt_graph);

							// statement state
							return this.statement();
						}
						else {
							// prepare sticky regex index
							R_GRAPH_LABELED_BLANK_NODE.lastIndex = i;
							// execute regex
							let m_graph_labeled_blank_node = R_GRAPH_LABELED_BLANK_NODE.exec(s);

							// regex was a match
							if(m_graph_labeled_blank_node) {
								// advance index
								this.i = R_GRAPH_LABELED_BLANK_NODE.lastIndex;
								let s_label = m_graph_labeled_blank_node[1];

								this._kt_graph = this.blank_node(s_label);

								this.emit('enter', this._kt_graph);

								// statement state
								return this.statement();

							// iriref
							}
							else {
								// prepare sticky regex index
								R_IRIREF_ESCAPELESS.lastIndex = i;
								// execute regex
								let m_iriref_e_graph_subject = R_IRIREF_ESCAPELESS.exec(s);

								// regex was a match
								if(m_iriref_e_graph_subject) {
									// advance index
									this.i = R_IRIREF_ESCAPELESS.lastIndex;

									// ref iri
									let s_iri = m_iriref_e_graph_subject[1];
									// absolute iri
									if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
										// set subject
										this._kt_subject = this.check_named_node_escapeless(s_iri);
									}
									// relative iri
									else {
										this._kt_subject = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
									}

									// graph or subject
									return this.graph_or_subject();



								// prefixed name
								}
								else {
									// try match
									let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
									// stack bail out
									if(!aw_valid_this_match_prefixed_name_escapeless) return true;
									let [m_prefixed_named_e_subject, im_prefixed_named_e_subject] = aw_valid_this_match_prefixed_name_escapeless;
									if(m_prefixed_named_e_subject) {
										// advance index
										this.i = im_prefixed_named_e_subject;

										// check valid prefix
										let s_prefix_id = m_prefixed_named_e_subject[1] || '';
										// invalid prefix
										if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


										// make subject key
										this._kt_subject = this.prefixed_name(s_prefix_id, m_prefixed_named_e_subject[2]);

										// predicate-object pairs state
										return this.graph_or_subject();

									// blank node label
									}
									else {
										// prepare sticky regex index
										R_BLANK_NODE_LABEL.lastIndex = i;
										// execute regex
										let m_blank_node_label_subject = R_BLANK_NODE_LABEL.exec(s);

										// regex was a match
										if(m_blank_node_label_subject) {
											// advance index
											this.i = R_BLANK_NODE_LABEL.lastIndex;
											// extract label
											let s_label = m_blank_node_label_subject[1];

											// make subject key
											this._kt_subject = this.blank_node(s_label);

											// predicate-object pairs state
											return this.graph_or_subject();

										// anonymous blank node subject
										}
										else {
											// prepare sticky regex index
											R_ANONYMOUS_BLANK_NODE.lastIndex = i;

											if(R_ANONYMOUS_BLANK_NODE.exec(s)) {
												// advance index
												this.i = R_ANONYMOUS_BLANK_NODE.lastIndex;
												// set new blank node as subject
												this._kt_subject = this.anonymous_blank_node(this.next_label());

												// goto pairs state for inside property list
												return this.graph_or_subject();

											// anonymous blank node property list subject
											}
											else {
												// prepare sticky regex index
												R_CHAR_BLANK_NODE.lastIndex = i;

												if(R_CHAR_BLANK_NODE.exec(s)) {
													// advance index
													this.i = R_CHAR_BLANK_NODE.lastIndex;
													// enter blank node
													this._kt_subject = this.anonymous_blank_node(this.next_label());

													// how to resume when we pop state
													this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_blank_subject']);

													// goto pairs state for inside property list
													return this.graph_or_subject_property_list();

												// rdf collection
												}
												else {
													// prepare sticky regex index
													R_CHAR_COLLECTION.lastIndex = i;

													if(R_CHAR_COLLECTION.exec(s)) {
														// advance index
														this.i = R_CHAR_COLLECTION.lastIndex;
														// indicate that collection subject should emit an initial statement
														this._kt_subject = null;

// (don't push state, we don't have a subject yet)

														// goto collection-subject state
														return this.collection_subject();

													// prefix with interupt (e.g., a comment)
													}
													else {
														// prepare sticky regex index
														R_PREFIX_KEYWORD.lastIndex = i;
														// execute regex
														let m_prefix_keyword = R_PREFIX_KEYWORD.exec(s);

														// regex was a match
														if(m_prefix_keyword) {
															// advance index
															this.i = R_PREFIX_KEYWORD.lastIndex;
															// save whether or not to expect a full stop
															this._b_expecting_full_stop = !!m_prefix_keyword[1];

															// goto prefix state
															return this.prefix_id();

														// base with interupt (e.g., a comment)
														}
														else {
															// prepare sticky regex index
															R_BASE_KEYWORD.lastIndex = i;
															// execute regex
															let m_base_keyword = R_BASE_KEYWORD.exec(s);

															// regex was a match
															if(m_base_keyword) {
																// advance index
																this.i = R_BASE_KEYWORD.lastIndex;
																// save whether or not to expect a full stop
																this._b_expecting_full_stop = !!m_base_keyword[1];

																// goto base state
																return this.base_iri();


															// iriref
															}
															else {
																// prepare sticky regex index
																R_IRIREF.lastIndex = i;
																// execute regex
																let m_iriref_subject = R_IRIREF.exec(s);

																// regex was a match
																if(m_iriref_subject) {
																	// advance index
																	this.i = R_IRIREF.lastIndex;

																	// ref iri
																	let s_iri = m_iriref_subject[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
																	// absolute iri
																	if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
																		// set subject
																		this._kt_subject = this.check_named_node(s_iri);
																	}
																	// relative iri
																	else {
																		this._kt_subject = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
																	}

																	// predicate-object pairs state
																	return this.graph_or_subject();

																// prefixed name
																}
																else {
																	// try match
																	let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
																	// stack bail out
																	if(!aw_valid_this_match_prefixed_name) return true;
																	let [m_prefixed_named_subject, im_prefixed_named_subject] = aw_valid_this_match_prefixed_name;
																	if(m_prefixed_named_subject) {
																		// advance index
																		this.i = im_prefixed_named_subject;
																		// check valid prefix
																		let s_prefix_id = m_prefixed_named_subject[1] || '';
																		// invalid prefix
																		if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


																		// escape local escapes
																		let s_suffix = m_prefixed_named_subject[2]
																			.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
																			.replace(R_PN_LOCAL_ESCAPES, '$1');

																		// make subject key
																		this._kt_subject = this.prefixed_name(s_prefix_id, s_suffix);

																		// predicate-object pairs state
																		return this.graph_or_subject();
																	}
																	else {
																		// prepare sticky regex index
																		R_GRAPH_IRI.lastIndex = i;
																		// execute regex
																		let m_graph_iriref_graph = R_GRAPH_IRI.exec(s);

																		// regex was a match
																		if(m_graph_iriref_graph) {
																			// advance index
																			this.i = R_GRAPH_IRI.lastIndex;

																			// ref iri
																			let s_iri = m_graph_iriref_graph[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
																			// absolute iri
																			if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
																				// set graph
																				this._kt_graph = this.check_named_node(s_iri);
																			}
																			// relative iri
																			else {
																				this._kt_graph = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
																			}

																			this.emit('enter', this._kt_graph);

																			// statement state
																			return this.statement();

																		// comment
																		}
																		else {
																			// prepare sticky regex index
																			R_COMMENT.lastIndex = i;
																			// execute regex
																			let m_comment = R_COMMENT.exec(s);

																			// regex was a match
																			if(m_comment) {
																				// advance index
																				i = R_COMMENT.lastIndex;
																				if(this.emit_comments) this.emit_comments(m_comment[0]);
																				continue;
																			}
																			else {
																				// prepare sticky regex index
																				R_GRAPH.lastIndex = i;

																				if(R_GRAPH.exec(s)) {
																					// advance index
																					this.i = R_GRAPH.lastIndex;
																					return this.graph_keyword();

				// not iriref, not prefixed name, not blank node label, not prefix id, not base
				// match counter: 17
																				}
																				else {
																					// break loop to retry on next chunk if eos
																					break;
																				}
																			} // brace #17
																		} // brace #16
																	} // brace #15
																} // brace #14
															} // brace #13
														} // brace #12
													} // brace #11
												} // brace #10
											} // brace #9
										} // brace #8
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('block');
				}
			}
		}

		// save state before pausing
		this._f_state = this.block;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for graph_or_subject
	graph_or_subject() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let x = s[i];

			if('{' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// shift placeholder subject
				this._kt_graph = this._kt_subject;

				this.emit('enter', this._kt_graph);

				// reset subject in case of collections
				this._kt_subject = null;

				// statement state
				return this.statement();

			// non-comment
			}
			else if('#' !== x) {
				return this.pairs();

			// comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('graph_or_subject');
				}
			}
		}

		// save state before pausing
		this._f_state = this.graph_or_subject;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for graph_or_subject_property_list
	graph_or_subject_property_list() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let x = s[i];

			if(']' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// next state
				return this.graph_or_subject_anon();

			// non-comment
			}
			else if('#' !== x) {
				return this.pairs();

			// comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('graph_or_subject_property_list');
				}
			}
		}

		// save state before pausing
		this._f_state = this.graph_or_subject_property_list;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for graph_or_subject_anon
	graph_or_subject_anon() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let x = s[i];

			if('{' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// shift placeholder subject
				this._kt_graph = this._kt_subject;

				this.emit('enter', this._kt_graph);

				// reset subject in case of collections
				this._kt_subject = null;

				// pop dummy state
				this._a_nested.pop();

				// statement state
				return this.statement();

			// non-comment
			}
			else if('#' !== x) {
				return this.pairs();

			// comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('graph_or_subject_anon');
				}
			}
		}

		// save state before pausing
		this._f_state = this.graph_or_subject_anon;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for graph_keyword
	graph_keyword() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// prefixed name
			// try match
			let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
			// stack bail out
			if(!aw_valid_this_match_prefixed_name_escapeless) return true;
			let [m_prefixed_named_e_graph, im_prefixed_named_e_graph] = aw_valid_this_match_prefixed_name_escapeless;
			if(m_prefixed_named_e_graph) {
				// advance index
				this.i = im_prefixed_named_e_graph;

				// check valid prefix
				let s_prefix_id = m_prefixed_named_e_graph[1] || '';
				// invalid prefix
				if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


				// make subject key
				this._kt_graph = this.prefixed_name(s_prefix_id, m_prefixed_named_e_graph[2]);

				// predicate-object pairs state
				return this.graph_post_name();

			// iriref
			}
			else {
				// prepare sticky regex index
				R_IRIREF_ESCAPELESS.lastIndex = i;
				// execute regex
				let m_iriref_e_graph = R_IRIREF_ESCAPELESS.exec(s);

				// regex was a match
				if(m_iriref_e_graph) {
					// advance index
					this.i = R_IRIREF_ESCAPELESS.lastIndex;

					// ref iri
					let s_iri = m_iriref_e_graph[1];
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set graph
						this._kt_graph = this.check_named_node_escapeless(s_iri);
					}
					// relative iri
					else {
						this._kt_graph = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
					}

					// graph
					return this.graph_post_name();

				// blank node label
				}
				else {
					// prepare sticky regex index
					R_BLANK_NODE_LABEL.lastIndex = i;
					// execute regex
					let m_blank_node_label_graph = R_BLANK_NODE_LABEL.exec(s);

					// regex was a match
					if(m_blank_node_label_graph) {
						// advance index
						this.i = R_BLANK_NODE_LABEL.lastIndex;
						// extract label
						let s_label = m_blank_node_label_graph[1];

						// make graph key
						this._kt_graph = this.blank_node(s_label);

						// predicate-object pairs state
						return this.graph_post_name();

					// anonymous blank node graph
					}
					else {
						// prepare sticky regex index
						R_ANONYMOUS_BLANK_NODE.lastIndex = i;

						if(R_ANONYMOUS_BLANK_NODE.exec(s)) {
							// advance index
							this.i = R_ANONYMOUS_BLANK_NODE.lastIndex;
							// set new blank node as graph
							this._kt_graph = this.anonymous_blank_node(this.next_label());

							// goto pairs state for inside property list
							return this.graph_post_name();

						// iriref
						}
						else {
							// prepare sticky regex index
							R_IRIREF.lastIndex = i;
							// execute regex
							let m_iriref_graph = R_IRIREF.exec(s);

							// regex was a match
							if(m_iriref_graph) {
								// advance index
								this.i = R_IRIREF.lastIndex;

								// ref iri
								let s_iri = m_iriref_graph[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
								// absolute iri
								if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
									// set graph
									this._kt_graph = this.check_named_node(s_iri);
								}
								// relative iri
								else {
									this._kt_graph = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
								}

								// predicate-object pairs state
								return this.graph_post_name();

							// prefixed name
							}
							else {
								// try match
								let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
								// stack bail out
								if(!aw_valid_this_match_prefixed_name) return true;
								let [m_prefixed_named_graph, im_prefixed_named_graph] = aw_valid_this_match_prefixed_name;
								if(m_prefixed_named_graph) {
									// advance index
									this.i = im_prefixed_named_graph;
									// check valid prefix
									let s_prefix_id = m_prefixed_named_graph[1] || '';
									// invalid prefix
									if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


									// escape local escapes
									let s_suffix = m_prefixed_named_graph[2]
										.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
										.replace(R_PN_LOCAL_ESCAPES, '$1');

									// make subject key
									this._kt_graph = this.prefixed_name(s_prefix_id, s_suffix);

									// predicate-object pairs state
									return this.graph_post_name();

								// comment
								}
								else {
									// prepare sticky regex index
									R_COMMENT.lastIndex = i;
									// execute regex
									let m_comment = R_COMMENT.exec(s);

									// regex was a match
									if(m_comment) {
										// advance index
										i = R_COMMENT.lastIndex;
										if(this.emit_comments) this.emit_comments(m_comment[0]);
										continue;

				// not iriref, not prefixed name, not blank node label, not prefix id, not base
				// match counter: 6
									}
									else {
										// break loop to retry on next chunk if eos
										break;
									}
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('graph_keyword');
				}
			}
		}

		// save state before pausing
		this._f_state = this.graph_keyword;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for graph_post_name
	graph_post_name() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let x = s[i];

			if('{' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				this.emit('enter', this._kt_graph);

				// statement state
				return this.statement();

			// comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('graph_post_name');
				}
			}
		}

		// save state before pausing
		this._f_state = this.graph_post_name;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for pairs
	pairs() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// benchmarks indicate: regex for end of blank node property list faster than ch


// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_predicate = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_predicate) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_predicate[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set predicate
					this._kt_predicate = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_predicate = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

				// object-list state
				return this.object_list();

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_predicate, im_prefixed_named_e_predicate] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_predicate) {
					// advance index
					this.i = im_prefixed_named_e_predicate;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_predicate[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// make predicate key
					this._kt_predicate = this.prefixed_name(s_prefix_id, m_prefixed_named_e_predicate[2]);

					// object-list state
					return this.object_list();

				// 'a'
				}
				else {
					// prepare sticky regex index
					R_A.lastIndex = i;

					if(R_A.exec(s)) {
						// advance index
						this.i = R_A.lastIndex;
						// make predicate key
						this._kt_predicate = this._kt_rdf_type;

						// object-list state
						return this.object_list();

					// ']' end of blank node property list
					}
					else {
						// prepare sticky regex index
						R_CHAR_KET.lastIndex = i;

						if(R_CHAR_KET.exec(s)) {
							// advance index
							this.i = R_CHAR_KET.lastIndex;
							let s_resume_state;
							[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
							return this[s_resume_state]();

						// iriref
						}
						else {
							// prepare sticky regex index
							R_IRIREF.lastIndex = i;
							// execute regex
							let m_iriref_predicate = R_IRIREF.exec(s);

							// regex was a match
							if(m_iriref_predicate) {
								// advance index
								this.i = R_IRIREF.lastIndex;

								// ref iri
								let s_iri = m_iriref_predicate[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
								// absolute iri
								if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
									// set predicate
									this._kt_predicate = this.check_named_node(s_iri);
								}
								// relative iri
								else {
									this._kt_predicate = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
								}

								// object-list state
								return this.object_list();

							// prefixed name
							}
							else {
								// try match
								let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
								// stack bail out
								if(!aw_valid_this_match_prefixed_name) return true;
								let [m_prefixed_named_predicate, im_prefixed_named_predicate] = aw_valid_this_match_prefixed_name;
								if(m_prefixed_named_predicate) {
									// advance index
									this.i = im_prefixed_named_predicate;
									// check valid prefix
									let s_prefix_id = m_prefixed_named_predicate[1] || '';
									// invalid prefix
									if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


									// escape local escapes
									let s_suffix = m_prefixed_named_predicate[2]
										.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
										.replace(R_PN_LOCAL_ESCAPES, '$1');

									// make predicate key
									this._kt_predicate = this.prefixed_name(s_prefix_id, s_suffix);

									// object-list state
									return this.object_list();
								}
								else {
									// prepare sticky regex index
									R_COMMENT.lastIndex = i;
									// execute regex
									let m_comment = R_COMMENT.exec(s);

									// regex was a match
									if(m_comment) {
										// advance index
										i = R_COMMENT.lastIndex;
										if(this.emit_comments) this.emit_comments(m_comment[0]);
										continue;

			// not iriref, not prefixed name, not 'a'
			// match counter: 6
									}
									else {
										// break loop to retry on next chunk if eos
										break;
									}
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('pairs');
				}
			}
		}

		// save state before pausing
		this._f_state = this.pairs;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for object_list
	object_list() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// string literal * double
			if('"' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if('"' === s[i+1] && '"' === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_double();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_double();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && '"' !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_double();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// prefixed name quick
			}
			else {
				// prepare sticky regex index
				R_PREFIXED_NAME_QUICK.lastIndex = i;
				// execute regex
				let m_pnq_object = R_PREFIXED_NAME_QUICK.exec(s);

				// regex was a match
				if(m_pnq_object) {
					// advance index
					this.i = R_PREFIXED_NAME_QUICK.lastIndex;
					// check valid prefix
					let s_prefix_id = m_pnq_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_pnq_object[2]);

				// iriref
				}
				else {
					// prepare sticky regex index
					R_IRIREF_ESCAPELESS.lastIndex = i;
					// execute regex
					let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

					// regex was a match
					if(m_iriref_e_object) {
						// advance index
						this.i = R_IRIREF_ESCAPELESS.lastIndex;

						// ref iri
						let s_iri = m_iriref_e_object[1];
						// absolute iri
						if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
							// set object
							this._kt_object = this.check_named_node_escapeless(s_iri);
						}
						// relative iri
						else {
							this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
						}

					// prefixed name
					}
					else {
						// try match
						let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
						// stack bail out
						if(!aw_valid_this_match_prefixed_name_escapeless) return true;
						let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
						if(m_prefixed_named_e_object) {
							// advance index
							this.i = im_prefixed_named_e_object;
							// check valid prefix
							let s_prefix_id = m_prefixed_named_e_object[1] || '';
							// invalid prefix
							if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


							// commit object iri from resolve prefixed name
							this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

						// string literal * single
						}
						else 	if('\'' === x) {
							// enough chars to deduce type
							if((i+2) < n) {
								// long type
								if("'" === s[i+1] && "'" === s[i+2]) {
									// advance index beyond token
									this.i = i + 3;

									// read contents
									return this.string_literal_long_single();
								}
								// not long type
								else {
									// advance index beyond token
									this.i = i + 1;

									// read contents
									return this.string_literal_short_single();
								}
							}
							// enough chars to eliminate long type
							else if((i+1) < n && "'" !== s[i+1]) {
								// advance index beyond token
								this.i = i + 1;

								// read contents
								return this.string_literal_short_single();
							}
							// not enough chars to deduce type; retry next chunk
							else {
								break;
							}

						// numeric literal
						}
						else {
							// prepare sticky regex index
							R_NUMERIC_LITERAL.lastIndex = i;
							// execute regex
							let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

							// regex was a match
							if(m_numeric_literal) {
								// advance index
								this.i = R_NUMERIC_LITERAL.lastIndex;
								// it has exponent term, xsd:double
								if(m_numeric_literal[4]) {
									this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
								}
								// contains decimal point, xsd:decimal
								else if(m_numeric_literal[2] || m_numeric_literal[3]) {
									this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
								}
								// otherwise, it is an integer
								else {
									this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
								}


							// boolean literal
							}
							else {
								// prepare sticky regex index
								R_BOOLEAN_LITERAL.lastIndex = i;
								// execute regex
								let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

								// regex was a match
								if(m_boolean_literal) {
									// advance index
									this.i = R_BOOLEAN_LITERAL.lastIndex;
									// make literal
									this._kt_object = this._dc_factory.boolean(!!m_boolean_literal[1]);


								// blank node property list
								}
								else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
									R_WS.lastIndex = i+1;
									R_WS.exec(s);
									this.i = R_WS.lastIndex;

									// make object
									let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());

									// emit statement event
									this.data();


									// push state to stack
									this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_object']);

									// set new subject
									this._kt_subject = kt_blank_node;

									// goto parsing pairs state
									return this.pairs();

								// labeled blank node
								}
								else {
									// prepare sticky regex index
									R_BLANK_NODE_LABEL_TERMINAL.lastIndex = i;
									// execute regex
									let m_blank_node_label_object = R_BLANK_NODE_LABEL_TERMINAL.exec(s);

									// regex was a match
									if(m_blank_node_label_object) {
										// advance index
										this.i = R_BLANK_NODE_LABEL_TERMINAL.lastIndex;
										// ref blank node label
										let s_label = m_blank_node_label_object[1];

										// make object
										this._kt_object = this.blank_node(s_label);

									// collection
									}
									else 	if('(' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
										R_WS.lastIndex = i+1;
										R_WS.exec(s);
										this.i = R_WS.lastIndex;

										// state to resume after collection ends
										this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_object']);

										// goto collection-object state
										return this.collection_object();

									// iriref
									}
									else {
										// prepare sticky regex index
										R_IRIREF.lastIndex = i;
										// execute regex
										let m_iriref_object = R_IRIREF.exec(s);

										// regex was a match
										if(m_iriref_object) {
											// advance index
											this.i = R_IRIREF.lastIndex;

											// ref iri
											let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
											// absolute iri
											if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
												// set object
												this._kt_object = this.check_named_node(s_iri);
											}
											// relative iri
											else {
												this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
											}

										// prefixed name
										}
										else {
											// try match
											let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
											// stack bail out
											if(!aw_valid_this_match_prefixed_name) return true;
											let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
											if(m_prefixed_named_object) {
												// advance index
												this.i = im_prefixed_named_object;
												// check valid prefix
												let s_prefix_id = m_prefixed_named_object[1] || '';
												// invalid prefix
												if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


												// escape local escapes
												let s_suffix = m_prefixed_named_object[2]
													.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
													.replace(R_PN_LOCAL_ESCAPES, '$1');

												// commit object iri from resolve prefixed name
												this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
											}
											else {
												// prepare sticky regex index
												R_COMMENT.lastIndex = i;
												// execute regex
												let m_comment = R_COMMENT.exec(s);

												// regex was a match
												if(m_comment) {
													// advance index
													i = R_COMMENT.lastIndex;
													if(this.emit_comments) this.emit_comments(m_comment[0]);
													continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 9
												}
												else {
													// break loop to retry on next chunk if eos
													break;
												}
											} // brace #9
										} // brace #8
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			// fall through for cases that did not change state on their own
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('object_list');
				}
			}
		}

		// save state before pausing
		this._f_state = this.object_list;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_short_double
	string_literal_short_double() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_short_double: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_SHORT_DOUBLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_SHORT_DOUBLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_SHORT_DOUBLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case '"': {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 1;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_SHORT_DOUBLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_SHORT_DOUBLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_short_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_short_double;
						}
					}

					// invalid '\n'
					case '\n': {
						return this.info_error(`expected string_literal_short_double but invalid line feed character '\\n' (newline) within contents. failed to parse a valid token`);
					}

					// invalid '\r'
					case '\r': {
						return this.info_error(`expected string_literal_short_double but invalid form feed character '\\r' (carriage return) within contents. failed to parse a valid token`);
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_short_double`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// save
				this._s_literal += i? s.slice(i): s;

				// set unparsed index
				i = n;

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_short_double');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_short_double;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_short_single
	string_literal_short_single() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_short_single: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_SHORT_SINGLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_SHORT_SINGLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_SHORT_SINGLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case "'": {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 1;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_SHORT_SINGLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_SHORT_SINGLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_short_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_short_single;
						}
					}

					// invalid '\n'
					case '\n': {
						return this.info_error(`expected string_literal_short_single but invalid line feed character '\\n' (newline) within contents. failed to parse a valid token`);
					}

					// invalid '\r'
					case '\r': {
						return this.info_error(`expected string_literal_short_single but invalid form feed character '\\r' (carriage return) within contents. failed to parse a valid token`);
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_short_single`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// save
				this._s_literal += i? s.slice(i): s;

				// set unparsed index
				i = n;

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_short_single');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_short_single;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_long_double
	string_literal_long_double() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_long_double: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_LONG_DOUBLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_LONG_DOUBLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_LONG_DOUBLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case '"': {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 3;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_LONG_DOUBLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_LONG_DOUBLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_long_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_long_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_long_double;
						}
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_long_double`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// could be unfinished terminator
				R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM.lastIndex = i;
				let m_unfinished = R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM.exec(s);

				// unfinished terminator
				if(m_unfinished) {
					// save valid portion
					this._s_literal += s.slice(i, m_unfinished.index);

					// set unparsed index
					i = m_unfinished.index;
				}
				// not unfinished
				else {
					// save
					this._s_literal += i? s.slice(i): s;

					// set unparsed index
					i = n;
				}

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_long_double');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_long_double;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_long_single
	string_literal_long_single() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_long_single: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_LONG_SINGLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_LONG_SINGLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_LONG_SINGLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case "'": {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 3;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_LONG_SINGLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_LONG_SINGLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_long_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_long_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_long_single;
						}
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_long_single`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// could be unfinished terminator
				R_STRLIT_LONG_SINGLE_UNFINISHED_TERM.lastIndex = i;
				let m_unfinished = R_STRLIT_LONG_SINGLE_UNFINISHED_TERM.exec(s);

				// unfinished terminator
				if(m_unfinished) {
					// save valid portion
					this._s_literal += s.slice(i, m_unfinished.index);

					// set unparsed index
					i = m_unfinished.index;
				}
				// not unfinished
				else {
					// save
					this._s_literal += i? s.slice(i): s;

					// set unparsed index
					i = n;
				}

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_long_single');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_long_single;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal
	string_literal() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref character
			let x = s[i];

			// string literal * double
			if('"' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if('"' === s[i+1] && '"' === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_double();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_double();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && '"' !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_double();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// string literal * single
			}
			else 	if('\'' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if("'" === s[i+1] && "'" === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_single();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_single();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && "'" !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_single();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// not string literal long single quote, not string literal single quote
			// match counter: 0
			}
			else {
				// break loop to retry on next chunk if eos
				break;
			}
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_string_length) {
					return this.parse_error('string_literal');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for datatype_or_langtag
	datatype_or_langtag() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref character
			let x = s[i];

			// next token indicates datatype or langtag
			if('^' === x || '@' === x) {
// '^^' datatype

				// prepare sticky regex index
				R_DOUBLE_CARET.lastIndex = i;

				if(R_DOUBLE_CARET.exec(s)) {
					// advance index
					this.i = R_DOUBLE_CARET.lastIndex;
					return this.datatype();

				// '@' language tag
				}
				else {
					// prepare sticky regex index
					R_LANGTAG.lastIndex = i;
					// execute regex
					let m_langtag = R_LANGTAG.exec(s);

					// regex was a match
					if(m_langtag) {
						// advance index
						this.i = R_LANGTAG.lastIndex;
						this._kt_object = this._dc_factory.languagedLiteral(this._s_literal, m_langtag[1]);

						// reset literal
						this._s_literal = '';

				// next token definitely datatype or langtag, we are just being interrupted by eos
				// match counter: 1
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #1
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					this._kt_object = this._dc_factory.simpleLiteral(this._s_literal);

					// reset literal
					this._s_literal = '';

				// not datatype, not language tag => that's okay! those are optional
				}
			} // brace #1


			// goto end of statement state
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype_or_langtag');
				}
			}
		}

		// save state before pausing
		this._f_state = this.datatype_or_langtag;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for datatype
	datatype() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let kt_datatype = null;

// prefixed name quick

			// prepare sticky regex index
			R_PREFIXED_NAME_QUICK.lastIndex = i;
			// execute regex
			let m_pnq_datatype = R_PREFIXED_NAME_QUICK.exec(s);

			// regex was a match
			if(m_pnq_datatype) {
				// advance index
				this.i = R_PREFIXED_NAME_QUICK.lastIndex;
				// check valid prefix
				let s_prefix_id = m_pnq_datatype[1] || '';
				// invalid prefix
				if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


				// commit object iri from resolve prefixed name
				kt_datatype = this.prefixed_name(s_prefix_id, m_pnq_datatype[2]);

			// iriref
			}
			else {
				// prepare sticky regex index
				R_IRIREF_ESCAPELESS.lastIndex = i;
				// execute regex
				let m_iriref_e_datatype = R_IRIREF_ESCAPELESS.exec(s);

				// regex was a match
				if(m_iriref_e_datatype) {
					// advance index
					this.i = R_IRIREF_ESCAPELESS.lastIndex;
					let p_datatype;

					// ref iri
					let s_iri = m_iriref_e_datatype[1];
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set p_datatype
						p_datatype = s_iri;
					}
					// relative iri
					else {
						p_datatype = uri.resolve(this._s_base_url, s_iri);
					}

					kt_datatype = this.check_named_node_escapeless(p_datatype);

				// prefixed name
				}
				else {
					// try match
					let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
					// stack bail out
					if(!aw_valid_this_match_prefixed_name_escapeless) return true;
					let [m_prefixed_named_e_datatype, im_prefixed_named_e_datatype] = aw_valid_this_match_prefixed_name_escapeless;
					if(m_prefixed_named_e_datatype) {
						// advance index
						this.i = im_prefixed_named_e_datatype;
						// check valid prefix
						let s_prefix_id = m_prefixed_named_e_datatype[1] || '';
						// invalid prefix
						if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


						kt_datatype = this.prefixed_name(s_prefix_id, m_prefixed_named_e_datatype[2]);

					// iriref
					}
					else {
						// prepare sticky regex index
						R_IRIREF.lastIndex = i;
						// execute regex
						let m_iriref_datatype = R_IRIREF.exec(s);

						// regex was a match
						if(m_iriref_datatype) {
							// advance index
							this.i = R_IRIREF.lastIndex;
							let p_datatype;

							// ref iri
							let s_iri = m_iriref_e_datatype[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
							// absolute iri
							if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
								// set p_datatype
								p_datatype = s_iri;
							}
							// relative iri
							else {
								p_datatype = uri.resolve(this._s_base_url, s_iri);
							}

							kt_datatype = this.check_named_node(p_datatype);

						// prefixed name
						}
						else {
							// try match
							let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
							// stack bail out
							if(!aw_valid_this_match_prefixed_name) return true;
							let [m_prefixed_named_datatype, im_prefixed_named_datatype] = aw_valid_this_match_prefixed_name;
							if(m_prefixed_named_datatype) {
								// advance index
								this.i = im_prefixed_named_datatype;
								// check valid prefix
								let s_prefix_id = m_prefixed_named_datatype[1] || '';
								// invalid prefix
								if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


								// escape local escapes
								let s_suffix = m_prefixed_named_datatype[2]
									.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
									.replace(R_PN_LOCAL_ESCAPES, '$1');

								// set literal datatype
								kt_datatype = this.prefixed_name(s_prefix_id, s_suffix);

			// not iriref, not prefixed name
			// match counter: 4
							}
							else {
								// break loop to retry on next chunk if eos
								break;
							}
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			this._kt_object = this._dc_factory.datatypedLiteral(this._s_literal, kt_datatype);

			// reset literal
			this._s_literal = '';

			// goto end of statement state
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype');
				}
			}
		}

		// save state before pausing
		this._f_state = this.datatype;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for post_object
	post_object() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let i_reset = i;

			// benchmarks confirm: character ref faster than regexes in this context
			let x = s[i];

			// advance index to next token beyond delimiter
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i+1;
			R_WS.exec(s);
			this.i = R_WS.lastIndex;

			// ',' more objects
			if(',' === x) {
				return this.object_list();

			// ';' more predicate-object pairs
			}
			else 	if(';' === x) {
				for(;;) {
					// next token is end of outer section
					let s_peek = s[this.i];
					if('.' === s_peek || ']' === s_peek || ';' === s_peek || '}' === s_peek) {
						// goto post_object state
						return this.post_object();
					}
					// comment
					else if('#' === s_peek) {
						// comment
						i = this.i;

						// prepare sticky regex index
						R_COMMENT.lastIndex = i;
						// execute regex
						let m_comment = R_COMMENT.exec(s);

						// regex was a match
						if(m_comment) {
							// advance index
							this.i = R_COMMENT.lastIndex;
							if(this.emit_comments) this.emit_comments(m_comment[0]);
							// retry
							continue;
						}


						// no eol to close comment (yet)
						else {
							// already consumed
							break;
						}
					}
					// eos
					else if(this.i === n) {
						break;
					}
					// something else
					else {
						return this.pairs();
					}
				}

				// rather than pushing a dedicated state, just try again next chunk
				i = i_reset;
				break;

			// '.' end of statement
			}
			else 	if('.' === x) {
				// assert not nested
				if(this._a_nested.length) {
					// reset index to that character
					this.i = i;

					// emit parse error
					return this.parse_error('end_of_property_list');
				}

				return (this._kt_default_graph === this._kt_graph)? this.block(): this.statement();

			// ']' end of property-object pairs
			}
			else 	if(']' === x) {
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();

			// ')' end of collection
			}
			else 	if(')' === x) {
				// should not be here
				return Reader$syntax_error(this, i, 'post_object', 'but encountered end of collection');

			// closing graph '}'
			}
			else {
				// prepare sticky regex index
				R_CHAR_CLOSE.lastIndex = i;

				if(R_CHAR_CLOSE.exec(s)) {
					// advance index
					this.i = R_CHAR_CLOSE.lastIndex;
					// emit graph_close event
					this.emit('exit', this._kt_graph);

					// reset graph
					this._kt_graph = this._kt_default_graph;

					return this.block();

				// comment
				}
				else {
					// prepare sticky regex index
					R_COMMENT.lastIndex = i;
					// execute regex
					let m_comment = R_COMMENT.exec(s);

					// regex was a match
					if(m_comment) {
						// advance index
						i = R_COMMENT.lastIndex;
						if(this.emit_comments) this.emit_comments(m_comment[0]);
						// do not change state
						continue;

			// comment interrupted by eos?
			// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('post_object');
				}
			}
		}

		// save state before pausing
		this._f_state = this.post_object;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for base_iri
	base_iri() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefix id

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_base = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_base) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_base[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set base_url
					this._s_base_url = s_iri;
				}
				// relative iri
				else {
					this._s_base_url = uri.resolve(this._s_base_url, s_iri);
				}		let m_base_iri = R_BASE_IRI.exec(this._s_base_url);
				this._s_base_url = m_base_iri[1];
				this._s_base_url_root = m_base_iri[2] || '';
				this._s_base_url_scheme = m_base_iri[3] || '';
				this._s_base_url_path = m_base_iri[4] || '';


				// emit base event
				this.emit('base', this._s_base_url);

				if(this._b_expecting_full_stop) {
					// change state
					return this.full_stop();
				}

				// goto prefix iri state
				return this.block();

			// prefix id
			}
			else {
				// prepare sticky regex index
				R_IRIREF.lastIndex = i;
				// execute regex
				let m_iriref_base = R_IRIREF.exec(s);

				// regex was a match
				if(m_iriref_base) {
					// advance index
					this.i = R_IRIREF.lastIndex;

					// ref iri
					let s_iri = m_iriref_base[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set base_url
						this._s_base_url = s_iri;
					}
					// relative iri
					else {
						this._s_base_url = uri.resolve(this._s_base_url, s_iri);
					}		let m_base_iri = R_BASE_IRI.exec(this._s_base_url);
					this._s_base_url = m_base_iri[1];
					this._s_base_url_root = m_base_iri[2] || '';
					this._s_base_url_scheme = m_base_iri[3] || '';
					this._s_base_url_path = m_base_iri[4] || '';


					// emit base event
					this.emit('base', this._s_base_url);

					if(this._b_expecting_full_stop) {
						// change state
						return this.full_stop();
					}

					// goto prefix iri state
					return this.block();

				// for poorly-placed comments
				}
				else {
					// prepare sticky regex index
					R_COMMENT.lastIndex = i;
					// execute regex
					let m_comment = R_COMMENT.exec(s);

					// regex was a match
					if(m_comment) {
						// advance index
						i = R_COMMENT.lastIndex;
						if(this.emit_comments) this.emit_comments(m_comment[0]);
						// do not change state
						continue;

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('base_iri');
				}
			}
		}

		// save state before pausing
		this._f_state = this.base_iri;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for prefix_id
	prefix_id() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefix id

			// prepare sticky regex index
			R_PREFIX_ID.lastIndex = i;
			// execute regex
			let m_prefix_id = R_PREFIX_ID.exec(s);

			// regex was a match
			if(m_prefix_id) {
				// advance index
				this.i = R_PREFIX_ID.lastIndex;
				// set temp prefix id
				this._s_temp_prefix_id = m_prefix_id[1];

				// goto prefix iri state
				return this.prefix_iri();

			// for poorly-placed comments
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					// do not change state
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('prefix_id');
				}
			}
		}

		// save state before pausing
		this._f_state = this.prefix_id;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for prefix_iri
	prefix_iri() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let h_prefixes = this._h_prefixes;
			let s_prefix_id = this._s_temp_prefix_id;
			let p_prefix_iri;

// prefix iri

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_prefix = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_prefix) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_prefix[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set p_prefix_iri
					p_prefix_iri = s_iri;
				}
				// relative iri
				else {
					p_prefix_iri = uri.resolve(this._s_base_url, s_iri);
				}

				let b_relax = this._b_relax;

// existing mapping

				if(s_prefix_id in h_prefixes) {
					// doesn't match existing
					if(p_prefix_iri !== h_prefixes[s_prefix_id]) {
						// emit change event
						if(this.prefix_change) {
							this.prefix_change(s_prefix_id, h_prefixes[s_prefix_id], p_prefix_iri);
						}

						// update prefix
						h_prefixes[s_prefix_id] = p_prefix_iri;
					}
				}
				// first mapping
				else {
					// check namespace, invalid
					if(!b_relax && !RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
						return this.error(`Invalid namespace for prefixed name: "${s_prefix_id}:"`);
					}

					// set prefix
					h_prefixes[s_prefix_id] = p_prefix_iri;
				}

				// check iri, invalid
				if(!b_relax && !RT_NAMED_NODE_VALID.test(p_prefix_iri)) {
					return this.error(`Invalid IRI found in prefix delcaration: "${s_iri}"`);
				}

				// emit prefix event
				this.event('prefix', s_prefix_id, p_prefix_iri);

				if(this._b_expecting_full_stop) {
					// change state
					return this.full_stop();
				}

				// goto statement state
				return this.block();

			// prefix iri
			}
			else {
				// prepare sticky regex index
				R_IRIREF.lastIndex = i;
				// execute regex
				let m_iriref_prefix = R_IRIREF.exec(s);

				// regex was a match
				if(m_iriref_prefix) {
					// advance index
					this.i = R_IRIREF.lastIndex;

					// ref iri
					let s_iri = m_iriref_prefix[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set p_prefix_iri
						p_prefix_iri = s_iri;
					}
					// relative iri
					else {
						p_prefix_iri = uri.resolve(this._s_base_url, s_iri);
					}

					let b_relax = this._b_relax;

// existing mapping

					if(s_prefix_id in h_prefixes) {
						// doesn't match existing
						if(p_prefix_iri !== h_prefixes[s_prefix_id]) {
							// emit change event
							if(this.prefix_change) {
								this.prefix_change(s_prefix_id, h_prefixes[s_prefix_id], p_prefix_iri);
							}

							// update prefix
							h_prefixes[s_prefix_id] = p_prefix_iri;
						}
					}
					// first mapping
					else {
						// check namespace, invalid
						if(!b_relax && !RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
							return this.error(`Invalid namespace for prefixed name: "${s_prefix_id}:"`);
						}

						// set prefix
						h_prefixes[s_prefix_id] = p_prefix_iri;
					}

					// check iri, invalid
					if(!b_relax && !RT_NAMED_NODE_VALID.test(p_prefix_iri)) {
						return this.error(`Invalid IRI found in prefix delcaration: "${s_iri}"`);
					}

					// emit prefix event
					this.event('prefix', s_prefix_id, p_prefix_iri);

					if(this._b_expecting_full_stop) {
						// change state
						return this.full_stop();
					}

					// goto statement state
					return this.block();

				// for poorly-placed comments
				}
				else {
					// prepare sticky regex index
					R_COMMENT.lastIndex = i;
					// execute regex
					let m_comment = R_COMMENT.exec(s);

					// regex was a match
					if(m_comment) {
						// advance index
						i = R_COMMENT.lastIndex;
						if(this.emit_comments) this.emit_comments(m_comment[0]);
						// do not change state
						continue;

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('prefix_iri');
				}
			}
		}

		// save state before pausing
		this._f_state = this.prefix_iri;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}


// in case eos happens twice during prefix / base (extremely unlikely)


	// parse state for full_stop
	full_stop() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// prepare sticky regex index
			R_CHAR_STOP.lastIndex = i;

			if(R_CHAR_STOP.exec(s)) {
				// advance index
				this.i = R_CHAR_STOP.lastIndex;
				// resume statement
				return this.block();

			// poorly-placed comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					// try again
					continue;

			// possibly interrupted by eos
			// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('full_stop');
				}
			}
		}

		// save state before pausing
		this._f_state = this.full_stop;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for collection_subject
	collection_subject() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// end of collection
			if(')' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// no items in collection subject
				if(null === this._kt_subject) {
					// prepare subject
					this._kt_subject = this._kt_rdf_nil;

					// state was never pushed to stack, jump to post_subject state
					return this.post_blank_subject();
				}
// otherwise, there must be items in collection

				// commit collection end
				this._kt_object = this._kt_rdf_nil;
				this.data();


				// restore state from stack
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();
			}



			// otherwise, pre-emptively secure the next blank node label
			let s_pointer_label;

			// very first collection object
			let b_pushed = false;
			if(null === this._kt_subject) {
				// set quasi subject (really for resume state)
				s_pointer_label = this.next_label();
				this._kt_subject = this.anonymous_blank_node(s_pointer_label);
				this._a_nested.push([this._kt_subject, this._kt_predicate, 'pairs']);
				// reset subject for later conditional branch
				this._kt_subject = null;
				b_pushed = true;
			}

// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_object) {
				// advance index
				i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_object[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set object
					this._kt_object = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_object) {
					// advance index
					i = im_prefixed_named_e_object;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

				// string literal
				}
				else 	if('"' === x || '\'' === x) {
					// first item in list
					if(null === this._kt_subject) {
						s_pointer_label = this.next_label();
						this._kt_subject = this.anonymous_blank_node(s_pointer_label);
						this._kt_predicate = this._kt_rdf_first;
					}
					// not first item in list
					else {
						// make nest list item
						s_pointer_label = this.next_label();
						let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
						this.data();


						// setup for object literal
						this._kt_subject = kt_blank_node;
						this._kt_predicate = this._kt_rdf_first;
					}

					// how to resume collection subject state after object literal
					this.after_end_of_statement = function() {
						this._kt_predicate = this._kt_rdf_rest;
						this.after_end_of_statement = this.post_object;
						return this.collection_subject();
					};
					return this.string_literal();

				// numeric literal
				}
				else {
					// prepare sticky regex index
					R_NUMERIC_LITERAL.lastIndex = i;
					// execute regex
					let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

					// regex was a match
					if(m_numeric_literal) {
						// advance index
						i = R_NUMERIC_LITERAL.lastIndex;
						// it has exponent term, xsd:double
						if(m_numeric_literal[4]) {
							this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
						}
						// contains decimal point, xsd:decimal
						else if(m_numeric_literal[2] || m_numeric_literal[3]) {
							this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
						}
						// otherwise, it is an integer
						else {
							this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
						}


					// boolean literal
					}
					else {
						// prepare sticky regex index
						R_BOOLEAN_LITERAL.lastIndex = i;
						// execute regex
						let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

						// regex was a match
						if(m_boolean_literal) {
							// advance index
							i = R_BOOLEAN_LITERAL.lastIndex;
							// make literal
							this._kt_object = this._dc_factory.boolean(!!m_boolean_literal[1]);

						// blank node property list
						}
						else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							this.i = R_WS.lastIndex;

							// this blank node is just the next item in the list
							s_pointer_label = this.next_label();
							let kt_blank_node;
							if(null !== this._kt_subject) {
								kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
								this.data();
							}

							// subject needs to be set
							this._kt_subject = kt_blank_node || this.anonymous_blank_node(s_pointer_label);
							this._kt_predicate = this._kt_rdf_first;
							let s_label = this.next_label();
							kt_blank_node = this._kt_object = this.anonymous_blank_node(s_label);
							this.data();


							// when resume
							this._kt_predicate = this._kt_rdf_rest;

							// push state
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_subject']);

							// prepare next triple
							this._kt_subject = kt_blank_node;

							// goto parsing pairs state
							return this.pairs();

						// new collection
						}
						else 	if('(' === x) {
							// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							i = R_WS.lastIndex;

							// empty collection
							if(')' === s[i]) {
								this.i = i;
								this._kt_subject = this._a_nested[this._a_nested.length-1][0];
								this._kt_predicate = this._kt_rdf_first;
								this._a_nested.push([
									this._kt_subject,
									this._kt_rdf_rest,
									'collection_subject',
								]);
								return this.collection_object();
							}



							// commit list item pointer
							s_pointer_label = this.next_label();
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
							this.data();


							// add this list as an item to the outer list
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// prepare next triple
							this._kt_predicate = this._kt_rdf_first;



							// flowing
							continue;

						// labeled blank node
						}
						else {
							// prepare sticky regex index
							R_BLANK_NODE_LABEL.lastIndex = i;
							// execute regex
							let m_blank_node_label_object = R_BLANK_NODE_LABEL.exec(s);

							// regex was a match
							if(m_blank_node_label_object) {
								// advance index
								i = R_BLANK_NODE_LABEL.lastIndex;
								// ref blank node label
								let s_label = m_blank_node_label_object[1];

								// make object
								this._kt_object = this.blank_node(s_label);

							// iriref
							}
							else {
								// prepare sticky regex index
								R_IRIREF.lastIndex = i;
								// execute regex
								let m_iriref_object = R_IRIREF.exec(s);

								// regex was a match
								if(m_iriref_object) {
									// advance index
									i = R_IRIREF.lastIndex;

									// ref iri
									let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
									// absolute iri
									if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
										// set object
										this._kt_object = this.check_named_node(s_iri);
									}
									// relative iri
									else {
										this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
									}

								// prefixed name
								}
								else {
									// try match
									let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
									// stack bail out
									if(!aw_valid_this_match_prefixed_name) return true;
									let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
									if(m_prefixed_named_object) {
										// advance index
										i = im_prefixed_named_object;
										// check valid prefix
										let s_prefix_id = m_prefixed_named_object[1] || '';
										// invalid prefix
										if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


										// escape local escapes
										let s_suffix = m_prefixed_named_object[2]
											.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
											.replace(R_PN_LOCAL_ESCAPES, '$1');

										// commit object iri from resolve prefixed name
										this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
									}
									else {
										// prepare sticky regex index
										R_COMMENT.lastIndex = i;
										// execute regex
										let m_comment = R_COMMENT.exec(s);

										// regex was a match
										if(m_comment) {
											// advance index
											i = R_COMMENT.lastIndex;
											if(this.emit_comments) this.emit_comments(m_comment[0]);
											continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 7
										}
										else {
											// ran out of characters after pushing state, pop it
											if(b_pushed) this._a_nested.pop();

											// break loop to retry on next chunk if eos
											break;
										}
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			let kt_blank_node_outer;
			if(!s_pointer_label) s_pointer_label = this.next_label();

			// not the very first item of collection subject
			if(this._kt_subject !== null) {
				// ref object
				let w_object = this._kt_object;

				// create blanknode to embed list
				kt_blank_node_outer = this._kt_object = this.anonymous_blank_node(s_pointer_label);

				// emit statement that functions as collection's head "pointer"
				this.data();


				// swap back object
				this._kt_object = w_object;
			}

			// emit statement that is item
			this._kt_subject = kt_blank_node_outer || this.anonymous_blank_node(s_pointer_label);
			this._kt_predicate = this._kt_rdf_first;
			this.data();


			// prepare next predicate
			this._kt_predicate = this._kt_rdf_rest;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('collection_subject');
				}
			}
		}

		// save state before pausing
		this._f_state = this.collection_subject;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for collection_object
	collection_object() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// end of collection
			if(')' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// make & emit collection's tail "pointer"
				this._kt_object = this._kt_rdf_nil;
				this.data();


				// restore previous state
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();
			}



			// otherwise, pre-emptively secure the next blank node label
			let s_pointer_label;

// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_object) {
				// advance index
				i = R_IRIREF_ESCAPELESS.lastIndex;
// commit object iri as is

				// ref iri
				let s_iri = m_iriref_e_object[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set object
					this._kt_object = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_object) {
					// advance index
					i = im_prefixed_named_e_object;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

				// string literal
				}
				else 	if('"' === x || '\'' === x) {
					// update index before changing states
					this.i = i;

					// create blanknode to embed list
					let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());

					// emit statement that functions as collection's head "pointer"
					this.data();


					// prepare statement that is item
					this._kt_subject = kt_blank_node;
					this._kt_predicate = this._kt_rdf_first;

					this.after_end_of_statement = function() {
						this._kt_predicate = this._kt_rdf_rest;
						this.after_end_of_statement = this.post_object;
						return this.collection_object();
					};
					return this.string_literal();

				// numeric literal
				}
				else {
					// prepare sticky regex index
					R_NUMERIC_LITERAL.lastIndex = i;
					// execute regex
					let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

					// regex was a match
					if(m_numeric_literal) {
						// advance index
						i = R_NUMERIC_LITERAL.lastIndex;
						// it has exponent term, xsd:double
						if(m_numeric_literal[4]) {
							this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
						}
						// contains decimal point, xsd:decimal
						else if(m_numeric_literal[2] || m_numeric_literal[3]) {
							this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
						}
						// otherwise, it is an integer
						else {
							this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
						}


					// boolean literal
					}
					else {
						// prepare sticky regex index
						R_BOOLEAN_LITERAL.lastIndex = i;
						// execute regex
						let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

						// regex was a match
						if(m_boolean_literal) {
							// advance index
							i = R_BOOLEAN_LITERAL.lastIndex;
							// make literal
							this._kt_object = this._dc_factory.booelan(!!m_boolean_literal[1]);

						// blank node property list
						}
						else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							this.i = R_WS.lastIndex;

							// commit head of list pointer
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());
							this.data();


							// setup state to resume and push
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// enter blank node
							this._kt_predicate = this._kt_rdf_first;
							kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());
							this.data();


							// prepare next triple
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_first;

							// goto parsing pairs state
							return this.pairs();

						// new collection
						}
						else 	if('(' === x) {
							// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							i = R_WS.lastIndex;

							// commit list item pointer
							s_pointer_label = this.next_label();
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
							if(null === this._kt_subject) {
								let a_recent = this._a_nested[this._a_nested.length-1];
								this._kt_subject = a_recent[0];
								this._kt_predicate = a_recent[1];
							}
							this.data();


							// add this list as an item to the outer list
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// prepare next triple
							this._kt_predicate = this._kt_rdf_first;

							// flowing
							continue;

						// labeled blank node
						}
						else {
							// prepare sticky regex index
							R_BLANK_NODE_LABEL.lastIndex = i;
							// execute regex
							let m_blank_node_label_object = R_BLANK_NODE_LABEL.exec(s);

							// regex was a match
							if(m_blank_node_label_object) {
								// advance index
								i = R_BLANK_NODE_LABEL.lastIndex;
								// ref blank node label
								let s_label = m_blank_node_label_object[1];

								// make collection pointer label first
								s_pointer_label = this.next_label();

								// make object
								this._kt_object = this.blank_node(s_label);

							// iriref
							}
							else {
								// prepare sticky regex index
								R_IRIREF.lastIndex = i;
								// execute regex
								let m_iriref_object = R_IRIREF.exec(s);

								// regex was a match
								if(m_iriref_object) {
									// advance index
									i = R_IRIREF.lastIndex;
// commit object iri as is

									// ref iri
									let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
									// absolute iri
									if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
										// set object
										this._kt_object = this.check_named_node(s_iri);
									}
									// relative iri
									else {
										this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
									}

								// prefixed name
								}
								else {
									// try match
									let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
									// stack bail out
									if(!aw_valid_this_match_prefixed_name) return true;
									let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
									if(m_prefixed_named_object) {
										// advance index
										i = im_prefixed_named_object;
										// check valid prefix
										let s_prefix_id = m_prefixed_named_object[1] || '';
										// invalid prefix
										if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


										// escape local escapes
										let s_suffix = m_prefixed_named_object[2]
											.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
											.replace(R_PN_LOCAL_ESCAPES, '$1');

										// commit object iri from resolve prefixed name
										this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
									}
									else {
										// prepare sticky regex index
										R_COMMENT.lastIndex = i;
										// execute regex
										let m_comment = R_COMMENT.exec(s);

										// regex was a match
										if(m_comment) {
											// advance index
											i = R_COMMENT.lastIndex;
											if(this.emit_comments) this.emit_comments(m_comment[0]);
											continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 7
										}
										else {
											// break loop to retry on next chunk if eos
											break;
										}
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1



			// ref object
			let w_object = this._kt_object;

			// create blanknode to embed list
			if(!s_pointer_label) s_pointer_label = this.next_label();
			let kt_blank_node_outer = this._kt_object = this.anonymous_blank_node(s_pointer_label);

			// emit statement that functions as collection's head "pointer"
			this.data();


			// emit statement that is item
			this._kt_subject = kt_blank_node_outer;
			this._kt_predicate = this._kt_rdf_first;
			this._kt_object = w_object;
			this.data();


			// prepare next predicate
			this._kt_predicate = this._kt_rdf_rest;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('collection_object');
				}
			}
		}

		// save state before pausing
		this._f_state = this.collection_object;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}


	destroy(e_destroy) {
		this.post_blank_subject = () => {};

		this.statement = () => {};

		this.block = () => {};

		this.graph_or_subject = () => {};

		this.graph_or_subject_property_list = () => {};

		this.graph_or_subject_anon = () => {};

		this.graph_keyword = () => {};

		this.graph_post_name = () => {};

		this.pairs = () => {};

		this.object_list = () => {};

		this.string_literal_short_double = () => {};

		this.string_literal_short_single = () => {};

		this.string_literal_long_double = () => {};

		this.string_literal_long_single = () => {};

		this.string_literal = () => {};

		this.datatype_or_langtag = () => {};

		this.datatype = () => {};

		this.post_object = () => {};

		this.base_iri = () => {};

		this.prefix_id = () => {};

		this.prefix_iri = () => {};

		this.full_stop = () => {};

		this.collection_subject = () => {};

		this.collection_object = () => {};


		this.eof = () => {
			this.s = null;
		};

		this._b_destroyed = true;

		// propagate input destroy
		if(!e_destroy && this._ds_input) {
			this._ds_input.destroy(e_destroy);
		}

		this.transform.demolish(e_destroy);
	}
}

module.exports = function(...a_args) {
	let g_config = {};

	// at least one argument
	if(a_args.length) {
		let z_arg_0 = a_args[0];

		// input given unspecified
		if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
			z_arg_0 = z_arg_0.input;
		}

		// string
		if('string' === typeof z_arg_0) {
			g_config.input = {string:z_arg_0};
		}
		// null
		else if(null === z_arg_0) {
			g_config.input = null;
		}
		// node stream
		else if('function' === typeof z_arg_0.setEncoding) {
			g_config.input = {stream:z_arg_0};
		}
		// whatwg stream
		else if('function' === typeof z_arg_0.pipeTo) {
			throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
		// g_config.input = {stream:z_arg_0};
		}
		// config struct
		else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
			g_config = z_arg_0;

			// more args; invalid
			if(a_args.length > 1) {
				throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
			}
		}
		// unknown
		else {
			throw new TypeError(`unexpected input type: ${z_arg_0}`);
		}

		// more args
		if(a_args.length > 1) {
			// copy onto struct
			Object.assign(g_config, a_args[1]);

			// more args
			if(a_args.length > 2) {
				throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
			}
		}
	}

	// create reader, return transform stream
	return (new Reader(g_config)).transform;
};

}).call(this)}).call(this,require("buffer").Buffer)
},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21,"buffer":74,"string_decoder":76,"uri-js":229}],12:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Scribable = require('@graphy/core.class.scribable');

const {
	terse,
	c1_to_nt,
} = factory;

const KT_DEFAULT_GRAPH = factory.defaultGraph();


function terse_s(yt_subject, h_prefixes) {
	if('NamedNode' === yt_subject.termType) {
		return terse(yt_subject.value, h_prefixes);
	}
	else {
		return '_:'+yt_subject.value;
	}
}


function terse_g(yt_subject, h_prefixes) {
	switch(yt_subject.termType) {
		// default graph
		case 'DefaultGraph': return '';

		// named node
		case 'NamedNode': return terse(yt_subject.value, h_prefixes);

		// blank node
		default: return '_:'+yt_subject.value;
	}
}


const terse_p = (yt_predicate, h_prefixes) => terse(yt_predicate.value, h_prefixes);

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function terse_o(yt_object, h_prefixes) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return terse(yt_object.value, h_prefixes);

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^'+terse(yt_object.datatype.value, h_prefixes);
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}



class TriG_Scriber extends Scribable {
	constructor(gc_scriber={}) {
		super(gc_scriber);

		this._yt_graph = KT_DEFAULT_GRAPH;
		this._yt_subject = null;
		this._yt_predicate = null;

		// prefixes given
		if(gc_scriber.prefixes) {
			// update prefixes and push to output
			this.push(this._serialize_prefixes(gc_scriber.prefixes, true) || '');
		}
	}

	_reset() {
		// some subject is open
		if(this._yt_subject) {
			// some graph is open
			if(!KT_DEFAULT_GRAPH.equals(this._yt_graph)) {
				// reset graph
				this._yt_graph = KT_DEFAULT_GRAPH;

				// close graph
				this._s_push += ' .\n}\n\n';
			}
			// no graph, just subject; close subject
			else {
				this._s_push += ' .\n\n';
			}

			// reset subject
			this._yt_subject = null;
		}

		// reset predicate
		this._yt_predicate = null;
	}

	_serialize_prefixes(h_prefixes_in, b_force_serialize=false) {
		// ref current prefixes
		let h_prefixes = this._h_prefixes;

		// serialize new prefixes
		let st_prefixes = '';
		for(let si_prefix in h_prefixes_in) {
			// prefix already exists and no change; skip
			if((si_prefix in h_prefixes) && h_prefixes_in[si_prefix] === h_prefixes[si_prefix] && !b_force_serialize) {
				continue;
			}

			// serialize addition
			st_prefixes += `@prefix ${si_prefix}: ${factory.namedNode(h_prefixes_in[si_prefix]).verbose()} .\n`;
		}

		// change detected
		if(st_prefixes) {
			// (re)cache prefixes
			this._update_prefixes(h_prefixes_in, true);

			// reset all markers
			this._reset();

			// write prefixes
			return st_prefixes+'\n';
		}
	}


	_serialize_c3r(hc3r_triples) {
		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// string building
		let st_quads = '';


		let b_subjects = false;

		for(let sc1_subject in hc3r_triples) {
			// quick convert subject from concise term to terse
			let st1_subject = c1_to_nt(sc1_subject, h_prefixes);

			// not a term; skip
			if(!st1_subject) continue;

			let st_triples = '';
			if(b_subjects) st_triples += ' .\n\n';

	//
			st_triples += st1_subject+' ';

			let b_predicates = false;

			// each predicate
			let hc2r_pairs = hc3r_triples[sc1_subject];
			for(let sc1_predicate in hc2r_pairs) {
				// quick convert predicate from concise term to terse
				let st1_predicate = c1_to_nt(sc1_predicate, h_prefixes);

				// not a term; skip
				if(!st1_predicate) continue;

		//
				let st_pairs = '';
				if(b_predicates) st_pairs += ' ;\n\t';

				// pairs output
				st_pairs += st1_predicate+' ';

				let b_objects = false;

				// each object
				for(let sc1_object of hc2r_pairs[sc1_predicate]) {
					// quick convert object from concise term to terse
					let st1_object = c1_to_nt(sc1_object, h_prefixes);

					// not a term; skip
					if(!st1_object) continue;

					if(b_objects) st_pairs += ', ';
					b_objects = true;

					// add object to pairs
					st_pairs += st1_object;
				}

				// objects written; add pairs to output
				if(b_objects) {
					st_triples += st_pairs;
					b_predicates = true;
				}
			}

			// predicates written; add triples to output
			if(b_predicates) {
				st_quads += st_triples;
				b_subjects = true;
			}
		}

		// subjects written; terminate
		if(b_subjects) st_quads += ' .\n\n';

		// reset all markers
		this._reset();

		return st_quads;
	}

	_serialize_c4r(hc4r_quads) {
		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// string building
		let st_build = '';

		let b_graphs = false;

		for(let sc1_graph in hc4r_quads) {
			// quick convert subject from concise term to terse
			let st1_graph = c1_to_nt(sc1_graph, h_prefixes);

			// not a term; skip
			if('*' !== sc1_graph && !st1_graph) continue;

			st_build += (st1_graph? st1_graph+' ': '')+'{\n';

			let st_quads = '';
			let hc3r_triples = hc4r_quads[sc1_graph];
			let b_subjects = false;

			for(let sc1_subject in hc3r_triples) {
				// quick convert subject from concise term to terse
				let st1_subject = c1_to_nt(sc1_subject, h_prefixes);

				// not a term; skip
				if(!st1_subject) continue;

				let st_triples = '';
				if(b_subjects) st_triples += ' .\n\n';

	//
				st_triples += '	'+st1_subject+' ';

				let b_predicates = false;

				// each predicate
				let hc2r_pairs = hc3r_triples[sc1_subject];
				for(let sc1_predicate in hc2r_pairs) {
					// quick convert predicate from concise term to terse
					let st1_predicate = c1_to_nt(sc1_predicate, h_prefixes);

					// not a term; skip
					if(!st1_predicate) continue;

		//
					let st_pairs = '';
					if(b_predicates) st_pairs += ' ;\n\t	';

					// pairs output
					st_pairs += st1_predicate+' ';

					let b_objects = false;

					// each object
					for(let sc1_object of hc2r_pairs[sc1_predicate]) {
						// quick convert object from concise term to terse
						let st1_object = c1_to_nt(sc1_object, h_prefixes);

						// not a term; skip
						if(!st1_object) continue;

						if(b_objects) st_pairs += ', ';
						b_objects = true;

						// add object to pairs
						st_pairs += st1_object;
					}

					// objects written; add pairs to output
					if(b_objects) {
						st_triples += st_pairs;
						b_predicates = true;
					}
				}

				// predicates written; add triples to output
				if(b_predicates) {
					st_quads += st_triples;
					b_subjects = true;
				}
			}

			if(b_subjects) st_build += st_quads+' .\n';

			// subjects written; terminate
			st_build += '}\n\n';
		}

		// reset all markers
		this._reset();

		return st_build;
	}

	_serialize_quad(g_quad) {
		let h_prefixes = this._h_prefixes;

		let {
			subject: yt_subject,
			predicate: yt_predicate,
			object: yt_object,
			graph: yt_graph,
		} = g_quad;

		// same graph
		if(yt_graph.equals(this._yt_graph)) {
			// same subject
			if(yt_subject.equals(this._yt_subject)) {
				// same prediate
				if(yt_predicate.equals(this._yt_predicate)) {
					// write object
					this._s_push += ', '+terse_o(yt_object, h_prefixes);
				}
				// different predicate
				else {
					// write pair
					this._s_push += ' ;\n\t'+terse_p(yt_predicate, h_prefixes)+' '+terse_o(yt_object, h_prefixes);

					// update prediate
					this._yt_predicate = yt_predicate;
				}
			}
			// subject not identical to previous
			else {
				let st_line = terse_s(yt_subject, h_prefixes)+' '+terse_p(yt_predicate, h_prefixes)+' '+terse_o(yt_object, h_prefixes);

				// different subject
				if(this._yt_subject) {
					// write triple
					this._s_push += ' .\n\n'+st_line;
				}
				// first subject
				else {
					this._s_push += st_line;
				}

				// save subject and predicate
				this._yt_subject = yt_subject;
				this._yt_predicate = yt_predicate;
			}
		}
		// graph not identical to previous
		else {
			// what to write this call
			let s_write = '';

			// different graph
			if(this._yt_graph) {
				// close graph
				s_write = ' .\n}\n\n';
			}

			// write graph
			this._s_push += s_write+terse_g(yt_graph, h_prefixes)+' {\n';

			// save graph
			this._yt_graph = yt_graph;
			this._yt_subject = yt_subject;
			this._yt_predicate = yt_predicate;
		}
	}

	_flush() {
		// flush buffer
		TriG_Scriber._flush_buffer(this);

		// triple needs closing
		if(this._yt_subject) {
			this.push(' .\n');
		}

		// eof
		this.push(null);
	}
}

Object.assign(TriG_Scriber, {
	_serialize_comment: Scribable.prototype._serialize_hash_comment,
});

module.exports = function(g_config) {
	return new TriG_Scriber(g_config);
};

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],13:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const factory = require('@graphy/core.data.factory');
const Writable = require('@graphy/core.class.writable');

// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_NAMESPACE_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?)?$/u;
const N_MAX_STRING_BUFFER = 1 << 12;

const XC_DIRECTIVES_TYPE_SPARQL = 0b001;
const XC_DIRECTIVES_CASE_PASCAL = 0b010;
const XC_DIRECTIVES_CASE_UPPER = 0b100;



class TriG_Writer extends Writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			prefixes: h_prefixes={},
			lists: gc_lists=null,
			debug: b_debug=false,
			style: gc_style=null,
		} = gc_writer;

		Object.assign(this, {
			_b_debug: b_debug,
			_s_indent: '\t',
			_b_simplify_default_graph: false,
			_xc_directives: 0,
			_s_token_prefix: '@prefix',
		});

		let s_graph_keyword = '';

		// style config
		if(gc_style) {
			// 'graph' keyword
			let z_graph_keyword = gc_style.graph_keyword || gc_style.graphKeyword || gc_style['graph-keyword'];
			if(z_graph_keyword) {
				// boolean true
				if(true === z_graph_keyword) {
					s_graph_keyword = 'GRAPH ';
				}
				// invalid type
				else if('string' !== typeof z_graph_keyword) {
					throw new TypeError(`Invalid argument type given for 'graph' token: ${z_graph_keyword}`);
				}
				// invalid token string
				else if(!/^graph$/i.test(z_graph_keyword)) {
					throw new Error(`Graph token must equal case-insensitive "GRAPH"; found: "${z_graph_keyword}"`);
				}
				// valid graph token; append space
				else {
					s_graph_keyword = z_graph_keyword+' ';
				}
			}

			// default graph simplification
			let w_simplify_default_graph = gc_style.simplify_default_graph || gc_style.simplifyDefaultGraph || gc_style['simplify-default-graph'];
			if(w_simplify_default_graph) {
				this._b_simplify_default_graph = !!w_simplify_default_graph;
			}

			// indent
			if(gc_style.indent) {
				this._s_indent = gc_style.indent.replace(/[^\s]/g, '');
			}

			// use sparql directives
			let z_directives = gc_style.directives || gc_style.directives;
			if(z_directives) {
				switch(z_directives) {
					case 'sparql': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL;
						this._s_token_prefix = 'prefix';
						break;
					}

					case 'Sparql': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL | XC_DIRECTIVES_CASE_PASCAL;
						this._s_token_prefix = 'Prefix';
						break;
					}

					case 'SPARQL': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL | XC_DIRECTIVES_CASE_UPPER;
						this._s_token_prefix = 'PREFIX';
						break;
					}

					case 'turtle': {
						break;
					}

					case 'Turtle': {
						this._xc_directives = XC_DIRECTIVES_CASE_PASCAL;
						this._s_token_prefix = '@Prefix';
						break;
					}

					case 'TURTLE': {
						this._xc_directives = XC_DIRECTIVES_CASE_UPPER;
						this._s_token_prefix = '@PREFIX';
						break;
					}

					default: {
						throw new Error(`Value not understood for 'directives' option: ${z_directives}`);
					}
				}
			}
		}

		// set graph token
		this._s_graph_keyword = s_graph_keyword;



		// custom list keys
		if(gc_lists) {
			// serialize list object
			this._serialize_list_object = function(a_list, n_nest_level) {
				// transcode list object
				let hc2_transcoded = this._transcode_list(a_list);

				// serialize object
				return this._encode_objects(hc2_transcoded, n_nest_level);
			};
		}

		// serialize initial prefix mappings
		let s_token_prefix = this._s_token_prefix;
		let s_prefix_eol = (this._xc_directives & XC_DIRECTIVES_TYPE_SPARQL)? '\n': ' .\n';
		let s_prefixes = '';
		try {
			// each user-defined prefix
			for(let s_prefix_id in h_prefixes) {
				// invalid prefix id
				if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
					throw new Error(`Invlalid prefix id for application/trig RDF serialization format: '${s_prefix_id}'`);
				}

				// append to string
				s_prefixes += `${s_token_prefix} ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()}${s_prefix_eol}`;
			}
		}
		// serialization error
		catch(e_serialize) {
			queueMicrotask(() => {
				this.emit('error', e_serialize);
			});
		}

		// push prefixes
		if(s_prefixes) this.push(s_prefixes);
	}

	// serialize prefixes
	_serialize_prefixes(h_prefixes) {
		// build prefixes string
		let s_prefixes = (2 === this._xc_state)? '\n\n': '';

		// update state
		this._xc_state = 0;

		// clone prefixes
		this._h_prefixes = {...this._h_prefixes};

		// ref prefix token
		let s_token_prefix = this._s_token_prefix;

		// prep eol string
		let s_prefix_eol = (this._xc_directives & XC_DIRECTIVES_TYPE_SPARQL)? '\n': ' .\n';

		// each user-defined prefix
		for(let s_prefix_id in h_prefixes) {
			// invalid prefix id
			if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
				throw new Error(`Invlalid prefix id for application/trig RDF serialization format: '${s_prefix_id}'`);
			}

			// append to string
			s_prefixes += `${s_token_prefix} ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()}${s_prefix_eol}`;

			// set prefix
			this._h_prefixes[s_prefix_id] = h_prefixes[s_prefix_id];
		}

		// recache
		factory.cache_prefixes(this._h_prefixes);

		// return prefix string
		return s_prefixes;
	}



	// serialize c3 hash
	_serialize_c3(hc3_triples) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,

		} = this;
		// break line if non-data state
		let s_write = 2 !== this._xc_state? '\n': '';
		// update state
		this._xc_state = 2;

		// triple delimiter
		let s_delim_triples = '';
		// subject exit listener
		let f_exit_subject = null;
		// each subject
		for(let sc1_subject in hc3_triples) {
			// directive
			if('`' === sc1_subject[0]) {
				let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
				// write data
				if(g_apply.write) {
					s_write += s_delim_triples+g_apply.write;
					// do not break next line
					s_delim_triples = '';
				}
				// save exit listener
				if(g_apply.exit) f_exit_subject = g_apply.exit;
				continue;
			}
			// position before subject
			let i_triples = s_write.length;
			// serialize subject
			s_write += s_delim_triples+factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';
			// pair indent & terminator
			let s_indent_pairs = '';
			let s_term_pairs = '';
			// ref pairs
			let hc2_pairs = hc3_triples[sc1_subject];
			// position before pairs
			let i_pairs = s_write.length;
			// were objects written?
			let b_empty = true;
			// predicate exit listener
			let f_exit_predicate = null;
			// each predicate
			for(let sc1_predicate in hc2_pairs) {
				// directive
				if('`' === sc1_predicate[0]) {
					// apply directive
					let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// write data
					if(g_apply.write) {
						// break line
						s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent+g_apply.write;
						// pair already terminated
						s_term_pairs = '';
						// indent next pair
						s_indent_pairs = s_indent;
					}
					// save exit listener
					if(g_apply.exit) f_exit_predicate = g_apply.exit;
					continue;
				}
				// ref objects
				let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
				let st_objects = this._encode_objects(z_objects);
				// no objects; skip pair
				if(!st_objects) continue;
				// not empty
				b_empty = false;
				// cannot use blank node in predicate position
				if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
					throw new Error(`Cannot use blank node in predicate position of c3 hash; subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
				}
				// create predicate
				let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);
				// tersify rdf:type
				let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);
				// serialize predicate and object(s)
				s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;
				// update state
				this._xc_state = 2;
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
				// terminate next pair
				s_term_pairs = ' ;\n';
				// indent next pair
				s_indent_pairs = s_indent;
				// call exit predicate listener
				if(f_exit_predicate) f_exit_predicate();
			}
			// empty triples; cut out
			if(b_empty) {
				s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
				continue;
			}
			// delimit triple(s)
			s_delim_triples = '\n';
			// close triple
			s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; //
			// call exit subject listener
			if(f_exit_subject) f_exit_subject();
		}

		s_write += '\n';
		return s_write;
	}


	// serialize c4 hash
	_serialize_c4(hc4_quads) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,

		} = this;
		// break line if non-data state
		let s_write = 2 !== this._xc_state? '\n': '';
		// update state
		this._xc_state = 2;
		// force default graph brace
		let b_simplify_default_graph = this._b_simplify_default_graph;

		// graph token
		let s_graph_keyword = this._s_graph_keyword;

		// graph exit listener
		let f_exit_graph = null;

		// each graph
		for(let sc1_graph in hc4_quads) {
			// directive
			if('`' === sc1_graph[0]) {
				let g_apply = this._apply_directive(sc1_graph, hc4_quads[sc1_graph]);

				// write data
				if(g_apply.write) s_write += g_apply.write;

				// save exit listener
				if(g_apply.exit) f_exit_graph = g_apply.exit;
				continue;
			}

			// serialize open graph
			let st_graph = factory.c1_node(sc1_graph, h_prefixes).terse(h_prefixes);

			s_write += st_graph
				? s_graph_keyword+st_graph+' {\n'
				: (b_simplify_default_graph? '': s_graph_keyword+'{\n');

			// simplify default graph implies no indent
			let s_indent_root = (!st_graph && b_simplify_default_graph)? '': s_indent;

			// update state
			this._xc_state = 2;

			// ref triples
			let hc3_triples = hc4_quads[sc1_graph];

			// triple delimiter
			let s_delim_triples = '';
			// subject exit listener
			let f_exit_subject = null;
			// each subject
			for(let sc1_subject in hc3_triples) {
				// directive
				if('`' === sc1_subject[0]) {
					let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
					// write data
					if(g_apply.write) {
						s_write += s_delim_triples+s_indent_root+g_apply.write;
						// do not break next line
						s_delim_triples = '';
					}
					// save exit listener
					if(g_apply.exit) f_exit_subject = g_apply.exit;
					continue;
				}
				// position before subject
				let i_triples = s_write.length;
				// serialize subject
				s_write += s_delim_triples+s_indent_root+factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';
				// pair indent & terminator
				let s_indent_pairs = '';
				let s_term_pairs = '';
				// ref pairs
				let hc2_pairs = hc3_triples[sc1_subject];
				// position before pairs
				let i_pairs = s_write.length;
				// were objects written?
				let b_empty = true;
				// predicate exit listener
				let f_exit_predicate = null;
				// each predicate
				for(let sc1_predicate in hc2_pairs) {
					// directive
					if('`' === sc1_predicate[0]) {
						// apply directive
						let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
						// write data
						if(g_apply.write) {
							// break line
							s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent+s_indent_root+g_apply.write;
							// pair already terminated
							s_term_pairs = '';
							// indent next pair
							s_indent_pairs = s_indent+s_indent_root;
						}
						// save exit listener
						if(g_apply.exit) f_exit_predicate = g_apply.exit;
						continue;
					}
					// ref objects
					let z_objects = hc2_pairs[sc1_predicate];
					// serialize objects
					let st_objects = this._encode_objects(z_objects);
					// no objects; skip pair
					if(!st_objects) continue;
					// not empty
					b_empty = false;
					// cannot use blank node in predicate position
					if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
						throw new Error(`Cannot use blank node in predicate position of c4 hash; graph:'${sc1_graph}', subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
					}
					// create predicate
					let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);
					// tersify rdf:type
					let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);
					// serialize predicate and object(s)
					s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;
					// update state
					this._xc_state = 2;
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
					// terminate next pair
					s_term_pairs = ' ;\n';
					// indent next pair
					s_indent_pairs = s_indent+s_indent_root;
					// call exit predicate listener
					if(f_exit_predicate) f_exit_predicate();
				}
				// empty triples; cut out
				if(b_empty) {
					s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
					continue;
				}
				// delimit triple(s)
				s_delim_triples = '\n';
				// close triple
				s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; // \n
				// call exit subject listener
				if(f_exit_subject) f_exit_subject();
			}
			// close graph
			s_write += ((st_graph || !b_simplify_default_graph)? '}\n': '')+'\n';

			// call exit graph listener
			if(f_exit_graph) f_exit_graph();
		}
		return s_write;
	}

	// write objects
	_encode_objects(z_objects, n_nest_level=1) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,
			_hm_coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return factory.c1(z_objects, h_prefixes).terse(h_prefixes);

			// numeric type
			case 'number': return factory.number(z_objects).terse(h_prefixes);

			// boolean type
			case 'boolean': return factory.boolean(z_objects).terse(h_prefixes);

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// object terminator
					let s_term_object = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; serialize list
						if(Array.isArray(z_item)) {
							s_write += s_term_object + this._serialize_list_object(z_item, n_nest_level);
						}
						// non-array
						else {
							// recurse on item
							s_write += s_term_object + this._encode_objects(z_item, n_nest_level);
						}

						// terminate next object
						s_term_object = ', ';
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// open blank node block
					let s_write = '[';

					// whether the block is empty
					let b_empty = true;

					// object exit listener
					let f_exit_object = null;

					// each pair
					for(let sc1_predicate in z_objects) {
						// block is not empty
						b_empty = false;

						// terminate previous pair
						s_write += '\n'+s_indent.repeat(2+n_nest_level);

						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							let g_apply = this._apply_directive(sc1_predicate, z_objects[sc1_predicate]);

							// write data
							if(g_apply.write) s_write += g_apply.write;

							// save exit listener
							if(g_apply.exit) f_exit_object = g_apply.exit;
							continue;
						}

						// write predicate and object(s)
						s_write += factory.c1(sc1_predicate, h_prefixes).terse(h_prefixes) + ' '
							+ this._encode_objects(z_objects[sc1_predicate], n_nest_level+1) +' ;';
					}

					// close blank node block
					s_write += (b_empty? '': '\n'+s_indent.repeat(1+n_nest_level))+']';

					// call exit object listener
					if(f_exit_object) f_exit_object();

					// serialize current predicate to blank node
					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return kt_converted.terse(h_prefixes);
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return z_objects.terse(h_prefixes);
				}
				// RDFJS term
				else if(z_objects.termType) {
					return factory.from.term(z_objects).terse(h_prefixes);
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// serialize collection object
	_serialize_collection_object(a_collection, n_nest_level) {
		let s_indent = this._s_indent;

		// open collection block
		let s_write = '(';

		// each item
		for(let z_item of a_collection) {
			let s_objects = '';

			// item is array; serialize as sub-collection
			if(Array.isArray(z_item)) {
				s_objects = this._serialize_collection_object(z_item, n_nest_level+1);
			}
			// non-array item
			else {
				s_objects = this._encode_objects(z_item, n_nest_level+1);
			}

			// serialize collection
			s_write += '\n'+s_indent.repeat(2+n_nest_level)+s_objects;
		}

		// break line if anything was written (including comments)
		if(a_collection.length) s_write += '\n'+s_indent.repeat(1+n_nest_level);

		// close collection block
		s_write += ')';

		return s_write;
	}

	// rdfjs quad
	_serialize_quad(g_quad) {
		let h_prefixes = this._h_prefixes;
		let kq_quad = factory.from.quad(g_quad);

		let st_graph = kq_quad.graph.terse(h_prefixes);

		// serialize quad
		this._s_push += (2 !== this._xc_state? '\n': '')
							+this._s_graph_keyword+(st_graph? st_graph+' ': '')+'{\n\t'
						+kq_quad.subject.terse(h_prefixes)+' '
			+kq_quad.predicate.terse(h_prefixes)+' '
			+kq_quad.object.terse(h_prefixes)+' .\n'
							+'}\n\n';


		// update state
		this._xc_state = 2;
	}
}

Object.assign(TriG_Writer.prototype, {
	anonymous_blank_nodes: true,
	_serialize_c3r: TriG_Writer.prototype._serialize_c3,
	_serialize_c4r: TriG_Writer.prototype._serialize_c4,
	_serialize_comment: Writable.prototype._serialize_hash_comment,
	_serialize_list_object: TriG_Writer.prototype._serialize_collection_object,
});

module.exports = function(gc_writer) {
	return new TriG_Writer(gc_writer);
};

},{"@graphy/core.class.writable":19,"@graphy/core.data.factory":20}],14:[function(require,module,exports){
(function (Buffer){(function (){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const uri = require('uri-js');
const string_decoder = require('string_decoder');

const stream = require('@graphy/core.iso.stream');
const factory = require('@graphy/core.data.factory');
const quad = k => factory.quad(k._kt_subject, k._kt_predicate, k._kt_object, k._kt_graph);

// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_NAMESPACE_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?)?$/u;
// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_LOCAL_NAME_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_:0-9]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%])(([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.:]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%])*([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}:]|%[A-Fa-f0-9]{2}|\\[_~.\-!$&'()*+,;=/?#@%]))?$/u;
// eslint-disable-next-line no-misleading-character-class
const RT_BLANK_NODE_VALID = /^[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_0-9]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?$/u;
const RT_NAMED_NODE_VALID = /^([^\0-\x20<>"{}|^`\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;
const RT_NAMED_NODE_ESCAPELESS_VALID = /^([^\0-\x20<>"{}|^`])*$/;

const RT_LITERAL_CONTENTS_VALID = /^(?:[^\\]|\\[tbnrf"'\\]|\\u[A-Fa-f0-9]{4}|\\U[A-Fa-f0-9]{8})*$/;

const R_UNICODE_ANY = /\\u([0-9A-Fa-f]{4})|\\U([0-9A-Fa-f]{8})/g;

const F_REPLACE_UNICODE_ANY = 	(s_, s_4, s_8) => String.fromCodePoint(parseInt(s_4 || s_8, 16));

const OPHOP = Object.prototype.hasOwnProperty;



const R_PREFIXED_NAME_QUICK = /([A-Za-z][A-Za-z0-9_-]*)?:([A-Za-z_0-9:][A-Za-z0-9_:-]*)(?:\s+|(?=\.?[<[("';,)\]#]|\.[\s\0]))/y;


const R_PREFIXED_NAME_ESCAPELESS = /([^\s#@<[("':_][^\s#@<[("':]*)?:((?:[^\s#@<[("'.;,)\]\\](?:[^\s#@<[("';,)\]\\]*[^\s#@<[("'.;,)\]\\])?)?)(?:\s+|(?=\.?[<[("';,)\]#]|\.[\s\0]))/y;



const R_PREFIXED_NAME = /([^\s#@<[("':_][^\s#@<[("':]*)?:((?:(?:[^\s#@<[("'.;,)\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))(?:(?:[^\s#@<[("';,)\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"]))*(?:[^\s#@<[("'.;,)\]\\]|\\(?:%[0-9A-Fa-f][0-9A-Fa-f]|[^\s"])))?)?)(?:\s+|(?=\.?[<[("';,)\]#]|\.[\s\0]))/y;

const R_PN_LOCAL_ESCAPES = /\\(.)/g;


const R_BLANK_NODE_LABEL = /_:(.(?:[^\s:<;,)\]#]*[^\s:<.;,)\]#])?)(?:\s+|(?=[<:,;\])#]))/y;
const R_BLANK_NODE_LABEL_TERMINAL = /_:(.(?:[^\s:<;,)\]#]*[^\s:<.;,)\]#])?)(?:\s+|(?=\.?[<:,;\])#])|(?=\.[\s@#<({[}]))/y;

const R_IRIREF_ESCAPELESS = /<([^\\>]*)>\s*/y;
const R_IRIREF = /<([^>]*)>\s*/y;

const R_NUMERIC_LITERAL = /([+-]?(?:[0-9]+(\.[0-9]+)?|(\.[0-9]+))(\.?[eE][+-]?[0-9]+)?)(?:\s+|(?=\.[^eE0-9]|[;,)\]]))/y;
const R_BOOLEAN_LITERAL = /(?:(true|TRUE)|false|FALSE)\s*/y;
const R_A = /a(?:\s+|(?=[[("'<#]))/y;

const R_DOUBLE_CARET = /\^\^/y;
const R_WS = /\s*/y;
const R_LANGTAG = /@([A-Za-z]+(?:-[A-Za-z0-9-]+)*)(?:\s+|(?=[.,;\])#]))/y;

const R_PREFIX_KEYWORD = /(?:(@prefix)|[pP][rR][eE][fF][iI][xX])\s*/y;
const R_PREFIX_ID = /([^#:]*):\s*/iy;
const R_BASE_KEYWORD = /(?:(@base)|[bB][aA][sS][eE])\s*/y;


const R_COMMENT = /(#[^\n]*\n\s*)+/y;

const RT_IRI_ABSOLUTE = /^[A-Za-z][A-Za-z0-9.\-+]*:/;
const R_RELATIVE_URI = /^(\/[^?#]+)([?#].*)?$/;
const R_BASE_IRI = /^((([A-Za-z0-9.\-+]*:\/)?\/[^/>]*)?(\/(?:[^/>]*\/)*)?[^>]*)$/;

const R_ANONYMOUS_BLANK_NODE = /\[\s*\]\s*/y;
const R_CHAR_BLANK_NODE = /\[(?:\s+|(?=[^\]]))/y;
const R_CHAR_COLLECTION = /\(\s*/y;

const R_CHAR_KET = /\]\s*/y;


const R_CHAR_STOP = /\.\s*/y;



const R_STRLIT_SHORT_DOUBLE_BREAK = /[\\"\r\n]/g;
const R_STRLIT_SHORT_SINGLE_BREAK = /[\\'\r\n]/g;

const R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM = /"{1,2}$/g;
const R_STRLIT_LONG_SINGLE_UNFINISHED_TERM = /'{1,2}$/g;

const R_STRLIT_LONG_DOUBLE_BREAK = /(\\|""")/g;
const R_STRLIT_LONG_SINGLE_BREAK = /(\\|''')/g;


const F_REPLACE_STRLIT_CONTENTS = (s_, s_whitespace, s_auto, s_4, s_8, s_invalid) => {
	if(s_whitespace) {
		switch(s_whitespace) {
			case 't': return '\t';
			case 'n': return '\n';
			case 'r': return '\r';
			case 'f': return '\f';
			case 'b': return '\b';
			default: {
				console.assert(`bad regex escape char mapping: '${s_whitespace}'`);
			}
		}
	}
	else if(s_auto) {
		return s_auto;
	}
	else if(s_4) {
		return String.fromCodePoint(parseInt(s_4, 16));
	}
	else if(s_8) {
		return String.fromCodePoint(parseInt(s_8, 16));
	}
	else if(s_invalid) {
		// pointless escape
		if('\\' === s_invalid[0]) {
				// // relaxed
				// return s_invalid[1];
			// if relaxed then return s_invalid, otherwise throw:
			throw new Error(`expected string_literal but invalid escape sequence within contents: '${s_invalid}'. failed to parse a valid token`);
		}
		// bad character
		else {
			throw new Error(`expected string_literal but invalid whitespace character within contents: ${JSON.stringify(s_invalid)}. failed to parse a valid token`);
		}
	}
	else {
		console.assert(`unexpected no match branch in escape sequence replace callback`);
	}
};


const R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\.))/g;
const R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|([\r\n]|\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_short_hard = s_literal => s_literal
	.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_short_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_SHORT_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};


const R_STRLIT_LONG_CONTENTS_ESCAPES_HARD = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|(\\.))/g;
const R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT = /(?:\\(?:([tnrfb])|([\\"'])|u([0-9A-Fa-f]{4})|U([0-9A-Fa-f]{8}))|(\\[^uU]|\\u[^]{4}|\\U[^]{8}))/g;

const unescape_literal_long_hard = s_literal => s_literal
	.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_HARD, F_REPLACE_STRLIT_CONTENTS);

const unescape_literal_long_soft = (s_literal) => {
	let m_incomplete = R_STRLIT_ESCAPE_INCOMPLETE.exec(s_literal);

	// incomplete escape
	if(m_incomplete) {
		let i_safe = m_incomplete.index;

		// rewind
		return [
			s_literal.slice(0, i_safe)
				.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			s_literal.slice(i_safe),
		];
	}
	// done
	else {
		return [
			s_literal
				.replace(R_STRLIT_LONG_CONTENTS_ESCAPES_SOFT, F_REPLACE_STRLIT_CONTENTS),
			'',
		];
	}
};

// lookbehind regexes
const [
	R_STRLIT_ESCAPE_INCOMPLETE,
	R_STRLIT_SHORT_DOUBLE_TERM,
	R_STRLIT_SHORT_SINGLE_TERM,
	R_STRLIT_LONG_DOUBLE_TERM,
	R_STRLIT_LONG_SINGLE_TERM,
] = (() => {
	function RegExp_$lookbehind_polyfill(s_input) {
		let m_match = RegExp.prototype.exec.call(this, s_input);

		if(m_match) {
			let i_start = m_match[0].length - m_match[1].length;
			m_match.index += i_start;
			m_match[0] = m_match[0].slice(i_start);
		}

		return m_match;
	}
	let mk_lookbehind_regex = (() => {
		try {
			new RegExp('(?<!h)i');  // eslint-disable-line no-new
		}
		catch(e_compile) {
			return (f_lookbehind, r_polyfill, f_polyfill) => {
				r_polyfill.exec = f_polyfill;
				return r_polyfill;
			};
		}
		return f_lookbehind => f_lookbehind();
	})();
	return [
		// R_STRLIT_ESCAPE_INCOMPLETE
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\\\\(|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7})$'),
			/^(?:(?:[^\\]|\\.)*)(\\(?:|u[0-9A-Fa-f]{0,3}|U[0-9A-Fa-f]{0,7}))$/,
			function RegExp_$lookbehind_polyfill_n(s_input) {
				let m_match = RegExp.prototype.exec.call(this, s_input);
				if(m_match) {
					m_match.index += m_match[0].length - m_match[1].length;
				}

				return m_match;
			},
		),
		// R_STRLIT_SHORT_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"\\s*', 'g'),
			/(?:[^\\"]|\\.)*("\s*)/y,
			RegExp_$lookbehind_polyfill,
		),
		// R_STRLIT_SHORT_SINGLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\'\\s*', 'g'),
			/(?:[^\\']|\\.)*('\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

		// R_STRLIT_LONG_DOUBLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)"""\\s*', 'g'),
			/(?:[^\\"]|\\.|""?(?!"))*("""\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

		// R_STRLIT_LONG_SINGLE_TERM
		mk_lookbehind_regex(
			() => new RegExp('(?<!(?:[^\\\\]|^)(?:\\\\\\\\)*\\\\)\'\'\'\\s*', 'g'),
			/(?:[^\\']|\\.|''?(?!'))*('''\s*)/y,
			RegExp_$lookbehind_polyfill,
		),

	];
})();

const match_prefixed_name_quick = (s, i) => {
	R_PREFIXED_NAME_QUICK.lastIndex = i;
	return [R_PREFIXED_NAME_QUICK.exec(s), R_PREFIXED_NAME_QUICK.lastIndex];
};

const match_prefixed_name_escapeless = (s, i) => {
	R_PREFIXED_NAME_ESCAPELESS.lastIndex = i;
	return [R_PREFIXED_NAME_ESCAPELESS.exec(s), R_PREFIXED_NAME_ESCAPELESS.lastIndex];
};

const match_prefixed_name = (s, i) => {
	R_PREFIXED_NAME.lastIndex = i;
	return [R_PREFIXED_NAME.exec(s), R_PREFIXED_NAME.lastIndex];
};



function Reader$syntax_error(k_self, i, si_state, s_info) {
	let i_off = Math.min(i, Math.abs(i-15));

	let s = k_self.s;

	return k_self.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
		+` ${' '.repeat(i-i_off)}^\n`
		+`expected ${si_state} ${s_info || ''}.  failed to parse a valid token starting at ${s[i]? '"'+s[i]+'"': '<<EOF>>'}`);
}



class Turtle_Reader extends stream.Transform {
	constructor(g_impls) {
		super({
			// do not decode strings into buffers
			decodeStrings: false,

			// accept strings as input on writable side
			writableObjectMode: false,

			// output quad objects on readable side
			readableObjectMode: true,

			// implementations
			flush: g_impls.flush,
			transform: g_impls.transform,
		});
	}

	// intercept pipe
	pipe(ds_out) {
		let ds_dst = ds_out;

		// non-object mode
		if(!ds_dst._writableState.objectMode) {
			// transform to JSON
			ds_out = stream.quads_to_json();
		}
		// yet object mode and graphy writable
		else if(ds_out.isGraphyWritable) {
			// transform to writable data events
			ds_out = stream.quads_to_writable();
		}

		// interim stream created
		if(ds_out !== ds_dst) {
			// forward output to super
			super.pipe(ds_out);

			// pipe outpu to destination
			return ds_out.pipe(ds_dst);
		}
		// forward as-is to super
		else {
			return super.pipe(ds_dst);
		}
	}
}


class Reader {
	constructor(g_config={}) {
		// impl-specific configs
		let {
			// input medium
			input: g_input=null,

			// a state to inherit
			state: g_state={},
		} = g_config;

		// inherit state from creator
		let {
			// index for anonymous blank node labels
			blank_node_index: i_anon=0,

			// prefix map
			prefixes: h_prefixes={},

			// blank node label map
			labels: h_labels={},
		} = g_state;


		let dc_factory = factory.adopt(g_config.dataFactory || g_config.data_factory || factory.unfiltered);

		let kt_default_graph = dc_factory.defaultGraph();

		// if data factory is not graphy, it might be returning the same object on each call to .defaultGraph()
		if(dc_factory !== factory.unfiltered) {
			// do not trust it, create a new object
			kt_default_graph = Object.create(kt_default_graph);
		}

		let kt_rdf_first = dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#first');

		let blankNode = dc_factory.blankNode;
		let namedNode = dc_factory.namedNode;

		this.emit_data = factory.unfiltered === dc_factory
			? function() {
				ds_transform.push(quad(this));
			}
			: function() {
				let g_quad = dc_factory.quad(this._kt_subject, this._kt_predicate, this._kt_object, this._kt_graph);
				ds_transform.push(g_quad);
			};

		// fields
		Object.assign(this, {
			// read index
			i: 0,

			// string buffer
			s: '',

			// string buffer length
			n: 0,

			// left-over string from previous data chunk
			pre: g_config.prepend || '',

			// debug state
			_b_debug: g_config.debug || false,

			// relax
			_b_relax: g_config.relax || false,

			// factory
			_dc_factory: dc_factory,

			// current reader state
			_f_state: this.statement,

			// map of current prefix ids => iris
			_h_prefixes: h_prefixes,


			// reader was destroyed by an error
			_b_destroyed: false,

			// current @base url
			_s_base_url: '',
			_s_base_url_scheme: '',
			_s_base_url_root: '',
			_s_base_url_path: '',

			// current data
			_kt_subject: null,
			_kt_predicate: kt_rdf_first,
			_kt_object: null,
			_kt_graph: kt_default_graph,
			_s_literal: '',

			// static terms
			_kt_rdf_type: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'),
			_kt_rdf_first: kt_rdf_first,
			_kt_rdf_rest: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#rest'),
			_kt_rdf_nil: dc_factory.namedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#nil'),
			_kt_default_graph: kt_default_graph,

			// queue of nested subject, predicate, state for blanknodes and collections
			_a_nested: [],

			// hash to keep track of all blank node labels in use
			_h_labels: h_labels,

			// event routing
			event: this.emit,
			data: this.emit_data,

			// for restoring the original event callback when resuming paused stream
			restore_data: this.emit_data,

			// keep a queue of data events to hold onto until stream resumes (only happens in rare conditions)
			_a_queue_event: [],

			// helper states
			_b_expecting_full_stop: false,
			_s_temp_prefix_id: null,
			_b_trim_start: true,

			anonymous_blank_node: s_label => blankNode(s_label, true),

			// finds the next non-conflicting blank node label
			next_label() {
				let s_label = '';
				do {
					s_label = 'g'+(i_anon++);
				} while(this._h_labels[s_label]);

				// claim this label, and remember that we invented it
				this._h_labels[s_label] = 2;

				// return the label
				return s_label;
			},

			// what to do when reach eos
			eos: null,

			// which state to go to after end of statement
			after_end_of_statement: this.post_object,

			// maximum length of a token: defaults to 2048 => http://stackoverflow.com/a/417184/1641160
			_n_max_token_length: g_config.max_token_length || g_config.maxTokenLength || 2048,

			// maximum length of a string (overrides max_token_length): defaults to Infinity
			_n_max_string_length: g_config.max_string_length || g_config.maxStringLength || Infinity,

			// byte tracking
			_b_byte_tracking: g_config.byte_tracking || g_config.byteTracking || false,
			_nb_seen: 0,
			_nb_last: 0,
			_nb_curr: 0,
		});

		if(g_config.relaxed) {
			console.warn((new Error(`no such option 'relaxed'; did you mean 'relax' ?`)).stack.replace(/^Error:/, 'Warning:'));
		}
		if('validate' in g_config) {
			console.warn((new Error(`option 'validate' has been deprecated. Validation is now enabled by default. Use the 'relax' option if you wish to disable validation.`)).stack.replace(/^Error:/, 'Warning:'));
		}



		// term constructors
		Object.assign(this, !g_config.relax
			? {
				blank_node(s_label) {
					// test valid blank node label
					if(!RT_BLANK_NODE_VALID.test(s_label)) return this.error(`invalid blank node label: "${s_label}"`);

					// not first time use of label
					let z_label_state = this._h_labels[s_label];
					if(z_label_state) {
						// label was used previously by document and has no conflict
						if(1 === z_label_state) {}  // eslint-disable-line no-empty
						// label is in use by invention, this would cause a conflict
						else if(2 === z_label_state) {
							// so create a redirect mapping for this actual label & use it instead
							s_label = this._h_labels[s_label] = this.next_label();
						}
						// label already has a redirect mapping
						else {
							// use redirected label
							s_label = this._h_labels[s_label];
						}
					}
					// first time use of label
					else {
						// store label in hash so we avoid future collisions
						this._h_labels[s_label] = 1;
					}

					// make term
					return blankNode(s_label);
				},

				check_named_node(p_iri) {
					if(!RT_NAMED_NODE_VALID.test(p_iri)) return this.error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				check_named_node_escapeless(p_iri) {
					if(!RT_NAMED_NODE_ESCAPELESS_VALID.test(p_iri)) return this.error(`invalid IRI: "${p_iri}"`);
					return namedNode(p_iri);
				},

				match_prefixed_name_quick(s, i) {
					R_PREFIXED_NAME_QUICK.lastIndex = i;
					return [R_PREFIXED_NAME_QUICK.exec(s), R_PREFIXED_NAME_QUICK.lastIndex];
				},

				match_prefixed_name_escapeless(s, i) {
					let [m_prefixed_name_e, im_prefixed_name_e] = match_prefixed_name_escapeless(s, i);
					if(m_prefixed_name_e) {
						// invalid local name
						if(!RT_PREFIXED_NAME_LOCAL_NAME_VALID.test(m_prefixed_name_e[2]) && m_prefixed_name_e[2]) {
							this.error(`invalid prefixed name local name: "${m_prefixed_name_e[2]}:"`);
							return;
						}
					}

					return [m_prefixed_name_e, im_prefixed_name_e];
				},

				match_prefixed_name(s, i) {
					let [m_prefixed_name, im_prefixed_name] = match_prefixed_name(s, i);
					if(m_prefixed_name) {
						// invalid local name
						if(!RT_PREFIXED_NAME_LOCAL_NAME_VALID.test(m_prefixed_name[2])) {
							this.error(`invalid prefixed name local name: "${m_prefixed_name[2]}:"`);
							return;
						}
					}

					return [m_prefixed_name, im_prefixed_name];
				},
			}
			: {
				// term constructors
				blank_node(s_label) {
					// not first time use of label
					let z_label_state = this._h_labels[s_label];
					if(z_label_state) {
						// label was used previously by document and has no conflict
						if(1 === z_label_state) {}  // eslint-disable-line no-empty
						// label is in use by invention, this would cause a conflict
						else if(2 === z_label_state) {
							// so create a redirect mapping for this actual label & use it instead
							s_label = this._h_labels[s_label] = this.next_label();
						}
						// label already has a redirect mapping
						else {
							// use redirected label
							s_label = this._h_labels[s_label];
						}
					}
					// first time use of label
					else {
						// store label in hash so we avoid future collisions
						this._h_labels[s_label] = 1;
					}

					// make term
					return blankNode(s_label);
				},

				check_named_node: namedNode,

				check_named_node_escapeless: namedNode,

				match_prefixed_name_escapeless,

				match_prefixed_name,
			});


		this.named_node = namedNode;

		this.prefixed_name = function(si_prefix, s_suffix) {
			return namedNode(h_prefixes[si_prefix] + s_suffix);
		};


		// oops -- user passed string into `base`
		if('string' === typeof g_config.base) {
			throw new TypeError(`invalid type 'string' was given for 'base' event listener: '${g_config.base}'\n`
				+`did you mean to use the 'base_uri' key instead?`);
		}

		// base uri
		let p_set_base_uri = g_config.base_uri || g_config.baseUri || g_config.baseURI || g_config.base_iri || g_config.baseIri || g_config.baseIRI;
		if(p_set_base_uri) {
			let m_base_iri = R_BASE_IRI.exec(p_set_base_uri);
			this._s_base_url = m_base_iri[1];
			this._s_base_url_root = m_base_iri[2] || '';
			this._s_base_url_scheme = m_base_iri[3] || '';
			this._s_base_url_path = m_base_iri[4] || '';
		}
		// not set; 'url' variant is
		else if(g_config.base_url || g_config.baseUrl || g_config.baseURL) {
			throw new Error(`invalid option: .base${g_config.base_url? '_url': g_config.baseUrl? 'Url': g_config.baseURL? 'URL': ''}; use the '.base_uri' key instead`);
		}

		// transform stream
		let ds_transform = this.transform = new Turtle_Reader({
			// on data event
			transform: (s_chunk, s_encoding, fke_chunk) => {
				// concatenate current chunk to previous chunk
				let s = this.s = this.pre + s_chunk;

				// cache chunk length
				this.n = s.length;

				// eat whitespace before token and reset index
				if(this._b_trim_start) {
					// consume whitespace (and incidentally reset index)
					R_WS.lastIndex = 0;
					R_WS.exec(s);
					this.i = R_WS.lastIndex;
				}
				// do not eat whitespace; start at beginning
				else {
					this.i = 0;
				}

				// resume parsing; no errors
				if(this.safe_parse(true)) {
					// emit progress event updates
					ds_transform.emit('progress', s_chunk.length);

					// done transforming this chunk
					fke_chunk();
				}
			},

			// once there's no more data to consume, invoke eof
			flush: (fke_flush) => {
				// now that input stream has ended, clean up remainder
				try {
					this.eof(1);
				}
				// read error occurred
				catch(e_eof) {
					// destroy self and stream
					this.destroy(e_eof);

					// exit gracefully
					return;
				}

				// no errors. done flushing, close read stream
				fke_flush();
			},
		});

		// when the writable side is piped into
		ds_transform.on('pipe', (ds_input) => {
			this._ds_input = ds_input;

			let b_byte_tracking = this._b_byte_tracking;

			// byte-tracking is disable & input stream has encoding option; ensure stream encoding is utf8
			if(!b_byte_tracking && 'function' === typeof ds_input.setEncoding) {
				ds_input.setEncoding('utf8');
			}
			// set decoding on write
			else {
				let f_write = ds_transform.write;
				let d_decoder = new string_decoder.StringDecoder('utf8');

				let f_write_track = (s_chunk, s_encoding, fk_write) => {
					// TODO: optimize by testing for multibyte chars and using string length instead?
					let nb_chunk = Buffer.from(s_chunk, 'utf8').length;
					this._nb_seen += nb_chunk;
					this._nb_last = nb_chunk;
					return f_write.call(ds_transform, s_chunk, s_encoding, fk_write);
				};

				let f_decode_write_track = (ab_chunk, s_encoding, fk_write) => {
					let nb_chunk = this._nb_last = ab_chunk.length;
					this._nb_seen += nb_chunk;
					return f_write.call(ds_transform, d_decoder.write(ab_chunk), s_encoding, fk_write);
				};

				let f_decode_write = (ab_chunk, s_encoding, fk_write) => f_write.call(ds_transform, d_decoder.write(ab_chunk), s_encoding, fk_write);

				ds_transform.write = function(z_chunk, s_encoding, fk_write) {
					// not null
					if(null !== z_chunk) {
						// chunk is string; adapt by resetting method to original
						if('string' === typeof z_chunk) {
							ds_transform.write = b_byte_tracking? f_write_track: f_write;
						}
						// chunk is buffer; adapt by setting decoder write method
						else {
							ds_transform.write = b_byte_tracking? f_decode_write_track: f_decode_write;
						}

						// use set method
						return ds_transform.write(z_chunk, s_encoding, fk_write);
					}

					// null, use parent
					return f_write.call(ds_transform, z_chunk, s_encoding, fk_write);
				};

				// byte tracking is enabled
				if(b_byte_tracking) {
					// overwrite emit_data method
					this.emit_data = this.data = this.restore_data = function() {
						let g_quad = this._dc_factory.quad(this._kt_subject, this._kt_predicate, this._kt_object, this._kt_graph);
						let nb_post = Buffer.from(this.s.slice(this.i)).length;
						let ib_post = this._nb_seen - nb_post;
						g_quad.byteRange = [this._nb_curr, ib_post];
						this._nb_curr = ib_post;
						this.transform.push(g_quad);
					};
				}
			}
		});

		// new listener added
		ds_transform.on('newListener', (s_event) => {
			// comment
			if('comment' === s_event) {
				this.emit_comments = (s_captured) => {
					let a_comments = s_captured.slice(1).replace(/\n\s+$/, '').split(/\n+\s*#/g);

					for(let s_comment of a_comments) {
						ds_transform.emit('comment', s_comment);
					}
				};
			}
		});

		// destroy
		ds_transform._destroy = (...a_args) => {
			this.destroy(...a_args);
		};

		// bind events to transform stream
		this.bind(g_config);

		// input given
		if(g_input) {
			// input is stream
			if(g_input.stream) {
				let ds_input = g_input.stream;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_input.pipe(ds_transform);
				});
			}
			// string
			else if('string' === typeof g_input.string) {
				let s_input = g_input.string;

				// go async so caller has chance to bind event listeners
				queueMicrotask(() => {
					ds_transform.end(s_input, 'utf8');
				});
			}
			// invalid arg
			else {
				throw new TypeError(`Invalid argument for input parameter: ${'object' === typeof g_input? JSON.stringify(g_input): g_input}`);
			}
		}
	}

	// begin parsing, keep applying until no more stack bail-outs
	safe_parse() {
		try {
			let f_sync = this._f_state();
			while('function' === typeof f_sync) {
				f_sync = f_sync.apply(this);
			}
		}
		// read error occurred
		catch(e_read) {
			// destroy self and stream
			this.destroy(e_read);

			// failure
			return false;
		}

		// okay
		return true;
	}


	emit(s_event, ...a_args) {
		this.transform.emit(s_event, ...a_args);
	}

	queue(s_event, ...a_args) {
		this._a_queue_event.push({
			event: s_event,
			args: a_args,
		});
	}

	error(s_message) {
		// bail out
		throw new Error(s_message);
	}

	// parse_error (not meant to be an event callback)
	parse_error(s_expected, b_eof=false) {
		let i = this.i;

		let i_off = Math.min(i, Math.abs(i-15));

		let s = this.s;

		return this.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
			+` ${' '.repeat(i-i_off)}^\n`
			+`expected ${s_expected} ${b_eof? 'but encountered <<EOF>>': ''}.  failed to parse a valid token starting at ${s[i]? '"'+s[i]+'"': '<<EOF>>'}`);
	}

	info_error(s_message) {
		let i = this.i;

		let i_off = Math.min(i, Math.abs(i-15));

		let s = this.s;

		this.error(`\n\`${s.substr(i_off, i_off+90).replace(/[\n\t]/g, ' ')}\`\n`
			+` ${' '.repeat(i-i_off)}^\n`
			+s_message);
	}

	// end of file
	eof() {
		// there are events queued
		if(this._a_queue_event.length) {
			let a_queue = this._a_queue_event;

			// drain event queue
			while(a_queue.length) {
				// remove event from front of queue
				let h_event = a_queue.shift();

				// make event callback
				this[h_event.event](h_event.data);
			}
		}

		// invalid parsing state
		if(this.statement !== this._f_state) {
			// append EOF char
			this.s += '\0';

			// exit "flowing" mode
			this.n = this.s.length;

			// resume parsing; no errors
			if(this.safe_parse()) {
				// eof has occurred under safe parse
				if(null === this.s) return;

				// still invalid parsing state
				if(this.statement !== this._f_state) {
					return this.parse_error(this._f_state.name, true);
				}
			}
		}

		// there are still unparsed characters
		if(this.i < this.n) {
			// consume whitespace and comments
			let s = this.s;
			let i = this.i;
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i;
			R_WS.exec(s);
			i = R_WS.lastIndex;
			R_COMMENT.lastIndex = i;
			let m_comment = R_COMMENT.exec(s);

			// advance beyond comment
			if(R_COMMENT.lastIndex > i) {
				this.i = i = R_COMMENT.lastIndex;
				if(this.emit_comments) this.emit_comments(m_comment[0]);
			}

			// still unparsed characters
			if(i < this.n) {
				// not EOF
				if(!(i === this.n - 1 && '\0' === s[i])) {
					// bad input; parse error
					return this.parse_error(this._f_state.name);
				}
			}
		}

		// make buffer's alloc eligible for gc
		this.s = null;

		// transform stream
		let ds_transform = this.transform;

		// final progress update: no additional bytes were read
		ds_transform.emit('progress', 0);

		// call end event listener
		ds_transform.emit('eof', this._h_prefixes);

		// close write stream (EOF-signaling)
		ds_transform.push(null);
	}



	// bind event listeners to transform stream
	bind(g_config) {
		let ds_transform = this.transform;
		if(g_config.base) ds_transform.on('base', g_config.base);
		if(g_config.prefix) ds_transform.on('prefix', g_config.prefix);
		if(g_config.comment) ds_transform.on('comment', g_config.comment);
		if(g_config.error) ds_transform.on('error', g_config.error);
		if(g_config.read) ds_transform.once('read', g_config.read);
		if(g_config.progress) ds_transform.on('progress', g_config.progress);
		if(g_config.eof) ds_transform.once('eof', g_config.eof);
		if(g_config.end) ds_transform.once('end', g_config.end);
		if(g_config.finish) ds_transform.once('finish', g_config.finish);
		if(g_config.data) ds_transform.on('data', g_config.data);
	}

	// after a blank node subject (either property-list or colleciton)
	post_blank_subject() {
		let {s, i} = this;
		if('.' === s[i]) {
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i+1;
			R_WS.exec(s);
			this.i = R_WS.lastIndex;

			return this.statement();
		}
		return this.pairs();
	}



	// parse state for statement
	statement() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefixed name quick

			// prepare sticky regex index
			R_PREFIXED_NAME_QUICK.lastIndex = i;
			// execute regex
			let m_pnq_subject = R_PREFIXED_NAME_QUICK.exec(s);

			// regex was a match
			if(m_pnq_subject) {
				// advance index
				this.i = R_PREFIXED_NAME_QUICK.lastIndex;
				// check valid prefix
				let s_prefix_id = m_pnq_subject[1] || '';
				// invalid prefix
				if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


				// commit subject iri from resolve prefixed name
				this._kt_subject = this.prefixed_name(s_prefix_id, m_pnq_subject[2]);

				// predicate-object pairs state
				return this.pairs();

			// iriref
			}
			else {
				// prepare sticky regex index
				R_IRIREF_ESCAPELESS.lastIndex = i;
				// execute regex
				let m_iriref_e_subject = R_IRIREF_ESCAPELESS.exec(s);

				// regex was a match
				if(m_iriref_e_subject) {
					// advance index
					this.i = R_IRIREF_ESCAPELESS.lastIndex;

					// ref iri
					let s_iri = m_iriref_e_subject[1];
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set subject
						this._kt_subject = this.check_named_node_escapeless(s_iri);
					}
					// relative iri
					else {
						this._kt_subject = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
					}

					// predicate-object pairs state
					return this.pairs();



				// prefixed name
				}
				else {
					// try match
					let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
					// stack bail out
					if(!aw_valid_this_match_prefixed_name_escapeless) return true;
					let [m_prefixed_named_e_subject, im_prefixed_named_e_subject] = aw_valid_this_match_prefixed_name_escapeless;
					if(m_prefixed_named_e_subject) {
						// advance index
						this.i = im_prefixed_named_e_subject;

						// check valid prefix
						let s_prefix_id = m_prefixed_named_e_subject[1] || '';
						// invalid prefix
						if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


						// make subject key
						this._kt_subject = this.prefixed_name(s_prefix_id, m_prefixed_named_e_subject[2]);

						// predicate-object pairs state
						return this.pairs();

					// blank node label
					}
					else {
						// prepare sticky regex index
						R_BLANK_NODE_LABEL.lastIndex = i;
						// execute regex
						let m_blank_node_label_subject = R_BLANK_NODE_LABEL.exec(s);

						// regex was a match
						if(m_blank_node_label_subject) {
							// advance index
							this.i = R_BLANK_NODE_LABEL.lastIndex;
							// extract label
							let s_label = m_blank_node_label_subject[1];

							// make subject key
							this._kt_subject = this.blank_node(s_label);

							// predicate-object pairs state
							return this.pairs();

						// anonymous blank node subject
						}
						else {
							// prepare sticky regex index
							R_ANONYMOUS_BLANK_NODE.lastIndex = i;

							if(R_ANONYMOUS_BLANK_NODE.exec(s)) {
								// advance index
								this.i = R_ANONYMOUS_BLANK_NODE.lastIndex;
								// set new blank node as subject
								this._kt_subject = this.anonymous_blank_node(this.next_label());

								// goto pairs state for inside property list
								return this.pairs();

							// anonymous blank node property list subject
							}
							else {
								// prepare sticky regex index
								R_CHAR_BLANK_NODE.lastIndex = i;

								if(R_CHAR_BLANK_NODE.exec(s)) {
									// advance index
									this.i = R_CHAR_BLANK_NODE.lastIndex;
									// enter blank node
									this._kt_subject = this.anonymous_blank_node(this.next_label());

									// how to resume when we pop state
									this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_blank_subject']);

									// goto pairs state for inside property list
									return this.pairs();

								// rdf collection
								}
								else {
									// prepare sticky regex index
									R_CHAR_COLLECTION.lastIndex = i;

									if(R_CHAR_COLLECTION.exec(s)) {
										// advance index
										this.i = R_CHAR_COLLECTION.lastIndex;
										// indicate that collection subject should emit an initial statement
										this._kt_subject = null;

// (don't push state, we don't have a subject yet)

										// goto collection-subject state
										return this.collection_subject();

									// prefix with interupt (e.g., a comment)
									}
									else {
										// prepare sticky regex index
										R_PREFIX_KEYWORD.lastIndex = i;
										// execute regex
										let m_prefix_keyword = R_PREFIX_KEYWORD.exec(s);

										// regex was a match
										if(m_prefix_keyword) {
											// advance index
											this.i = R_PREFIX_KEYWORD.lastIndex;
											// save whether or not to expect a full stop
											this._b_expecting_full_stop = !!m_prefix_keyword[1];

											// goto prefix state
											return this.prefix_id();

										// base with interupt (e.g., a comment)
										}
										else {
											// prepare sticky regex index
											R_BASE_KEYWORD.lastIndex = i;
											// execute regex
											let m_base_keyword = R_BASE_KEYWORD.exec(s);

											// regex was a match
											if(m_base_keyword) {
												// advance index
												this.i = R_BASE_KEYWORD.lastIndex;
												// save whether or not to expect a full stop
												this._b_expecting_full_stop = !!m_base_keyword[1];

												// goto base state
												return this.base_iri();


											// iriref
											}
											else {
												// prepare sticky regex index
												R_IRIREF.lastIndex = i;
												// execute regex
												let m_iriref_subject = R_IRIREF.exec(s);

												// regex was a match
												if(m_iriref_subject) {
													// advance index
													this.i = R_IRIREF.lastIndex;

													// ref iri
													let s_iri = m_iriref_subject[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
													// absolute iri
													if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
														// set subject
														this._kt_subject = this.check_named_node(s_iri);
													}
													// relative iri
													else {
														this._kt_subject = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
													}

													// predicate-object pairs state
													return this.pairs();

												// prefixed name
												}
												else {
													// try match
													let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
													// stack bail out
													if(!aw_valid_this_match_prefixed_name) return true;
													let [m_prefixed_named_subject, im_prefixed_named_subject] = aw_valid_this_match_prefixed_name;
													if(m_prefixed_named_subject) {
														// advance index
														this.i = im_prefixed_named_subject;
														// check valid prefix
														let s_prefix_id = m_prefixed_named_subject[1] || '';
														// invalid prefix
														if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


														// escape local escapes
														let s_suffix = m_prefixed_named_subject[2]
															.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
															.replace(R_PN_LOCAL_ESCAPES, '$1');

														// make subject key
														this._kt_subject = this.prefixed_name(s_prefix_id, s_suffix);

														// predicate-object pairs state
														return this.pairs();


													// comment
													}
													else {
														// prepare sticky regex index
														R_COMMENT.lastIndex = i;
														// execute regex
														let m_comment = R_COMMENT.exec(s);

														// regex was a match
														if(m_comment) {
															// advance index
															i = R_COMMENT.lastIndex;
															if(this.emit_comments) this.emit_comments(m_comment[0]);
															continue;

			// not iriref, not prefixed name, not blank node label, not prefix id, not base
			// match counter: 11
														}
														else {
															// break loop to retry on next chunk if eos
															break;
														}
													} // brace #11
												} // brace #10
											} // brace #9
										} // brace #8
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('statement');
				}
			}
		}

		// save state before pausing
		this._f_state = this.statement;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for pairs
	pairs() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// benchmarks indicate: regex for end of blank node property list faster than ch


// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_predicate = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_predicate) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_predicate[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set predicate
					this._kt_predicate = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_predicate = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

				// object-list state
				return this.object_list();

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_predicate, im_prefixed_named_e_predicate] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_predicate) {
					// advance index
					this.i = im_prefixed_named_e_predicate;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_predicate[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// make predicate key
					this._kt_predicate = this.prefixed_name(s_prefix_id, m_prefixed_named_e_predicate[2]);

					// object-list state
					return this.object_list();

				// 'a'
				}
				else {
					// prepare sticky regex index
					R_A.lastIndex = i;

					if(R_A.exec(s)) {
						// advance index
						this.i = R_A.lastIndex;
						// make predicate key
						this._kt_predicate = this._kt_rdf_type;

						// object-list state
						return this.object_list();

					// ']' end of blank node property list
					}
					else {
						// prepare sticky regex index
						R_CHAR_KET.lastIndex = i;

						if(R_CHAR_KET.exec(s)) {
							// advance index
							this.i = R_CHAR_KET.lastIndex;
							let s_resume_state;
							[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
							return this[s_resume_state]();

						// iriref
						}
						else {
							// prepare sticky regex index
							R_IRIREF.lastIndex = i;
							// execute regex
							let m_iriref_predicate = R_IRIREF.exec(s);

							// regex was a match
							if(m_iriref_predicate) {
								// advance index
								this.i = R_IRIREF.lastIndex;

								// ref iri
								let s_iri = m_iriref_predicate[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
								// absolute iri
								if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
									// set predicate
									this._kt_predicate = this.check_named_node(s_iri);
								}
								// relative iri
								else {
									this._kt_predicate = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
								}

								// object-list state
								return this.object_list();

							// prefixed name
							}
							else {
								// try match
								let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
								// stack bail out
								if(!aw_valid_this_match_prefixed_name) return true;
								let [m_prefixed_named_predicate, im_prefixed_named_predicate] = aw_valid_this_match_prefixed_name;
								if(m_prefixed_named_predicate) {
									// advance index
									this.i = im_prefixed_named_predicate;
									// check valid prefix
									let s_prefix_id = m_prefixed_named_predicate[1] || '';
									// invalid prefix
									if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


									// escape local escapes
									let s_suffix = m_prefixed_named_predicate[2]
										.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
										.replace(R_PN_LOCAL_ESCAPES, '$1');

									// make predicate key
									this._kt_predicate = this.prefixed_name(s_prefix_id, s_suffix);

									// object-list state
									return this.object_list();
								}
								else {
									// prepare sticky regex index
									R_COMMENT.lastIndex = i;
									// execute regex
									let m_comment = R_COMMENT.exec(s);

									// regex was a match
									if(m_comment) {
										// advance index
										i = R_COMMENT.lastIndex;
										if(this.emit_comments) this.emit_comments(m_comment[0]);
										continue;

			// not iriref, not prefixed name, not 'a'
			// match counter: 6
									}
									else {
										// break loop to retry on next chunk if eos
										break;
									}
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('pairs');
				}
			}
		}

		// save state before pausing
		this._f_state = this.pairs;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for object_list
	object_list() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// string literal * double
			if('"' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if('"' === s[i+1] && '"' === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_double();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_double();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && '"' !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_double();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// prefixed name quick
			}
			else {
				// prepare sticky regex index
				R_PREFIXED_NAME_QUICK.lastIndex = i;
				// execute regex
				let m_pnq_object = R_PREFIXED_NAME_QUICK.exec(s);

				// regex was a match
				if(m_pnq_object) {
					// advance index
					this.i = R_PREFIXED_NAME_QUICK.lastIndex;
					// check valid prefix
					let s_prefix_id = m_pnq_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_pnq_object[2]);

				// iriref
				}
				else {
					// prepare sticky regex index
					R_IRIREF_ESCAPELESS.lastIndex = i;
					// execute regex
					let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

					// regex was a match
					if(m_iriref_e_object) {
						// advance index
						this.i = R_IRIREF_ESCAPELESS.lastIndex;

						// ref iri
						let s_iri = m_iriref_e_object[1];
						// absolute iri
						if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
							// set object
							this._kt_object = this.check_named_node_escapeless(s_iri);
						}
						// relative iri
						else {
							this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
						}

					// prefixed name
					}
					else {
						// try match
						let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
						// stack bail out
						if(!aw_valid_this_match_prefixed_name_escapeless) return true;
						let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
						if(m_prefixed_named_e_object) {
							// advance index
							this.i = im_prefixed_named_e_object;
							// check valid prefix
							let s_prefix_id = m_prefixed_named_e_object[1] || '';
							// invalid prefix
							if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


							// commit object iri from resolve prefixed name
							this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

						// string literal * single
						}
						else 	if('\'' === x) {
							// enough chars to deduce type
							if((i+2) < n) {
								// long type
								if("'" === s[i+1] && "'" === s[i+2]) {
									// advance index beyond token
									this.i = i + 3;

									// read contents
									return this.string_literal_long_single();
								}
								// not long type
								else {
									// advance index beyond token
									this.i = i + 1;

									// read contents
									return this.string_literal_short_single();
								}
							}
							// enough chars to eliminate long type
							else if((i+1) < n && "'" !== s[i+1]) {
								// advance index beyond token
								this.i = i + 1;

								// read contents
								return this.string_literal_short_single();
							}
							// not enough chars to deduce type; retry next chunk
							else {
								break;
							}

						// numeric literal
						}
						else {
							// prepare sticky regex index
							R_NUMERIC_LITERAL.lastIndex = i;
							// execute regex
							let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

							// regex was a match
							if(m_numeric_literal) {
								// advance index
								this.i = R_NUMERIC_LITERAL.lastIndex;
								// it has exponent term, xsd:double
								if(m_numeric_literal[4]) {
									this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
								}
								// contains decimal point, xsd:decimal
								else if(m_numeric_literal[2] || m_numeric_literal[3]) {
									this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
								}
								// otherwise, it is an integer
								else {
									this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
								}


							// boolean literal
							}
							else {
								// prepare sticky regex index
								R_BOOLEAN_LITERAL.lastIndex = i;
								// execute regex
								let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

								// regex was a match
								if(m_boolean_literal) {
									// advance index
									this.i = R_BOOLEAN_LITERAL.lastIndex;
									// make literal
									this._kt_object = this._dc_factory.boolean(!!m_boolean_literal[1]);


								// blank node property list
								}
								else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
									R_WS.lastIndex = i+1;
									R_WS.exec(s);
									this.i = R_WS.lastIndex;

									// make object
									let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());

									// emit statement event
									this.data();


									// push state to stack
									this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_object']);

									// set new subject
									this._kt_subject = kt_blank_node;

									// goto parsing pairs state
									return this.pairs();

								// labeled blank node
								}
								else {
									// prepare sticky regex index
									R_BLANK_NODE_LABEL_TERMINAL.lastIndex = i;
									// execute regex
									let m_blank_node_label_object = R_BLANK_NODE_LABEL_TERMINAL.exec(s);

									// regex was a match
									if(m_blank_node_label_object) {
										// advance index
										this.i = R_BLANK_NODE_LABEL_TERMINAL.lastIndex;
										// ref blank node label
										let s_label = m_blank_node_label_object[1];

										// make object
										this._kt_object = this.blank_node(s_label);

									// collection
									}
									else 	if('(' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
										R_WS.lastIndex = i+1;
										R_WS.exec(s);
										this.i = R_WS.lastIndex;

										// state to resume after collection ends
										this._a_nested.push([this._kt_subject, this._kt_predicate, 'post_object']);

										// goto collection-object state
										return this.collection_object();

									// iriref
									}
									else {
										// prepare sticky regex index
										R_IRIREF.lastIndex = i;
										// execute regex
										let m_iriref_object = R_IRIREF.exec(s);

										// regex was a match
										if(m_iriref_object) {
											// advance index
											this.i = R_IRIREF.lastIndex;

											// ref iri
											let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
											// absolute iri
											if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
												// set object
												this._kt_object = this.check_named_node(s_iri);
											}
											// relative iri
											else {
												this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
											}

										// prefixed name
										}
										else {
											// try match
											let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
											// stack bail out
											if(!aw_valid_this_match_prefixed_name) return true;
											let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
											if(m_prefixed_named_object) {
												// advance index
												this.i = im_prefixed_named_object;
												// check valid prefix
												let s_prefix_id = m_prefixed_named_object[1] || '';
												// invalid prefix
												if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


												// escape local escapes
												let s_suffix = m_prefixed_named_object[2]
													.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
													.replace(R_PN_LOCAL_ESCAPES, '$1');

												// commit object iri from resolve prefixed name
												this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
											}
											else {
												// prepare sticky regex index
												R_COMMENT.lastIndex = i;
												// execute regex
												let m_comment = R_COMMENT.exec(s);

												// regex was a match
												if(m_comment) {
													// advance index
													i = R_COMMENT.lastIndex;
													if(this.emit_comments) this.emit_comments(m_comment[0]);
													continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 9
												}
												else {
													// break loop to retry on next chunk if eos
													break;
												}
											} // brace #9
										} // brace #8
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			// fall through for cases that did not change state on their own
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('object_list');
				}
			}
		}

		// save state before pausing
		this._f_state = this.object_list;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_short_double
	string_literal_short_double() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_short_double: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_SHORT_DOUBLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_SHORT_DOUBLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_SHORT_DOUBLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case '"': {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 1;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_SHORT_DOUBLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_SHORT_DOUBLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_short_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_short_double;
						}
					}

					// invalid '\n'
					case '\n': {
						return this.info_error(`expected string_literal_short_double but invalid line feed character '\\n' (newline) within contents. failed to parse a valid token`);
					}

					// invalid '\r'
					case '\r': {
						return this.info_error(`expected string_literal_short_double but invalid form feed character '\\r' (carriage return) within contents. failed to parse a valid token`);
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_short_double`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// save
				this._s_literal += i? s.slice(i): s;

				// set unparsed index
				i = n;

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_short_double');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_short_double;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_short_single
	string_literal_short_single() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_short_single: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_SHORT_SINGLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_SHORT_SINGLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_SHORT_SINGLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case "'": {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 1;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_SHORT_SINGLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_SHORT_SINGLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_short_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_short_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_short_single;
						}
					}

					// invalid '\n'
					case '\n': {
						return this.info_error(`expected string_literal_short_single but invalid line feed character '\\n' (newline) within contents. failed to parse a valid token`);
					}

					// invalid '\r'
					case '\r': {
						return this.info_error(`expected string_literal_short_single but invalid form feed character '\\r' (carriage return) within contents. failed to parse a valid token`);
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_short_single`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// save
				this._s_literal += i? s.slice(i): s;

				// set unparsed index
				i = n;

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_short_single');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_short_single;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_long_double
	string_literal_long_double() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_long_double: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_LONG_DOUBLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_LONG_DOUBLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_LONG_DOUBLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case '"': {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 3;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_LONG_DOUBLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_LONG_DOUBLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_long_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_long_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_long_double;
						}
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_long_double`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// could be unfinished terminator
				R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM.lastIndex = i;
				let m_unfinished = R_STRLIT_LONG_DOUBLE_UNFINISHED_TERM.exec(s);

				// unfinished terminator
				if(m_unfinished) {
					// save valid portion
					this._s_literal += s.slice(i, m_unfinished.index);

					// set unparsed index
					i = m_unfinished.index;
				}
				// not unfinished
				else {
					// save
					this._s_literal += i? s.slice(i): s;

					// set unparsed index
					i = n;
				}

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_long_double');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_long_double;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal_long_single
	string_literal_long_single() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		string_literal_long_single: while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// something breaks string in this chunk

			// prepare sticky regex index
			R_STRLIT_LONG_SINGLE_BREAK.lastIndex = i;
			// execute regex
			let m_break = R_STRLIT_LONG_SINGLE_BREAK.exec(s);

			// regex was a match
			if(m_break) {
				// advance index
				this.i = R_STRLIT_LONG_SINGLE_BREAK.lastIndex;
				// index of break
				let i_break = m_break.index;

				// add to contents
				this._s_literal += s.slice(i, i_break);

				// depending on char
				switch(s[i_break]) {
					// terminator
					case "'": {
					// advance index to next token beyond delimiter
					// consume whitespace (and incidentally reset index)
						R_WS.lastIndex = i_break + 3;
						R_WS.exec(s);
						this.i = R_WS.lastIndex;

						// resume eating whitespace at start of next chunk
						this._b_trim_start = true;

						// consume rest
						return this.datatype_or_langtag();
					}

					// escape
					case '\\': {
						// try to find end
						R_STRLIT_LONG_SINGLE_TERM.lastIndex = i_break;
						let m_term = R_STRLIT_LONG_SINGLE_TERM.exec(s);

						// end is in this chunk
						if(m_term) {
							// index of terminator
							let i_term = m_term.index;

							// extract dirty potion
							let s_dirty = s.slice(i_break, i_term);

							// clean and save
							this._s_literal += unescape_literal_long_hard(s_dirty);

							// advance index beyond terminator
							this.i = i_term + m_term[0].length;

							// resume eating whitespace at start of next chunk
							this._b_trim_start = true;

							// consume rest
							return this.datatype_or_langtag();
						}
						// end is not in this chunk
						else {
							// extract whole portion
							let s_dirty = s.slice(i_break);

							// unescape to clean part
							let [s_clean, s_incomplete] = unescape_literal_long_soft(s_dirty);

							// save
							this._s_literal += s_clean;

							// set unparsed index
							i = n - s_incomplete.length;

							// reached eos; pause normally
							break string_literal_long_single;
						}
					}

					// invalid
					default: {
						console.assert(`Unhandle invalid character ${JSON.stringify(s[i_break])} case for string_literal_long_single`);
					}
				}

		// no terminator and nothing to escape
		// match counter: 0
			}
			else {
				// could be unfinished terminator
				R_STRLIT_LONG_SINGLE_UNFINISHED_TERM.lastIndex = i;
				let m_unfinished = R_STRLIT_LONG_SINGLE_UNFINISHED_TERM.exec(s);

				// unfinished terminator
				if(m_unfinished) {
					// save valid portion
					this._s_literal += s.slice(i, m_unfinished.index);

					// set unparsed index
					i = m_unfinished.index;
				}
				// not unfinished
				else {
					// save
					this._s_literal += i? s.slice(i): s;

					// set unparsed index
					i = n;
				}

				// reached eos; pause normally
				break;
			}
		}

		// do not eat whitespace at start of next chunk
		this._b_trim_start = false;

	// ran out of characters
	// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('string_literal_long_single');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal_long_single;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for string_literal
	string_literal() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref character
			let x = s[i];

			// string literal * double
			if('"' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if('"' === s[i+1] && '"' === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_double();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_double();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && '"' !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_double();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// string literal * single
			}
			else 	if('\'' === x) {
				// enough chars to deduce type
				if((i+2) < n) {
					// long type
					if("'" === s[i+1] && "'" === s[i+2]) {
						// advance index beyond token
						this.i = i + 3;

						// read contents
						return this.string_literal_long_single();
					}
					// not long type
					else {
						// advance index beyond token
						this.i = i + 1;

						// read contents
						return this.string_literal_short_single();
					}
				}
				// enough chars to eliminate long type
				else if((i+1) < n && "'" !== s[i+1]) {
					// advance index beyond token
					this.i = i + 1;

					// read contents
					return this.string_literal_short_single();
				}
				// not enough chars to deduce type; retry next chunk
				else {
					break;
				}

			// not string literal long single quote, not string literal single quote
			// match counter: 0
			}
			else {
				// break loop to retry on next chunk if eos
				break;
			}
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_string_length) {
					return this.parse_error('string_literal');
				}
			}
		}

		// save state before pausing
		this._f_state = this.string_literal;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for datatype_or_langtag
	datatype_or_langtag() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref character
			let x = s[i];

			// next token indicates datatype or langtag
			if('^' === x || '@' === x) {
// '^^' datatype

				// prepare sticky regex index
				R_DOUBLE_CARET.lastIndex = i;

				if(R_DOUBLE_CARET.exec(s)) {
					// advance index
					this.i = R_DOUBLE_CARET.lastIndex;
					return this.datatype();

				// '@' language tag
				}
				else {
					// prepare sticky regex index
					R_LANGTAG.lastIndex = i;
					// execute regex
					let m_langtag = R_LANGTAG.exec(s);

					// regex was a match
					if(m_langtag) {
						// advance index
						this.i = R_LANGTAG.lastIndex;
						this._kt_object = this._dc_factory.languagedLiteral(this._s_literal, m_langtag[1]);

						// reset literal
						this._s_literal = '';

				// next token definitely datatype or langtag, we are just being interrupted by eos
				// match counter: 1
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #1
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					continue;

				// match counter: 1
				}
				else {
					this._kt_object = this._dc_factory.simpleLiteral(this._s_literal);

					// reset literal
					this._s_literal = '';

				// not datatype, not language tag => that's okay! those are optional
				}
			} // brace #1


			// goto end of statement state
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype_or_langtag');
				}
			}
		}

		// save state before pausing
		this._f_state = this.datatype_or_langtag;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for datatype
	datatype() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let kt_datatype = null;

// prefixed name quick

			// prepare sticky regex index
			R_PREFIXED_NAME_QUICK.lastIndex = i;
			// execute regex
			let m_pnq_datatype = R_PREFIXED_NAME_QUICK.exec(s);

			// regex was a match
			if(m_pnq_datatype) {
				// advance index
				this.i = R_PREFIXED_NAME_QUICK.lastIndex;
				// check valid prefix
				let s_prefix_id = m_pnq_datatype[1] || '';
				// invalid prefix
				if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


				// commit object iri from resolve prefixed name
				kt_datatype = this.prefixed_name(s_prefix_id, m_pnq_datatype[2]);

			// iriref
			}
			else {
				// prepare sticky regex index
				R_IRIREF_ESCAPELESS.lastIndex = i;
				// execute regex
				let m_iriref_e_datatype = R_IRIREF_ESCAPELESS.exec(s);

				// regex was a match
				if(m_iriref_e_datatype) {
					// advance index
					this.i = R_IRIREF_ESCAPELESS.lastIndex;
					let p_datatype;

					// ref iri
					let s_iri = m_iriref_e_datatype[1];
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set p_datatype
						p_datatype = s_iri;
					}
					// relative iri
					else {
						p_datatype = uri.resolve(this._s_base_url, s_iri);
					}

					kt_datatype = this.check_named_node_escapeless(p_datatype);

				// prefixed name
				}
				else {
					// try match
					let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
					// stack bail out
					if(!aw_valid_this_match_prefixed_name_escapeless) return true;
					let [m_prefixed_named_e_datatype, im_prefixed_named_e_datatype] = aw_valid_this_match_prefixed_name_escapeless;
					if(m_prefixed_named_e_datatype) {
						// advance index
						this.i = im_prefixed_named_e_datatype;
						// check valid prefix
						let s_prefix_id = m_prefixed_named_e_datatype[1] || '';
						// invalid prefix
						if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


						kt_datatype = this.prefixed_name(s_prefix_id, m_prefixed_named_e_datatype[2]);

					// iriref
					}
					else {
						// prepare sticky regex index
						R_IRIREF.lastIndex = i;
						// execute regex
						let m_iriref_datatype = R_IRIREF.exec(s);

						// regex was a match
						if(m_iriref_datatype) {
							// advance index
							this.i = R_IRIREF.lastIndex;
							let p_datatype;

							// ref iri
							let s_iri = m_iriref_e_datatype[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
							// absolute iri
							if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
								// set p_datatype
								p_datatype = s_iri;
							}
							// relative iri
							else {
								p_datatype = uri.resolve(this._s_base_url, s_iri);
							}

							kt_datatype = this.check_named_node(p_datatype);

						// prefixed name
						}
						else {
							// try match
							let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
							// stack bail out
							if(!aw_valid_this_match_prefixed_name) return true;
							let [m_prefixed_named_datatype, im_prefixed_named_datatype] = aw_valid_this_match_prefixed_name;
							if(m_prefixed_named_datatype) {
								// advance index
								this.i = im_prefixed_named_datatype;
								// check valid prefix
								let s_prefix_id = m_prefixed_named_datatype[1] || '';
								// invalid prefix
								if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


								// escape local escapes
								let s_suffix = m_prefixed_named_datatype[2]
									.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
									.replace(R_PN_LOCAL_ESCAPES, '$1');

								// set literal datatype
								kt_datatype = this.prefixed_name(s_prefix_id, s_suffix);

			// not iriref, not prefixed name
			// match counter: 4
							}
							else {
								// break loop to retry on next chunk if eos
								break;
							}
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			this._kt_object = this._dc_factory.datatypedLiteral(this._s_literal, kt_datatype);

			// reset literal
			this._s_literal = '';

			// goto end of statement state
			// at this point, a new statement has been parsed
			this.data();


			// goto next parsing state; bail out of stack
			return this.after_end_of_statement;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('datatype');
				}
			}
		}

		// save state before pausing
		this._f_state = this.datatype;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for post_object
	post_object() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let i_reset = i;

			// benchmarks confirm: character ref faster than regexes in this context
			let x = s[i];

			// advance index to next token beyond delimiter
			// consume whitespace (and incidentally reset index)
			R_WS.lastIndex = i+1;
			R_WS.exec(s);
			this.i = R_WS.lastIndex;

			// ',' more objects
			if(',' === x) {
				return this.object_list();

			// ';' more predicate-object pairs
			}
			else 	if(';' === x) {
				for(;;) {
					// next token is end of outer section
					let s_peek = s[this.i];
					if('.' === s_peek || ']' === s_peek || ';' === s_peek) {
						// goto post_object state
						return this.post_object();
					}
					// comment
					else if('#' === s_peek) {
						// comment
						i = this.i;

						// prepare sticky regex index
						R_COMMENT.lastIndex = i;
						// execute regex
						let m_comment = R_COMMENT.exec(s);

						// regex was a match
						if(m_comment) {
							// advance index
							this.i = R_COMMENT.lastIndex;
							if(this.emit_comments) this.emit_comments(m_comment[0]);
							// retry
							continue;
						}


						// no eol to close comment (yet)
						else {
							// already consumed
							break;
						}
					}
					// eos
					else if(this.i === n) {
						break;
					}
					// something else
					else {
						return this.pairs();
					}
				}

				// rather than pushing a dedicated state, just try again next chunk
				i = i_reset;
				break;

			// '.' end of statement
			}
			else 	if('.' === x) {
				// assert not nested
				if(this._a_nested.length) {
					// reset index to that character
					this.i = i;

					// emit parse error
					return this.parse_error('end_of_property_list');
				}
				return this.statement();

			// ']' end of property-object pairs
			}
			else 	if(']' === x) {
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();

			// ')' end of collection
			}
			else 	if(')' === x) {
				// should not be here
				return Reader$syntax_error(this, i, 'post_object', 'but encountered end of collection');


			// comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					// do not change state
					continue;

			// comment interrupted by eos?
			// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('post_object');
				}
			}
		}

		// save state before pausing
		this._f_state = this.post_object;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for base_iri
	base_iri() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefix id

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_base = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_base) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_base[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set base_url
					this._s_base_url = s_iri;
				}
				// relative iri
				else {
					this._s_base_url = uri.resolve(this._s_base_url, s_iri);
				}		let m_base_iri = R_BASE_IRI.exec(this._s_base_url);
				this._s_base_url = m_base_iri[1];
				this._s_base_url_root = m_base_iri[2] || '';
				this._s_base_url_scheme = m_base_iri[3] || '';
				this._s_base_url_path = m_base_iri[4] || '';


				// emit base event
				this.emit('base', this._s_base_url);

				if(this._b_expecting_full_stop) {
					// change state
					return this.full_stop();
				}

				// goto prefix iri state
				return this.statement();

			// prefix id
			}
			else {
				// prepare sticky regex index
				R_IRIREF.lastIndex = i;
				// execute regex
				let m_iriref_base = R_IRIREF.exec(s);

				// regex was a match
				if(m_iriref_base) {
					// advance index
					this.i = R_IRIREF.lastIndex;

					// ref iri
					let s_iri = m_iriref_base[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set base_url
						this._s_base_url = s_iri;
					}
					// relative iri
					else {
						this._s_base_url = uri.resolve(this._s_base_url, s_iri);
					}		let m_base_iri = R_BASE_IRI.exec(this._s_base_url);
					this._s_base_url = m_base_iri[1];
					this._s_base_url_root = m_base_iri[2] || '';
					this._s_base_url_scheme = m_base_iri[3] || '';
					this._s_base_url_path = m_base_iri[4] || '';


					// emit base event
					this.emit('base', this._s_base_url);

					if(this._b_expecting_full_stop) {
						// change state
						return this.full_stop();
					}

					// goto prefix iri state
					return this.statement();

				// for poorly-placed comments
				}
				else {
					// prepare sticky regex index
					R_COMMENT.lastIndex = i;
					// execute regex
					let m_comment = R_COMMENT.exec(s);

					// regex was a match
					if(m_comment) {
						// advance index
						i = R_COMMENT.lastIndex;
						if(this.emit_comments) this.emit_comments(m_comment[0]);
						// do not change state
						continue;

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('base_iri');
				}
			}
		}

		// save state before pausing
		this._f_state = this.base_iri;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for prefix_id
	prefix_id() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
// prefix id

			// prepare sticky regex index
			R_PREFIX_ID.lastIndex = i;
			// execute regex
			let m_prefix_id = R_PREFIX_ID.exec(s);

			// regex was a match
			if(m_prefix_id) {
				// advance index
				this.i = R_PREFIX_ID.lastIndex;
				// set temp prefix id
				this._s_temp_prefix_id = m_prefix_id[1];

				// goto prefix iri state
				return this.prefix_iri();

			// for poorly-placed comments
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					// do not change state
					continue;

				// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('prefix_id');
				}
			}
		}

		// save state before pausing
		this._f_state = this.prefix_id;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for prefix_iri
	prefix_iri() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			let h_prefixes = this._h_prefixes;
			let s_prefix_id = this._s_temp_prefix_id;
			let p_prefix_iri;

// prefix iri

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_prefix = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_prefix) {
				// advance index
				this.i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_prefix[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set p_prefix_iri
					p_prefix_iri = s_iri;
				}
				// relative iri
				else {
					p_prefix_iri = uri.resolve(this._s_base_url, s_iri);
				}

				let b_relax = this._b_relax;

// existing mapping

				if(s_prefix_id in h_prefixes) {
					// doesn't match existing
					if(p_prefix_iri !== h_prefixes[s_prefix_id]) {
						// emit change event
						if(this.prefix_change) {
							this.prefix_change(s_prefix_id, h_prefixes[s_prefix_id], p_prefix_iri);
						}

						// update prefix
						h_prefixes[s_prefix_id] = p_prefix_iri;
					}
				}
				// first mapping
				else {
					// check namespace, invalid
					if(!b_relax && !RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
						return this.error(`Invalid namespace for prefixed name: "${s_prefix_id}:"`);
					}

					// set prefix
					h_prefixes[s_prefix_id] = p_prefix_iri;
				}

				// check iri, invalid
				if(!b_relax && !RT_NAMED_NODE_VALID.test(p_prefix_iri)) {
					return this.error(`Invalid IRI found in prefix delcaration: "${s_iri}"`);
				}

				// emit prefix event
				this.event('prefix', s_prefix_id, p_prefix_iri);

				if(this._b_expecting_full_stop) {
					// change state
					return this.full_stop();
				}

				// goto statement state
				return this.statement();

			// prefix iri
			}
			else {
				// prepare sticky regex index
				R_IRIREF.lastIndex = i;
				// execute regex
				let m_iriref_prefix = R_IRIREF.exec(s);

				// regex was a match
				if(m_iriref_prefix) {
					// advance index
					this.i = R_IRIREF.lastIndex;

					// ref iri
					let s_iri = m_iriref_prefix[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
					// absolute iri
					if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
						// set p_prefix_iri
						p_prefix_iri = s_iri;
					}
					// relative iri
					else {
						p_prefix_iri = uri.resolve(this._s_base_url, s_iri);
					}

					let b_relax = this._b_relax;

// existing mapping

					if(s_prefix_id in h_prefixes) {
						// doesn't match existing
						if(p_prefix_iri !== h_prefixes[s_prefix_id]) {
							// emit change event
							if(this.prefix_change) {
								this.prefix_change(s_prefix_id, h_prefixes[s_prefix_id], p_prefix_iri);
							}

							// update prefix
							h_prefixes[s_prefix_id] = p_prefix_iri;
						}
					}
					// first mapping
					else {
						// check namespace, invalid
						if(!b_relax && !RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
							return this.error(`Invalid namespace for prefixed name: "${s_prefix_id}:"`);
						}

						// set prefix
						h_prefixes[s_prefix_id] = p_prefix_iri;
					}

					// check iri, invalid
					if(!b_relax && !RT_NAMED_NODE_VALID.test(p_prefix_iri)) {
						return this.error(`Invalid IRI found in prefix delcaration: "${s_iri}"`);
					}

					// emit prefix event
					this.event('prefix', s_prefix_id, p_prefix_iri);

					if(this._b_expecting_full_stop) {
						// change state
						return this.full_stop();
					}

					// goto statement state
					return this.statement();

				// for poorly-placed comments
				}
				else {
					// prepare sticky regex index
					R_COMMENT.lastIndex = i;
					// execute regex
					let m_comment = R_COMMENT.exec(s);

					// regex was a match
					if(m_comment) {
						// advance index
						i = R_COMMENT.lastIndex;
						if(this.emit_comments) this.emit_comments(m_comment[0]);
						// do not change state
						continue;

					// match counter: 2
					}
					else {
						// break loop to retry on next chunk if eos
						break;
					}
				} // brace #2
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('prefix_iri');
				}
			}
		}

		// save state before pausing
		this._f_state = this.prefix_iri;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}


// in case eos happens twice during prefix / base (extremely unlikely)


	// parse state for full_stop
	full_stop() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// prepare sticky regex index
			R_CHAR_STOP.lastIndex = i;

			if(R_CHAR_STOP.exec(s)) {
				// advance index
				this.i = R_CHAR_STOP.lastIndex;
				// resume statement
				return this.statement();

			// poorly-placed comment
			}
			else {
				// prepare sticky regex index
				R_COMMENT.lastIndex = i;
				// execute regex
				let m_comment = R_COMMENT.exec(s);

				// regex was a match
				if(m_comment) {
					// advance index
					i = R_COMMENT.lastIndex;
					if(this.emit_comments) this.emit_comments(m_comment[0]);
					// try again
					continue;

			// possibly interrupted by eos
			// match counter: 1
				}
				else {
					// break loop to retry on next chunk if eos
					break;
				}
			} // brace #1
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('full_stop');
				}
			}
		}

		// save state before pausing
		this._f_state = this.full_stop;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for collection_subject
	collection_subject() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// end of collection
			if(')' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// no items in collection subject
				if(null === this._kt_subject) {
					// prepare subject
					this._kt_subject = this._kt_rdf_nil;

					// state was never pushed to stack, jump to post_subject state
					return this.post_blank_subject();
				}
// otherwise, there must be items in collection

				// commit collection end
				this._kt_object = this._kt_rdf_nil;
				this.data();


				// restore state from stack
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();
			}



			// otherwise, pre-emptively secure the next blank node label
			let s_pointer_label;

			// very first collection object
			let b_pushed = false;
			if(null === this._kt_subject) {
				// set quasi subject (really for resume state)
				s_pointer_label = this.next_label();
				this._kt_subject = this.anonymous_blank_node(s_pointer_label);
				this._a_nested.push([this._kt_subject, this._kt_predicate, 'pairs']);
				// reset subject for later conditional branch
				this._kt_subject = null;
				b_pushed = true;
			}

// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_object) {
				// advance index
				i = R_IRIREF_ESCAPELESS.lastIndex;

				// ref iri
				let s_iri = m_iriref_e_object[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set object
					this._kt_object = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_object) {
					// advance index
					i = im_prefixed_named_e_object;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

				// string literal
				}
				else 	if('"' === x || '\'' === x) {
					// first item in list
					if(null === this._kt_subject) {
						s_pointer_label = this.next_label();
						this._kt_subject = this.anonymous_blank_node(s_pointer_label);
						this._kt_predicate = this._kt_rdf_first;
					}
					// not first item in list
					else {
						// make nest list item
						s_pointer_label = this.next_label();
						let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
						this.data();


						// setup for object literal
						this._kt_subject = kt_blank_node;
						this._kt_predicate = this._kt_rdf_first;
					}

					// how to resume collection subject state after object literal
					this.after_end_of_statement = function() {
						this._kt_predicate = this._kt_rdf_rest;
						this.after_end_of_statement = this.post_object;
						return this.collection_subject();
					};
					return this.string_literal();

				// numeric literal
				}
				else {
					// prepare sticky regex index
					R_NUMERIC_LITERAL.lastIndex = i;
					// execute regex
					let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

					// regex was a match
					if(m_numeric_literal) {
						// advance index
						i = R_NUMERIC_LITERAL.lastIndex;
						// it has exponent term, xsd:double
						if(m_numeric_literal[4]) {
							this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
						}
						// contains decimal point, xsd:decimal
						else if(m_numeric_literal[2] || m_numeric_literal[3]) {
							this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
						}
						// otherwise, it is an integer
						else {
							this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
						}


					// boolean literal
					}
					else {
						// prepare sticky regex index
						R_BOOLEAN_LITERAL.lastIndex = i;
						// execute regex
						let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

						// regex was a match
						if(m_boolean_literal) {
							// advance index
							i = R_BOOLEAN_LITERAL.lastIndex;
							// make literal
							this._kt_object = this._dc_factory.boolean(!!m_boolean_literal[1]);

						// blank node property list
						}
						else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							this.i = R_WS.lastIndex;

							// this blank node is just the next item in the list
							s_pointer_label = this.next_label();
							let kt_blank_node;
							if(null !== this._kt_subject) {
								kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
								this.data();
							}

							// subject needs to be set
							this._kt_subject = kt_blank_node || this.anonymous_blank_node(s_pointer_label);
							this._kt_predicate = this._kt_rdf_first;
							let s_label = this.next_label();
							kt_blank_node = this._kt_object = this.anonymous_blank_node(s_label);
							this.data();


							// when resume
							this._kt_predicate = this._kt_rdf_rest;

							// push state
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_subject']);

							// prepare next triple
							this._kt_subject = kt_blank_node;

							// goto parsing pairs state
							return this.pairs();

						// new collection
						}
						else 	if('(' === x) {
							// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							i = R_WS.lastIndex;

							// empty collection
							if(')' === s[i]) {
								this.i = i;
								this._kt_subject = this._a_nested[this._a_nested.length-1][0];
								this._kt_predicate = this._kt_rdf_first;
								this._a_nested.push([
									this._kt_subject,
									this._kt_rdf_rest,
									'collection_subject',
								]);
								return this.collection_object();
							}



							// commit list item pointer
							s_pointer_label = this.next_label();
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
							this.data();


							// add this list as an item to the outer list
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// prepare next triple
							this._kt_predicate = this._kt_rdf_first;



							// flowing
							continue;

						// labeled blank node
						}
						else {
							// prepare sticky regex index
							R_BLANK_NODE_LABEL.lastIndex = i;
							// execute regex
							let m_blank_node_label_object = R_BLANK_NODE_LABEL.exec(s);

							// regex was a match
							if(m_blank_node_label_object) {
								// advance index
								i = R_BLANK_NODE_LABEL.lastIndex;
								// ref blank node label
								let s_label = m_blank_node_label_object[1];

								// make object
								this._kt_object = this.blank_node(s_label);

							// iriref
							}
							else {
								// prepare sticky regex index
								R_IRIREF.lastIndex = i;
								// execute regex
								let m_iriref_object = R_IRIREF.exec(s);

								// regex was a match
								if(m_iriref_object) {
									// advance index
									i = R_IRIREF.lastIndex;

									// ref iri
									let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
									// absolute iri
									if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
										// set object
										this._kt_object = this.check_named_node(s_iri);
									}
									// relative iri
									else {
										this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
									}

								// prefixed name
								}
								else {
									// try match
									let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
									// stack bail out
									if(!aw_valid_this_match_prefixed_name) return true;
									let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
									if(m_prefixed_named_object) {
										// advance index
										i = im_prefixed_named_object;
										// check valid prefix
										let s_prefix_id = m_prefixed_named_object[1] || '';
										// invalid prefix
										if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


										// escape local escapes
										let s_suffix = m_prefixed_named_object[2]
											.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
											.replace(R_PN_LOCAL_ESCAPES, '$1');

										// commit object iri from resolve prefixed name
										this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
									}
									else {
										// prepare sticky regex index
										R_COMMENT.lastIndex = i;
										// execute regex
										let m_comment = R_COMMENT.exec(s);

										// regex was a match
										if(m_comment) {
											// advance index
											i = R_COMMENT.lastIndex;
											if(this.emit_comments) this.emit_comments(m_comment[0]);
											continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 7
										}
										else {
											// ran out of characters after pushing state, pop it
											if(b_pushed) this._a_nested.pop();

											// break loop to retry on next chunk if eos
											break;
										}
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1


			let kt_blank_node_outer;
			if(!s_pointer_label) s_pointer_label = this.next_label();

			// not the very first item of collection subject
			if(this._kt_subject !== null) {
				// ref object
				let w_object = this._kt_object;

				// create blanknode to embed list
				kt_blank_node_outer = this._kt_object = this.anonymous_blank_node(s_pointer_label);

				// emit statement that functions as collection's head "pointer"
				this.data();


				// swap back object
				this._kt_object = w_object;
			}

			// emit statement that is item
			this._kt_subject = kt_blank_node_outer || this.anonymous_blank_node(s_pointer_label);
			this._kt_predicate = this._kt_rdf_first;
			this.data();


			// prepare next predicate
			this._kt_predicate = this._kt_rdf_rest;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('collection_subject');
				}
			}
		}

		// save state before pausing
		this._f_state = this.collection_subject;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}



	// parse state for collection_object
	collection_object() {
		// destruct chunk, length, and index
		let {s, n, i} = this;

		// start labeled loop, run while there are characters
		while(i < n) {  // eslint-disable-line no-unmodified-loop-condition
			// ref char
			let x = s[i];

			// end of collection
			if(')' === x) {
				// consume whitespace (and incidentally reset index)
				R_WS.lastIndex = i+1;
				R_WS.exec(s);
				this.i = R_WS.lastIndex;

				// make & emit collection's tail "pointer"
				this._kt_object = this._kt_rdf_nil;
				this.data();


				// restore previous state
				let s_resume_state;
				[this._kt_subject, this._kt_predicate, s_resume_state] = this._a_nested.pop();
				return this[s_resume_state]();
			}



			// otherwise, pre-emptively secure the next blank node label
			let s_pointer_label;

// iriref

			// prepare sticky regex index
			R_IRIREF_ESCAPELESS.lastIndex = i;
			// execute regex
			let m_iriref_e_object = R_IRIREF_ESCAPELESS.exec(s);

			// regex was a match
			if(m_iriref_e_object) {
				// advance index
				i = R_IRIREF_ESCAPELESS.lastIndex;
// commit object iri as is

				// ref iri
				let s_iri = m_iriref_e_object[1];
				// absolute iri
				if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
					// set object
					this._kt_object = this.check_named_node_escapeless(s_iri);
				}
				// relative iri
				else {
					this._kt_object = this.check_named_node_escapeless(uri.resolve(this._s_base_url, s_iri));
				}

			// prefixed name
			}
			else {
				// try match
				let aw_valid_this_match_prefixed_name_escapeless = this.match_prefixed_name_escapeless(s, i);
				// stack bail out
				if(!aw_valid_this_match_prefixed_name_escapeless) return true;
				let [m_prefixed_named_e_object, im_prefixed_named_e_object] = aw_valid_this_match_prefixed_name_escapeless;
				if(m_prefixed_named_e_object) {
					// advance index
					i = im_prefixed_named_e_object;
					// check valid prefix
					let s_prefix_id = m_prefixed_named_e_object[1] || '';
					// invalid prefix
					if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


					// commit object iri from resolve prefixed name
					this._kt_object = this.prefixed_name(s_prefix_id, m_prefixed_named_e_object[2]);

				// string literal
				}
				else 	if('"' === x || '\'' === x) {
					// update index before changing states
					this.i = i;

					// create blanknode to embed list
					let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());

					// emit statement that functions as collection's head "pointer"
					this.data();


					// prepare statement that is item
					this._kt_subject = kt_blank_node;
					this._kt_predicate = this._kt_rdf_first;

					this.after_end_of_statement = function() {
						this._kt_predicate = this._kt_rdf_rest;
						this.after_end_of_statement = this.post_object;
						return this.collection_object();
					};
					return this.string_literal();

				// numeric literal
				}
				else {
					// prepare sticky regex index
					R_NUMERIC_LITERAL.lastIndex = i;
					// execute regex
					let m_numeric_literal = R_NUMERIC_LITERAL.exec(s);

					// regex was a match
					if(m_numeric_literal) {
						// advance index
						i = R_NUMERIC_LITERAL.lastIndex;
						// it has exponent term, xsd:double
						if(m_numeric_literal[4]) {
							this._kt_object = this._dc_factory.double(m_numeric_literal[1]);
						}
						// contains decimal point, xsd:decimal
						else if(m_numeric_literal[2] || m_numeric_literal[3]) {
							this._kt_object = this._dc_factory.decimal(m_numeric_literal[1]);
						}
						// otherwise, it is an integer
						else {
							this._kt_object = this._dc_factory.integer(m_numeric_literal[1]);
						}


					// boolean literal
					}
					else {
						// prepare sticky regex index
						R_BOOLEAN_LITERAL.lastIndex = i;
						// execute regex
						let m_boolean_literal = R_BOOLEAN_LITERAL.exec(s);

						// regex was a match
						if(m_boolean_literal) {
							// advance index
							i = R_BOOLEAN_LITERAL.lastIndex;
							// make literal
							this._kt_object = this._dc_factory.booelan(!!m_boolean_literal[1]);

						// blank node property list
						}
						else 	if('[' === x) {
				// advance index to next token
				// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							this.i = R_WS.lastIndex;

							// commit head of list pointer
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());
							this.data();


							// setup state to resume and push
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// enter blank node
							this._kt_predicate = this._kt_rdf_first;
							kt_blank_node = this._kt_object = this.anonymous_blank_node(this.next_label());
							this.data();


							// prepare next triple
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_first;

							// goto parsing pairs state
							return this.pairs();

						// new collection
						}
						else 	if('(' === x) {
							// consume whitespace (and incidentally reset index)
							R_WS.lastIndex = i+1;
							R_WS.exec(s);
							i = R_WS.lastIndex;

							// commit list item pointer
							s_pointer_label = this.next_label();
							let kt_blank_node = this._kt_object = this.anonymous_blank_node(s_pointer_label);
							if(null === this._kt_subject) {
								let a_recent = this._a_nested[this._a_nested.length-1];
								this._kt_subject = a_recent[0];
								this._kt_predicate = a_recent[1];
							}
							this.data();


							// add this list as an item to the outer list
							this._kt_subject = kt_blank_node;
							this._kt_predicate = this._kt_rdf_rest;
							this._a_nested.push([this._kt_subject, this._kt_predicate, 'collection_object']);

							// prepare next triple
							this._kt_predicate = this._kt_rdf_first;

							// flowing
							continue;

						// labeled blank node
						}
						else {
							// prepare sticky regex index
							R_BLANK_NODE_LABEL.lastIndex = i;
							// execute regex
							let m_blank_node_label_object = R_BLANK_NODE_LABEL.exec(s);

							// regex was a match
							if(m_blank_node_label_object) {
								// advance index
								i = R_BLANK_NODE_LABEL.lastIndex;
								// ref blank node label
								let s_label = m_blank_node_label_object[1];

								// make collection pointer label first
								s_pointer_label = this.next_label();

								// make object
								this._kt_object = this.blank_node(s_label);

							// iriref
							}
							else {
								// prepare sticky regex index
								R_IRIREF.lastIndex = i;
								// execute regex
								let m_iriref_object = R_IRIREF.exec(s);

								// regex was a match
								if(m_iriref_object) {
									// advance index
									i = R_IRIREF.lastIndex;
// commit object iri as is

									// ref iri
									let s_iri = m_iriref_object[1].replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY);
									// absolute iri
									if(!this._s_base_url || RT_IRI_ABSOLUTE.test(s_iri)) {
										// set object
										this._kt_object = this.check_named_node(s_iri);
									}
									// relative iri
									else {
										this._kt_object = this.check_named_node(uri.resolve(this._s_base_url, s_iri));
									}

								// prefixed name
								}
								else {
									// try match
									let aw_valid_this_match_prefixed_name = this.match_prefixed_name(s, i);
									// stack bail out
									if(!aw_valid_this_match_prefixed_name) return true;
									let [m_prefixed_named_object, im_prefixed_named_object] = aw_valid_this_match_prefixed_name;
									if(m_prefixed_named_object) {
										// advance index
										i = im_prefixed_named_object;
										// check valid prefix
										let s_prefix_id = m_prefixed_named_object[1] || '';
										// invalid prefix
										if(!OPHOP.call(this._h_prefixes, s_prefix_id)) return this.error(`no such prefix "${s_prefix_id}"`);


										// escape local escapes
										let s_suffix = m_prefixed_named_object[2]
											.replace(R_UNICODE_ANY, F_REPLACE_UNICODE_ANY)
											.replace(R_PN_LOCAL_ESCAPES, '$1');

										// commit object iri from resolve prefixed name
										this._kt_object = this.prefixed_name(s_prefix_id, s_suffix);
									}
									else {
										// prepare sticky regex index
										R_COMMENT.lastIndex = i;
										// execute regex
										let m_comment = R_COMMENT.exec(s);

										// regex was a match
										if(m_comment) {
											// advance index
											i = R_COMMENT.lastIndex;
											if(this.emit_comments) this.emit_comments(m_comment[0]);
											continue;

			// not iriref, not prefixed name, not string literal, not numeric literal, not boolean literal, not blank node property list, not collection
			// match counter: 7
										}
										else {
											// break loop to retry on next chunk if eos
											break;
										}
									} // brace #7
								} // brace #6
							} // brace #5
						} // brace #4
					} // brace #3
				} // brace #2
			} // brace #1



			// ref object
			let w_object = this._kt_object;

			// create blanknode to embed list
			if(!s_pointer_label) s_pointer_label = this.next_label();
			let kt_blank_node_outer = this._kt_object = this.anonymous_blank_node(s_pointer_label);

			// emit statement that functions as collection's head "pointer"
			this.data();


			// emit statement that is item
			this._kt_subject = kt_blank_node_outer;
			this._kt_predicate = this._kt_rdf_first;
			this._kt_object = w_object;
			this.data();


			// prepare next predicate
			this._kt_predicate = this._kt_rdf_rest;
		}

				// ran out of characters
				// update index value
		this.i = i;

		// not yet eos
		if(i < this.n) {
			// expected token was not found
			if(0 === i) {
				// we've exceeded the maximum token length
				if(this.n > this.max_token_length) {
					return this.parse_error('collection_object');
				}
			}
		}

		// save state before pausing
		this._f_state = this.collection_object;

		// store what is unparsed
		this.pre = s.slice(i);

		// if we're not parsing a stream, then this is an error
		if(this.eos) this.eos();
		return;
	}


	destroy(e_destroy) {
		this.post_blank_subject = () => {};

		this.statement = () => {};

		this.pairs = () => {};

		this.object_list = () => {};

		this.string_literal_short_double = () => {};

		this.string_literal_short_single = () => {};

		this.string_literal_long_double = () => {};

		this.string_literal_long_single = () => {};

		this.string_literal = () => {};

		this.datatype_or_langtag = () => {};

		this.datatype = () => {};

		this.post_object = () => {};

		this.base_iri = () => {};

		this.prefix_id = () => {};

		this.prefix_iri = () => {};

		this.full_stop = () => {};

		this.collection_subject = () => {};

		this.collection_object = () => {};


		this.eof = () => {
			this.s = null;
		};

		this._b_destroyed = true;

		// propagate input destroy
		if(!e_destroy && this._ds_input) {
			this._ds_input.destroy(e_destroy);
		}

		this.transform.demolish(e_destroy);
	}
}

module.exports = function(...a_args) {
	let g_config = {};

	// at least one argument
	if(a_args.length) {
		let z_arg_0 = a_args[0];

		// input given unspecified
		if(z_arg_0 && z_arg_0.input && 'undefined' === typeof z_arg_0.input.string && !z_arg_0.input.stream) {
			z_arg_0 = z_arg_0.input;
		}

		// string
		if('string' === typeof z_arg_0) {
			g_config.input = {string:z_arg_0};
		}
		// null
		else if(null === z_arg_0) {
			g_config.input = null;
		}
		// node stream
		else if('function' === typeof z_arg_0.setEncoding) {
			g_config.input = {stream:z_arg_0};
		}
		// whatwg stream
		else if('function' === typeof z_arg_0.pipeTo) {
			throw new TypeError(`Sorry, WHATWG streams are currently not supported :(`);
		// g_config.input = {stream:z_arg_0};
		}
		// config struct
		else if(z_arg_0 && 'object' === typeof z_arg_0 && '[object Object]' === Object.prototype.toString.call(z_arg_0)) {
			g_config = z_arg_0;

			// more args; invalid
			if(a_args.length > 1) {
				throw new TypeError(`unexpected argument(s) after config struct: ${a_args.slice(1)}`);
			}
		}
		// unknown
		else {
			throw new TypeError(`unexpected input type: ${z_arg_0}`);
		}

		// more args
		if(a_args.length > 1) {
			// copy onto struct
			Object.assign(g_config, a_args[1]);

			// more args
			if(a_args.length > 2) {
				throw new TypeError(`unexpected argument(s) after input and config struct: ${a_args.slice(2)}`);
			}
		}
	}

	// create reader, return transform stream
	return (new Reader(g_config)).transform;
};

}).call(this)}).call(this,require("buffer").Buffer)
},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21,"buffer":74,"string_decoder":76,"uri-js":229}],15:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Scribable = require('@graphy/core.class.scribable');

const {
	terse,
	c1_to_nt,
} = factory;



function terse_s(yt_subject, h_prefixes) {
	if('NamedNode' === yt_subject.termType) {
		return terse(yt_subject.value, h_prefixes);
	}
	else {
		return '_:'+yt_subject.value;
	}
}



const terse_p = (yt_predicate, h_prefixes) => terse(yt_predicate.value, h_prefixes);

const P_IRI_XSD_STRING = 'http://www.w3.org/2001/XMLSchema#';
function terse_o(yt_object, h_prefixes) {
	switch(yt_object.termType) {
		// named node
		case 'NamedNode': return terse(yt_object.value, h_prefixes);

		// literal
		case 'Literal': {
			let s_contents = JSON.stringify(yt_object.value);

			if(yt_object.language) {
				return s_contents+'@'+yt_object.language;
			}
			else if(P_IRI_XSD_STRING === yt_object.datatype.value) {
				return s_contents;
			}
			else {
				return s_contents+'^^'+terse(yt_object.datatype.value, h_prefixes);
			}
		}

		// blank node
		default: return '_:'+yt_object.value;
	}
}



class Turtle_Scriber extends Scribable {
	constructor(gc_scriber={}) {
		super(gc_scriber);

		this._yt_subject = null;
		this._yt_predicate = null;

		// prefixes given
		if(gc_scriber.prefixes) {
			// update prefixes and push to output
			this.push(this._serialize_prefixes(gc_scriber.prefixes, true) || '');
		}
	}

	_reset() {
		// some subject is open
		if(this._yt_subject) {
			// close subject
			this._s_push += ' .\n\n';

			// reset subject
			this._yt_subject = null;
		}

		// reset predicate
		this._yt_predicate = null;
	}

	_serialize_prefixes(h_prefixes_in, b_force_serialize=false) {
		// ref current prefixes
		let h_prefixes = this._h_prefixes;

		// serialize new prefixes
		let st_prefixes = '';
		for(let si_prefix in h_prefixes_in) {
			// prefix already exists and no change; skip
			if((si_prefix in h_prefixes) && h_prefixes_in[si_prefix] === h_prefixes[si_prefix] && !b_force_serialize) {
				continue;
			}

			// serialize addition
			st_prefixes += `@prefix ${si_prefix}: ${factory.namedNode(h_prefixes_in[si_prefix]).verbose()} .\n`;
		}

		// change detected
		if(st_prefixes) {
			// (re)cache prefixes
			this._update_prefixes(h_prefixes_in, true);

			// reset all markers
			this._reset();

			// write prefixes
			return st_prefixes+'\n';
		}
	}


	_serialize_c3r(hc3r_triples) {
		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// string building
		let st_quads = '';


		let b_subjects = false;

		for(let sc1_subject in hc3r_triples) {
			// quick convert subject from concise term to terse
			let st1_subject = c1_to_nt(sc1_subject, h_prefixes);

			// not a term; skip
			if(!st1_subject) continue;

			let st_triples = '';
			if(b_subjects) st_triples += ' .\n\n';

	//
			st_triples += st1_subject+' ';

			let b_predicates = false;

			// each predicate
			let hc2r_pairs = hc3r_triples[sc1_subject];
			for(let sc1_predicate in hc2r_pairs) {
				// quick convert predicate from concise term to terse
				let st1_predicate = c1_to_nt(sc1_predicate, h_prefixes);

				// not a term; skip
				if(!st1_predicate) continue;

		//
				let st_pairs = '';
				if(b_predicates) st_pairs += ' ;\n\t';

				// pairs output
				st_pairs += st1_predicate+' ';

				let b_objects = false;

				// each object
				for(let sc1_object of hc2r_pairs[sc1_predicate]) {
					// quick convert object from concise term to terse
					let st1_object = c1_to_nt(sc1_object, h_prefixes);

					// not a term; skip
					if(!st1_object) continue;

					if(b_objects) st_pairs += ', ';
					b_objects = true;

					// add object to pairs
					st_pairs += st1_object;
				}

				// objects written; add pairs to output
				if(b_objects) {
					st_triples += st_pairs;
					b_predicates = true;
				}
			}

			// predicates written; add triples to output
			if(b_predicates) {
				st_quads += st_triples;
				b_subjects = true;
			}
		}

		// subjects written; terminate
		if(b_subjects) st_quads += ' .\n\n';

		// reset all markers
		this._reset();

		return st_quads;
	}


	_serialize_quad(g_quad) {
		let h_prefixes = this._h_prefixes;

		let {
			subject: yt_subject,
			predicate: yt_predicate,
			object: yt_object,
		} = g_quad;


		// same subject
		if(yt_subject.equals(this._yt_subject)) {
			// same prediate
			if(yt_predicate.equals(this._yt_predicate)) {
				// write object
				this._s_push += ', '+terse_o(yt_object, h_prefixes);
			}
			// different predicate
			else {
				// write pair
				this._s_push += ' ;\n\t'+terse_p(yt_predicate, h_prefixes)+' '+terse_o(yt_object, h_prefixes);

				// update prediate
				this._yt_predicate = yt_predicate;
			}
		}
		// subject not identical to previous
		else {
			let st_line = terse_s(yt_subject, h_prefixes)+' '+terse_p(yt_predicate, h_prefixes)+' '+terse_o(yt_object, h_prefixes);

			// different subject
			if(this._yt_subject) {
				// write triple
				this._s_push += ' .\n\n'+st_line;
			}
			// first subject
			else {
				this._s_push += st_line;
			}

			// save subject and predicate
			this._yt_subject = yt_subject;
			this._yt_predicate = yt_predicate;
		}
	}

	_flush() {
		// flush buffer
		Turtle_Scriber._flush_buffer(this);

		// triple needs closing
		if(this._yt_subject) {
			this.push(' .\n');
		}

		// eof
		this.push(null);
	}
}

Object.assign(Turtle_Scriber, {
	_serialize_comment: Scribable.prototype._serialize_hash_comment,
});

module.exports = function(g_config) {
	return new Turtle_Scriber(g_config);
};

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],16:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}



const factory = require('@graphy/core.data.factory');
const Writable = require('@graphy/core.class.writable');

// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_NAMESPACE_VALID = /^([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}]([A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}.]*[A-Za-z\xc0-\xd6\xd8-\xf6\xf8-\u{02ff}\u{0370}-\u{037d}\u{037f}-\u{1fff}\u{200c}-\u{200d}\u{2070}-\u{218f}\u{2c00}-\u{2fef}\u{3001}-\u{d7ff}\u{f900}-\u{fdcf}\u{fdf0}-\u{fffd}\u{10000}-\u{effff}_\-0-9\xb7\u{0300}-\u{036f}\u{203f}-\u{2040}])?)?$/u;
const N_MAX_STRING_BUFFER = 1 << 12;

const XC_DIRECTIVES_TYPE_SPARQL = 0b001;
const XC_DIRECTIVES_CASE_PASCAL = 0b010;
const XC_DIRECTIVES_CASE_UPPER = 0b100;



class Turtle_Writer extends Writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			prefixes: h_prefixes={},
			lists: gc_lists=null,
			debug: b_debug=false,
			style: gc_style=null,
		} = gc_writer;

		Object.assign(this, {
			_b_debug: b_debug,
			_s_indent: '\t',
			_b_simplify_default_graph: false,
			_xc_directives: 0,
			_s_token_prefix: '@prefix',
		});


		// style config
		if(gc_style) {
			// indent
			if(gc_style.indent) {
				this._s_indent = gc_style.indent.replace(/[^\s]/g, '');
			}

			// use sparql directives
			let z_directives = gc_style.directives || gc_style.directives;
			if(z_directives) {
				switch(z_directives) {
					case 'sparql': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL;
						this._s_token_prefix = 'prefix';
						break;
					}

					case 'Sparql': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL | XC_DIRECTIVES_CASE_PASCAL;
						this._s_token_prefix = 'Prefix';
						break;
					}

					case 'SPARQL': {
						this._xc_directives = XC_DIRECTIVES_TYPE_SPARQL | XC_DIRECTIVES_CASE_UPPER;
						this._s_token_prefix = 'PREFIX';
						break;
					}

					case 'turtle': {
						break;
					}

					case 'Turtle': {
						this._xc_directives = XC_DIRECTIVES_CASE_PASCAL;
						this._s_token_prefix = '@Prefix';
						break;
					}

					case 'TURTLE': {
						this._xc_directives = XC_DIRECTIVES_CASE_UPPER;
						this._s_token_prefix = '@PREFIX';
						break;
					}

					default: {
						throw new Error(`Value not understood for 'directives' option: ${z_directives}`);
					}
				}
			}
		}



		// custom list keys
		if(gc_lists) {
			// serialize list object
			this._serialize_list_object = function(a_list, n_nest_level) {
				// transcode list object
				let hc2_transcoded = this._transcode_list(a_list);

				// serialize object
				return this._encode_objects(hc2_transcoded, n_nest_level);
			};
		}

		// serialize initial prefix mappings
		let s_token_prefix = this._s_token_prefix;
		let s_prefix_eol = (this._xc_directives & XC_DIRECTIVES_TYPE_SPARQL)? '\n': ' .\n';
		let s_prefixes = '';
		try {
			// each user-defined prefix
			for(let s_prefix_id in h_prefixes) {
				// invalid prefix id
				if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
					throw new Error(`Invlalid prefix id for text/turtle RDF serialization format: '${s_prefix_id}'`);
				}

				// append to string
				s_prefixes += `${s_token_prefix} ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()}${s_prefix_eol}`;
			}
		}
		// serialization error
		catch(e_serialize) {
			queueMicrotask(() => {
				this.emit('error', e_serialize);
			});
		}

		// push prefixes
		if(s_prefixes) this.push(s_prefixes);
	}

	// serialize prefixes
	_serialize_prefixes(h_prefixes) {
		// build prefixes string
		let s_prefixes = (2 === this._xc_state)? '\n\n': '';

		// update state
		this._xc_state = 0;

		// clone prefixes
		this._h_prefixes = {...this._h_prefixes};

		// ref prefix token
		let s_token_prefix = this._s_token_prefix;

		// prep eol string
		let s_prefix_eol = (this._xc_directives & XC_DIRECTIVES_TYPE_SPARQL)? '\n': ' .\n';

		// each user-defined prefix
		for(let s_prefix_id in h_prefixes) {
			// invalid prefix id
			if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
				throw new Error(`Invlalid prefix id for text/turtle RDF serialization format: '${s_prefix_id}'`);
			}

			// append to string
			s_prefixes += `${s_token_prefix} ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()}${s_prefix_eol}`;

			// set prefix
			this._h_prefixes[s_prefix_id] = h_prefixes[s_prefix_id];
		}

		// recache
		factory.cache_prefixes(this._h_prefixes);

		// return prefix string
		return s_prefixes;
	}



	// serialize c3 hash
	_serialize_c3(hc3_triples) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,

		} = this;
		// break line if non-data state
		let s_write = 2 !== this._xc_state? '\n': '';
		// update state
		this._xc_state = 2;

		// triple delimiter
		let s_delim_triples = '';
		// subject exit listener
		let f_exit_subject = null;
		// each subject
		for(let sc1_subject in hc3_triples) {
			// directive
			if('`' === sc1_subject[0]) {
				let g_apply = this._apply_directive(sc1_subject, hc3_triples[sc1_subject]);
				// write data
				if(g_apply.write) {
					s_write += s_delim_triples+g_apply.write;
					// do not break next line
					s_delim_triples = '';
				}
				// save exit listener
				if(g_apply.exit) f_exit_subject = g_apply.exit;
				continue;
			}
			// position before subject
			let i_triples = s_write.length;
			// serialize subject
			s_write += s_delim_triples+factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';
			// pair indent & terminator
			let s_indent_pairs = '';
			let s_term_pairs = '';
			// ref pairs
			let hc2_pairs = hc3_triples[sc1_subject];
			// position before pairs
			let i_pairs = s_write.length;
			// were objects written?
			let b_empty = true;
			// predicate exit listener
			let f_exit_predicate = null;
			// each predicate
			for(let sc1_predicate in hc2_pairs) {
				// directive
				if('`' === sc1_predicate[0]) {
					// apply directive
					let g_apply = this._apply_directive(sc1_predicate, hc2_pairs[sc1_predicate]);
					// write data
					if(g_apply.write) {
						// break line
						s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent+g_apply.write;
						// pair already terminated
						s_term_pairs = '';
						// indent next pair
						s_indent_pairs = s_indent;
					}
					// save exit listener
					if(g_apply.exit) f_exit_predicate = g_apply.exit;
					continue;
				}
				// ref objects
				let z_objects = hc2_pairs[sc1_predicate];
				// serialize objects
				let st_objects = this._encode_objects(z_objects);
				// no objects; skip pair
				if(!st_objects) continue;
				// not empty
				b_empty = false;
				// cannot use blank node in predicate position
				if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
					throw new Error(`Cannot use blank node in predicate position of c3 hash; subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
				}
				// create predicate
				let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);
				// tersify rdf:type
				let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);
				// serialize predicate and object(s)
				s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;
				// update state
				this._xc_state = 2;
					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }
				// terminate next pair
				s_term_pairs = ' ;\n';
				// indent next pair
				s_indent_pairs = s_indent;
				// call exit predicate listener
				if(f_exit_predicate) f_exit_predicate();
			}
			// empty triples; cut out
			if(b_empty) {
				s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
				continue;
			}
			// delimit triple(s)
			s_delim_triples = '\n';
			// close triple
			s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; //
			// call exit subject listener
			if(f_exit_subject) f_exit_subject();
		}

		s_write += '\n';
		return s_write;
	}


	// write objects
	_encode_objects(z_objects, n_nest_level=1) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,
			_hm_coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return factory.c1(z_objects, h_prefixes).terse(h_prefixes);

			// numeric type
			case 'number': return factory.number(z_objects).terse(h_prefixes);

			// boolean type
			case 'boolean': return factory.boolean(z_objects).terse(h_prefixes);

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// object terminator
					let s_term_object = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; serialize list
						if(Array.isArray(z_item)) {
							s_write += s_term_object + this._serialize_list_object(z_item, n_nest_level);
						}
						// non-array
						else {
							// recurse on item
							s_write += s_term_object + this._encode_objects(z_item, n_nest_level);
						}

						// terminate next object
						s_term_object = ', ';
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// open blank node block
					let s_write = '[';

					// whether the block is empty
					let b_empty = true;

					// object exit listener
					let f_exit_object = null;

					// each pair
					for(let sc1_predicate in z_objects) {
						// block is not empty
						b_empty = false;

						// terminate previous pair
						s_write += '\n'+s_indent.repeat(1+n_nest_level);

						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							let g_apply = this._apply_directive(sc1_predicate, z_objects[sc1_predicate]);

							// write data
							if(g_apply.write) s_write += g_apply.write;

							// save exit listener
							if(g_apply.exit) f_exit_object = g_apply.exit;
							continue;
						}

						// write predicate and object(s)
						s_write += factory.c1(sc1_predicate, h_prefixes).terse(h_prefixes) + ' '
							+ this._encode_objects(z_objects[sc1_predicate], n_nest_level+1) +' ;';
					}

					// close blank node block
					s_write += (b_empty? '': '\n'+s_indent.repeat(n_nest_level))+']';

					// call exit object listener
					if(f_exit_object) f_exit_object();

					// serialize current predicate to blank node
					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return kt_converted.terse(h_prefixes);
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return z_objects.terse(h_prefixes);
				}
				// RDFJS term
				else if(z_objects.termType) {
					return factory.from.term(z_objects).terse(h_prefixes);
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// serialize collection object
	_serialize_collection_object(a_collection, n_nest_level) {
		let s_indent = this._s_indent;

		// open collection block
		let s_write = '(';

		// each item
		for(let z_item of a_collection) {
			let s_objects = '';

			// item is array; serialize as sub-collection
			if(Array.isArray(z_item)) {
				s_objects = this._serialize_collection_object(z_item, n_nest_level+1);
			}
			// non-array item
			else {
				s_objects = this._encode_objects(z_item, n_nest_level+1);
			}

			// serialize collection
			s_write += '\n'+s_indent.repeat(1+n_nest_level)+s_objects;
		}

		// break line if anything was written (including comments)
		if(a_collection.length) s_write += '\n'+s_indent.repeat(n_nest_level);

		// close collection block
		s_write += ')';

		return s_write;
	}

	// rdfjs quad
	_serialize_quad(g_quad) {
		let h_prefixes = this._h_prefixes;
		let kq_quad = factory.from.quad(g_quad);


		// serialize quad
		this._s_push += (2 !== this._xc_state? '\n': '')
						+kq_quad.subject.terse(h_prefixes)+' '
			+kq_quad.predicate.terse(h_prefixes)+' '
			+kq_quad.object.terse(h_prefixes)+' .\n\n';


		// update state
		this._xc_state = 2;
	}
}

Object.assign(Turtle_Writer.prototype, {
	anonymous_blank_nodes: true,
	_serialize_c3r: Turtle_Writer.prototype._serialize_c3,
	_serialize_c4r: Turtle_Writer.prototype._serialize_c4,
	_serialize_comment: Writable.prototype._serialize_hash_comment,
	_serialize_list_object: Turtle_Writer.prototype._serialize_collection_object,
});

module.exports = function(gc_writer) {
	return new Turtle_Writer(gc_writer);
};

},{"@graphy/core.class.writable":19,"@graphy/core.data.factory":20}],17:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Scribable = require('@graphy/core.class.scribable');

const {
	c1,
	namedNode,
	$_PREFIX_CACHE,
} = factory;

const R_XML_ESCAPES = /[&"<>']/g;
const H_XML_ESCAPES = {
	'&': '&amp;',
	'<': '&lt;',
	'>': '&gt;',
	'"': '&quot;',
	"'": '&apos;',
};

const R_NS_XML = /^xml/i;

const escape_xml_text = s_text => s_text.replace(R_XML_ESCAPES, s => H_XML_ESCAPES[s]);

const R_XML_NAME_SIMPLE_EOS = /([A-Za-z_][A-Za-z_.0-9-]*)$/;



const R_XML_NAME_EXTENDED_EOS = /([A-Za-z_\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u{10000}-\u{EFFFF}][A-Za-z_.0-9\-\u00b7\u203f-\u2040\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\u{10000}-\u{EFFFF}]*$)/u;

function XML_Serializer$pair(k_self, sx1_predicate, sx_arc, kt_object) {
	// named node
	if(kt_object.isNamedNode) {
		sx_arc += ' rdf:resource="'+escape_xml_text(kt_object.value)+'"/>';
	}
	// literal
	else if(kt_object.isLiteral) {
		// languaged
		if(kt_object.isLanguaged) {
			sx_arc += ' xml:lang="'+kt_object.language+'"';
		}
		// datatyped
		else if(kt_object.isDatatyped) {
			sx_arc += ' rdf:datatype="'+escape_xml_text(kt_object.datatype.value)+'"';
		}

		// all literals
		sx_arc += '>'+escape_xml_text(kt_object.value)+'</'+sx1_predicate+'>';
	}
	// blank node
	else if(kt_object.isBlankNode) {
		sx_arc += ' rdf:nodeID="'+escape_xml_text(kt_object.value)+'"/>';
	}
	// other
	else {
		throw new Error(`Not allowed to serialize term type '${kt_object.termType}' as object in XML serializer.`);
	}

	return sx_arc;
}

function XML_Serializer$predicate(k_self, kt_predicate) {
	let h_prefixes = k_self._h_prefixes;

	let p_predicate = kt_predicate.value;

	// split predicate
	let p_edge_prefix_iri;
	let s_edge_suffix;
	{
		let m_edge_name = R_XML_NAME_SIMPLE_EOS.exec(p_predicate);

		// simple name
		if(m_edge_name) {
			p_edge_prefix_iri = p_predicate.slice(0, m_edge_name.index);
			s_edge_suffix = m_edge_name[1];
		}
		// not a simple name
		else {
			m_edge_name = R_XML_NAME_EXTENDED_EOS.exec(p_predicate);

			// extended name
			if(m_edge_name) {
				p_edge_prefix_iri = p_predicate.slice(0, m_edge_name.index);
				s_edge_suffix = m_edge_name[1];
			}
			// cannot serialize
			else {
				throw new Error(`Cannot serialize predicate <${p_predicate}> into an XML qname`);
			}
		}
	}

	// predicate tag
	let sx1_predicate;
	let sx_arc;

	TEMPORARY_PREFIX:
	for(;;) {
		PREFIX_LOOKUP:
		for(;;) {
			// prefix cache
			if(h_prefixes[$_PREFIX_CACHE]) {
				let h_inverse = h_prefixes[$_PREFIX_CACHE]._h_inverse;

				// prefix exists
				if(p_edge_prefix_iri in h_inverse) {
					let si_prefix = h_inverse[p_edge_prefix_iri];

					// set predicate tag
					sx1_predicate = (si_prefix? si_prefix+':': '')+s_edge_suffix;

					// start arc
					sx_arc = '<'+sx1_predicate;

					// done
					break TEMPORARY_PREFIX;
				}
				// prefix does not exist
				else {
					break;
				}
			}
			// no cache
			else {
				// each prefix in hash
				for(let si_prefix in h_prefixes) {
					let p_prefix_iri = h_prefixes[si_prefix];

					// prefix matches
					if(p_prefix_iri === p_edge_prefix_iri) {
						// set predicate tag
						sx1_predicate = (si_prefix? si_prefix+':': '')+s_edge_suffix;

						// start arc
						sx_arc = '<'+sx1_predicate;

						// stop searching hash
						break PREFIX_LOOKUP;
					}
				}

				// prefix not found
				break;
			}
		}

		// create temporary prefix
		let si_prefix_tmp = '__g'+(k_self._c_prefixes_tmp++);

		// set predicate tag
		sx1_predicate = si_prefix_tmp+':'+s_edge_suffix;

		// start arc
		sx_arc = '<'+sx1_predicate+' xmlns:'+si_prefix_tmp+'="'+p_edge_prefix_iri+'"';

		// done
		break;
	}

	return [sx1_predicate, sx_arc];
}

class XML_Scriber extends Scribable {
	constructor(gc_scriber={}) {
		// special case, remove prefixes before forwarding to super
		let h_prefixes = gc_scriber.prefixes;
		delete gc_scriber.prefixes;

		super(gc_scriber);

		// whether or not we can still add prefixes
		this._b_prefixes_open = true;

		this._c_prefixes_tmp = 0;

		this._kt_subject = null;
// this._kt_predicate = null;

		// open xml document and root node
		let sx_open = '<?xml version="1.0" encoding="utf-8"?>\n<rdf:RDF'
			+'\n\txmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"';

		// force default prefix
		this._update_prefixes({
			rdf: 'http://www.w3.org/1999/02/22-rdf-syntax-ns#',
		});

		// prefixes given
		if(h_prefixes) {
			// update prefixes and push to output
			this.push(sx_open+this._serialize_prefixes(h_prefixes));
		}
		// no prefixes
		else {
			this.push(sx_open);
		}
	}

	_serialize_prefixes(h_prefixes_in, b_force_serialize=false) {
		// prefixes are frozen; reject prefix event
		if(!this._b_prefixes_open) return;

		// ref current prefixes
		let h_prefixes = this._h_prefixes;

		// serialize new prefixes
		let sx_prefixes = '';
		for(let si_prefix in h_prefixes_in) {
			// prefix already exists
			if((si_prefix in h_prefixes)) {
				// and no change; skip
				if(h_prefixes_in[si_prefix] === h_prefixes[si_prefix] && !b_force_serialize) {
					continue;
				}
				// attempted change to prefix
				else {
					throw new Error(`Cannot change prefixes in RDF/XML serializer. Attempted to modify '${si_prefix}' from <${h_prefixes[si_prefix]}> to <${h_prefixes_in[si_prefix]}>`);
				}
			}

			// prefix not allowed
			if(R_NS_XML.test(si_prefix)) {
				throw new Error(`Cannot serialize prefix '${si_prefix}' since it is reserved under the blanket XML namespace.`);
			}

			// serialize prefix
			sx_prefixes += `\n\txmlns${si_prefix? ':'+si_prefix: ''}="${namedNode(h_prefixes_in[si_prefix]).value}"`;
		}

		// change detected
		if(sx_prefixes) {
			// (re)cache prefixes
			this._update_prefixes(h_prefixes_in, true);
		}

		// write prefixes
		return sx_prefixes;
	}


	_serialize_c3r(hc3r_triples) {
		// string building
		let sx_output = '';

		// no longer able to modify prefixes
		if(this._b_prefixes_open) {
			sx_output += '>';
			this._b_prefixes_open = false;
		}

		// ref prefixes
		let h_prefixes = this._h_prefixes;

		// hanging subject
		if(null !== this._kt_subject) {
			// close previous
			sx_output += '\n\t</rdf:Description>';

			// reset
			this._kt_subject = null;
		}

		for(let sc1_subject in hc3r_triples) {
			let sx_triples = '';

			// interpret subject
			let kt_subject = c1(sc1_subject, h_prefixes);

			// not a term; skip
			if(!kt_subject.termType) continue;

			// not a node
			if(!kt_subject.isNamedNode && !kt_subject.isBlankNode) {
				throw new Error(`Cannot use ${kt_subject.termType} term type in subject position`);
			}

			// convert to xml
			{
				// named node
				if(kt_subject.isNamedNode) {
					sx_triples += '\n\n\t<rdf:Description rdf:about="'+escape_xml_text(kt_subject.value)+'">';
				}
				// named node
				else if(kt_subject.isBlankNode) {
					sx_triples += '\n\n\t<rdf:Description rdf:nodeID="'+escape_xml_text(kt_subject.value)+'">';
				}
				// other
				else {
					throw new Error(`Not allowed to serialize term type '${kt_subject.termType}' as subject in XML serializer.`);
				}
			}

			let b_predicates = false;

			// each predicate
			let hc2r_pairs = hc3r_triples[sc1_subject];
			for(let sc1_predicate in hc2r_pairs) {
				// interpret predicate
				let kt_predicate = c1(sc1_predicate, h_prefixes);

				// not a term; skip
				if(!kt_predicate.termType) continue;

				// not a node
				if(!kt_predicate.isNamedNode) {
					throw new Error(`Cannot use ${kt_predicate.termType} term type in subject position`);
				}

				// convert to xml
				let [sx1_predicate, sx_arc] = XML_Serializer$predicate(this, kt_predicate);

				// pairs
				let sx_pairs = '';

				// each object
				for(let sc1_object of hc2r_pairs[sc1_predicate]) {
					// interpret object
					let kt_object = c1(sc1_object, h_prefixes);

					// not a term; skip
					if(!kt_object.termType) continue;

					// add object to pairs
					sx_pairs += '\n\t\t'+XML_Serializer$pair(this, sx1_predicate, sx_arc, kt_object);
				}

				// objects written; add pairs to output
				if(sx_pairs) {
					sx_triples += sx_pairs;
					b_predicates = true;
				}
			}

			// predicates written; add triples to output
			if(b_predicates) {
				sx_output += sx_triples+'\n\t</rdf:Description>';
			}
		}

		return sx_output;
	}

	_serialize_quad(g_quad) {
		// normalize quad
		let kq_quad = factory.from.quad(g_quad);

		// no longer able to modify prefixes
		if(this._b_prefixes_open) {
			this._s_push += '>';
			this._b_prefixes_open = false;
		}

		let {
			subject: kt_subject,
			predicate: kt_predicate,
			object: kt_object,
		} = kq_quad;

		// serialize predicate
		let [sx1_predicate, sx_arc] = XML_Serializer$predicate(this, kt_predicate);
		let sx_pair = '\n\t\t'+XML_Serializer$pair(this, sx1_predicate, sx_arc, kt_object);

		// same subject
		if(kt_subject.equals(this._kt_subject)) {
			this._s_push += sx_pair;
		}
		// subject not identical to previous
		else {
			// not a node
			if(!kt_subject.isNamedNode && !kt_subject.isBlankNode) {
				throw new Error(`Cannot use ${kt_subject.termType} term type in subject position`);
			}

			// convert to xml
			let sx_line;
			{
				// named node
				if(kt_subject.isNamedNode) {
					sx_line = '\n\n\t<rdf:Description rdf:about="'+escape_xml_text(kt_subject.value)+'">'+sx_pair;
				}
				// named node
				else if(kt_subject.isBlankNode) {
					sx_line = '\n\n\t<rdf:Description rdf:nodeID="'+escape_xml_text(kt_subject.value)+'">'+sx_pair;
				}
				// other
				else {
					throw new Error(`Not allowed to serialize term type '${kt_subject.termType}' as subject in XML serializer.`);
				}
			}

			// different subject
			if(this._kt_subject) {
				// write triple
				this._s_push += '\n\t</rdf:Description>'+sx_line;
			}
			// first subject
			else {
				this._s_push += sx_line;
			}

			// save subject and predicate
			this._kt_subject = kt_subject;
		// this._kt_predicate = kt_predicate;
		}
	}

	_flush() {
		// flush buffer
		XML_Scriber._flush_buffer(this);

		// no longer able to modify prefixes
		if(this._b_prefixes_open) {
			this.push('>');
			this._b_prefixes_open = false;
		}

		// triple needs closing
		if(this._kt_subject) {
			this.push('\n\t</rdf:Description>\n</rdf:RDF>\n');
		}
		// just close document
		else {
			this.push('\n</rdf:RDF>\n');
		}

		// eof
		this.push(null);
	}
}

Object.assign(XML_Scriber, {
	_serialize_comment: Scribable.prototype._serialize_hash_comment,
});

module.exports = function(g_config) {
	return new XML_Scriber(g_config);
};

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],18:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}


const factory = require('@graphy/core.data.factory');
const stream = require('@graphy/core.iso.stream');


// max string buffer size
const N_DEFAULT_MAX_BUFFER = 1 << 15;  // 32 KiB


class Scribable extends stream.Transform {
	// flush buffer
	static _flush_buffer(k_self) {
		// no buffer; exit
		if(!k_self._s_push) return;

		// push buffer to stream
		k_self.push(k_self._s_push);

		// reset buffer
		k_self._s_push = '';
	}

	constructor(gc_scribable={}) {
		super({
			writableObjectMode: true,
			readableObjectMode: false,
		});

		let {
			prefixes: h_prefixes={},
		} = gc_scribable;

		// internal buffer
		this._s_push = '';

		// max buffer length
		this._n_max_buffer = gc_scribable.max_buffer || gc_scribable.maxBuffer || N_DEFAULT_MAX_BUFFER;

		// prefixes
		this._h_prefixes = factory.cache_prefixes(h_prefixes || {});

		// on new source(s)
		this.on('pipe', (ds_src) => {
			// listen for prefix events
			ds_src.on('prefix', (s_prefix_id, p_iri) => {
				this.write({
					type: 'prefixes',
					value: {
						[s_prefix_id]: p_iri,
					},
				});
			});

			// listen for comment events
			ds_src.on('comment', (s_comment) => {
				this.write({
					type: 'comment',
					value: s_comment,
				});
			});
		});

		// bind event listeners
		if(gc_scribable.close) this.once('close', gc_scribable.close);
		if(gc_scribable.drain) this.on('drain', gc_scribable.drain);
		if(gc_scribable.error) this.on('error', gc_scribable.error);
		if(gc_scribable.finish) this.once('finish', gc_scribable.finish);
		if(gc_scribable.data) this.on('data', gc_scribable.data);
		if(gc_scribable.end) this.once('end', gc_scribable.end);
		if(gc_scribable.warning) this.on('warning', gc_scribable.warning);
	}

	_serialize_hash_comment(s_comment) {
		return '# '+s_comment.replace(/\n/g, '\n# ')+'\n';
	}

	_serialize_newlines(n_newlines=1) {
		return '\n'.repeat(n_newlines);
	}

	_serialize_c4r(hc4r_quads) {
		let h_prefixes = this._h_prefixes;
		let a_unions = [];
		let s_write = '';

		// each graph in quads hash
		for(let sc1_graph in hc4r_quads) {
			// non-default graph; union from dataset
			if('*' !== sc1_graph) a_unions.push(sc1_graph);

			// add all quads from graph
			s_write += this._serialize_c3r(hc4r_quads[sc1_graph]);
		}

		// a union was performed
		if(a_unions.length) {
			// warn about implicit union
			let s_warning = `Destination format does not support quads; an implicit union into the default graph was performed on the quads contained in graphs: ${a_unions.map(sc1 => factory.c1(sc1, h_prefixes).verbose()).join(', ')}`;

			// emit warning, wasn't listened to; force thru warn/stderr channel
			if(!this.emit('warning', s_warning)) {
				console.warn(s_warning);
			}
		}

		return s_write;
	}


	_serialize_c3() {
		throw new Error(`Write event type 'c3' not supported by ${this.constructor.name}`);
	}

	_serialize_c4() {
		throw new Error(`Write event type 'c4' not supported by ${this.constructor.name}`);
	}



	_serialize_c3r() {
		throw new Error(`Write event type 'c3r' should have been implemented by subclass ${this.constructor.name}`);
	}

	_serialize_quad() {
		throw new Error(`Write event type 'quad' should have been implemented by subclass ${this.constructor.name}`);
	}


	// ignorable events
	_serialize_comment() {}  // eslint-disable-line class-methods-use-this

	// update prefix mappings
	_update_prefixes(h_prefixes_in, b_terse=false) {
		// merge prefixes
		let h_prefixes = {
			...this._h_prefixes,
			...h_prefixes_in,
		};

		// recache prefixes
		this._h_prefixes = factory.cachePrefixes(h_prefixes || {}, b_terse);
	}

	// implement stream.Transform
	_transform(g_event, s_encoding, fke_transform) {
		let w_write;

		// try to serialize input value
		try {
			w_write = this.serialize(g_event);
		}
		// serialization error
		catch(e_serialize) {
			// report error
			fke_transform(e_serialize);

			// bail on transform
			return e_serialize;
		}

		// data to push
		if(w_write) {
			// flush internal buffer
			Scribable._flush_buffer(this);

			// push data to stream
			this.push(w_write);
		}
		// nothing returned from serialization
		else {
			let nl_push = this._s_push.length;

			// internal buffer high water mark
			if(nl_push > this._n_max_buffer) {
				Scribable._flush_buffer(this);
			}
			// allow buffer to build
			else if(nl_push) {
				// do not worry about clearing timeouts
				queueMicrotask(() => Scribable._flush_buffer(this));
			}
		}

		// callback
		fke_transform();
	}

	// queue data to be pushed later
	_queue(s_push) {
		this._s_push += s_push;

		// internal buffer high water mark
		if(this._s_push.length > this._n_max_buffer) {
			Scribable._flush_buffer(this);
		}
		else {
			// do not worry about clearing timeouts
			queueMicrotask(() => Scribable._flush_buffer(this));
		}
	}

	// route event object to serialization method
	serialize(g_event) {
		switch(g_event.type) {
			// rdfjs quad
			// eslint-disable-next-line no-undefined
			case undefined: return this._serialize_quad(g_event);

			// concise triple struct strict-mode
			case 'c3r': return this._serialize_c3r(g_event.value);

			// concise quad struct strict-mode
			case 'c4r': return this._serialize_c4r(g_event.value);

			// array of events
			case 'array': {
				// string building
				let s_write = '';

				// each subevent
				for(let g_sub of g_event.value) {
					// build serialization string
					let s_push = this.serialize(g_sub);

					// something to push
					if(s_push) {
						s_write += s_push;
					}
					// push was queued
					else if(this._s_push) {
						// concat to write
						s_write += this._s_push;

						// reset push
						this._s_push = '';
					}
				}

				// all done
				return s_write;
			}

			// quad
			case 'quad': return this._serialize_quad(g_event.value);

			// concise triple struct
			case 'c3': return this._serialize_c3(g_event.value);

			// concise quad struct
			case 'c4': return this._serialize_c4(g_event.value);

			// prefixes
			case 'prefixes': {
				return this._serialize_prefixes(g_event.value);
			}

			// comment
			case 'comment': {
				return this._serialize_comment(g_event.value);
			}

			// newline(s)
			case 'newline':
			case 'newlines': {
				return this._serialize_newlines(g_event.value);
			}

			// no such event type
			default: {
				throw new Error(`no such writable data event type for RDF stream: '${g_event.type}'`);
			}
		}
	}

	// rinse off buffer to writable
	rinse() {
		this._reset();
		Scribable._flush_buffer(this);
	}

	_flush() {
		// flush buffer
		Scribable._flush_buffer(this);

		// eof
		this.push(null);
	}
}

Object.assign(Scribable.prototype, {
	isGraphyWritable: true,
	_serialize_prefixes: Scribable.prototype._update_prefixes,
});

module.exports = Scribable;

},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21}],19:[function(require,module,exports){



const factory = require('@graphy/core.data.factory');
const Scribable = require('@graphy/core.class.scribable');

const R_DIRECTIVE_CONTENTS = /^`\[[^\]]+\](.*)$/;

const HM_COERCIONS_DEFAULT = new Map([
	[Date, dt => factory.dateTime(dt)],
	[Number, x => factory.number(x)],
]);

class Writable extends Scribable {
	constructor(gc_writable={}) {
		super(gc_writable);

		let {
			lists: gc_lists=null,
		} = gc_writable;

		// start with default coercions map
		let hm_coercions = HM_COERCIONS_DEFAULT;

		// user is overriding coercions
		if(gc_writable.coercions) {
			// copy default map
			hm_coercions = new Map(hm_coercions);

			// add each entry from user-defined map
			for(let [dc_type, f_transform] of gc_writable.coercions) {
				hm_coercions.set(dc_type, f_transform);
			}
		}

		// lists
		let g_lists = {
			first: '>http://www.w3.org/1999/02/22-rdf-syntax-ns#first',
			rest: '>http://www.w3.org/1999/02/22-rdf-syntax-ns#rest',
			nil: '>http://www.w3.org/1999/02/22-rdf-syntax-ns#nil',
		};

		// custom transcoder
		if(gc_lists) {
			let {
				first: sc1_first=null,
				rest: sc1_rest=null,
				nil: sc1_nil=null,
			} = gc_lists;

			if(sc1_first) g_lists.first = sc1_first;
			if(sc1_rest) g_lists.rest = sc1_rest;
			if(sc1_nil) g_lists.nil = sc1_nil;
		}

		Object.assign(this, {
			_xc_state: 0,
			_hm_coercions: hm_coercions,
			_g_lists: g_lists,
		});
	}

	// serialize comment
	_serialize_comment(s_comment, g_directive) {
		let s_write = '';

		// non-data state
		if(2 !== this._xc_state) {
			// break line
			s_write += '\n';

			// update state
			this._xc_state = 2;
		}

		// comment width
		if(g_directive && g_directive.width) {
			let n_width = g_directive.width;

			let a_lines = [];

			while(s_comment.length > n_width) {
				let s_line = s_comment.slice(0, n_width+1);

				let m_line = /^(.*[^\s])\s+/.exec(s_line);

				if(m_line) {
					let s_push = m_line[1];
					a_lines.push(s_push);
					s_comment = s_comment.slice(s_push.length).replace(/^\s+/, '');
				}
				else {
					a_lines.push(s_comment.slice(0, n_width));
					s_comment = s_comment.slice(n_width);
				}
			}

			s_comment = a_lines.join('\n');
		}

		return s_write+(super._serialize_comment(s_comment) || '');
	}


	// transcode list into concise-pairs hash
	_transcode_list(a_list, g_lists=this._g_lists) {
		// empty list
		if(!a_list.length) {
			return g_lists.nil;
		}
		// non-empty list
		else {
			let z_item = a_list[0];
			let w_first = z_item;

			// item is nested list; transcode
			if(Array.isArray(z_item)) {
				w_first = this._transcode_list(z_item, g_lists);  // eslint-disable-line no-invalid-this
			}

			return {
				// first item
				[g_lists.first]: w_first,

				// rest of items
				[g_lists.rest]: 1 === a_list.length
					? g_lists.nil
					: this._transcode_list(a_list.slice(1), g_lists),  // eslint-disable-line no-invalid-this
			};
		}
	}

	// serialize a writable data event directive
	_apply_directive(sc1_directive, w_value) {
		// directive contents
		let m_directive = R_DIRECTIVE_CONTENTS.exec(sc1_directive);
		if(!m_directive) {
			throw new Error(`Invalid writable data event directive string: "${sc1_directive}"`);
		}

		// parse as JSON
		let g_directive;
		try {
			g_directive = JSON.parse(m_directive[1]);
		}
		catch(e_parse) {
			throw new Error(`Unable to parse JSON in writable data event directive: "${m_directive[1]}"`);
		}

		// directive type
		let s_type = g_directive.type;

		// deduce directive type
		switch(s_type) {
			// comment
			case 'comment': {
				// serializer supports commenting; serialize comment
				if(this._serialize_comment) {
					return {
						write: this._serialize_comment(w_value+'', g_directive),
					};
				}
				break;
			}

			// newlines
			case 'newlines': {
				// serializer supports newlines; serialize newlines
				if(this._serialize_newlines) {
					return {
						write: this._serialize_newlines(w_value),
					};
				}
				break;
			}

			// config
			case 'config': {
				switch(g_directive.value) {
					// list config
					case 'lists': {
						// ref stack of list serializers
						let a_list_serializers = this._a_list_serializers;

						// push current method to stack
						a_list_serializers.push(this._serialize_list_object);

						// inherit unspecified keys from parent
						let g_list_default = this._g_lists;

						// build list config
						let g_lists = {
							first: w_value.first || g_list_default.first,
							rest: w_value.rest || g_list_default.rest,
							nil: w_value.nil || g_list_default.nil,
						};

						// redefine list object serialization
						this._serialize_list_object = function(a_list, n_nest_level) {
							// transcode list object
							let hc2_transcoded = this._transcode_list(a_list, g_lists);

							// serialize object
							return this._encode_objects(hc2_transcoded, n_nest_level);
						};

						// return local directive instructions
						return {
							exit: () => {
								this._serialize_list_object = a_list_serializers.pop();
							},
						};
					}

					// no such key
					default: {
						throw new Error(`No such config key '${g_directive.value}'`);
					}
				}
			}

			// other
			default: {
				throw new Error(`Invalid writable data event directive type: '${s_type}'`);
			}
		}

		// nothing
		return {};
	}

	// if not overriden by subclass, serialize quads in default graph
	_serialize_c4(hc4_quads) {
		let h_prefixes = this._h_prefixes;
		let a_unions = [];
		let s_write = '';

		// each graph in quads hash
		for(let sv1_graph in hc4_quads) {
			// non-default graph; union from dataset
			if('*' !== sv1_graph) a_unions.push(sv1_graph);

			// add all quads from graph
			s_write += this._serialize_c3(hc4_quads[sv1_graph]);
		}

		// a union was performed
		if(a_unions.length) {
			// warn about implicit union
			let s_warning = `Destination format does not support quads; an implicit union into the default graph was performed on the quads contained in graphs: ${a_unions.map(sc1 => factory.c1(sc1, h_prefixes).verbose()).join(', ')}`;

			// emit warning, wasn't listened to; force thru warn/stderr channel
			if(!this.emit('warning', s_warning)) {
				console.warn(s_warning);
			}
		}

		return s_write;
	}
}

module.exports = Writable;

},{"@graphy/core.class.scribable":18,"@graphy/core.data.factory":20}],20:[function(require,module,exports){



const crypto = require('crypto');

const R_INVALID_IRIREF = /([\x00-\x20<>"{}|^`\\]|%(?![0-9A-F][0-9A-F]))/g;
const F_REPLACE_INVALID_IRIREF = (s_, s_v) => {
	let s_code = s_v.codePointAt(0).toString(16)+'';
	return s_code.length > 4
		? '\\U'+s_code.padStart(8, '0')
		: '\\u'+s_code.padStart(4, '0');
};

const clean_iri = p_iri_dirty => p_iri_dirty.replace(R_INVALID_IRIREF, F_REPLACE_INVALID_IRIREF);



// eslint-disable-next-line no-misleading-character-class
const RT_AVOID_PNAME_NS = /^(?:[\u0000-@[-`{-\u00bf\u00d7\u00f7\u0300-\u306f\u037e\u2000-\u200b\u200e-\u206f\u2190-\u2bff\u2ff0-\u3000\ud800-\uf8ff\ufdd0-\ufddf\ufffe\uffff].+|(?:.+?[\u0000-,\/:-@[-^`{-\u00b6\u00b8-\u00bf\u00d7\u00f7\u037e\u2000-\u200b\u200e-\u203e\u2041-\u206f\u2190-\u2bff\u2ff0-\u3000\ud800-\uf8ff\ufdd0-\ufddf\ufffe\uffff].*)|.+\.)$/;

// eslint-disable-next-line no-misleading-character-class
const RT_AVOID_PNAME_LOCAL = /^(?:\\|[\u0000-\/;-@[-^`{-\u00bf\u00d7\u00f7\u0300-\u306f\u037e\u2000-\u200b\u200e-\u206f\u2190-\u2bff\u2ff0-\u3000\ud800-\uf8ff\ufdd0-\ufddf\ufffe\uffff].+|(?:.+?(?:\\|[\u0000-,\/;-@[-^`{-\u00b6\u00b8-\u00bf\u00d7\u00f7\u037e\u2000-\u200b\u200e-\u203e\u2041-\u206f\u2190-\u2bff\u2ff0-\u3000\ud800-\uf8ff\ufdd0-\ufddf\ufffe\uffff]).+)|(?:.+?(?:\\|[\u0000-,.\/;-@[-^`{-\u00b6\u00b8-\u00bf\u00d7\u00f7\u037e\u2000-\u200b\u200e-\u203e\u2041-\u206f\u2190-\u2bff\u2ff0-\u3000\ud800-\uf8ff\ufdd0-\ufddf\ufffe\uffff])))$/;

const RT_BOOLEAN_TRUE = /^([Tt](rue)?|TRUE)$/;
const RT_BOOLEAN_FALSE = /^([Ff](alse)?|FALSE)$/;

const S_UUID_V4 = 'xxxxxxxx_xxxx_4xxx_yxxx_xxxxxxxxxxxx';
const R_UUID_V4 = /[xy]/g;

const uuid_v4 = () => {
	let dt_now = Date.now();
	if('undefined' !== typeof performance) dt_now += performance.now();
	return S_UUID_V4.replace(R_UUID_V4, (s) => {
		let x_r = (dt_now + (Math.random()*16)) % 16 | 0;
		dt_now = Math.floor(dt_now / 16);
		return ('x' === s? x_r: ((x_r & 0x3) | 0x8)).toString(16);
	});
};


// symbol to access cache on a prefix mapping
const $_PREFIX_CACHE = Symbol('prefix-cache');

// escape characters for compiling regexes
const R_REGEX_ESCAPE = /[$^*()+[\\{}|.?]/g;

// valid locals of prefixed names
const SR_PN_LOCAL = '((?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u{02ff}\\u{0370}-\\u{037d}\\u{037f}-\\u{1fff}\\u{200c}-\\u{200d}\\u{2070}-\\u{218f}\\u{2c00}-\\u{2fef}\\u{3001}-\\u{d7ff}\\u{f900}-\\u{fdcf}\\u{fdf0}-\\u{fffd}\\u{10000}-\\u{effff}_:0-9]|%[A-Fa-f0-9]{2}|\\\\[_~.\\-!$&\'()*+,;=/?#@%])(?:(?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u{02ff}\\u{0370}-\\u{037d}\\u{037f}-\\u{1fff}\\u{200c}-\\u{200d}\\u{2070}-\\u{218f}\\u{2c00}-\\u{2fef}\\u{3001}-\\u{d7ff}\\u{f900}-\\u{fdcf}\\u{fdf0}-\\u{fffd}\\u{10000}-\\u{effff}_\\-0-9\\xb7\\u{0300}-\\u{036f}\\u{203f}-\\u{2040}.:]|%[A-Fa-f0-9]{2}|\\\\[_~.\\-!$&\'()*+,;=/?#@%])*(?:[A-Za-z\\xc0-\\xd6\\xd8-\\xf6\\xf8-\\u{02ff}\\u{0370}-\\u{037d}\\u{037f}-\\u{1fff}\\u{200c}-\\u{200d}\\u{2070}-\\u{218f}\\u{2c00}-\\u{2fef}\\u{3001}-\\u{d7ff}\\u{f900}-\\u{fdcf}\\u{fdf0}-\\u{fffd}\\u{10000}-\\u{effff}_\\-0-9\\xb7\\u{0300}-\\u{036f}\\u{203f}-\\u{2040}:]|%[A-Fa-f0-9]{2}|\\\\[_~.\\-!$&\'()*+,;=/?#@%]))?)$';


// create a cache on a prefix mapping
function cache_prefixes(h_prefixes, b_terse=false) {
	// regex cache string building
	let a_cache = [];

	// inverse mappings
	let h_inverse = {};

	// each prefix/iri pair
	for(let si_prefix in h_prefixes) {
		let p_iri = h_prefixes[si_prefix];

		// prefix would make an invalid namespace; skip
		if(b_terse && RT_AVOID_PNAME_NS.test(si_prefix)) continue;

		// save inverse mapping
		h_inverse[p_iri] = si_prefix;

		// push iri
		a_cache.push(p_iri.replace(R_REGEX_ESCAPE, '\\$&'));
	}

	// no prefixes; forgo cache
	if(!a_cache.length) return h_prefixes;

	// save cache object
	h_prefixes[$_PREFIX_CACHE] = {
		_r_iris: new RegExp(`^(${a_cache.join('|')})${SR_PN_LOCAL}`, 'u'),
		_h_inverse: h_inverse,
	};

	// freeze object
	return Object.freeze(h_prefixes);
}



// attempt to turn an iri into a terse prefixed name
const terse = (p_iri, h_prefixes) => {
	// ref cache
	let g_cache = h_prefixes[$_PREFIX_CACHE];

	// cache exists
	if(g_cache) {
		// iri matching
		let m_iri = g_cache._r_iris.exec(p_iri);

		// prefix mapped; compress
		if(m_iri) {
			return g_cache._h_inverse[m_iri[1]]+':'+m_iri[2];
		}
	}
	// cache does not exist
	else {
		// best prefix id
		let si_best_prefix = '';
		let s_best_suffix = '';

		// length of longest matching iri
		let nl_best_prefix_iri = -1;

		// each prefix in hash
		for(let si_prefix in h_prefixes) {
			let p_prefix_iri = h_prefixes[si_prefix];

			// target iri starts with prefix iri and its longer than the current best
			if(0 === p_iri.indexOf(p_prefix_iri) && p_prefix_iri.length > nl_best_prefix_iri
				// namespace is okay to use
				&& !RT_AVOID_PNAME_NS.test(si_prefix)
			) {
				// compute suffix
				let s_suffix = p_iri.slice(p_prefix_iri.length);

				// suffix is okay to use
				if(!RT_AVOID_PNAME_LOCAL.test(s_suffix)) {
					s_best_suffix = s_suffix;

					// save prefix id as best
					si_best_prefix = si_prefix;

					// update best iri length
					nl_best_prefix_iri = p_prefix_iri.length;
				}
			}
		}

		// found a prefix
		if(-1 !== nl_best_prefix_iri) {
			// use terse prefixed name
			return si_best_prefix+':'+s_best_suffix;
		}
	}

	// fallback
	return '<'+p_iri+'>';
};

// attempt to turn an iri into a concise prefixed name
const concise = (p_iri, h_prefixes={}) => {
	// ref cache
	let g_cache = h_prefixes[$_PREFIX_CACHE];

	// cache exists
	if(g_cache) {
		// iri matching
		let m_iri = g_cache._r_iris.exec(p_iri);

		// prefix mapped; compress
		if(m_iri) {
			return g_cache._h_inverse[m_iri[1]]+':'+m_iri[2];
		}
	}
	// cache does not exists
	else {
		// best prefix id
		let s_best_prefix_id = '';

		// length of longest matching iri
		let nl_best_prefix_iri = -1;

		// each prefix in hash
		for(let s_prefix_id in h_prefixes) {
			let p_prefix_iri = h_prefixes[s_prefix_id];

			// target iri starts with prefix iri and its longer than the current best
			if(p_iri.startsWith(p_prefix_iri) && p_prefix_iri.length > nl_best_prefix_iri) {
				// save prefix id as best
				s_best_prefix_id = s_prefix_id;

				// update best iri length
				nl_best_prefix_iri = p_prefix_iri.length;
			}
		}

		// found a prefix
		if(-1 !== nl_best_prefix_iri) {
			return s_best_prefix_id+':'+p_iri.slice(nl_best_prefix_iri);
		}
	}

	// no prefix found; default to full iri
	return '>'+p_iri;
};

const R_C1N_DECONSTRUCT = /^([^:]*):(.*)$/;

function c1_to_nt(sc1_in, h_prefixes={}, b_verbose=false) {
	switch(sc1_in[0]) {
		// absolute iri
		case '>': return '<'+sc1_in.slice(1)+'>';

		// blank node
		case '_': {
			// ephemeral hint
			if(sc1_in.length <= 2 || '#' === sc1_in[2]) {
				return (new EphemeralBlankNode())[b_verbose? 'verbose': 'terse']();
			}
			// labeled
			else {
				return sc1_in;
			}
		}

		// simple literal
		case '"': return JSON.stringify(sc1_in.slice(1));

		// languaged literal
		case '@': {
			let i_contents = sc1_in.indexOf('"');
			return JSON.stringify(sc1_in.slice(i_contents+1))+sc1_in.slice(0, i_contents);
		}

		// datatyped literal
		case '^': {
			let i_contents = sc1_in.indexOf('"');
			return JSON.stringify(sc1_in.slice(i_contents+1))+'^^'+c1_to_nt(sc1_in.slice(1, i_contents), h_prefixes, b_verbose);
		}

		// default graph
		case '*': return '';

		// directive / node explicit
		case '<':
		case '`': return factory.c1(sc1_in).terse(h_prefixes);

		// otherwise
		default: {
			// rdf:type alis
			if('a' === sc1_in) return b_verbose? '<http://www.w3.org/1999/02/22-rdf-syntax-ns#type>': 'a';

			// deconstruct prefixed name
			let [, si_prefix, s_suffix] = R_C1N_DECONSTRUCT.exec(sc1_in);

			// avoid illegal prefixed name parts
			if(b_verbose || RT_AVOID_PNAME_LOCAL.test(s_suffix) || RT_AVOID_PNAME_NS.test(si_prefix)) {
				return '<'+h_prefixes[si_prefix]+s_suffix+'>';
			}

			// good as-is
			return sc1_in;
		}
	}
}


class GenericTerm {
	valueOf() {
		return this.concise();
	}

	toString() {
		return this.concise();
	}

	equals(z_other) {
		return z_other
			? this === z_other
				|| (z_other.termType === this.termType && z_other.value === this.value)
			: false;
	}
} Object.assign(GenericTerm.prototype, {
	isGraphyTerm: true,
});


class NamedNode extends GenericTerm {
	constructor(s_iri) {
		super();
		this.value = s_iri;
	}

	concise(h_prefixes={}) {
		return concise(this.value, h_prefixes);
	}

	terse(h_prefixes={}, b_opt=false) {
		return terse(clean_iri(this.value), h_prefixes, b_opt);
	}

	verbose() {
		return '<'+clean_iri(this.value)+'>';
	}

	isolate() {
		return {
			termType: 'NamedNode',
			value: this.value,
		};
	}
} Object.assign(NamedNode.prototype, {
	termType: 'NamedNode',
	isNamedNode: true,
});

const KT_RDF_TYPE = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#type');
KT_RDF_TYPE.isRdfTypeAlias = true;  // for serialization

const KT_RDF_LANG_STRING = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#langString');
const G_ISOLATE_RDF_LANG_STRING = KT_RDF_LANG_STRING.isolate();

const KT_RDF_FIRST = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#first');
const KT_RDF_REST = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#rest');
const KT_RDF_NIL = new NamedNode('http://www.w3.org/1999/02/22-rdf-syntax-ns#nil');

const KT_XSD_DATE = new NamedNode('http://www.w3.org/2001/XMLSchema#date');
const KT_XSD_DATETIME = new NamedNode('http://www.w3.org/2001/XMLSchema#dateTime');
const KT_XSD_STRING = new NamedNode('http://www.w3.org/2001/XMLSchema#string');

class GenericLiteral extends GenericTerm {
	equals(z_other) {
		return z_other
			? this === z_other
				|| ('Literal' === z_other.termType && z_other.value === this.value
					&& this.datatype.equals(z_other.datatype) && z_other.language === this.language)
			: false;
	}

	verbose() {
		return JSON.stringify(this.value)
			+ (this.language
				? '@'+this.language
				: '^^'+this.datatype.verbose());
	}

	concise(h_prefixes) {
		if(this.language) {
			return '@'+this.language+'"'+this.value;
		}
		else {
			return '^'+concise(this.datatype.value, h_prefixes)+'"'+this.value;
		}
	}

	terse(h_prefixes={}) {
		// turn into terse
		let st_datatype = this.datatype.terse(h_prefixes);

		// stringify literal
		return JSON.stringify(this.value)
			+ (this.language
				? '@'+this.language
				: '^^'+st_datatype);
	}

	isolate() {
		return {
			termType: 'Literal',
			value: this.value,
			language: this.language,
			datatype: this.datatype.isolate(),
		};
	}
} Object.assign(GenericLiteral.prototype, {
	datatype: KT_XSD_STRING,
	language: '',
	termType: 'Literal',
	isLiteral: true,
	isSimple: false,
});

class LanguagedLiteral extends GenericLiteral {
	constructor(s_value, s_lang) {
		super();
		this.value = s_value;

		// remove optional '@' character from beginning
		this.language = ('@' === s_lang[0]? s_lang.slice(1): s_lang).toLowerCase();
	}

	verbose() {
		return JSON.stringify(this.value)+'@'+this.language;
	}

	concise() {
		return '@'+this.language+'"'+this.value;
	}

	terse() {
		// stringify literal
		return JSON.stringify(this.value)+'@'+this.language;
	}

	isolate() {
		return {
			termType: 'Literal',
			value: this.value,
			language: this.language,
			datatype: G_ISOLATE_RDF_LANG_STRING,
		};
	}
} Object.assign(LanguagedLiteral.prototype, {
	datatype: KT_RDF_LANG_STRING,
	isLanguaged: true,
});


class DatatypedLiteral extends GenericLiteral {
	verbose() {
		return JSON.stringify(this.value)+'^^'+this.datatype.verbose();
	}

	concise(h_prefixes) {
		return '^'+concise(this.datatype.value, h_prefixes)+'"'+this.value;
	}

	terse(h_prefixes={}) {
		// turn into terse
		let st_datatype = this.datatype.terse(h_prefixes);

		// stringify literal
		return JSON.stringify(this.value)+'^^'+st_datatype;
	}

	isolate() {
		return {
			termType: 'Literal',
			value: this.value,
			language: this.language,
			datatype: this.datatype.isolate(),
		};
	}
} Object.assign(DatatypedLiteral.prototype, {
	isDatatyped: true,
});

class ExplicitlyDatatypedLiteral extends DatatypedLiteral {
	constructor(s_value, kt_datatype) {
		super();
		this.value = s_value;
		this.datatype = kt_datatype;
	}
}

class RawLiteral extends GenericTerm {
	constructor(s_value) {
		super();
		this.value = s_value;
	}

	get isSimple() {
		return !this.language && !this.datatype.equals(KT_XSD_STRING);
	}

	get isLanguaged() {
		return !!this.language;
	}

	get isDatatyped() {
		return KT_XSD_STRING.equals(this.datatype);
	}

	equals(z_other) {
		return z_other
			? this === z_other
				|| ('Literal' === z_other.termType && z_other.value === this.value
					&& this.datatype.equals(z_other.datatype) && z_other.language === this.language)
			: false;
	}

	verbose() {
		return JSON.stringify(this.value)
			+ (this.language
				? '@'+this.language
				: '^^'+this.datatype.verbose());
	}

	concise(h_prefixes) {
		if(this.language) {
			return '@'+this.language+'"'+this.value;
		}
		else {
			return '^'+concise(this.datatype.value, h_prefixes)+'"'+this.value;
		}
	}

	terse(h_prefixes={}) {
		// turn into terse
		let st_datatype = this.datatype.terse(h_prefixes);

		// stringify literal
		return JSON.stringify(this.value)
			+ (this.language
				? '@'+this.language
				: '^^'+st_datatype);
	}

	isolate() {
		return {
			termType: 'Literal',
			value: this.value,
			language: this.language,
			datatype: this.datatype.isolate(),
		};
	}
} Object.assign(RawLiteral.prototype, {
	datatype: KT_XSD_STRING,
	language: '',
	termType: 'Literal',
	isLiteral: true,
});

class SimpleLiteral extends GenericLiteral {
	constructor(s_value) {
		super();
		this.value = s_value;
	}

	verbose() {
		return JSON.stringify(this.value);
	}

	concise() {
		return '"'+this.value;
	}

	terse() {
		return JSON.stringify(this.value);
	}
} Object.assign(SimpleLiteral.prototype, {
	isSimple: true,
});



const KT_XSD_INTEGER = new NamedNode('http://www.w3.org/2001/XMLSchema#integer');
class Literal_Integer extends DatatypedLiteral {
	static from(s_literal) {
		let kt = new Literal_Integer(+s_literal);
		kt.value = s_literal;
		return kt;
	}

	constructor(x_value) {
		super();
		this.value = x_value+'';

		this.number = x_value;
	}

	concise(h_prefixes={}) {
		return '^'+KT_XSD_INTEGER.concise(h_prefixes)+'"'+this.value;
	}

	terse() {
		return this.value.includes('e')
			? `"${this.value}"^^<http://www.w3.org/2001/XMLSchema#integer>`
			: this.value;
	}
} Object.assign(Literal_Integer.prototype, {
	datatype: KT_XSD_INTEGER,

	isNumeric: true,
	isInteger: true,
});
const KT_XSD_DOUBLE = new NamedNode('http://www.w3.org/2001/XMLSchema#double');
class Literal_Double extends DatatypedLiteral {
	static from(s_literal) {
		let kt = new Literal_Double(+s_literal);
		kt.value = s_literal;
		return kt;
	}

	constructor(x_value) {
		super();
		this.value = x_value+'';

		this.number = x_value;
	}

	concise(h_prefixes={}) {
		return '^'+KT_XSD_DOUBLE.concise(h_prefixes)+'"'+this.value;
	}

	terse() {
		return this.number.toExponential();
	}
} Object.assign(Literal_Double.prototype, {
	datatype: KT_XSD_DOUBLE,

	isNumeric: true,
	isDouble: true,
});
const KT_XSD_DECIMAL = new NamedNode('http://www.w3.org/2001/XMLSchema#decimal');
class Literal_Decimal extends DatatypedLiteral {
	static from(s_literal) {
		let kt = new Literal_Decimal(+s_literal);
		kt.value = s_literal;
		return kt;
	}

	constructor(x_value) {
		super();
		this.value = x_value+'';

		this.number = x_value;
	}

	concise(h_prefixes={}) {
		return '^'+KT_XSD_DECIMAL.concise(h_prefixes)+'"'+this.value;
	}

	terse() {
		return this.value.includes('e')
			? `"${this.value}"^^<http://www.w3.org/2001/XMLSchema#decimal>`
			: this.value+(this.value.includes('.')? '': '.0');
	}
} Object.assign(Literal_Decimal.prototype, {
	datatype: KT_XSD_DECIMAL,

	isNumeric: true,
	isDecimal: true,
});
const KT_XSD_BOOLEAN = new NamedNode('http://www.w3.org/2001/XMLSchema#boolean');
class Literal_Boolean extends DatatypedLiteral {
	static from(s_literal) {
		let kt = new Literal_Boolean(+s_literal);
		kt.value = s_literal;
		return kt;
	}

	constructor(b_value) {
		super();
		this.value = b_value+'';
		this.boolean = b_value;
	}

	concise(h_prefixes={}) {
		return '^'+KT_XSD_BOOLEAN.concise(h_prefixes)+'"'+this.value;
	}

	terse() {
		return this.value+'';
	}
} Object.assign(Literal_Boolean.prototype, {
	datatype: KT_XSD_BOOLEAN,
	isBoolean: true,
});



class Literal_PositiveInfinity extends Literal_Double {
	constructor() {
		super(Infinity);
		this.value = 'INF';
	}

	terse(h_prefixes) {
		return '"INF"^^'+KT_XSD_DOUBLE.terse(h_prefixes);
	}
} Object.assign(Literal_PositiveInfinity.prototype, {
	isInfinite: true,
});

class Literal_NegativeInfinity extends Literal_Double {
	constructor() {
		super(-Infinity);
		this.value = '-INF';
	}

	terse(h_prefixes) {
		return '"-INF"^^'+KT_XSD_DOUBLE.terse(h_prefixes);
	}
} Object.assign(Literal_NegativeInfinity.prototype, {
	isInfinite: true,
});

class Literal_NaN extends Literal_Double {
	constructor() {
		super(NaN);
		this.value = 'NaN';
	}

	terse(h_prefixes) {
		return '"NaN"^^'+KT_XSD_DOUBLE.terse(h_prefixes);
	}
} Object.assign(Literal_NaN.prototype, {
	isNaN: true,
});


function BlankNode(s_value, b_anonymous=false) {
	this.value = s_value;
	this.isAnonymous = b_anonymous;
} BlankNode.prototype = Object.assign(
	Object.create(GenericTerm.prototype), {
		termType: 'BlankNode',
		isBlankNode: true,

		concise() {
			return '_:'+this.value;
		},

		terse() {
			return '_:'+this.value;
		},

		verbose() {
			return '_:'+this.value;
		},

		isolate() {
			return {
				termType: 'BlankNode',
				value: this.value,
			};
		},
	});


function EphemeralBlankNode() {}
EphemeralBlankNode.prototype = Object.assign(
	Object.create(BlankNode.prototype), {
		isAnonymous: true,
		isEphemeral: true,

		concise() {
			return '_:#'+this.value;
		},

		terse() {
			return '[]';
		},

		verbose() {
			return '_:'+this.value;
		},

		isolate() {
			return {
				termType: 'BlankNode',
				value: this.value,
			};
		},

		equals() {
			return false;
		},
	});
Object.defineProperty(EphemeralBlankNode.prototype, 'value', {
	get() {
		return '_'+uuid_v4();
	},
});

class Variable extends GenericTerm {
	constructor(s_label) {
		super();
		this.value = s_label;
	}

	concise() {
		return '?'+this.value;
	}

	terse() {
		throw new Error(`Cannot call .terse() on 'Variable' term type`);
	}

	verbose() {
		throw new Error(`Cannot call .verbose() on 'Variable' term type`);
	}

	isolate() {
		return {
			termType: 'Variable',
			value: this.value,
		};
	}
} Object.assign(Variable.prototype, {
	termType: 'Variable',
	isVariable: true,
});


function DefaultGraph() {}
DefaultGraph.prototype = Object.assign(
	Object.create(GenericTerm.prototype), {
		value: '',
		termType: 'DefaultGraph',
		isDefaultGraph: true,

		concise() {
			return '*';
		},

		terse() {
			return '';
		},

		verbose() {
			return '';
		},

		isolate() {
			return {
				termType: 'DefaultGraph',
				value: '',
			};
		},
	});

function NoGraph() {}
NoGraph.prototype = Object.assign(
	Object.create(GenericTerm.prototype), {
		value: '',
		termType: 'NoGraph',

		concise() {
			return '';
		},

		terse() {
			return '';
		},

		verbose() {
			return '';
		},

		isolate() {
			return {
				termType: 'NoGraph',
				value: '',
			};
		},
	});

const KT_DEFAULT_GRAPH = new DefaultGraph();
function Quad(h_subject, h_predicate, h_object, h_graph=KT_DEFAULT_GRAPH) {
	this.subject = h_subject;
	this.predicate = h_predicate;
	this.object = h_object;
	this.graph = h_graph;
} Object.assign(Quad.prototype, {
	isGraphyQuad: true,

	equals(z_other) {
		return z_other
			? this === z_other
				|| (this.object.equals(z_other.object)
					&& this.subject.equals(z_other.subject)
					&& this.predicate.equals(z_other.predicate)
					&& this.graph.equals(z_other.graph))
			: false;
	},

	valueOf() {
		return this.verbose();
	},

	concise(h_prefixes={}) {
		return [
			this.subject.concise(h_prefixes),
			this.predicate.concise(h_prefixes),
			this.object.concise(h_prefixes),
			this.graph.concise(h_prefixes),
		];
	},

	terse(h_prefixes) {
		let b_default_graph = this.graph.isDefaultGraph;
		return (b_default_graph? '': this.graph.terse(h_prefixes)+' { ')
			+this.subject.terse(h_prefixes)
			+' '+this.predicate.terse(h_prefixes)
			+' '+this.object.terse(h_prefixes)+' .'
			+(b_default_graph? '': ' }');
	},

	verbose() {
		return this.subject.verbose()
			+' '+this.predicate.verbose()
			+' '+this.object.verbose()
			+' '+(this.graph.isDefaultGraph? '': this.graph.verbose()+' ')+'.';
	},

	isolate() {
		return {
			subject: this.subject.isolate(),
			predicate: this.predicate.isolate(),
			object: this.object.isolate(),
			graph: this.graph.isolate(),
		};
	},
});



let g_raw = {
	namedNode(p_iri) {
		return new NamedNode(p_iri);
	},

	blankNode(s_label, b_anonymous) {
		return new BlankNode(s_label, b_anonymous);
	},

	literal(s_value) {
		return new RawLiteral(s_value);
	},

	defaultGraph() {
		return new DefaultGraph();
	},

	quad(kt_subject, kt_predicate, kt_object, kt_graph) {
		return new Quad(kt_subject, kt_predicate, kt_object, kt_graph || KT_DEFAULT_GRAPH);
	},

	integer(w) {
		return Literal_Integer.from(w);
	},

	double(w) {
		return Literal_Double.from(w);
	},

	decimal(w) {
		return Literal_Decimal.from(w);
	},

	boolean(w) {
		return new Literal_Boolean(w);
	},

};


const factory = module.exports = {
	concise,

	adopt(dc_factory) {
		let dc_extend = Object.create(dc_factory);
		let b_use_extend = false;

		if('function' !== typeof dc_factory.boolean) {
			let kt_xsd_boolean = dc_factory.namedNode('http://www.w3.org/2001/XMLSchema#boolean');
			dc_extend.boolean = b_value => dc_factory.literal(b_value, kt_xsd_boolean);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.double) {
			let kt_xsd_double = dc_factory.namedNode('http://www.w3.org/2001/XMLSchema#double');
			dc_extend.double = s_value => dc_factory.double(s_value, kt_xsd_double);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.decimal) {
			let kt_xsd_decimal = dc_factory.namedNode('http://www.w3.org/2001/XMLSchema#decimal');
			dc_extend.decimal = s_value => dc_factory.decimal(s_value, kt_xsd_decimal);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.integer) {
			let kt_xsd_integer = dc_factory.namedNode('http://www.w3.org/2001/XMLSchema#integer');
			dc_extend.integer = s_value => dc_factory.integer(s_value, kt_xsd_integer);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.simpleLiteral) {
			dc_extend.simpleLiteral = s_value => dc_factory.literal(s_value);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.languagedLiteral) {
			dc_extend.languagedLiteral = (s_value, s_lang) => dc_factory.literal(s_value, s_lang);
			b_use_extend = true;
		}

		if('function' !== typeof dc_factory.datatypedLiteral) {
			dc_extend.datatypedLiteral = (s_value, kt_datatype) => dc_factory.literal(s_value, kt_datatype);
			b_use_extend = true;
		}

		if(b_use_extend) {
			return dc_extend;
		}
		else {
			return dc_factory;
		}
	},

	raw: g_raw,
	unfiltered: {
		...g_raw,
		literal(s_value, z_datatype_or_lang) {
			if(!z_datatype_or_lang || KT_XSD_STRING.equals(z_datatype_or_lang)) {
				return new SimpleLiteral(s_value);
			}
			else if('string' === typeof z_datatype_or_lang) {
				return new LanguagedLiteral(s_value, z_datatype_or_lang);
			}
			else if(KT_XSD_STRING.equals(z_datatype_or_lang)) {
				return new SimpleLiteral(s_value);
			}
			else {
				return new ExplicitlyDatatypedLiteral(s_value, z_datatype_or_lang);
			}
		},

		simpleLiteral(s_value) {
			return new SimpleLiteral(s_value);
		},

		languagedLiteral(s_value, s_language) {
			return new LanguagedLiteral(s_value, s_language);
		},

		datatypedLiteral(s_value, kt_datatype) {
			if(KT_XSD_STRING.equals(kt_datatype)) {
				return new SimpleLiteral(s_value);
			}
			else {
				return new ExplicitlyDatatypedLiteral(s_value, kt_datatype);
			}
		},
	},

	number(x) {
		// not finite or not a number
		if('number' === typeof x && (!Number.isFinite(x) || Number.isNaN(x))) {
			return factory.double(x);
		}
		// integer or bigint
		else if(Number.isInteger(x) || 'bigint' === typeof x) {  // eslint-disable-line valid-typeof
			return factory.integer(x);
		}
		// non-integer
		else {
			return factory.decimal(x);
		}
	},

	date(dt) {
		return factory.literal(dt.toISOString().replace(/T.+$/, 'Z'), KT_XSD_DATE);
	},

	dateTime(dt) {
		return factory.literal(dt.toISOString(), KT_XSD_DATETIME);
	},

	namedNode(p_iri) {
		return new NamedNode(p_iri);
	},

	ephemeral() {
		return new EphemeralBlankNode();
	},

	// @deprecated
	anonymous() {
		return new EphemeralBlankNode();
	},

	blankNode(z_label) {
		// no label given, generate a UUID
		if(!z_label) {
			// eslint-disable-next-line no-undef
			return new BlankNode('_'+uuid_v4(), true);
		}
		// label given
		else if('string' === typeof z_label) {
			return new BlankNode(z_label);
		}

		throw new TypeError(`factory.blankNode(label) expects 'label' parameter to be falsy or a string; instead found: ${z_label}`);
	},

	literal(s_value, z_datatype_or_lang) {
		if(!z_datatype_or_lang || KT_XSD_STRING.equals(z_datatype_or_lang)) {
			return new SimpleLiteral(s_value);
		}
		else if('string' === typeof z_datatype_or_lang) {
			return new LanguagedLiteral(s_value, z_datatype_or_lang);
		}
		else {
			return new ExplicitlyDatatypedLiteral(s_value, z_datatype_or_lang);
		}
	},

	integer(w_value) {
		let s_type = typeof w_value;

		// a number was given
		if('number' === s_type) {
			// not a finite number
			if(!Number.isFinite(w_value)) {
				// NaN
				if(Number.isNaN(w_value)) {
					throw new Error('XSD integer cannot encode NaN. Try using double');
				}

				throw new Error('XSD integer cannot encode +/-infinity. Try using double');
			}
			// not an integer
			else if(!Number.isInteger(w_value)) {
				throw new Error('Number is not an integer: '+w_value);
			}

			return new Literal_Integer(w_value);
		}
		// string
		else if('string' === s_type) {
			// empty string
			if('' === w_value) {
				throw new Error('Refusing to serialize empty string as xsd:integer');
			}

			// parse to number
			let x_value = +w_value;

			// failed to parse or not an integer
			if(Number.isNaN(x_value) || !Number.isInteger(x_value)) {
				throw new Error('Invalid integer string: '+w_value);
			}

			return new Literal_Integer(x_value);
		}
		// undefined
		else if('undefined' === s_type) {
			throw new Error('Refusing to serialize undefined value as xsd:integer');
		}
		// other
		else {
			// null
			if(null === w_value) {
				throw new Error('Refusing to serialize null value as xsd:integer');
			}

			// invalid
			throw new Error('XSD integer expects a number type or integer string');
		}
	},
	double(w_value) {
		let s_type = typeof w_value;

		// a number was given
		if('number' === s_type) {
			// not a finite number
			if(!Number.isFinite(w_value)) {
				// NaN
				if(Number.isNaN(w_value)) {
					return new Literal_NaN();
				}

				return w_value > 0
					? new Literal_PositiveInfinity()
					: new Literal_NegativeInfinity();
			}

			return new Literal_Double(w_value);
		}
		// string
		else if('string' === s_type) {
			// empty string
			if('' === w_value) {
				throw new Error('Refusing to serialize empty string as xsd:double');
			}

			// parse to number
			let x_value = +w_value;

			// failed to parse
			if(Number.isNaN(x_value)) {
				throw new Error('Invalid decimal string: '+w_value);
			}

			return new Literal_Double(x_value);
		}
		// undefined
		else if('undefined' === s_type) {
			throw new Error('Refusing to serialize undefined value as xsd:double');
		}
		// other
		else {
			// null
			if(null === w_value) {
				throw new Error('Refusing to serialize null value as xsd:double');
			}

			// invalid
			throw new Error('XSD double expects a number type or double string');
		}
	},
	decimal(w_value) {
		let s_type = typeof w_value;

		// a number was given
		if('number' === s_type) {
			// not a finite number
			if(!Number.isFinite(w_value)) {
				// NaN
				if(Number.isNaN(w_value)) {
					throw new Error('XSD decimal cannot encode NaN. Try using double');
				}

				throw new Error('XSD decimal cannot encode +/-infinity. Try using double');
			}

			return new Literal_Decimal(w_value);
		}
		// string
		else if('string' === s_type) {
			// empty string
			if('' === w_value) {
				throw new Error('Refusing to serialize empty string as xsd:decimal');
			}

			// parse to number
			let x_value = +w_value;

			// failed to parse
			if(Number.isNaN(x_value)) {
				throw new Error('Invalid decimal string: '+w_value);
			}

			return new Literal_Decimal(x_value);
		}
		// undefined
		else if('undefined' === s_type) {
			throw new Error('Refusing to serialize undefined value as xsd:decimal');
		}
		// other
		else {
			// null
			if(null === w_value) {
				throw new Error('Refusing to serialize null value as xsd:decimal');
			}

			// invalid
			throw new Error('XSD decimal expects a number type or decimal string');
		}
	},
	boolean(w_value) {
		let s_type = typeof w_value;

		// boolean
		if('boolean' === s_type) {
			return new Literal_Boolean(w_value);
		}
		// number
		else if('number' === s_type) {
			// 1
			if(1 === w_value) {
				return new Literal_Boolean(true);
			}
			// 0
			else if(0 === w_value) {
				return new Literal_Boolean(false);
			}

			// invalid
			throw new Error(`Boolean value 'w_value' must be either a '1' or '0' if using numbers`);
		}
		// string
		else if('string' === s_type) {
			// truthy value
			if(RT_BOOLEAN_TRUE.test(w_value)) {
				return new Literal_Boolean(true);
			}
			// falsy value
			else if(RT_BOOLEAN_FALSE.test(w_value)) {
				return new Literal_Boolean(false);
			}

			// empty string
			if('' === w_value) {
				throw new Error('Refusing to serialize empty string as xsd:boolean');
			}

			// failed to parse
			throw new Error('Invalid boolean string: '+w_value);
		}
		// undefined
		else if('undefined' === s_type) {
			throw new Error('Refusing to serialize undefined value as xsd:boolean');
		}
		// other
		else {
			// null
			if(null === w_value) {
				throw new Error('Refusing to serialize null value as xsd:boolean');
			}

			// invalid
			throw new Error('XSD boolean expects a boolean type or boolean string');
		}
	},


	defaultGraph() {
		return new DefaultGraph();
	},

	variable(s_label) {
		return new Variable(s_label);
	},

	// warn
	triple(h_subject, h_predicate, h_object) {
		let e_stack = new Error('It is strongly encouraged to use .quad() instead of .triple()');
		console.warn(e_stack.stack.replace(/^(\s*)Error:/, '$1Warning:'));
		return new Quad(h_subject, h_predicate, h_object);
	},

	quad(h_subject, h_predicate, h_object, h_graph) {
		return new Quad(h_subject, h_predicate, h_object, h_graph || KT_DEFAULT_GRAPH);
	},

	term(z_term, w_prefixes) {
		// concise term
		if('string' === typeof z_term) {
			return factory.c1(z_term, w_prefixes);
		}
		// rdfjs term
		else {
			return factory.from.rdfjs_term(z_term);
		}
	},

	/**
	 * construct a term object from a concise term string
	 * @param  {c1_string} sc1_term - a representation of the term object to create
	 * @param  {Object} h_prefixes - mappings for prefixes
	 * @return {Term} - an RDFJS-compatible term object
	 */
	c1(sc1_term, h_prefixes={}) {
		// deduce term type
		switch(sc1_term[0]) {
			// datatyped literal
			case '^': {
				// find literal's contents delimiter
				let i_contents = sc1_term.indexOf('"');

				// no delimiter
				if(-1 === i_contents) {
					throw new Error(`Invalid concise-term string, no content literal delimiter found: '${sc1_term}'`);
				}

				// extract datatype
				let s_datatype = sc1_term.slice(1, i_contents);

				// make term
				return factory.literal(sc1_term.slice(i_contents+1), factory.c1_node_explicit(s_datatype, h_prefixes));
			}

			// languaged literal
			case '@': {
				// find literal's contents delimiter
				let i_contents = sc1_term.indexOf('"');

				// no delimiter
				if(-1 === i_contents) {
					throw new Error(`Invalid concise-term string, no content literal delimiter found: '${sc1_term}'`);
				}

				// extract language
				let s_language = sc1_term.slice(1, i_contents);

				// make term
				return factory.literal(sc1_term.slice(i_contents+1), s_language);
			}

			// simple literal
			case '"': {
				// make term
				return factory.literal(sc1_term.slice(1));
			}

			// prefixed name
			default: return factory.c1_node(sc1_term, h_prefixes);
		}
	},

	// construct a term object from a concise term string for nodes
	c1_node(sc1_node, h_prefixes={}) {
		// rdf:type shortcut
		if('a' === sc1_node) return KT_RDF_TYPE;

		// default graph
		if('*' === sc1_node) return factory.defaultGraph();

		// blank node
		if('_' === sc1_node[0]) {
			if(':' !== sc1_node[1]) throw new Error(`Invliad concise-term string, prefixes are not allowed to start with an underscore: '${sc1_node}'`);

			// interpret ephemeral hint
			if('#' === sc1_node[2] || 2 === sc1_node.length) return factory.ephemeral();

			// create blank node
			return factory.blankNode(sc1_node.slice(2));
		}

		// other
		return factory.c1_node_explicit(sc1_node, h_prefixes);
	},

	// construct a named node
	c1_named_node(sc1_node, h_prefixes={}) {
		// rdf:type shortcut
		if('a' === sc1_node) return KT_RDF_TYPE;

		// other
		return factory.c1_node_explicit(sc1_node, h_prefixes);
	},

	// construct a term object from a concise term string for nodes (no shortcuts)
	c1_node_explicit(sc1_node, h_prefixes={}) {
		// deduce term type
		switch(sc1_node[0]) {
			// iri
			case '>': return factory.namedNode(sc1_node.slice(1));

			// invalid concise-term string
			case '<': throw new Error(`Whoops! It looks like this concise-term string starts with a '<' character. Remember to use '>' if you are trying to make an absolute IRI reference.\nInvalid concise-term string '${sc1_node}'`);
			case '`': throw new Error(`The backtick character '\`' is reserved for concise-struct key directives and should not be used in the object position.\nInvalid concise-term string '${sc1_node}'`);

			// prefixed name
			default: return this.c1_prefixed_node(sc1_node, h_prefixes);
		}
	},

	// construct a term object from a concise term string for prefixed nodes
	c1_prefixed_node(sc1_node, h_prefixes={}) {
		// find prefix delimiter
		let i_colon = sc1_node.indexOf(':');

		// no delimter; invalid concise-term string for node
		if(-1 === i_colon) throw new Error(`A relative or prefixed node must include a ':' character. \nInvalid concise-term string for node: '${sc1_node}'`);

		// prefix id
		let s_prefix_id = sc1_node.slice(0, i_colon);

		// suffix
		let s_suffix = sc1_node.slice(i_colon+1);

		// find prefix in hash
		if(s_prefix_id in h_prefixes) {
			return factory.namedNode(h_prefixes[s_prefix_id]+s_suffix);
		}
		// prefix not exists
		else {
			throw new Error(`Prefix not defined: '${s_prefix_id}'`);
		}
	},

	c1_to_nt,

	* quads(hc4_quads, h_prefixes={}) {
		for(let sc1_graph in hc4_quads) {
			yield* factory.triples(hc4_quads[sc1_graph], h_prefixes, sc1_graph);
		}
	},

	* triples(hc3_triples, h_prefixes={}, sc1_graph='*') {
		let k_graph = factory.c1(sc1_graph, h_prefixes);
		for(let sc1_subject in hc3_triples) {
			let k_subject = factory.c1(sc1_subject, h_prefixes);
			let hc2_pairs = hc3_triples[sc1_subject];

			yield* factory.pairs(k_graph, k_subject, hc2_pairs, h_prefixes);
		}
	},

	* pairs(k_graph, k_subject, hc2_pairs, h_prefixes={}) {
		for(let sc1_predicate in hc2_pairs) {
			let k_predicate = factory.c1(sc1_predicate, h_prefixes);
			let z_objects = hc2_pairs[sc1_predicate];

			yield* factory.objects(k_graph, k_subject, k_predicate, z_objects, h_prefixes);
		}
	},

	* collection(k_graph, k_subject, a_objects, h_prefixes={}) {
		// first item
		yield* factory.objects(k_graph, k_subject, KT_RDF_FIRST, a_objects[0], h_prefixes);

		// rest of items
		let a_rest = a_objects.slice(1);

		// no more
		if(!a_rest.length) {
			yield new Quad(k_subject, KT_RDF_REST, KT_RDF_NIL, k_graph);
		}
		// more remain
		else {
			// auto blank node
			let k_hop = factory.blankNode();

			// incoming triple
			yield new Quad(k_subject, KT_RDF_REST, k_hop, k_graph);

			// outgoing triples
			yield* factory.collection(k_graph, k_hop, a_rest, h_prefixes);
		}
	},

	* objects(k_graph, k_subject, k_predicate, z_objects, h_prefixes, b_nested=false) {
		// value type
		let s_type = typeof z_objects;
		switch(s_type) {
			// c1-string
			case 'string': {
				yield new Quad(k_subject, k_predicate, factory.c1(z_objects, h_prefixes), k_graph);
				break;
			}

			// number
			case 'number': {
				yield new Quad(k_subject, k_predicate, factory.number(z_objects), k_graph);
				break;
			}

			// object
			case 'object': {
				// array
				if(Array.isArray(z_objects)) {
					// RDF collection
					if(b_nested) {
						// auto blank node
						let k_hop = factory.blankNode();

						// incoming triple
						yield new Quad(k_subject, k_predicate, k_hop, k_graph);

						// outgoing triple
						yield* factory.collection(k_graph, k_hop, z_objects, h_prefixes);
					}
					// list of objects
					else {
						for(let z_item of z_objects) {
							yield* factory.objects(k_graph, k_subject, k_predicate, z_item, h_prefixes, true);
						}
					}
				}
				// simple object
				else {
					// auto blank node
					let k_hop = factory.blankNode();

					// incoming triple
					yield new Quad(k_subject, k_predicate, k_hop, k_graph);

					// outgoing triples
					yield* factory.pairs(k_graph, k_hop, z_objects, h_prefixes);
				}
				break;
			}

			// other
			default: {
				throw new Error(`invalid object type: ${typeof z_objects}`);
			}
		}
	},

	from: {
		term(z_term) {
			if(z_term.isGraphyTerm) return z_term;

			return factory.from.rdfjs_term(z_term);
		},

		quad(g_quad) {
			if(g_quad.isGraphyQuad) return g_quad;

			let g_from = factory.from;
			return new Quad(
				g_from.rdfjs_term(g_quad.subject),
				g_from.rdfjs_term(g_quad.predicate),
				g_from.rdfjs_term(g_quad.object),
				g_quad.graph? g_from.rdfjs_term(g_quad.graph): KT_DEFAULT_GRAPH,
			);
		},

		rdfjs_term(g_term) {
			switch(g_term.termType) {
				case 'NamedNode': return new NamedNode(g_term.value);
				case 'BlankNode': return new BlankNode(g_term.value);
				case 'Literal': return factory.literal(g_term.value, g_term.language
					? g_term.language
					: (g_term.datatype
						? new NamedNode(g_term.datatype.value)
						: null));
				case 'DefaultGraph': return new DefaultGraph();
				default: {
					throw new TypeError(`invalid termType: ${g_term.termType}`);
				}
			}
		},

		sparql_result(g_term) {
			switch(g_term.type) {
				case 'uri': {
					return new NamedNode(g_term.value);
				}

				case 'literal':
				case 'typed-literal': {
					if('xml:lang' in g_term) {
						return new LanguagedLiteral(g_term.value, g_term['xml:lang']);
					}
					else if('datatype' in g_term && 'http://www.w3.org/2001/XMLSchema#string' !== g_term.datatype) {
						return new ExplicitlyDatatypedLiteral(g_term.value, new NamedNode(g_term.datatype));
					}
					else {
						return new SimpleLiteral(g_term.value);
					}
				}

				case 'bnode': {
					return new BlankNode(g_term.value);
				}

				default: {
					throw new Error(`unexpected SPARQL Result JSON Format Term type: ${g_term.type}`);
				}
			}
		},
	},

	to: {
		boolean: s_boolean => Literal_Boolean.from(s_boolean),
		integer: s_integer => Literal_Integer.from(s_integer),
		decimal: s_decimal => Literal_Decimal.from(s_decimal),
		double: s_double => Literal_Double.from(s_double),
	},


	/**
	 * @param  {Object} gc_comment -
	 * @return {string} a `concise-term string` directive to be used as a key in `concise-term structs`
	 * 	in order to write a comment to the document (only works with supporting serializers)
	 */
	comment(gc_comment={}) {
		return `\`[${uuid_v4()}]${JSON.stringify({...gc_comment, type:'comment'})}`;
	},

	/**
	 * @param  {integer} [line_count=1] - number of newlines to insert
	 * @return {string} a `concise-term string` directive to be used as a key in `concise-term structs`
	 * 	in order to write the given number of newlines to the document (only works with supporting serializers)
	 */
	newlines() {
		// if(!Number.isInteger(n_line_count)) throw new TypeError('graphy/core.data.factory#newlines() expects `line_count` argument to be an integer');
		return `\`[${uuid_v4()}]{"type":"newlines"}`;
	},

	/**
	 * @param {string} s_key - key that identifies which aspect to configure. e.g., 'lists'
	 * @return {string} a `concise-term string` directive to be used as a key in `concise-term structs`
	 * 	in order to write the given number of newlines to the document (only works with supporting serializers)
	 */
	config(s_key) {
		if('string' !== typeof s_key) throw new TypeError(`Expected 'key' argument to be a string, instead found ${typeof s_key}`);
		return `\`[${uuid_v4()}]{"type":"config","value":${JSON.stringify(s_key)}}`;
	},

	/**
	 * @param {AnyQuad} g_quad - quad to hash
	 * @return {string} a sha256 hash of the quad
	 */
	hash(g_quad) {
		// normalize quad
		let k_quad = factory.from.quad(g_quad);

		// create hash
		let d_hash = crypto.createHash('sha256');

		// verbose quad
		d_hash.update(k_quad.verbose());

		// return hash string
		return d_hash.digest('hex');
	},


	cache_prefixes,
	cachePrefixes: cache_prefixes,
	terse,

	clean_iri,
	cleanIri: clean_iri,

	$_PREFIX_CACHE,
};

Object.assign(factory, {
	c3: factory.triples,
	c4: factory.quads,
	fromTerm: factory.from.term,
	fromQuad: factory.from.quad,
});

},{"crypto":86}],21:[function(require,module,exports){
(function (process,Buffer){(function (){
const stream = require('readable-stream');



class Readable extends stream.Readable {
	constructor(gc_readable={}) {
		super(gc_readable);

		// use iterator
		if(gc_readable.iterator) {
			throw new Error('readable stream iterator shortcut not yet implemented');
		}
	}

	until(s_event, b_return_stream) {
		return new Promise((fk_until, fe_until) => {
			// convert error to rejected promise
			this.on('error', (e_stream) => {
				fe_until(e_stream);
			});

			// special cases returns `this`
			if(b_return_stream) {
				this.once(s_event, (...a_args) => {
					fk_until(this, ...a_args);
				});
			}
			else {
				this.once(s_event, fk_until);
			}
		});
	}

	bucket(s_encoding='utf8') {
		let g_readable = this._readableState;

		// object mode
		if(g_readable.objectMode) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let a_data = [];

				// pipe to writable
				this.pipe(new stream.Writable({
					write(w_event, s_write_encoding, fk_write) {
						a_data.push(w_event);
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						a_data.push(...a_chunks);
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(a_data);
					});
			});
		}
		// utf8-encoded strings
		else if('utf8' === s_encoding || 'utf-8' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let s_data = '';

				// set encoding
				this.setEncoding(s_encoding);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: false,

					write(s_chunk, s_write_encoding, fk_write) {
						s_data += s_chunk;
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						s_data += a_chunks.join('');
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(s_data);
					});
			});
		}
		// buffer
		else if('buffer' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let ab_data = Buffer.from([]);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: true,

					write(ab_chunk, s_write_encoding, fk_write) {
						ab_data = Buffer.concat([ab_data, ab_chunk], ab_data.length+ab_chunk.length);
						fk_write();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(ab_data);
					});
			});
		}
	}
}

class Writable extends stream.Writable {
	until(s_event, b_return_stream) {
		return new Promise((fk_until, fe_until) => {
			// convert error to rejected promise
			this.on('error', (e_stream) => {
				fe_until(e_stream);
			});

			// special cases returns `this`
			if(b_return_stream) {
				this.once(s_event, (...a_args) => {
					fk_until(this, ...a_args);
				});
			}
			else {
				this.once(s_event, fk_until);
			}
		});
	}

	// rdfjs impl
	import(ds_source) {
		ds_source
			.on('data', w_chunk => this.write(w_chunk))
			.on('end', () => this.end())
			.on('error', e_read => this.emit('error', e_read));

		return this;
	}
}

class Duplex extends stream.Duplex {
	until(s_event, b_return_stream) {
		return new Promise((fk_until, fe_until) => {
			// convert error to rejected promise
			this.on('error', (e_stream) => {
				fe_until(e_stream);
			});

			// special cases returns `this`
			if(b_return_stream) {
				this.once(s_event, (...a_args) => {
					fk_until(this, ...a_args);
				});
			}
			else {
				this.once(s_event, fk_until);
			}
		});
	}

	bucket(s_encoding='utf8') {
		let g_readable = this._readableState;

		// object mode
		if(g_readable.objectMode) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let a_data = [];

				// pipe to writable
				this.pipe(new stream.Writable({
					write(w_event, s_write_encoding, fk_write) {
						a_data.push(w_event);
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						a_data.push(...a_chunks);
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(a_data);
					});
			});
		}
		// utf8-encoded strings
		else if('utf8' === s_encoding || 'utf-8' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let s_data = '';

				// set encoding
				this.setEncoding(s_encoding);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: false,

					write(s_chunk, s_write_encoding, fk_write) {
						s_data += s_chunk;
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						s_data += a_chunks.join('');
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(s_data);
					});
			});
		}
		// buffer
		else if('buffer' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let ab_data = Buffer.from([]);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: true,

					write(ab_chunk, s_write_encoding, fk_write) {
						ab_data = Buffer.concat([ab_data, ab_chunk], ab_data.length+ab_chunk.length);
						fk_write();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(ab_data);
					});
			});
		}
	}
}

class Transform extends stream.Transform {
	until(s_event, b_return_stream) {
		return new Promise((fk_until, fe_until) => {
			// convert error to rejected promise
			this.on('error', (e_stream) => {
				fe_until(e_stream);
			});

			// special cases returns `this`
			if(b_return_stream) {
				this.once(s_event, (...a_args) => {
					fk_until(this, ...a_args);
				});
			}
			else {
				this.once(s_event, fk_until);
			}
		});
	}

	bucket(s_encoding='utf8') {
		let g_readable = this._readableState;

		// object mode
		if(g_readable.objectMode) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let a_data = [];

				// pipe to writable
				this.pipe(new stream.Writable({
					write(w_event, s_write_encoding, fk_write) {
						a_data.push(w_event);
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						a_data.push(...a_chunks);
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(a_data);
					});
			});
		}
		// utf8-encoded strings
		else if('utf8' === s_encoding || 'utf-8' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let s_data = '';

				// set encoding
				this.setEncoding(s_encoding);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: false,

					write(s_chunk, s_write_encoding, fk_write) {
						s_data += s_chunk;
						fk_write();
					},

					writev(a_chunks, fk_writev) {
						s_data += a_chunks.join('');
						fk_writev();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(s_data);
					});
			});
		}
		// buffer
		else if('buffer' === s_encoding) {
			// async operation
			return new Promise((fk_bucket, fe_bucket) => {
				let ab_data = Buffer.from([]);

				// pipe to writable
				this.pipe(new stream.Writable({
					decodeStrings: true,

					write(ab_chunk, s_write_encoding, fk_write) {
						ab_data = Buffer.concat([ab_data, ab_chunk], ab_data.length+ab_chunk.length);
						fk_write();
					},
				}))
					// error
					.on('error', (e_stream) => {
						fe_bucket(e_stream);
					})
					// wait for it to finish
					.on('finish', () => {
						fk_bucket(ab_data);
					});
			});
		}
	}

	// rdfjs impl
	import(ds_source) {
		ds_source
			.on('data', w_chunk => this.write(w_chunk))
			.on('end', () => this.end())
			.on('error', e_read => this.emit('error', e_read));

		return this;
	}

	demolish(e_destroy) {
		// do not allow to push
		this.push = (z_chunk) => {
			// ignore eof signals from node core
			if(null === z_chunk) return;

			// anything else is bad
			throw new Error(`[ERR_STREAM_DESTROYED]: Cannot push after stream was destroyed`);
		};

		// do not allow to emit 'end'
		this.emit = function(s_event, ...a_args) {
			if('end' === s_event) return;

			Object.getPrototypeOf(this).emit.apply(this, [s_event, ...a_args]);
		};

		// an error was given, destroy the stream as well
		if(e_destroy) {
			return stream.Transform.prototype.destroy.call(this, e_destroy);
		}
	}
}

// eslint-disable-next-line no-new-func
const b_is_node = (new Function(/* syntax: js */ `try {return this===global;}catch(e){return false;}`))();

// deduce the runtime environment
const [B_BROWSER, B_BROWSERIFY] = (() => 'undefined' === typeof process
	? [true, false]
	: (process.browser
		? [true, true]
		: ('undefined' === process.versions || 'undefined' === process.versions.node
			? [true, false]
			: [false, false])))();

// node.js or browserify; patch for node < v10
if(B_BROWSERIFY || (b_is_node && (+(/^v(\d+)/.exec(process.version)[1])) < 10)) {
	// override destroy methods
	Transform.prototype.destroy = Duplex.prototype.destroy = function(e_destroy, fke_destroy) {
		this._readableState.destroyed = true;
		this._writableState.destroyed = true;

		let f_emit_close = () => {
			if(!this._writableState.emitClose) return;
			if(!this._readableState.emitClose) return;
			this.emit('close');
		};

		this._destroy(e_destroy || null, (e_destroy_re) => {
			if(!fke_destroy && e_destroy_re) {
				process.nextTick(() => {
					this.emit('error', e_destroy_re);
					f_emit_close();
				});
				this._writableState.errorEmitted = true;
			}
			else {
				process.nextTick(f_emit_close);
				if(fke_destroy) fke_destroy(e_destroy_re);
			}
		});

		return this;
	};

	// override default _destroy implementations
	Transform.prototype._destroy = Duplex.prototype._destroy = (e_destroy, fke_destroy) => fke_destroy(e_destroy);
}

class QuadsToOther extends Transform {
	constructor(gc_transform={}) {
		super({
			...gc_transform,
			writableObjectMode: true,
			readableObjectMode: true,
		});

		this._as_inputs = new Set();

		// forward prefix and comment events
		this.on('pipe', (ds_src) => {
			this._as_inputs.add(ds_src);

			ds_src
				.on('prefix', (...a_args) => {
					this.emit('prefix', ...a_args);
				})
				.on('comment', (...a_args) => {
					this.emit('comment', ...a_args);
				});
		});

		this.on('unpipe', (ds_src) => {
			this._as_inputs.delete(ds_src);
		});
	}

	_destroy() {
		for(let ds_input of this._as_inputs) {
			ds_input.destroy();
		}
	}
}

class Quads_To_JSON_Transform extends QuadsToOther {
	// serializse json
	_transform(g_quad, s_encoding, fk_transform) {
		fk_transform(null, JSON.stringify(g_quad.isolate())+'\n');
	}
}

class Quads_To_Writable extends QuadsToOther {
	_transform(g_quad, s_encoding, fk_transform) {
		fk_transform(null, {
			type: 'quad',
			value: g_quad,
		});
	}
}

Transform.QuadsToOther = QuadsToOther;

module.exports = {
	...stream,
	Readable,
	Writable,
	Duplex,
	Transform,

	QuadsToOther,

	// create a transform from quad objects into JSON strings for trivial serialization
	quads_to_json() {
		return new Quads_To_JSON_Transform();
	},

	// create a transform from quad objects into writable data events
	quads_to_writable() {
		return new Quads_To_Writable();
	},

	// create a simple, single-event readable stream
	source(w_push, s_encoding=null) {
		// encoding not explicit, string given; assume utf8
		if(!s_encoding && 'string' === typeof w_push) s_encoding = 'utf8';

		// readable
		return new Readable({
			objectMode: !s_encoding && 'string' !== typeof w_push && !Buffer.isBuffer(w_push),

			read() {
				this.push(w_push, s_encoding);
				this.push(null);
			},
		});
	},
};

}).call(this)}).call(this,require('_process'),require("buffer").Buffer)
},{"_process":179,"buffer":74,"readable-stream":213}],22:[function(require,module,exports){
(function (process){(function (){
// deduce the runtime environment
const [B_BROWSER] = (() => 'undefined' === typeof process
	? [true]
	: (process.browser
		? [true]
		: ('undefined' === process.versions || 'undefined' === process.versions.node
			? [true]
			: [false])))();

module.exports = B_BROWSER? {
	master: require('./master-browser.js'),
	worker: require('./worker-browser.js'),
}: {
	master: require('./master-node.js'),
	worker: require('./worker-node.js'),
};

}).call(this)}).call(this,require('_process'))
},{"./master-browser.js":23,"./master-node.js":45,"./worker-browser.js":24,"./worker-node.js":45,"_process":179}],23:[function(require,module,exports){

class MasterWorkerPolyfill extends Worker {
	constructor(p_worker, gc_worker={}) {
		let f_message;
		if(gc_worker.message) {
			f_message = gc_worker.message;
			delete gc_worker.message;
		}

		let w_data;
		if(gc_worker.workerData) {
			w_data = gc_worker.workerData;
			delete gc_worker.workerData;
		}

		// remove extraneous node options
		if(gc_worker.__dirname) delete gc_worker.__dirname;
		if(gc_worker.resourceLimits) delete gc_worker.resourceLimits;

		super(p_worker, gc_worker);

		this.postMessage({
			type: 'init',
			value: {
				data: w_data,
			},
		});

		this.onmessage = f_message;
	}
}

module.exports = {
	Worker: MasterWorkerPolyfill,
};

},{}],24:[function(require,module,exports){

module.exports = (fk_init) => {
	onmessage = (e_msg) => {
		let g_msg = e_msg.data;

		if('init' === g_msg.type) {
			let g_value = g_msg.value;

			fk_init({
				workerData: g_value.data,
				parentPort: {
					postMessage,
				},
			});
		}
	};
};

},{}],25:[function(require,module,exports){



// queueMicrotask shim
{
	// not defined or not a function
	if('function' !== typeof queueMicrotask) {
		// create resolved promise
		let dp_resolve = Promise.resolve();

		// try to redefine
		try {
			// eslint-disable-next-line no-global-assign
			queueMicrotask = fk => dp_resolve.then(fk)
				.catch(e_callback => setTimeout(() => {
					throw e_callback;
				}, 0));
		}
		// oh well, at least we tried
		catch(e_define) {}
	}
}


/* eslint-disable no-prototype-builtins */



const crypto = require('crypto');

const stream = require('@graphy/core.iso.stream');
const factory = require('@graphy/core.data.factory');
const factory_from = factory.from;

const $_KEYS = Symbol('key-count');
const $_QUADS = Symbol('quad-count');
const $_KIDS = Symbol('has-descendents');
const $_THIN = Symbol('has-thin-keys');

const from_term = factory.from.term;
const from_quad = factory.from.quad;
const KT_DEFAULT_GRAPH = factory.defaultGraph();
const F_SORT_LINE = (g_a, g_b) => g_a.line < g_b.line? -1: 1;

class Matcher {
	constructor(k_set) {
		this._k_set = k_set;
	}


	* match(z_subject=null, z_predicate=null, z_object=null, z_graph=KT_DEFAULT_GRAPH) {
		let h_quad_tree = this._k_set._h_quad_tree;


		// declare list
		let a_graphs = [];
		// object
		if('object' === typeof z_graph) {
			// null
			if(null === z_graph) {
				// each key in tree
				for(let svt_graph in h_quad_tree) {
					// create Term object from verbose-term string
					let kt_graph = factory.c1(svt_graph);
					// produce canonical form of term
					let snt_graph = kt_graph.verbose();

					// add each entry to list
					a_graphs.push([snt_graph, kt_graph]);
				}
			}
			// regex
			else if(z_graph instanceof RegExp || '[object RegExp]' === Object.prototype.toString.call(z_graph)) {
				// cast to regex
				let r_graph = z_graph;
				// each key in tree
				for(let svt_graph in h_quad_tree) {
					// create Term object from verbose-term string
					let kt_graph = factory.c1(svt_graph);
					// produce canonical form of term
					let snt_graph = kt_graph.verbose();

					// regex matches key; add it to the list
					if(r_graph.test(snt_graph)) {
						a_graphs.push([snt_graph, kt_graph]);
					}
				}
			}
			// Term
			else if('string' === typeof z_graph.value) {
				// convert to graphy term
				let kt_graph = factory_from.rdfjs_term(z_graph);
				// convert to verbose-term string
				let svt_graph = kt_graph.concise();
				// term is indexed in tree; add subtree to list
				if(svt_graph in h_quad_tree) {
					a_graphs.push([kt_graph.verbose(), kt_graph]);
				}
			}
			// null or default graph; add subtree to list
			else if('defaultGraph' === z_graph.type) {
				a_graphs.push(['*', factory_from.rdfjs_term(z_graph)]);
			}
			// invalid
			else {
				throw new TypeError(`invalid object for graph argument`);
			}
		}
		// other
		else {
			throw new TypeError(`invalid type for graph argument`);
		}

		// each graph
		for(let [svt_graph, kt_graph] of a_graphs) {
			// fetch tree
			let h_subjects = h_quad_tree[svt_graph];


			// declare list
			let a_subjects = [];
			// object
			if('object' === typeof z_subject) {
				// null
				if(null === z_subject) {
					// each key in tree
					for(let svt_subject in h_subjects) {
						// create Term object from verbose-term string
						let kt_subject = factory.c1(svt_subject);
						// produce canonical form of term
						let snt_subject = kt_subject.verbose();

						// add each entry to list
						a_subjects.push([snt_subject, kt_subject]);
					}
				}
				// regex
				else if(z_subject instanceof RegExp || '[object RegExp]' === Object.prototype.toString.call(z_subject)) {
					// cast to regex
					let r_subject = z_subject;
					// each key in tree
					for(let svt_subject in h_subjects) {
						// create Term object from verbose-term string
						let kt_subject = factory.c1(svt_subject);
						// produce canonical form of term
						let snt_subject = kt_subject.verbose();

						// regex matches key; add it to the list
						if(r_subject.test(snt_subject)) {
							a_subjects.push([snt_subject, kt_subject]);
						}
					}
				}
				// Term
				else if('string' === typeof z_subject.value) {
					// convert to graphy term
					let kt_subject = factory_from.rdfjs_term(z_subject);
					// convert to verbose-term string
					let svt_subject = kt_subject.concise();
					// term is indexed in tree; add subtree to list
					if(svt_subject in h_subjects) {
						a_subjects.push([kt_subject.verbose(), kt_subject]);
					}
				}
				// invalid
				else {
					throw new TypeError(`invalid object for subject argument`);
				}
			}
			// other
			else {
				throw new TypeError(`invalid type for subject argument`);
			}

			// each subject
			for(let [svt_subject, kt_subject] of a_subjects) {
				// fetch tree
				let h_predicates = h_subjects[svt_subject];


				// declare list
				let a_predicates = [];
				// object
				if('object' === typeof z_predicate) {
					// null
					if(null === z_predicate) {
						// each key in tree
						for(let svt_predicate in h_predicates) {
							// create Term object from verbose-term string
							let kt_predicate = factory.c1(svt_predicate);
							// produce canonical form of term
							let snt_predicate = kt_predicate.verbose();

							// add each entry to list
							a_predicates.push([snt_predicate, kt_predicate]);
						}
					}
					// regex
					else if(z_predicate instanceof RegExp || '[object RegExp]' === Object.prototype.toString.call(z_predicate)) {
						// cast to regex
						let r_predicate = z_predicate;
						// each key in tree
						for(let svt_predicate in h_predicates) {
							// create Term object from verbose-term string
							let kt_predicate = factory.c1(svt_predicate);
							// produce canonical form of term
							let snt_predicate = kt_predicate.verbose();

							// regex matches key; add it to the list
							if(r_predicate.test(snt_predicate)) {
								a_predicates.push([snt_predicate, kt_predicate]);
							}
						}
					}
					// Term
					else if('string' === typeof z_predicate.value) {
						// convert to graphy term
						let kt_predicate = factory_from.rdfjs_term(z_predicate);
						// convert to verbose-term string
						let svt_predicate = kt_predicate.concise();
						// term is indexed in tree; add subtree to list
						if(svt_predicate in h_predicates) {
							a_predicates.push([kt_predicate.verbose(), kt_predicate]);
						}
					}
					// invalid
					else {
						throw new TypeError(`invalid object for predicate argument`);
					}
				}
				// other
				else {
					throw new TypeError(`invalid type for predicate argument`);
				}

				// each object
				for(let [svt_predicate, kt_predicate] of a_predicates) {
					// fetch set
					let as_objects = h_predicates[svt_predicate];

					// object
					if('object' === typeof z_object) {
						// null
						if(null === z_object) {
							// each value in set
							for(let svt_object of as_objects) {
								// create object term
								let kt_object = factory.c1(svt_object);

								// yield quad
								yield factory.quad(kt_subject, kt_predicate, kt_object, kt_graph);
							}
						}
						// regex
						else if(z_object instanceof RegExp || '[object RegExp]' === Object.prototype.toString.call(z_object)) {
							// cast to regex
							let r_object = z_object;

							// each value in set
							for(let svt_object of as_objects) {
								// create object term
								let kt_object = factory.c1(svt_object);

								// regex matches value; yield quad
								if(z_object.test(kt_object.verbose())) {
									yield factory.quad(kt_subject, kt_predicate, kt_object, kt_graph);
								}
							}
						}
						// Term
						else if('string' === typeof z_object.value) {
							// convert to graphy term
							let kt_object = factory_from.rdfjs_term(z_object);

							// term is in set; yield quad
							if(as_objects.has(kt_object.concise())) {
								yield factory.quad(kt_subject, kt_predicate, kt_object, kt_graph);
							}
						}
						// invalid
						else {
							throw new TypeError(`invalid object for object argument`);
						}
					}
					// other
					else {
						throw new TypeError(`invalid type for object argument`);
					}
				}
			}
		}
	}

	match_stream(z_subject, z_predicate, z_object, z_graph=KT_DEFAULT_GRAPH) {
		// create readable output
		return new stream.Readable({
			// from iterator (which is a generator)
			iterator: this.match(z_subject, z_predicate, z_object, z_graph),

			// outputs quad objets
			objectMode: true,
		});
	}
}


class Issuer {
	constructor(s_prefix='_:c14n') {
		Object.assign(this, {
			_s_prefix: s_prefix,
			_c_counter: 0,
			_h_existing: {},
		});
	}

	issue(s_label) {
		if(s_label in this._h_existing) return this._h_existing[s_label];

		return (this._h_existing[s_label] = this._s_prefix+(this._c_counter++));
	}

	has(s_label) {
		return s_label in this._h_existing;
	}

	clone() {
		return Object.assign(new Issuer(this._s_prefix), {
			counter: this._c_counter,
			existing: Object.assign({}, this._h_existing),
		});
	}
}

const F_SORT_CANONICALIZER_HASH = (g_a, g_b) => g_a.hash < g_b.hash? -1: (g_a.hash > g_b.hash? 1: 0);

const permutations = function *(a_list) {
	let b_done = false;
	let h_left = {};

	if(a_list.lenth <= 1) {
		yield a_list;
		return;
	}

	a_list.sort();
	for(let s_item of a_list) {
		h_left[s_item] = true;
	}

	do {
		// copy list to avoid race condition
		yield a_list.slice();

		let s_k = null;
		let i_pos = 0;
		let nl_list = a_list.length;
		for(let i_item=0; i_item<nl_list; i_item++) {
			let s_item = a_list[i_item];
			let b_left = h_left[s_item];
			if((null === s_k || s_item > s_k)
				&& ((b_left && i_item > 0 && s_item > a_list[i_item-1])
					|| (!b_left && i_item < (nl_list-1) && s_item > a_list[i_item+1]))
			) {
				s_k = s_item;
				i_pos = i_item;
			}
		}

		if(null === s_k) {
			b_done = true;
		}
		else {
			let i_swap = h_left[s_k]? i_pos-1: i_pos+1;
			a_list[i_pos] = a_list[i_swap];  // eslint-disable-line require-atomic-updates
			a_list[i_swap] = s_k;  // eslint-disable-line require-atomic-updates

			// reverse direction of all elements larger thn k
			for(let s_item of a_list) {
				if(s_item > s_k) {
					h_left[s_item] = !h_left[s_item];
				}
			}
		}
	} while(!b_done);

	yield a_list;
};



class Canonicalizer_ct {
	constructor(k_tree) {
		this._k_tree = k_tree;
		this._h_blanks = {};
		this._k_issuer = new Issuer('_:r');
		this._a_quads = [...k_tree.ct_quads()];
	}

	normalize() {
		let {
			_h_blanks: h_blanks,
			_k_issuer: k_issuer,
			_a_quads: a_quads,
		} = this;

		let h_hashes = {};
		let h_non_normal = {};

		// each quad
		for(let a_quad of a_quads) {
			let [sc1_graph, sc1_subject, , sc1_object] = a_quad;

			if('_' === sc1_graph[0]) {
				if(sc1_graph in h_blanks) {
					h_blanks[sc1_graph].quads.push(a_quad);
				}
				else {
					h_blanks[sc1_graph] = {quads:[a_quad]};
					h_non_normal[sc1_graph] = true;
				}
			}				if('_' === sc1_subject[0]) {
				if(sc1_subject in h_blanks) {
					h_blanks[sc1_subject].quads.push(a_quad);
				}
				else {
					h_blanks[sc1_subject] = {quads:[a_quad]};
					h_non_normal[sc1_subject] = true;
				}
			}				if('_' === sc1_object[0]) {
				if(sc1_object in h_blanks) {
					h_blanks[sc1_object].quads.push(a_quad);
				}
				else {
					h_blanks[sc1_object] = {quads:[a_quad]};
					h_non_normal[sc1_object] = true;
				}
			}
		}

		let b_simple = false;

		do {
			b_simple = false;

			h_hashes = {};

			for(let sc1_blank in h_non_normal) {
				let p_blank = this.hash_first_degree_quads(sc1_blank);

				if(p_blank in h_hashes) {
					h_hashes[p_blank].push(sc1_blank);
				}
				else {
					h_hashes[p_blank] = [sc1_blank];
				}
			}

			for(let p_blank of Object.keys(h_hashes).sort()) {
				let a_blanks = h_hashes[p_blank];
				if(a_blanks.length > 1) continue;

				let sc1_blank_0 = a_blanks[0];
				k_issuer.issue(sc1_blank_0);

				delete h_non_normal[sc1_blank_0];

				delete h_hashes[p_blank];

				b_simple = true;
			}
		} while(b_simple);

		for(let p_blank of Object.keys(h_hashes).sort()) {
			let a_paths = [];
			for(let sc1_blank of h_hashes[p_blank]) {
				if(k_issuer.has(sc1_blank)) continue;

				let k_issuer_tmp = new Issuer('_:g');
				k_issuer_tmp.issue(sc1_blank);

				a_paths.push(
					this.hash_n_degree_quads(sc1_blank, k_issuer_tmp));
			}

			for(let g_hash_result of a_paths.sort(F_SORT_CANONICALIZER_HASH)) {
				for(let sc1_existing in g_hash_result.issuer._h_existing) {
					k_issuer.issue(sc1_existing);
				}
			}
		}

		let a_normalized = [];
		let s_issuer_prefix = k_issuer._s_prefix;
		for(let a_quad of a_quads) {
			let [sc1_graph, sc1_subject, sc1_predicate, sc1_object] = a_quad;


			if('_' === sc1_graph[0] && !sc1_graph.startsWith(s_issuer_prefix)) {
				sc1_graph = k_issuer.issue(sc1_graph);
			}				if('_' === sc1_subject[0] && !sc1_subject.startsWith(s_issuer_prefix)) {
				sc1_subject = k_issuer.issue(sc1_subject);
			}				if('_' === sc1_object[0] && !sc1_object.startsWith(s_issuer_prefix)) {
				sc1_object = k_issuer.issue(sc1_object);
			}

			let [
				kt_subject,
				kt_predicate,
				kt_object,
				kt_graph,
			] = [
				factory.c1(sc1_subject),
				factory.c1(sc1_predicate),
				factory.c1(sc1_object),
				factory.c1(sc1_graph),
			];

			a_normalized.push({
				line: [
					sc1_graph,
					sc1_subject,
					sc1_predicate,
					sc1_object,
				].join('\0\t')+'\0\n',
				quad: factory.quad(kt_subject, kt_predicate, kt_object, kt_graph),
			});
		}

		// sort quads
		a_normalized.sort(F_SORT_LINE);

		// create dataset reflecting quad order
		let k_tree_normalized = new FastDataset({
			prefixes: Object.assign({}, this._k_tree._h_prefixes),
		});
		k_tree_normalized.addQuads(a_normalized.map(g => g.quad));

		// end writable side of stream
		k_tree_normalized.end();

		// return strut
		return {
			string: a_normalized.map(g => g.line).join(''),
			tree: k_tree_normalized,
		};
	}

	hash_first_degree_quads(sc1_blank) {
		let {
			_h_blanks: h_blanks,
			_a_quads: a_quads,
		} = this;

		let g_blank = h_blanks[sc1_blank];
		if('hash' in g_blank) return g_blank.hash;

		let a_nquads = [];
		for(let a_quad of a_quads) {
			let [sc1_graph, sc1_subject, sc1_predicate, sc1_object] = a_quad;


			a_nquads.push([
				sc1_blank === sc1_graph
					? '_:i'
					: ('_' === sc1_graph[0]
						? '_:o'
						: sc1_graph),
				sc1_blank === sc1_subject
					? '_:i'
					: ('_' === sc1_subject[0]
						? '_:o'
						: sc1_subject),
				sc1_predicate,
				sc1_blank === sc1_object
					? '_:i'
					: ('_' === sc1_object[0]
						? '_:o'
						: sc1_object),
			].join('\0\t')+'\0\n');
		}

		let p_hash = crypto.createHash('sha256')
			.update(a_nquads.sort().join('\n'))
			.digest('hex');

		g_blank.hash = p_hash;

		return p_hash;
	}

	hash_n_degree_quads(sc1_blank, k_issuer) {
		let {
			_k_issuer: k_issuer_root,
		} = this;

		let h_related = this.hash_to_related(sc1_blank, k_issuer);

		let d_hash = crypto.createHash('sha256');
		for(let p_related of Object.keys(h_related).sort()) {
			d_hash.update(p_related);
			let s_path_chosen = '';
			let k_issuer_chosen;

			for(let a_perm of permutations(h_related[p_related])) {
				let k_issuer_copy = k_issuer.clone();
				let s_path = '';
				let a_recurse = [];

				let b_next_perm = false;
				for(let p_other of a_perm) {
					if(k_issuer_root.has(p_other)) {
						s_path += k_issuer_root.issue(p_other);
					}
					else {
						if(!k_issuer_copy.has(p_other)) {
							a_recurse.push(p_other);
						}

						s_path += k_issuer_copy.issue(p_other);
					}

					if(s_path_chosen.length
						&& s_path.length >= s_path_chosen.length
						&& s_path > s_path_chosen
					) {
						b_next_perm = true;
						break;
					}
				}

				if(b_next_perm) continue;

				for(let p_other of a_recurse) {
					let g_hash_result = this.hash_n_degree_quads(p_other, k_issuer_copy);

					s_path += k_issuer_copy.issue(p_other);

					s_path += '_:#'+g_hash_result.hash;

					k_issuer_copy = g_hash_result.issuer;

					if(s_path_chosen.length
						&& s_path.length >= s_path_chosen.length
						&& s_path > s_path_chosen
					) {
						b_next_perm = true;
						break;
					}
				}

				if(b_next_perm) continue;

				if(!s_path_chosen.length || s_path < s_path_chosen) {
					s_path_chosen = s_path;
					k_issuer_chosen = k_issuer_copy;
				}
			}

			d_hash.update(s_path_chosen);

			k_issuer = k_issuer_chosen;
		}

		return {
			hash: d_hash.digest('hex'),
			issuer: k_issuer,
		};
	}

	hash_to_related(sc1_blank, k_issuer) {
		let {
			_h_blanks: h_blanks,
		} = this;

		let h_related = {};
		for(let a_quad of h_blanks[sc1_blank].quads) {
			let [sc1_graph, sc1_subject, , sc1_object] = a_quad;
			if('_' === sc1_graph[0] && sc1_graph !== sc1_blank) {
				let p_related = this.hash_related_blank_node(sc1_graph, a_quad, k_issuer, 0);
				if(p_related in h_related) {
					h_related[p_related].push(sc1_graph);
				}
				else {
					h_related[p_related] = [sc1_graph];
				}
			}
			if('_' === sc1_subject[0] && sc1_subject !== sc1_blank) {
				let p_related = this.hash_related_blank_node(sc1_subject, a_quad, k_issuer, 1);
				if(p_related in h_related) {
					h_related[p_related].push(sc1_subject);
				}
				else {
					h_related[p_related] = [sc1_subject];
				}
			}
			if('_' === sc1_object[0] && sc1_object !== sc1_blank) {
				let p_related = this.hash_related_blank_node(sc1_object, a_quad, k_issuer, 3);
				if(p_related in h_related) {
					h_related[p_related].push(sc1_object);
				}
				else {
					h_related[p_related] = [sc1_object];
				}
			}
		}

		return h_related;
	}

	hash_related_blank_node(sc1_blank, a_quad, k_issuer, i_role) {
		let k_issuer_root = this._k_issuer;
		let sc1_use;
		if(k_issuer_root.has(sc1_blank)) {
			sc1_use = k_issuer_root.issue(sc1_blank);
		}
		else if(k_issuer.has(sc1_blank)) {
			sc1_use = k_issuer.issue(sc1_blank);
		}
		else {
			sc1_use = this.hash_first_degree_quads(sc1_blank);
		}

		let d_hash = crypto.createHash('sha256');
		d_hash.update(i_role+'');
		if(i_role) {
			d_hash.update(`<${a_quad[2]}>`);
		}

		d_hash.update(sc1_use);

		return d_hash.digest('hex');
	}
}

// const thicken_quads = (h_tree) => {
// 	// create thickened object
// 	let h_thickened = {};

// 	// check each key
// 	for(let sv1_key in h_tree) {
// 		h_thickened[sv1_key] = thicken_triples(h_tree[sv1_key]);
// 	}

// 	// copy key count and quad count
// 	h_thickened[$_KEYS] = h_tree[$_KEYS];
// 	h_thickened[$_QUADS] = h_tree[$_QUADS];

// 	return h_thickened;
// };

// const thicken_triples = (h_tree) => {
// 	// create thickened object
// 	let h_thickened = {};

// 	// check each key
// 	for(let sv1_key in h_tree) {
// 		h_thickened[sv1_key] = thicken_pairs(h_tree[sv1_key]);
// 	}

// 	// copy key count and quad count
// 	h_thickened[$_KEYS] = h_tree[$_KEYS];
// 	h_thickened[$_QUADS] = h_tree[$_QUADS];

// 	return h_thickened;
// };

// const thicken_pairs = (h_tree) => {
// 	// create thickened object
// 	let h_thickened = {};

// 	// check each key
// 	for(let sv1_key in h_tree) {
// 		h_thickened[sv1_key] = new Set(h_tree[sv1_key]);
// 	}

// 	// copy key count and quad count
// 	h_thickened[$_KEYS] = h_tree[$_KEYS];
// 	h_thickened[$_QUADS] = h_tree[$_QUADS];

// 	return h_thickened;
// };
//

const thin_copy = (h_src) => {
	// create new hash
	let h_dst = Object.create(h_src);

	// src has weak descendents
	h_src[$_KIDS] = 1;

	// dst has weak keys
	h_dst[$_THIN] = 1;

	return h_dst;
};

// const thin_copy_paste = (h_src, h_dst_parent, s_dst_key) => {
// 	// create parent
// 	if(null === h_dst_parent) {
// 		h_dst_parent = {
// 			[$_KEYS]: 0,
// 			[$_QUADS]: 0,
// 		};
// 	}

// 	// append to new quad tree
// 	h_dst_parent[s_dst_key] = h_dst;

// 	// adds single key to parent tree
// 	h_dst_parent[$_KEYS] += 1;

// 	// all quad count from pairs hash
// 	h_dst_parent[$_QUADS] += h_src[$_QUADS];

// 	// return dst
// 	return h_dst;
// };


const thicken = (h_tree) => {
	// create thickened object
	let h_thickened = {};

	// check each key
	for(let sv1_key in h_tree) {
		h_thickened[sv1_key] = h_tree[sv1_key];
	}

	// copy key count and quad count
	h_thickened[$_KEYS] = h_tree[$_KEYS];
	h_thickened[$_QUADS] = h_tree[$_QUADS];

	return h_thickened;
};

class FastDataset extends stream.Duplex {
	static from(h_quad_tree, g_config={}) {
		// JSON import
		if(h_quad_tree['{KEYS}']) {
			h_quad_tree[$_KEYS] = h_quad_tree['{KEYS}'];
			h_quad_tree[$_QUADS] = h_quad_tree['{QUADS}'];
			delete h_quad_tree['{KEYS}'];
			delete h_quad_tree['{QUADS}'];
		}

		//
		return new FastDataset(g_config, h_quad_tree);
	}

	constructor(g_config={}, h_quad_tree=null) {
		super({
			// expect quads as input and write objects as output
			objectMode: true,
		});

		// config-struct event binding
		this.bind(g_config);

		let h_prefixes = g_config.prefixes || {};

		// source piped to this
		this.on('pipe', (ds_src) => {
			this._ds_src = ds_src;

			ds_src.on('prefix', (s_prefix, p_iri) => {
				// save/update prefix mapping
				h_prefixes[s_prefix] = p_iri;

				// graphy output and initial prefix mappings already flushed
				if(this._b_prefixes_flushed) {
					// flush single prefix
					this.push({
						type: 'prefixes',
						value: {
							[s_prefix]: p_iri,
						},
					});
				}
			});

			// once input ends
			ds_src.once('eof', () => {
				this._b_eofd = true;
				// debugger;
				// this.emit('ready', this);
			});
		});

		this.once('finish', () => {
			this.emit('ready', this);
			this._b_finishedd = true;

			if(this._n_push_waiting) {
				this._read(this._n_push_waiting);
			}
		});

		Object.assign(this, {
			_h_quad_tree: h_quad_tree || {[$_KEYS]:0, [$_QUADS]:0},
			_s_digest: null,
			_h_root_blanks: {},
			_h_leaf_blanks: {},
			_h_prefixes: h_prefixes,
			_b_prefixes_flushed: false,
			_b_debug: g_config.debug || false,
			_dg_quads: null,
			_dg_graphs: null,
			_di_graph: null,
			_dg_subjects: null,
			_b_transform_canonicalize: g_config.canonicalize || false,
			_k_transform_tree: this,
			_n_push_waiting: 0,
		});

		// data given
		if(h_quad_tree) {
			// auto-end writable side of duplex
			queueMicrotask(() => {
				this.end();
			});
		}
	}

	offspring(h_quad_tree=null) {
		return new FastDataset({
			prefixes: Object.assign({}, this._h_prefixes),
		}, h_quad_tree);
	}


	// on end input
	end(...a_args) {
		// overwrite mutators
		this.add = this.addAll = this.addQuads = this.add_quads = this.add_tree = this.clear = this.delete = this.deny;

		// end writable stream
		return super.end(...a_args);
	}

	// deny mutator call
	deny() {  // eslint-disable-line class-methods-use-this
		throw new Error('Set mutator call not allowed after writable side of duplex ended');
	}

	// on pipe
	pipe(ds_out) {
		// // graphy dataset tree
		// if(ds_out.isGraphyFastDataset) {
// 	debugger;

		// 	// change read moe
		// 	this._read = function(n_size) {
// 		this.push({

// 		});

		// 		// eos
		// 		this.push(null);
		// 	};
		// }

		// graphy writable
		if(ds_out.isGraphyWritable) {
			// change read mode
			this._read = function(n_size) {
				// push prefix mappings
				this.push({
					type: 'prefixes',
					value: this._h_prefixes,
				});

				// if more prefixes come in, push them immediately
				this._b_prefixes_flushed = true;

				// ready to start pushing
				if(this.writableFinished || this._writableState.finished) {
					return this.read_graphy_after_finished(n_size);
				}
				// not ready yet
				else {
					this._n_push_waiting = n_size;
					this._read = function(n_size_nry) {
						// ready to start pushing
						if(this.writableFinished || this._writableState.finished) {
							this._n_push_waiting = 0;
							return this.read_graphy_after_finished(n_size_nry);
						}
						// still not ready yet; append size
						else {
							this._n_push_waiting += n_size_nry;
						}
					};
				}
			};
		}
		// non-object mode
		else if(!ds_out._writableState.objectMode) {
			let ds_dst = ds_out;

			// transform to JSON strings first
			ds_out = stream.quads_to_json();

			// forward to super
			super.pipe(ds_out);

			// pipe to destination
			return ds_out.pipe(ds_dst);
		}

		// forward to super
		return super.pipe(ds_out);
	}

	// default read: quad mode
	_read(n_quads) {
		// ready to start pushing
		if(this.writableFinished || this._writableState.finished) {
			let k_tree = this;

			// transform canonicalize option
			if(this._b_transform_canonicalize) {
				k_tree = this.canonicalize();
			}

			// start new quad iterator
			this._dg_quads = k_tree.quads();

			// harden read method
			this._read = this.resume_read;

			// resume reading
			return this._read(n_quads);
		}
		// not ready yet
		else {
			this._n_push_waiting = n_quads;
		}
	}

	// resume default read: quad mode
	resume_read(n_quads) {
		let dg_quads = this._dg_quads;

		// advance iterator
		let di_next = dg_quads.next();

		// continue until iterator is done
		while(!di_next.done) {
			// back-pressure; stop pushing
			if(!this.push(di_next.value)) return;

			// advance iterator
			di_next = dg_quads.next();
		}

		// done iterating
		this.push(null);
	}

	read_graphy_after_finished(n_size) {
		let k_tree = this;

		// transform canonicalize option
		if(this._b_transform_canonicalize) {
			k_tree = this._k_transform_tree = this.canonicalize();
		}

		// initialize generator(s) & iterator
		let dg_graphs = this._dg_graphs = k_tree.c1_graphs();
		this._di_graph = dg_graphs.next();

		// harden read method
		this._read = this.resume_read_graphy;

		// resume reading
		return this._read(n_size);
	}

	resume_read_graphy(n_size) {
		let {
			_dg_graphs: dg_graphs,
			_di_graph: di_graph,
			_dg_subjects: dg_subjects,
			_k_transform_tree: k_tree,
		} = this;

		let h_quads = k_tree._h_quad_tree;

		// continue until iterator is done
		while(!di_graph.done) {
			let sv1_graph = di_graph.value;
			let h_triples = h_quads[sv1_graph];

			// advance subject iterator
			if(!dg_subjects) {
				dg_subjects = this._dg_subjects = k_tree.c1_subjects(sv1_graph);
			}

			// resume iterator
			let di_subject = dg_subjects.next();

			while(!di_subject.done) {
				let sv1_subject = di_subject.value;

				// push writable data event
				let b_pressure = this.push({
					type: 'c4r',
					value: {
						[sv1_graph]: {
							[sv1_subject]: h_triples[sv1_subject],
						},
					},
				});

				// backpressure; stop pushing
				if(b_pressure) return;

				// advance subject iterator
				di_subject = dg_subjects.next();
			}

			// advance graph iterator
			di_graph = this._di_graph = dg_graphs.next();
		}

		// done reading
		this.push(null);
	}

	_write(g_quad, s_encdoing, fk_write) {
		// add quad to tree
		this.add(g_quad);

		// done with object
		fk_write();
	}


	// bind event listeners to output stream
	bind(g_config) {
		if(g_config.ready) this.on('ready', g_config.ready);
	}

	export() {
		let h_quads_src = this._h_quad_tree;
		let h_quads_dst = {
			'{KEYS}': h_quads_src[$_KEYS],
			'{QUADS}': h_quads_src[$_QUADS],
		};

		for(let svt_graph in h_quads_src) {
			let h_triples_src = h_quads_src[svt_graph];
			let h_triples_dst = h_quads_dst[svt_graph] = {
				'{KEYS}': h_triples_src[$_KEYS],
				'{QUADS}': h_triples_src[$_QUADS],
			};
			for(let svt_subject in h_triples_src) {
				let h_pairs_src = h_triples_src[svt_subject];
				let h_pairs_dst = h_triples_dst[svt_subject] = {
					'{KEYS}': h_pairs_src[$_KEYS],
					'{QUADS}': h_pairs_src[$_QUADS],
				};
				for(let svt_predicate in h_pairs_src) {
					let as_objects_src = h_pairs_src[svt_predicate];
					h_pairs_dst[svt_predicate] = new Set([...as_objects_src]);
				}
			}
		}

		return h_quads_dst;
	}

	* [Symbol.iterator]() {
		yield* this.quads();
	}

	* quads() {
		let h_quads = this._h_quad_tree;
		for(let sv1_graph in h_quads) {
			let h_subjects = h_quads[sv1_graph];
			let g_graph = factory.c1(sv1_graph);
			for(let sv1_subject in h_subjects) {
				let h_predicates = h_subjects[sv1_subject];
				let g_subject = factory.c1(sv1_subject);
				for(let sv1_predicate in h_predicates) {
					let as_objects = h_predicates[sv1_predicate];
					let g_predicate = factory.c1(sv1_predicate);
					for(let sv1_object of as_objects) {
						yield factory.quad(
							g_subject,
							g_predicate,
							factory.c1(sv1_object),
							g_graph,
						);
					}
				}
			}
		}
	}

	* ct_quads() {
		let h_quads = this._h_quad_tree;
		for(let sc1_graph in h_quads) {
			let h_subjects = h_quads[sc1_graph];
			for(let sc1_subject in h_subjects) {
				let h_predicates = h_subjects[sc1_subject];
				for(let sc1_predicate in h_predicates) {
					let as_objects = h_predicates[sc1_predicate];
					for(let sc1_object of as_objects) {
						yield [sc1_graph, sc1_subject, sc1_predicate, sc1_object];
					}
				}
			}
		}
	}

	* c1_graphs() {
		for(let sv1_graph in this._h_quad_tree) {
			yield sv1_graph;
		}
	}

	* c1_subjects(sv1_graph) {
		let h_subjects = this._h_quad_tree[sv1_graph];
		for(let sv1_subject in h_subjects) {
			yield sv1_subject;
		}
	}

	* c1_predicates(s_graph, s_subject) {
		let h_predicates = this._h_quad_tree[s_graph][s_subject];
		for(let s_predicate in h_predicates) {
			yield s_predicate;
		}
	}

	* c1_objects(s_graph, s_subject, s_predicate) {
		yield* this._h_quad_tree[s_graph][s_subject][s_predicate];
	}

	* pairs(sv1_graph, sv1_subject) {
		let h_predicates = this._h_quad_tree[sv1_graph][sv1_subject];
		for(let sv1_predicate in h_predicates) {
			yield [sv1_predicate, h_predicates[sv1_predicate]];
		}
	}

	// match(z_subject, z_predicate, z_object, z_graph=null) {
	// 	return (new Matcher(this)).match(z_subject, z_predicate, z_object, z_graph);
// }

	match(z_subject=null, z_predicate=null, z_object=null, z_graph=null) {
		let h_quads_src = this._h_quad_tree;

		// +graph
		if(z_graph) {
			// convert graph to c1
			let sc1_graph_target = from_term(z_graph).concise();

			// no such graph; return new empty tree
			if(!(sc1_graph_target in h_quads_src)) return this.offspring();

			// ref triples hash
			let h_triples_src = h_quads_src[sc1_graph_target];

			// +grraph, +subject
			if(z_subject) {
				// convert subject to c1
				let sc1_subject_target = from_term(z_subject).concise();

				// no such subject; return new empty tree
				if(!(sc1_subject_target in h_triples_src)) return this.offspring();

				// ref pairs hash
				let h_pairs_src = h_triples_src[sc1_subject_target];

				// +graph, +subject, +predicate
				if(z_predicate) {
					// convert predicate to c1
					let sc1_predicate_target = from_term(z_predicate).concise();

					// no such predicate; return new empty tree
					if(!(sc1_predicate_target in h_pairs_src)) return this.offspring();

					// ref objects set
					let as_objects_src = h_pairs_src[sc1_predicate_target];

					// for both paths
					let n_quads_objects;
					let as_objects_dst;

					// +graph, +subject, +predicate, +object
					if(z_object) {
						// convert object to c1
						let sc1_object_target = from_term(z_object).concise();

						// no such object; return new empty tree
						if(!as_objects_src.has(sc1_object_target)) return this.offspring();

						// create set
						as_objects_dst = new Set([sc1_object_target]);

						// sole quad
						n_quads_objects = 1;
					}
					// +graph, +subject, +predicate, -object
					else {
						// copy set
						as_objects_dst = new Set(as_objects_src);

						// quad count
						n_quads_objects = as_objects_src.size;
					}

					// path merge; create new tree
					return this.offspring({
						[$_KEYS]: 1,
						[$_QUADS]: n_quads_objects,
						[sc1_graph_target]: {
							[$_KEYS]: 1,
							[$_QUADS]: n_quads_objects,
							[sc1_subject_target]: {
								[$_KEYS]: 1,
								[$_QUADS]: n_quads_objects,
								[sc1_predicate_target]: as_objects_dst,
							},
						},
					});
				}
				// +graph, +subject, -predicate, +object
				else if(z_object) {
					// convert object to c1
					let sc1_object_target = from_term(z_object).concise();

					// prepare for loading into set multiple times
					let a_object_load = [sc1_object_target];

					// how many distinct pairs are added
					let c_pairs = 0;

					// dst pairs hash
					let h_pairs_dst = {
						[$_KEYS]: 0,
						[$_QUADS]: 0,
					};

					// each pairs
					for(let sc1_predicate in h_pairs_src) {
						// object exists under pairs tree
						if(h_pairs_src[sc1_predicate].has(sc1_object_target)) {
							// create new objects set and save to dst pairs hash
							h_pairs_dst[sc1_predicate] = new Set(a_object_load);

							// increment pairs count
							c_pairs += 1;
						}
					}

					// no quads; empty tree
					if(!c_pairs) return this.offspring();

					// save keys and quads count
					h_pairs_dst[$_KEYS] = c_pairs;
					h_pairs_dst[$_QUADS] = c_pairs;

					// create new tree
					return this.offspring({
						[$_KEYS]: 1,
						[$_QUADS]: c_pairs,
						[sc1_graph_target]: {
							[$_KEYS]: 1,
							[$_QUADS]: c_pairs,
							[sc1_subject_target]: h_pairs_dst,
						},
					});
				}
				// +graph, +subject -predicate, -object
				else {
					// quad count
					let n_quads_pairs = h_pairs_src[$_QUADS];

					// create new tree
					return this.offspring({
						[$_KEYS]: 1,
						[$_QUADS]: n_quads_pairs,
						[sc1_graph_target]: {
							[$_KEYS]: 1,
							[$_QUADS]: n_quads_pairs,
							[sc1_subject_target]: thin_copy(h_pairs_src),
						},
					});
				}
			}
			// +graph, -subject, +predicate
			else if(z_predicate) {
				// convert predicate to c1
				let sc1_predicate_target = from_term(z_predicate).concise();

				// how many subject-keys and quads are added
				let c_subjects = 0;
				let c_quads = 0;

				// init dst triples hash
				let h_triples_dst = {
					[$_KEYS]: 0,
					[$_QUADS]: 0,
				};

				// +graph, -subject, +predicate, +object
				if(z_object) {
					// convert object to c1
					let sc1_object_target = from_term(z_object).concise();

					// prepare for loading into set multiple times
					let a_object_load = [sc1_object_target];

					// each triples
					for(let sc1_subject in h_triples_src) {
						// ref src pairs hash
						let h_pairs_src = h_triples_src[sc1_subject];

						// no such predicate; skip
						if(!(sc1_predicate_target in h_pairs_src)) continue;

						// ref src objects set
						let as_objects_src = h_pairs_src[sc1_predicate_target];

						// no such object; skip
						if(!as_objects_src.has(sc1_object_target)) continue;

						// create pairs subtree
						h_triples_dst[sc1_subject] = {
							[$_KEYS]: 1,
							[$_QUADS]: 1,
							[sc1_predicate_target]: new Set(a_object_load),
						};

						// increment quads count
						c_quads += 1;
					}

					// key count matches added quads count
					c_subjects = c_quads;
				}
				// +graph, -subject, +predicate, -object
				else {
					// each triples
					for(let sc1_subject in h_triples_src) {
						// ref src pairs hash
						let h_pairs_src = h_triples_src[sc1_subject];

						// no such predicate; skip
						if(!(sc1_predicate_target in h_pairs_src)) continue;

						// create dst objects set
						let as_objects_dst = new Set(h_pairs_src[sc1_predicate_target]);

						// create pairs subtree
						h_triples_dst[sc1_subject] = {
							[$_KEYS]: 1,
							[$_QUADS]: as_objects_dst.size,
							[sc1_predicate_target]: as_objects_dst,
						};

						// increment quads & subject-keys count
						c_quads += as_objects_dst.size;
						c_subjects += 1;
					}
				}

				// no quads; empty tree
				if(!c_subjects) return this.offspring();

				// save quads and subject-keys counts to dst triples hash
				h_triples_dst[$_KEYS] = c_subjects;
				h_triples_dst[$_QUADS] = c_quads;

				// create new tree
				return this.offspring({
					[$_KEYS]: 1,
					[$_QUADS]: c_quads,
					[sc1_graph_target]: h_triples_dst,
				});
			}
			// +graph, -subject, -predicate, +object
			else if(z_object) {
				// convert object to c1
				let sc1_object_target = from_term(z_object).concise();

				// prepare for loading into set multiple times
				let a_object_load = [sc1_object_target];

				// how many subject keys and quads are added
				let c_subjects = 0;
				let c_quads = 0;

				// init dst triples hash
				let h_triples_dst = {
					[$_KEYS]: 0,
					[$_QUADS]: 0,
				};

				// each triples
				for(let sc1_subject in h_triples_src) {
					// ref src pairs hash
					let h_pairs_src = h_triples_src[sc1_subject];

					// count distinct pairs
					let c_pairs = 0;

					// dst pairs hash
					let h_pairs_dst = {
						[$_KEYS]: 0,
						[$_QUADS]: 0,
					};

					// each pairs
					for(let sc1_predicate in h_pairs_src) {
						// ref src objects set
						let as_objects_src = h_pairs_src[sc1_predicate];

						// set has target object
						if(as_objects_src.has(sc1_object_target)) {
							// create object set
							h_pairs_dst[sc1_predicate] = new Set(a_object_load);

							// increment pair count
							c_pairs += 1;
						}
					}

					// no pairs; skip
					if(!c_pairs) continue;

					// save quads and predicate-keys count
					h_pairs_dst[$_KEYS] = c_pairs;
					h_pairs_dst[$_QUADS] = c_pairs;

					// save pairs hash tree
					h_triples_dst[sc1_subject] = h_pairs_dst;

					// increment super quads count
					c_quads += c_pairs;

					// increment subject-keys count
					c_subjects += 1;
				}

				// no quads; empty tree
				if(!c_subjects) return this.offspring();

				// save quads and subject-keys count
				h_triples_dst[$_KEYS] = c_subjects;
				h_triples_dst[$_QUADS] = c_quads;

				// create dataset tree
				return this.offspring({
					[$_KEYS]: 1,
					[$_QUADS]: c_quads,
					[sc1_graph_target]: h_triples_dst,
				});
			}
			// +graph, -subject, -predicate, -object
			else {
				// create dataset tree
				return this.offspring({
					[$_KEYS]: 1,
					[$_QUADS]: h_triples_src[$_QUADS],
					[sc1_graph_target]: thin_copy(h_triples_src),
				});
			}
		}
		// -graph
		else {
			// init dst quads hash
			let h_quads_dst = {
				[$_KEYS]: 0,
				[$_QUADS]: 0,
			};

			// -graph, +subject
			if(z_subject) {
				// convert subject to c1
				let sc1_subject_target = from_term(z_subject).concise();

				// -graph, +subject, +predicate
				if(z_predicate) {
					// convert predicate to c1
					let sc1_predicate_target = from_term(z_predicate).concise();

					// graph-keys and quads counts
					let c_graphs = 0;
					let c_quads = 0;

					// -graph, +subject, +predicate, +object
					if(z_object) {
						// convert object to c1
						let sc1_object_target = from_term(z_object).concise();

						// prepare for loading into set multiple times
						let a_object_load = [sc1_object_target];

						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// no such subject; skip
							if(!(sc1_subject_target in h_triples_src)) continue;

							// ref src pairs hash
							let h_pairs_src = h_triples_src[sc1_subject_target];

							// no such predicate; skip
							if(!(sc1_predicate_target in h_pairs_src)) continue;

							// ref src objects set
							let as_objects_src = h_pairs_src[sc1_predicate_target];

							// no such object; skip
							if(!as_objects_src.has(sc1_object_target)) continue;

							// create dst object set
							let as_objects_dst = new Set(a_object_load);

							// create dst triples tree
							h_quads_dst[sc1_graph] = {
								[$_KEYS]: 1,
								[$_QUADS]: 1,
								[sc1_subject_target]: {
									[$_KEYS]: 1,
									[$_QUADS]: 1,
									[sc1_predicate_target]: as_objects_dst,
								},
							};

							// increment graph-keys & quads count
							c_quads += 1;
						}

						// graph-keys count matches quads count
						c_graphs = c_quads;
					}
					// -graph, +subject, +predicate, -object
					else {
						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// no such subject; skip
							if(!(sc1_subject_target in h_triples_src)) continue;

							// ref src pairs hash
							let h_pairs_src = h_triples_src[sc1_subject_target];

							// no such predicate; skip
							if(!(sc1_predicate_target in h_pairs_src)) continue;

							// create dst objects set
							let as_objects_dst = new Set(h_pairs_src[sc1_predicate_target]);

							// how many objects are in set
							let n_objects = as_objects_dst.size;

							// create dst triples tree
							h_quads_dst[sc1_graph] = {
								[$_KEYS]: 1,
								[$_QUADS]: n_objects,
								[sc1_subject_target]: {
									[$_KEYS]: 1,
									[$_QUADS]: n_objects,
									[sc1_predicate_target]: as_objects_dst,
								},
							};

							// increment graph-keys & quads count
							c_graphs += 1;
							c_quads += n_objects;
						}
					}

					// no quads; empty tree
					if(!c_graphs) return this.offspring();

					// save quads and graph-keys counts
					h_quads_dst[$_KEYS] = c_graphs;
					h_quads_dst[$_QUADS] = c_quads;

					// create dataset tree
					return this.offspring(h_quads_dst);
				}
				// -graph, +subject, -predicate
				else {
					// count graph-keys and quads
					let c_graphs = 0;
					let c_quads = 0;

					// -graph, +subject, -predicate, +object
					if(z_object) {
						// convert object to c1
						let sc1_object_target = from_term(z_object).concise();

						// prepare for loading into set multiple times
						let a_object_load = [sc1_object_target];

						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// no such subject; skip
							if(!(sc1_subject_target in h_triples_src)) continue;

							// ref src pairs hash
							let h_pairs_src = h_triples_src[sc1_subject_target];

							// count pairs
							let c_pairs = 0;

							// init dst pairs hash
							let h_pairs_dst = {
								[$_KEYS]: 0,
								[$_QUADS]: 0,
							};

							// each predicate
							for(let sc1_predicate in h_pairs_src) {
								// ref src objets set
								let as_objects_src = h_pairs_src[sc1_predicate];

								// no such object; skip
								if(!as_objects_src.has(sc1_object_target)) continue;

								// create dst objects set
								h_pairs_dst[sc1_predicate] = new Set(a_object_load);

								// increment pairs count
								c_pairs += 1;
							}

							// no pairs hash to add; skip graph
							if(!c_pairs) continue;

							// save predicate-keys and quads counts
							h_pairs_dst[$_KEYS] = c_pairs;
							h_pairs_dst[$_QUADS] = c_pairs;

							// save pairs hash tree
							h_quads_dst[sc1_graph] = {
								[$_KEYS]: 1,
								[$_QUADS]: c_pairs,
								[sc1_subject_target]: h_pairs_dst,
							};

							// increment graph-keys and quads count
							c_graphs += 1;
							c_quads += c_pairs;
						}
					}
					// -graph, +subject, -predicate, -object
					else {
						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// no such subject; skip
							if(!(sc1_subject_target in h_triples_src)) continue;

							// ref src pairs hash
							let h_pairs_src = h_triples_src[sc1_subject_target];

							// quads under pairs tree
							let n_quads = h_pairs_src[$_QUADS];

							// save thin copy of pairs hash to dst quads hash
							h_quads_dst[sc1_graph] = {
								[$_KEYS]: 1,
								[$_QUADS]: n_quads,
								[sc1_subject_target]: thin_copy(h_pairs_src),
							};

							// increment graph-keys and quads count
							c_graphs += 1;
							c_quads += n_quads;
						}
					}

					// no quads; empty tree
					if(!c_graphs) return this.offspring();

					// save graph-keys and quads count
					h_quads_dst[$_KEYS] = c_graphs;
					h_quads_dst[$_QUADS] = c_quads;

					// save graph-keys and quads counts
					return this.offspring(h_quads_dst);
				}
			}
			// -graph, -subject
			else {
				// -graph, -subject, +predicate
				if(z_predicate) {
					// convert predicate to c1
					let sc1_predicate_target = from_term(z_predicate).concise();

					// graph-keys and quads count
					let c_graphs = 0;
					let c_quads = 0;

					// -graph, -subject, +predicate, +object
					if(z_object) {
						// convert predicate to c1
						let sc1_object_target = from_term(z_object).concise();

						// prepare for loading into set multiple times
						let a_object_load = [sc1_object_target];

						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// subjet-keys count
							let c_subjects = 0;

							// init dst triples hash
							let h_triples_dst = {
								[$_KEYS]: 0,
								[$_QUADS]: 0,
							};

							// each subject
							for(let sc1_subject in h_triples_src) {
								// ref src pairs hash
								let h_pairs_src = h_triples_src[sc1_subject];

								// no such predicate; skip
								if(!(sc1_predicate_target in h_pairs_src)) continue;

								// ref src objects set
								let as_objects_src = h_pairs_src[sc1_predicate_target];

								// no such object; skip
								if(!as_objects_src.has(sc1_object_target)) continue;

								// create dst triples tree
								h_triples_dst[sc1_subject] ={
									[$_KEYS]: 1,
									[$_QUADS]: 1,
									[sc1_predicate_target]: new Set(a_object_load),
								};

								// increment subject-keys and quads count
								c_subjects += 1;
							}

							// no triples trees to add; skip graph
							if(!c_subjects) continue;

							// save subject-keys and quads count
							h_triples_dst[$_KEYS] = c_subjects;
							h_triples_dst[$_QUADS] = c_subjects;

							// save triples hash tree
							h_quads_dst[sc1_graph] = h_triples_dst;

							// increment graph-keys and quads count
							c_graphs += 1;
							c_quads += c_subjects;
						}

						// no quads; empty tree
						if(!c_graphs) return this.offspring();

						// save graph-keys and quads count
						h_quads_dst[$_KEYS] = c_graphs;
						h_quads_dst[$_QUADS] = c_quads;

						// create dataset tree
						return this.offspring(h_quads_dst);
					}
					// -graph, -subject, +predicate, -object
					else {
						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// subjet-keys and quads count
							let c_subjects = 0;
							let c_triples = 0;

							// init dst triples hash
							let h_triples_dst = {
								[$_KEYS]: 0,
								[$_QUADS]: 0,
							};

							// each subject
							for(let sc1_subject in h_triples_src) {
								// ref src pairs hash
								let h_pairs_src = h_triples_src[sc1_subject];

								// no such predicate; skip
								if(!(sc1_predicate_target in h_pairs_src)) continue;

								// create dst objects set
								let as_objects_dst = new Set(h_pairs_src[sc1_predicate_target]);

								// objects count
								let n_objects = as_objects_dst.size;

								// create dst triples tree
								h_triples_dst[sc1_subject] ={
									[$_KEYS]: 1,
									[$_QUADS]: n_objects,
									[sc1_predicate_target]: as_objects_dst,
								};

								// increment subject-keys and quads count
								c_subjects += 1;
								c_triples += n_objects;
							}

							// no triples trees to add; skip graph
							if(!c_subjects) continue;

							// save subject-keys and quads count
							h_triples_dst[$_KEYS] = c_subjects;
							h_triples_dst[$_QUADS] = c_triples;

							// save triples hash tree
							h_quads_dst[sc1_graph] = h_triples_dst;

							// increment graph-keys and quads count
							c_graphs += 1;
							c_quads += c_triples;
						}

						// no quads; empty tree
						if(!c_graphs) return this.offspring();

						// save graph-keys and quads counts
						h_quads_dst[$_KEYS] = c_graphs;
						h_quads_dst[$_QUADS] = c_quads;

						// create dataset tree
						return this.offspring(h_quads_dst);
					}
				}
				// -graph, -subject, -predicate
				else {
					// -graph, -subject, -predicate, +object
					if(z_object) {
						// convert predicate to c1
						let sc1_object_target = from_term(z_object).concise();

						// prepare for loading into set multiple times
						let a_object_load = [sc1_object_target];

						// graph-keys and quads count
						let c_graphs = 0;
						let c_quads = 0;

						// each graph
						for(let sc1_graph in h_quads_src) {
							// ref src triples hash
							let h_triples_src = h_quads_src[sc1_graph];

							// subject-keys and quads count
							let c_subjects = 0;
							let c_triples = 0;

							// init dst triples hash
							let h_triples_dst = {
								[$_KEYS]: 0,
								[$_QUADS]: 0,
							};

							// each subject
							for(let sc1_subject in h_triples_src) {
								// ref src pairs hash
								let h_pairs_src = h_triples_src[sc1_subject];

								// predicate-keys count
								let c_predicates = 0;

								// init dst pairs hash
								let h_pairs_dst = {
									[$_KEYS]: 0,
									[$_QUADS]: 0,
								};

								// each predicate
								for(let sc1_predicate in h_pairs_src) {
									// ref src objects set
									let as_objects_src = h_pairs_src[sc1_predicate];

									// no such object; skip
									if(!as_objects_src.has(sc1_object_target)) continue;

									// create dst pairs hash
									h_pairs_dst[sc1_predicate] = new Set(a_object_load);

									// increment predicate-keys count
									c_predicates += 1;
								}

								// no quads
								if(!c_predicates) continue;

								// save predicate-keys and quads count
								h_pairs_dst[$_KEYS] = c_predicates;
								h_pairs_dst[$_QUADS] = c_predicates;

								// increment subject-keys and triples count
								c_subjects += 1;
								c_triples += c_predicates;

								// save to triples hash tree
								h_triples_dst[sc1_subject] = h_pairs_dst;
							}

							// no quads
							if(!c_subjects) continue;

							// save subject-keys and quads count
							h_triples_dst[$_KEYS] = c_subjects;
							h_triples_dst[$_QUADS] = c_triples;

							// increment graph-keys and quads count
							c_graphs += 1;
							c_quads += c_triples;

							// save triples hash tree
							h_quads_dst[sc1_graph] = h_triples_dst;
						}

						// no quads; empty tree
						if(!c_graphs) return this.offspring();

						// save subject-keys and quads count
						h_quads_dst[$_KEYS] = c_graphs;
						h_quads_dst[$_QUADS] = c_quads;

						// create dataset tree
						return this.offspring(h_quads_dst);
					}
					// -graph, -subject, -predicate, -object
					else {
						// same quad tree (clone)
						return this.union(new FastDataset());
					}
				}
			}
		}
	}

	get size() {
		return this._h_quad_tree[$_QUADS];
	}

	// add single quad
	add(w_quad) {
		this.add_quads([from_quad(w_quad)]);
		return this;
	}

	// add multiple quads
	addAll(z_quads) {
		// array
		if(Array.isArray(z_quads)) {
			this.add_quads(z_quads.map(from_quad));
		}
		// object
		else if('object' === typeof z_quads) {
			if(z_quads.isGraphyFastDataset) {
				this.add_tree(z_quads);
			}
			else if('function' === typeof z_quads[Symbol.iterator]) {
				let a_quads = [...z_quads];
				this.add_quads(a_quads.map(from_quad));
			}
			else {
				throw new Error(`failed to add quads from non-iterable object: ${z_quads}`);
			}
		}

		return this;
	}

	// add quads from sibling
	add_tree(k_tree) {
		let h_quads_src = k_tree._h_quad_tree;
		let h_quads_dst = this._h_quad_tree;

		// each graph in src
		for(let sv1_graph in h_quads_src) {
			// ref triples src subtree
			let h_triples_src = h_quads_src[sv1_graph];

			// ref/create triples dst subtree
			let h_triples_dst = h_quads_dst[sv1_graph] || {[$_KEYS]:0, [$_QUADS]:0};

			// each subject in src
			for(let sv1_subject in h_triples_src) {
				// ref pairs src subtree
				let h_pairs_src = h_triples_src[sv1_subject];

				// ref/create pairs dst subtree
				let h_pairs_dst = h_triples_dst[sv1_subject] || {[$_KEYS]:0, [$_QUADS]:0};

				// each predicate in pairs
				for(let sv1_predicate in h_pairs_src) {
					// ref objects src
					let as_objects_src = h_pairs_src[sv1_predicate];

					// predicate exists
					if(sv1_predicate in h_pairs_dst) {
						h_pairs_dst[sv1_predicate] = new Set([...h_pairs_dst[sv1_predicate], ...as_objects_src]);
					}
					// predicate not yet exists
					else {
						h_pairs_dst[sv1_predicate] = new Set(as_objects_src);
					}
				}
			}
		}
	}

	addQuads(a_quads_safe) {
		return this.add_quads(a_quads_safe);
	}

	// add quad(s) to this set
	add_quads(z_quads_safe) {
		let h_quads = this._h_quad_tree;
		let c_added = 0;

		// each quad in arguments
		for(let g_quad of z_quads_safe) {
			let p_graph = g_quad.graph.concise();
			let p_subject = g_quad.subject.concise();
			let p_predicate = g_quad.predicate.concise();
			let p_object = g_quad.object.concise();

			// so we don't have to check twice
			let b_thickened_quads = false;

			// first encounter of graph
			if(!(p_graph in h_quads)) {
				// has weak descendents; thicken self
				if(h_quads.hasOwnProperty($_KIDS)) {
					h_quads = this._h_quad_tree = thicken(h_quads);
					b_thickened_quads = true;
				}

				// add new tree under graph
				h_quads[p_graph] = {
					[$_KEYS]: 1,
					[$_QUADS]: 1,
					[p_subject]: {
						[$_KEYS]: 1,
						[$_QUADS]: 1,
						[p_predicate]: new Set([p_object]),
					},
				};

				// increment how many graphs there are in this set
				h_quads[$_KEYS] += 1;

				// increment counter
				c_added += 1;
			}
			// graph exists
			else {
				let h_triples = h_quads[p_graph];

				// first encounter of subject
				if(!(p_subject in h_triples)) {
					// triples tree is weak; thicken it
					if(h_triples.hasOwnProperty($_KIDS)) {
						h_triples = thicken(h_triples);
					}

					// add new tree under subject
					h_triples[p_subject] = {
						[$_KEYS]: 1,
						[$_QUADS]: 1,
						[p_predicate]: new Set([p_object]),
					};

					// increment how many subjects there are under this graph
					h_triples[$_KEYS] += 1;

					// increment counter
					c_added += 1;
				}
				// subject exists
				else {
					let h_pairs = h_triples[p_subject];

					// first encounter of predicate
					if(!(p_predicate in h_pairs)) {
						// pairs tree is weak; thicken it
						if(h_pairs.hasOwnProperty($_KIDS)) {
							h_pairs = thicken(h_pairs);
						}

						// add new set under predicate
						h_pairs[p_predicate] = new Set([p_object]);

						// increment how many predicates there are under this subject
						h_pairs[$_KEYS] += 1;

						// increment counter
						c_added += 1;
					}
					// predicate exists
					else {
						let as_objects = h_pairs[p_predicate];

						// first encounter of object
						if(!as_objects.has(p_object)) {
							// add object to set
							as_objects.add(p_object);

							// increment counter
							c_added += 1;
						}
						// duplicate
						else {
							continue;
						}
					}

					// pairs tree is weak; thicken it
					if(h_pairs.hasOwnProperty($_KIDS)) {
						h_pairs = thicken(h_pairs);
					}

					// increment how many quads there are under this subject
					h_pairs[$_QUADS] += 1;
				}

				// triples tree is weak; thicken it
				if(h_triples.hasOwnProperty($_KIDS)) {
					h_triples = thicken(h_triples);
				}

				// increment how many quads there are under this graph
				h_triples[$_QUADS] += 1;
			}

			// triples tree is weak; thicken it
			if(!b_thickened_quads && h_quads.hasOwnProperty($_KIDS)) {
				h_quads = this._h_quad_tree = thicken(h_quads);
			}

			// increment how many quads there are in set
			h_quads[$_QUADS] += 1;

			// subject is blank node
			if(g_quad.subject.isBlankNode) {
				let h_root_blanks = this._h_root_blanks;
				if(p_subject in h_root_blanks) {
					h_root_blanks[p_subject].add(g_quad);
				}
				else {
					h_root_blanks[p_subject] = new Set([g_quad]);
				}
			}

			// object is blank node
			if(g_quad.object.isBlankNode) {
				let h_leaf_blanks = this._h_leaf_blanks;
				if(p_object in h_leaf_blanks) {
					h_leaf_blanks[p_object].add(g_quad);
				}
				else {
					h_leaf_blanks[p_object] = new Set([g_quad]);
				}
			}
		}

		// invalidate hash and canonicalization
		this._s_hash = this._s_canonicalization = null;

		return c_added;
	}

	// remove all quads from this tree
	clear() {
		this._h_quad_tree = {[$_KEYS]:0, [$_QUADS]:0};
		this._s_digest = this._s_hash = this._s_canonicalization = null;
		this._h_root_blanks = {};
		this._h_leaf_blanks = {};
	}

	// delete set of quads
	delete(...a_quads) {
		let h_quads = this._h_quad_tree;
		let c_deleted = 0;

		for(let g_quad of a_quads) {
			let svt_graph = g_quad.graph.concise();
			let svt_subject = g_quad.subject.concise();
			let svt_predicate = g_quad.predicate.concise();
			let svt_object = g_quad.object.concise();

			// graph exists
			if(svt_graph in h_quads) {
				let h_triples = h_quads[svt_graph];

				// subject exists
				if(svt_subject in h_triples) {
					let h_pairs = h_triples[svt_subject];

					// predicate exists
					if(svt_predicate in h_pairs) {
						let as_objects = h_pairs[svt_predicate];

						// object exists in set
						if(as_objects.has(svt_object)) {
							// quads holds graph weakly
							if(!h_quads.hasOwnProperty(svt_graph)) {
								// thicken quad tree
								this._h_quad_tree = h_quads = thicken(h_quads);

								// thicken triples tree
								h_quads[svt_graph] = h_triples = thicken(h_triples);

								// thicken pairs tree
								h_triples[svt_subject] = h_pairs = thicken(h_pairs);

								// thicken set
								as_objects = h_pairs[svt_predicate] = new Set(as_objects);

								// delete object from set
								as_objects.delete(svt_object);

								// successfully deleted quad
								c_deleted += 1;
							}
							// triples holds subject weakly
							else if(!h_triples.hasOwnProperty(svt_subject)) {
								// thicken triples tree
								h_quads[svt_graph] = h_triples = thicken(h_triples);

								// thicken pairs tree
								h_triples[svt_subject] = h_pairs = thicken(h_pairs);

								// thicken set
								as_objects = h_pairs[svt_predicate] = new Set(as_objects);

								// delete object from set
								as_objects.delete(svt_object);

								// successfully deleted quad
								c_deleted += 1;

								// quads tree has weak descendents; thicken it
								if(h_quads.hasOwnProperty($_KIDS)) {
									this._h_quad_tree = h_quads = thicken(h_quads);
								}
							}
							// pairs holds predicate weakly
							else if(!h_pairs.hasOwnProperty(svt_predicate)) {
								// thicken pairs tree
								h_triples[svt_subject] = h_pairs = thicken(h_pairs);

								// thicken set
								as_objects = h_pairs[svt_predicate] = new Set(as_objects);

								// delete object from set
								as_objects.delete(svt_object);

								// successfully deleted quad
								c_deleted += 1;

								// triples tree has weak descendents; thicken it
								if(h_triples.hasOwnProperty($_KIDS)) {
									h_quads[svt_graph] = h_triples = thicken(h_triples);
								}

								// quads tree has weak descendents; thicken it
								if(h_quads.hasOwnProperty($_KIDS)) {
									this._h_quad_tree = h_quads = thicken(h_quads);
								}
							}
							else {
								// delete object from set
								as_objects.delete(svt_object);

								// successfully deleted quad
								c_deleted += 1;

								// pairs tree has weak descendents; thicken it
								if(h_pairs.hasOwnProperty($_KIDS)) {
									h_triples[svt_subject] = h_pairs = thicken(h_pairs);
								}

								// triples tree has weak descendents; thicken it
								if(h_triples.hasOwnProperty($_KIDS)) {
									h_quads[svt_graph] = h_triples = thicken(h_triples);
								}

								// quads tree has weak descendents; thicken it
								if(h_quads.hasOwnProperty($_KIDS)) {
									this._h_quad_tree = h_quads = thicken(h_quads);
								}
							}

							// subtract quad counts
							h_pairs[$_QUADS] -= 1;
							h_triples[$_QUADS] -= 1;
							h_quads[$_QUADS] -= 1;

							// set is now empty
							if(!as_objects.size) {
								// delete pairs mapping
								delete h_pairs[svt_predicate];

								// subtract key count
								h_pairs[$_KEYS] -= 1;

								// pairs is now empty
								if(!h_pairs[$_KEYS]) {
									// delete triple mapping
									delete h_triples[svt_subject];

									// subtract key count
									h_triples[$_KEYS] -= 1;

									// triples is now empty
									if(!h_triples[$_KEYS]) {
										// delete quad mapping
										delete h_quads[svt_graph];

										// subtract key count
										h_quads[$_KEYS] -= 1;
									}
								}
							}
						}
					}
				}
			}
		}

		// quad not in tree
		return c_deleted;
	}

	// tree has quad
	has(g_quad) {
		let h_quads = this._h_quad_tree;

		let svt_graph = g_quad.graph.concise();
		let svt_subject = g_quad.subject.concise();
		let svt_predicate = g_quad.predicate.concise();
		let svt_object = g_quad.object.concise();

		// graph exists
		if(svt_graph in h_quads) {
			let h_triples = h_quads[svt_graph];

			// subject exists
			if(svt_subject in h_triples) {
				let h_pairs = h_triples[svt_subject];

				// predicate exists
				if(svt_predicate in h_pairs) {
					let as_objects = h_pairs[svt_predicate];

					// return result of deleting from set
					return as_objects.has(svt_object);
				}
			}
		}

		// quad not in tree
		return false;
	}

	equals(k_other) {
		return 0 === this.difference(k_other).size;
	}

	equivalent(k_other) {
		// both have digest precomputed
		if(this._s_digest && k_other._s_digest) {
			return this._s_digest === k_other._s_digest;
		}

		// ref quads
		let h_quads_a = this._h_quad_tree;
		let h_quads_b = k_other._h_quad_tree;

		// different key count or quad count; cannot be equal
		if(h_quads_a[$_QUADS] !== h_quads_b[$_QUADS] || h_quads_a[$_KEYS] !== h_quads_b[$_KEYS]) {
			return false;
		}

		// compare digests
		return (new Canonicalizer_ct(this)).normalize().string === (new Canonicalizer_ct(k_other)).normalize().string;
	}

	// generate the canonical string representation of a quad
	canonicalize_quad(g_quad, h_hashed, a_visited) {
		let {
			subject: h_subject,
			object: h_object,
		} = g_quad;

		return g_quad.graph.concise()+'\0\n'
			+(h_subject.isBlankNode
				? this.hash_blank_node(h_subject.concise(), h_hashed, a_visited)
				: h_subject.concise()+'')+'\0\n'
			+g_quad.predicate.concise()+'\0\n'
			+(h_object.isBlankNode
				? this.hash_blank_node(h_object.concise(), h_hashed, a_visited)
				: h_object.concise())+'\0\n';
	}

	// canonicalize the dataset
	canonicalize() {
		let k_normalize = new Canonicalizer_ct(this);
		return k_normalize.normalize().tree;
	}

	normalize() {
		return (new Canonicalizer_ct(this)).normalize();
	}

	// create union of two sets
	union(k_other) {
		// ref quads
		let h_quads_a = this._h_quad_tree;
		let h_quads_b = k_other._h_quad_tree;

		// a has less keys than b; swap quads
		if(h_quads_a[$_KEYS] < h_quads_b[$_KEYS]) {
			[h_quads_a, h_quads_b] = [h_quads_b, h_quads_a];
		}

		// prep quads union
		let h_quads_u = Object.create(h_quads_a);

		// weak keys
		h_quads_u[$_THIN] = 1;

		// each graph in a
		for(let p_graph in h_quads_a) {
			// graph is also in b
			if(p_graph in h_quads_b) {
				// ref triples
				let h_triples_a = h_quads_a[p_graph];
				let h_triples_b = h_quads_b[p_graph];

				// triples are not swapped relative to quads
				let b_swapped_triples = false;

				// a has less keys than b
				if(h_triples_a[$_KEYS] < h_triples_b[$_KEYS]) {
					// swap triples
					[h_triples_a, h_triples_b] = [h_triples_b, h_triples_a];

					// beware consequence of swap
					b_swapped_triples = true;
				}

				// prep triples union
				let h_triples_u = Object.create(h_triples_a);

				// weak keys
				h_triples_u[$_THIN] = 1;

				// save triples union
				let b_save_triples = false;

				// each subject in a
				for(let p_subject in h_triples_a) {
					// subject is also in b
					if(p_subject in h_triples_b) {
						// ref pairs
						let h_pairs_a = h_triples_a[p_subject];
						let h_pairs_b = h_triples_b[p_subject];

						// pairs are not swapped relative to triples
						let b_swapped_pairs = false;

						// a has less keys than b
						if(h_pairs_a[$_KEYS] < h_pairs_b[$_KEYS]) {
							// swap pairs
							[h_pairs_a, h_pairs_b] = [h_pairs_b, h_pairs_a];

							// beware consequences of swap
							b_swapped_pairs = true;
						}

						// prep pairs union
						let h_pairs_u = h_triples_u[p_subject] = Object.create(h_pairs_a);

						// weak keys
						h_pairs_u[$_THIN] = 1;

						// quads to add under pairs
						let c_quads_add_pairs = 0;

						// each predicate in a
						for(let p_predicate in h_pairs_a) {
							// predicate is also in b
							if(p_predicate in h_pairs_b) {
								// ref objects
								let as_objects_a = h_pairs_a[p_predicate];
								let as_objects_b = h_pairs_b[p_predicate];

								// union sets and save it to pairs union
								let as_objects_u = h_pairs_u[p_predicate] = new Set([...as_objects_a, ...as_objects_b]);

								// update quad counts with difference
								c_quads_add_pairs += as_objects_u.size - as_objects_a.size;
							}
						}

						// each predicate in b
						for(let p_predicate in h_pairs_b) {
							// predicate is not in a
							if(!(p_predicate in h_pairs_a)) {
								// add all objects from this predicate
								let as_objects_u = h_pairs_u[p_predicate] = new Set(h_pairs_b[p_predicate]);

								// update key count
								h_pairs_u[$_KEYS] += 1;

								// update quad counts
								c_quads_add_pairs += as_objects_u.size;
							}
						}

						// difference
						if(c_quads_add_pairs) {
							// update counts
							h_pairs_u[$_QUADS] += c_quads_add_pairs;
							h_triples_u[$_QUADS] += c_quads_add_pairs;
							h_quads_u[$_QUADS] += c_quads_add_pairs;

							// union has same keys as prototype
							if(h_pairs_u[$_KEYS] === h_pairs_a[$_KEYS] && h_pairs_u.hasOwnProperty($_KEYS)) {
																	// thicken this
																	// set own symbol properties
								h_pairs_u[$_THIN] = 0;
								h_pairs_u[$_KEYS] = h_pairs_a[$_KEYS];

								// uninherit from a
								Object.setPrototypeOf(h_pairs_u, {});
							}
							// union differs from prototype
							else {
								// flag descendents on source
								h_pairs_a[$_KIDS] = 1;
							}

							// save reference in triples
							h_triples_u[p_subject] = h_pairs_u;

							// save triples reference
							b_save_triples = true;
						}
						// no difference, but prototype is invalid from pair swap
						else if(b_swapped_pairs) {
							// discard union object, recreate it and save to triples
							h_triples_u[p_subject] = Object.create(h_pairs_a);
						}
					}
				}

				// each subject in b
				for(let p_subject in h_triples_b) {
					// subject is not in a
					if(!(p_subject in h_triples_a)) {
						// ref pairs
						let h_pairs_b = h_triples_b[p_subject];

						// add all pairs from this subject and save to triples union
						let h_pairs_u = h_triples_u[p_subject] = Object.create(h_pairs_b);

						// weak descendents
						h_pairs_b[$_KIDS] = 1;

						// weak keys
						h_pairs_u[$_THIN] = 1;

						// update key count
						h_triples_u[$_KEYS] += 1;

						// update quad counts
						let n_quads_add = h_pairs_u[$_QUADS];
						h_triples_u[$_QUADS] += n_quads_add;
						h_quads_u[$_QUADS] += n_quads_add;

						// save triples reference
						b_save_triples = true;
					}
				}

				// yes mutations
				if(b_save_triples) {
					// union has same keys as prototype
					if(h_triples_u[$_KEYS] === h_triples_a[$_KEYS] && h_triples_u.hasOwnProperty($_KEYS)) {
													// thicken this
													// set own symbol properties
						h_triples_u[$_THIN] = 0;
						h_triples_u[$_KEYS] = h_triples_a[$_KEYS];

						// uninherit from a
						Object.setPrototypeOf(h_triples_u, {});
					}
					// union differs from prototype
					else {
						// flag descendents on source
						h_triples_a[$_KIDS] = 1;
					}

					// save triples union to quads union
					h_quads_u[p_graph] = h_triples_u;
				}
				// no mutations, but prototype is invalid from triple swap
				else if(b_swapped_triples) {
					// discard union object, recreate it and save to quads
					h_quads_u[p_graph] = Object.create(h_triples_a);
				}
			}
		}

		// each graph in b
		for(let p_graph in h_quads_b) {
			// graph is not in a
			if(!(p_graph in h_quads_a)) {
				// add all triples from this graph
				let h_triples_u = h_quads_u[p_graph] = Object.create(h_quads_b[p_graph]);

				// update key count
				h_quads_u[$_KEYS] += 1;

				// update quad counts
				let n_quads_add = h_triples_u[$_QUADS];
				h_quads_u[$_QUADS] += n_quads_add;
			}
		}

		// union has same keys as prototype
		if(h_quads_u[$_KEYS] === h_quads_a[$_KEYS] && h_quads_u.hasOwnProperty($_KEYS)) {
							// thicken this
							// set own symbol properties
			h_quads_u[$_THIN] = 0;
			h_quads_u[$_KEYS] = h_quads_a[$_KEYS];

			// uninherit from a
			Object.setPrototypeOf(h_quads_u, {});
		}
		// union differs from prototype
		else {
			// flag descendents on source
			h_quads_a[$_KIDS] = 1;
		}

		// always return new instance
		return new FastDataset({
			// merge prefixes; this instance has precedence
			prefixes: Object.assign({}, k_other._h_prefixes, this._h_prefixes),
		}, h_quads_u);
	}

	// compute intersection of two sets
	intersection(k_other) {
		// ref quads
		let h_quads_a = this._h_quad_tree;
		let h_quads_b = k_other._h_quad_tree;

		// set b has less quads than set a; swap quadss
		if(h_quads_b[$_KEYS] < h_quads_a[$_KEYS]) {
			[h_quads_a, h_quads_b] = [h_quads_b, h_quads_a];
		}

		// prep quads intersection
		let h_quads_i = {[$_KEYS]:0, [$_QUADS]:0};

		// each graph in a
		for(let p_graph in h_quads_a) {
			// graph is also in b
			if(p_graph in h_quads_b) {
				// ref tripless
				let h_triples_a = h_quads_a[p_graph];
				let h_triples_b = h_quads_b[p_graph];

				// set b has less triples than set a; swap triples
				if(h_triples_b[$_KEYS] < h_triples_a[$_KEYS]) {
					[h_triples_a, h_triples_b] = [h_triples_b, h_triples_a];
				}

				// prep triples intersection
				let h_triples_i = {[$_KEYS]:0, [$_QUADS]:0};

				// each subject in a
				for(let p_subject in h_triples_a) {
					// subject is also in b
					if(p_subject in h_triples_b) {
						// ref pairs
						let h_pairs_a = h_triples_a[p_subject];
						let h_pairs_b = h_triples_b[p_subject];

						// set b has less pairs than set a; swap pairs
						if(h_pairs_b[$_KEYS] < h_pairs_a[$_KEYS]) {
							[h_pairs_a, h_pairs_b] = [h_pairs_b, h_pairs_a];
						}

						// prep pairs intersection
						let h_pairs_i = {[$_KEYS]:0, [$_QUADS]:0};

						// each predicate in a
						for(let p_predicate in h_pairs_a) {
							// predicate is also in b
							if(p_predicate in h_pairs_b) {
								// ref objects
								let as_objects_a = h_pairs_a[p_predicate];
								let as_objects_b = h_pairs_b[p_predicate];

								// set b has less objects than set a; swap objects
								if(as_objects_b.size < as_objects_a.size) {
									[as_objects_a, as_objects_b] = [as_objects_b, as_objects_a];
								}

								// prep objects intersection
								let as_objects_i = new Set();

								// each object in a
								for(let p_object of as_objects_a) {
									// object is also in b
									if(as_objects_b.has(p_object)) {
										// add to intersection
										as_objects_i.add(p_object);
									}
								}

								// non-empty object intersection
								if(as_objects_i) {
									// add objects to pair
									h_pairs_i[p_predicate] = as_objects_i;

									// update key count
									h_pairs_i[$_KEYS] += 1;

									// update quad count
									h_pairs_i[$_QUADS] += as_objects_i.size;
								}
							}
						}

						// non-empty pairs intersection
						if(h_pairs_i[$_KEYS]) {
							// add pairs to triples
							h_triples_i[p_subject] = h_pairs_i;

							// update key count
							h_triples_i[$_KEYS] += 1;

							// update quad count
							h_triples_i[$_QUADS] += h_pairs_i[$_QUADS];
						}
					}
				}

				// non-empty triples intersection
				if(h_triples_i[$_KEYS]) {
					// add triples to quads
					h_quads_i[p_graph] = h_triples_i;

					// update key count
					h_quads_i[$_KEYS] += 1;

					// update quad count
					h_quads_i[$_QUADS] += h_triples_i[$_QUADS];
				}
			}
		}

		return new FastDataset({
			// merge prefixes; this instance has precedence
			prefixes: Object.assign({}, k_other._h_prefixes, this._h_prefixes),
		}, h_quads_i);
	}

	// subtract a subset from this
	minus_subset(k_subset) {
		// ref quads
		let h_quads_a = this._h_quad_tree;
		let h_quads_b = k_subset._h_quad_tree;

		// prep quads remainder
		let h_quads_r = {[$_KEYS]:0, [$_QUADS]:0};

		// each graph in a
		for(let p_graph in h_quads_a) {
			// graph is also in b
			if(p_graph in h_quads_b) {
				// ref tripless
				let h_triples_a = h_quads_a[p_graph];
				let h_triples_b = h_quads_b[p_graph];

				// prep triples remainder
				let h_triples_r = {[$_KEYS]:0, [$_QUADS]:0};

				// each subject in a
				for(let p_subject in h_triples_a) {
					// subject is also in b
					if(p_subject in h_triples_b) {
						// ref pairs
						let h_pairs_a = h_triples_a[p_subject];
						let h_pairs_b = h_triples_b[p_subject];

						// prep pairs remainder
						let h_pairs_r = {[$_KEYS]:0, [$_QUADS]:0};

						// each predicate in b
						for(let p_predicate in h_pairs_b) {
							// ref objects
							let as_objects_a = h_pairs_a[p_predicate];
							let as_objects_b = h_pairs_b[p_predicate];

							// prep objects remainder
							let as_objects_r = new Set(as_objects_a);

							// each object in b
							for(let p_object of as_objects_b) {
								// remove from remainder
								as_objects_r.delete(p_object);
							}

							// non-empty object remainder
							if(as_objects_r.size) {
								// add objects to pair
								h_pairs_r[p_predicate] = as_objects_r;

								// update key count
								h_pairs_r[$_KEYS] += 1;

								// update quad count
								h_pairs_r[$_QUADS] += as_objects_r.size;
							}
						}

						// non-empty pairs remainder
						if(h_pairs_r[$_KEYS]) {
							// add pairs to triples
							h_triples_r[p_subject] = h_pairs_r;

							// update key count
							h_triples_r[$_KEYS] += 1;

							// update quad count
							h_triples_r[$_QUADS] += h_pairs_r[$_QUADS];
						}
					}
					// subject is not in b
					else {
						// add all pairs from this subject
						let h_pairs_r = h_triples_r[p_subject] = h_triples_a[p_subject];

						// update key count
						h_triples_r[$_KEYS] += 1;

						// update quad count
						h_triples_r[$_QUADS] += h_pairs_r[$_QUADS];
					}
				}

				// non-empty triples intersection
				if(h_triples_r[$_KEYS]) {
					// add triples to quads
					h_quads_r[p_graph] = h_triples_r;

					// update key count
					h_quads_r[$_KEYS] += 1;

					// update quad count
					h_quads_r[$_QUADS] += h_triples_r[$_QUADS];
				}
			}
			// graph is not in b
			else {
				// add all triples from this graph
				let h_triples_r = h_quads_r[p_graph] = h_quads_a[p_graph];

				// update key count
				h_quads_r[$_KEYS] += 1;

				// update quad count
				h_quads_r[$_QUADS] += h_triples_r[$_QUADS];
			}
		}

		// return new dataset tree
		return new FastDataset({
			// merge prefixes; this instance has precedence
			prefixes: Object.assign({}, k_subset.prefixes, this._h_prefixes),
		}, h_quads_r);
	}

	// tests if another set is contained by this set
	contains(k_other) {
		// compute intersection first
		let k_i = this.intersection(k_other);

		// (A ∩ B) == B
		return k_i.equals(k_other);
	}

	// subtract another set from this
	minus(k_other) {
		// compte intersection first
		let k_i = this.intersection(k_other);

		// A - (A ∩ B)
		return this.minus_subset(k_i);
	}

	// (A ∩ B) == Ø
	disjoint(k_other) {
		return 0 === this.intersection(k_other).size;
	}

	// compute the difference of two sets
	difference(k_other) {
		// compute intersection first
		let k_i = this.intersection(k_other);

		// (A - (A ∩ B)) ∪ (B - (A ∩ B))
		return this.minus_subset(k_i)
			.union(k_other.minus_subset(k_i));
	}


	distinct_subjects() {
		return this._h_quad_tree[$_KEYS];
	}

	// count how many quads match the given selector
	count(a_terms=[]) {
		// no terms; return quad count
		if(!a_terms.length) return this._h_quad_tree[$_QUADS];

		// normalize terms
		let act_terms = a_terms.map((z) => {
			// concise term string
			if('string' === typeof z) return z;

			// rdfjs term
			if('termType' in z) {
				// graphy term
				if('concise' in z) return z.concise();

				// foreign term; make graphy
				return factory_from.rdfjs_term(z).concise();
			}

			// null
			if(null === z) return z;

			// invalid
			throw new TypeError(`invalid type for term in array: ${z}`);
		});

		// ref quads
		let h_quads = this._h_quad_tree;

		// number of terms
		let nl_terms = act_terms.length;

		// matching trees
		let a_trees = [];

		// graph
		let p_graph = act_terms[0];

		// variable; take all graphs
		if(null === p_graph) {
			a_trees = Object.values(h_quads);
		}
		// specific
		else {
			a_trees = [h_quads[p_graph]];
		}

		// subject
		if(nl_terms > 1) {
			let p_subject = act_terms[1];

			// prep to swap out trees
			let a_swap = [];

			// variable
			if(null === p_subject) {
				// take all subjects
				a_trees.forEach((h) => {
					a_swap.push(...Object.values(h));
				});
			}
			// specific
			else {
				a_trees.forEach((h) => {
					if(p_subject in h) {
						a_swap.push(h[p_subject]);
					}
				});
			}

			// swap in for trees
			a_trees = a_swap;

			// predicate given
			if(nl_terms > 2) {
				let p_predicate = act_terms[2];

				// prep to swap out trees
				a_swap = [];

				// variable
				if(null === p_predicate) {
					// take all predicates
					a_trees.forEach((h) => {
						a_swap.push(...Object.values(h));
					});
				}
				// specific
				else {
					a_trees.forEach((h) => {
						if(p_predicate in h) {
							a_swap.push(h[p_predicate]);
						}
					});
				}

				// swap in for trees
				a_trees = a_swap;

				// object given
				if(nl_terms > 3) {
					let p_object = act_terms[3];

					// prep to count objects
					let c_objects = 0;

					// variable
					if(null === p_object) {
						// take all objects
						a_trees.forEach((as) => {
							c_objects += as.size;
						});
					}
					// specific
					else {
						// count objects
						a_trees.forEach((h) => {
							if(p_object in h) {
								c_objects += 1;
							}
						});
					}

					// more terms given
					if(nl_terms > 4) {
						throw new Error(`too many values given in terms array`);
					}

					// object count
					return c_objects;
				}
			}
		}

		// reduce final quad count
		return a_trees.reduce((c, h) => c + h[$_QUADS], 0);
	}
}

Object.assign(FastDataset.prototype, {
	isGraphyFastDataset: true,
});

module.exports = Object.assign((...a_args) => new FastDataset(...a_args), {
	keys: $_KEYS,
	quads: $_QUADS,
});

},{"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21,"crypto":86}],26:[function(require,module,exports){


const dataset = require('@graphy/memory.dataset.fast');

console.warn(`The 'util.dataset.tree' package has been renamed to 'memory.dataset.fast'. Please update your require statement. This module, '@graphy/util.dataset.tree', may be deprecated and removed in the next major release.`);

module.exports = dataset;

},{"@graphy/memory.dataset.fast":25}],27:[function(require,module,exports){
'use strict';

const asn1 = exports;

asn1.bignum = require('bn.js');

asn1.define = require('./asn1/api').define;
asn1.base = require('./asn1/base');
asn1.constants = require('./asn1/constants');
asn1.decoders = require('./asn1/decoders');
asn1.encoders = require('./asn1/encoders');

},{"./asn1/api":28,"./asn1/base":30,"./asn1/constants":34,"./asn1/decoders":36,"./asn1/encoders":39,"bn.js":41}],28:[function(require,module,exports){
'use strict';

const encoders = require('./encoders');
const decoders = require('./decoders');
const inherits = require('inherits');

const api = exports;

api.define = function define(name, body) {
  return new Entity(name, body);
};

function Entity(name, body) {
  this.name = name;
  this.body = body;

  this.decoders = {};
  this.encoders = {};
}

Entity.prototype._createNamed = function createNamed(Base) {
  const name = this.name;

  function Generated(entity) {
    this._initNamed(entity, name);
  }
  inherits(Generated, Base);
  Generated.prototype._initNamed = function _initNamed(entity, name) {
    Base.call(this, entity, name);
  };

  return new Generated(this);
};

Entity.prototype._getDecoder = function _getDecoder(enc) {
  enc = enc || 'der';
  // Lazily create decoder
  if (!this.decoders.hasOwnProperty(enc))
    this.decoders[enc] = this._createNamed(decoders[enc]);
  return this.decoders[enc];
};

Entity.prototype.decode = function decode(data, enc, options) {
  return this._getDecoder(enc).decode(data, options);
};

Entity.prototype._getEncoder = function _getEncoder(enc) {
  enc = enc || 'der';
  // Lazily create encoder
  if (!this.encoders.hasOwnProperty(enc))
    this.encoders[enc] = this._createNamed(encoders[enc]);
  return this.encoders[enc];
};

Entity.prototype.encode = function encode(data, enc, /* internal */ reporter) {
  return this._getEncoder(enc).encode(data, reporter);
};

},{"./decoders":36,"./encoders":39,"inherits":136}],29:[function(require,module,exports){
'use strict';

const inherits = require('inherits');
const Reporter = require('../base/reporter').Reporter;
const Buffer = require('safer-buffer').Buffer;

function DecoderBuffer(base, options) {
  Reporter.call(this, options);
  if (!Buffer.isBuffer(base)) {
    this.error('Input not Buffer');
    return;
  }

  this.base = base;
  this.offset = 0;
  this.length = base.length;
}
inherits(DecoderBuffer, Reporter);
exports.DecoderBuffer = DecoderBuffer;

DecoderBuffer.isDecoderBuffer = function isDecoderBuffer(data) {
  if (data instanceof DecoderBuffer) {
    return true;
  }

  // Or accept compatible API
  const isCompatible = typeof data === 'object' &&
    Buffer.isBuffer(data.base) &&
    data.constructor.name === 'DecoderBuffer' &&
    typeof data.offset === 'number' &&
    typeof data.length === 'number' &&
    typeof data.save === 'function' &&
    typeof data.restore === 'function' &&
    typeof data.isEmpty === 'function' &&
    typeof data.readUInt8 === 'function' &&
    typeof data.skip === 'function' &&
    typeof data.raw === 'function';

  return isCompatible;
};

DecoderBuffer.prototype.save = function save() {
  return { offset: this.offset, reporter: Reporter.prototype.save.call(this) };
};

DecoderBuffer.prototype.restore = function restore(save) {
  // Return skipped data
  const res = new DecoderBuffer(this.base);
  res.offset = save.offset;
  res.length = this.offset;

  this.offset = save.offset;
  Reporter.prototype.restore.call(this, save.reporter);

  return res;
};

DecoderBuffer.prototype.isEmpty = function isEmpty() {
  return this.offset === this.length;
};

DecoderBuffer.prototype.readUInt8 = function readUInt8(fail) {
  if (this.offset + 1 <= this.length)
    return this.base.readUInt8(this.offset++, true);
  else
    return this.error(fail || 'DecoderBuffer overrun');
};

DecoderBuffer.prototype.skip = function skip(bytes, fail) {
  if (!(this.offset + bytes <= this.length))
    return this.error(fail || 'DecoderBuffer overrun');

  const res = new DecoderBuffer(this.base);

  // Share reporter state
  res._reporterState = this._reporterState;

  res.offset = this.offset;
  res.length = this.offset + bytes;
  this.offset += bytes;
  return res;
};

DecoderBuffer.prototype.raw = function raw(save) {
  return this.base.slice(save ? save.offset : this.offset, this.length);
};

function EncoderBuffer(value, reporter) {
  if (Array.isArray(value)) {
    this.length = 0;
    this.value = value.map(function(item) {
      if (!EncoderBuffer.isEncoderBuffer(item))
        item = new EncoderBuffer(item, reporter);
      this.length += item.length;
      return item;
    }, this);
  } else if (typeof value === 'number') {
    if (!(0 <= value && value <= 0xff))
      return reporter.error('non-byte EncoderBuffer value');
    this.value = value;
    this.length = 1;
  } else if (typeof value === 'string') {
    this.value = value;
    this.length = Buffer.byteLength(value);
  } else if (Buffer.isBuffer(value)) {
    this.value = value;
    this.length = value.length;
  } else {
    return reporter.error('Unsupported type: ' + typeof value);
  }
}
exports.EncoderBuffer = EncoderBuffer;

EncoderBuffer.isEncoderBuffer = function isEncoderBuffer(data) {
  if (data instanceof EncoderBuffer) {
    return true;
  }

  // Or accept compatible API
  const isCompatible = typeof data === 'object' &&
    data.constructor.name === 'EncoderBuffer' &&
    typeof data.length === 'number' &&
    typeof data.join === 'function';

  return isCompatible;
};

EncoderBuffer.prototype.join = function join(out, offset) {
  if (!out)
    out = Buffer.alloc(this.length);
  if (!offset)
    offset = 0;

  if (this.length === 0)
    return out;

  if (Array.isArray(this.value)) {
    this.value.forEach(function(item) {
      item.join(out, offset);
      offset += item.length;
    });
  } else {
    if (typeof this.value === 'number')
      out[offset] = this.value;
    else if (typeof this.value === 'string')
      out.write(this.value, offset);
    else if (Buffer.isBuffer(this.value))
      this.value.copy(out, offset);
    offset += this.length;
  }

  return out;
};

},{"../base/reporter":32,"inherits":136,"safer-buffer":216}],30:[function(require,module,exports){
'use strict';

const base = exports;

base.Reporter = require('./reporter').Reporter;
base.DecoderBuffer = require('./buffer').DecoderBuffer;
base.EncoderBuffer = require('./buffer').EncoderBuffer;
base.Node = require('./node');

},{"./buffer":29,"./node":31,"./reporter":32}],31:[function(require,module,exports){
'use strict';

const Reporter = require('../base/reporter').Reporter;
const EncoderBuffer = require('../base/buffer').EncoderBuffer;
const DecoderBuffer = require('../base/buffer').DecoderBuffer;
const assert = require('minimalistic-assert');

// Supported tags
const tags = [
  'seq', 'seqof', 'set', 'setof', 'objid', 'bool',
  'gentime', 'utctime', 'null_', 'enum', 'int', 'objDesc',
  'bitstr', 'bmpstr', 'charstr', 'genstr', 'graphstr', 'ia5str', 'iso646str',
  'numstr', 'octstr', 'printstr', 't61str', 'unistr', 'utf8str', 'videostr'
];

// Public methods list
const methods = [
  'key', 'obj', 'use', 'optional', 'explicit', 'implicit', 'def', 'choice',
  'any', 'contains'
].concat(tags);

// Overrided methods list
const overrided = [
  '_peekTag', '_decodeTag', '_use',
  '_decodeStr', '_decodeObjid', '_decodeTime',
  '_decodeNull', '_decodeInt', '_decodeBool', '_decodeList',

  '_encodeComposite', '_encodeStr', '_encodeObjid', '_encodeTime',
  '_encodeNull', '_encodeInt', '_encodeBool'
];

function Node(enc, parent, name) {
  const state = {};
  this._baseState = state;

  state.name = name;
  state.enc = enc;

  state.parent = parent || null;
  state.children = null;

  // State
  state.tag = null;
  state.args = null;
  state.reverseArgs = null;
  state.choice = null;
  state.optional = false;
  state.any = false;
  state.obj = false;
  state.use = null;
  state.useDecoder = null;
  state.key = null;
  state['default'] = null;
  state.explicit = null;
  state.implicit = null;
  state.contains = null;

  // Should create new instance on each method
  if (!state.parent) {
    state.children = [];
    this._wrap();
  }
}
module.exports = Node;

const stateProps = [
  'enc', 'parent', 'children', 'tag', 'args', 'reverseArgs', 'choice',
  'optional', 'any', 'obj', 'use', 'alteredUse', 'key', 'default', 'explicit',
  'implicit', 'contains'
];

Node.prototype.clone = function clone() {
  const state = this._baseState;
  const cstate = {};
  stateProps.forEach(function(prop) {
    cstate[prop] = state[prop];
  });
  const res = new this.constructor(cstate.parent);
  res._baseState = cstate;
  return res;
};

Node.prototype._wrap = function wrap() {
  const state = this._baseState;
  methods.forEach(function(method) {
    this[method] = function _wrappedMethod() {
      const clone = new this.constructor(this);
      state.children.push(clone);
      return clone[method].apply(clone, arguments);
    };
  }, this);
};

Node.prototype._init = function init(body) {
  const state = this._baseState;

  assert(state.parent === null);
  body.call(this);

  // Filter children
  state.children = state.children.filter(function(child) {
    return child._baseState.parent === this;
  }, this);
  assert.equal(state.children.length, 1, 'Root node can have only one child');
};

Node.prototype._useArgs = function useArgs(args) {
  const state = this._baseState;

  // Filter children and args
  const children = args.filter(function(arg) {
    return arg instanceof this.constructor;
  }, this);
  args = args.filter(function(arg) {
    return !(arg instanceof this.constructor);
  }, this);

  if (children.length !== 0) {
    assert(state.children === null);
    state.children = children;

    // Replace parent to maintain backward link
    children.forEach(function(child) {
      child._baseState.parent = this;
    }, this);
  }
  if (args.length !== 0) {
    assert(state.args === null);
    state.args = args;
    state.reverseArgs = args.map(function(arg) {
      if (typeof arg !== 'object' || arg.constructor !== Object)
        return arg;

      const res = {};
      Object.keys(arg).forEach(function(key) {
        if (key == (key | 0))
          key |= 0;
        const value = arg[key];
        res[value] = key;
      });
      return res;
    });
  }
};

//
// Overrided methods
//

overrided.forEach(function(method) {
  Node.prototype[method] = function _overrided() {
    const state = this._baseState;
    throw new Error(method + ' not implemented for encoding: ' + state.enc);
  };
});

//
// Public methods
//

tags.forEach(function(tag) {
  Node.prototype[tag] = function _tagMethod() {
    const state = this._baseState;
    const args = Array.prototype.slice.call(arguments);

    assert(state.tag === null);
    state.tag = tag;

    this._useArgs(args);

    return this;
  };
});

Node.prototype.use = function use(item) {
  assert(item);
  const state = this._baseState;

  assert(state.use === null);
  state.use = item;

  return this;
};

Node.prototype.optional = function optional() {
  const state = this._baseState;

  state.optional = true;

  return this;
};

Node.prototype.def = function def(val) {
  const state = this._baseState;

  assert(state['default'] === null);
  state['default'] = val;
  state.optional = true;

  return this;
};

Node.prototype.explicit = function explicit(num) {
  const state = this._baseState;

  assert(state.explicit === null && state.implicit === null);
  state.explicit = num;

  return this;
};

Node.prototype.implicit = function implicit(num) {
  const state = this._baseState;

  assert(state.explicit === null && state.implicit === null);
  state.implicit = num;

  return this;
};

Node.prototype.obj = function obj() {
  const state = this._baseState;
  const args = Array.prototype.slice.call(arguments);

  state.obj = true;

  if (args.length !== 0)
    this._useArgs(args);

  return this;
};

Node.prototype.key = function key(newKey) {
  const state = this._baseState;

  assert(state.key === null);
  state.key = newKey;

  return this;
};

Node.prototype.any = function any() {
  const state = this._baseState;

  state.any = true;

  return this;
};

Node.prototype.choice = function choice(obj) {
  const state = this._baseState;

  assert(state.choice === null);
  state.choice = obj;
  this._useArgs(Object.keys(obj).map(function(key) {
    return obj[key];
  }));

  return this;
};

Node.prototype.contains = function contains(item) {
  const state = this._baseState;

  assert(state.use === null);
  state.contains = item;

  return this;
};

//
// Decoding
//

Node.prototype._decode = function decode(input, options) {
  const state = this._baseState;

  // Decode root node
  if (state.parent === null)
    return input.wrapResult(state.children[0]._decode(input, options));

  let result = state['default'];
  let present = true;

  let prevKey = null;
  if (state.key !== null)
    prevKey = input.enterKey(state.key);

  // Check if tag is there
  if (state.optional) {
    let tag = null;
    if (state.explicit !== null)
      tag = state.explicit;
    else if (state.implicit !== null)
      tag = state.implicit;
    else if (state.tag !== null)
      tag = state.tag;

    if (tag === null && !state.any) {
      // Trial and Error
      const save = input.save();
      try {
        if (state.choice === null)
          this._decodeGeneric(state.tag, input, options);
        else
          this._decodeChoice(input, options);
        present = true;
      } catch (e) {
        present = false;
      }
      input.restore(save);
    } else {
      present = this._peekTag(input, tag, state.any);

      if (input.isError(present))
        return present;
    }
  }

  // Push object on stack
  let prevObj;
  if (state.obj && present)
    prevObj = input.enterObject();

  if (present) {
    // Unwrap explicit values
    if (state.explicit !== null) {
      const explicit = this._decodeTag(input, state.explicit);
      if (input.isError(explicit))
        return explicit;
      input = explicit;
    }

    const start = input.offset;

    // Unwrap implicit and normal values
    if (state.use === null && state.choice === null) {
      let save;
      if (state.any)
        save = input.save();
      const body = this._decodeTag(
        input,
        state.implicit !== null ? state.implicit : state.tag,
        state.any
      );
      if (input.isError(body))
        return body;

      if (state.any)
        result = input.raw(save);
      else
        input = body;
    }

    if (options && options.track && state.tag !== null)
      options.track(input.path(), start, input.length, 'tagged');

    if (options && options.track && state.tag !== null)
      options.track(input.path(), input.offset, input.length, 'content');

    // Select proper method for tag
    if (state.any) {
      // no-op
    } else if (state.choice === null) {
      result = this._decodeGeneric(state.tag, input, options);
    } else {
      result = this._decodeChoice(input, options);
    }

    if (input.isError(result))
      return result;

    // Decode children
    if (!state.any && state.choice === null && state.children !== null) {
      state.children.forEach(function decodeChildren(child) {
        // NOTE: We are ignoring errors here, to let parser continue with other
        // parts of encoded data
        child._decode(input, options);
      });
    }

    // Decode contained/encoded by schema, only in bit or octet strings
    if (state.contains && (state.tag === 'octstr' || state.tag === 'bitstr')) {
      const data = new DecoderBuffer(result);
      result = this._getUse(state.contains, input._reporterState.obj)
        ._decode(data, options);
    }
  }

  // Pop object
  if (state.obj && present)
    result = input.leaveObject(prevObj);

  // Set key
  if (state.key !== null && (result !== null || present === true))
    input.leaveKey(prevKey, state.key, result);
  else if (prevKey !== null)
    input.exitKey(prevKey);

  return result;
};

Node.prototype._decodeGeneric = function decodeGeneric(tag, input, options) {
  const state = this._baseState;

  if (tag === 'seq' || tag === 'set')
    return null;
  if (tag === 'seqof' || tag === 'setof')
    return this._decodeList(input, tag, state.args[0], options);
  else if (/str$/.test(tag))
    return this._decodeStr(input, tag, options);
  else if (tag === 'objid' && state.args)
    return this._decodeObjid(input, state.args[0], state.args[1], options);
  else if (tag === 'objid')
    return this._decodeObjid(input, null, null, options);
  else if (tag === 'gentime' || tag === 'utctime')
    return this._decodeTime(input, tag, options);
  else if (tag === 'null_')
    return this._decodeNull(input, options);
  else if (tag === 'bool')
    return this._decodeBool(input, options);
  else if (tag === 'objDesc')
    return this._decodeStr(input, tag, options);
  else if (tag === 'int' || tag === 'enum')
    return this._decodeInt(input, state.args && state.args[0], options);

  if (state.use !== null) {
    return this._getUse(state.use, input._reporterState.obj)
      ._decode(input, options);
  } else {
    return input.error('unknown tag: ' + tag);
  }
};

Node.prototype._getUse = function _getUse(entity, obj) {

  const state = this._baseState;
  // Create altered use decoder if implicit is set
  state.useDecoder = this._use(entity, obj);
  assert(state.useDecoder._baseState.parent === null);
  state.useDecoder = state.useDecoder._baseState.children[0];
  if (state.implicit !== state.useDecoder._baseState.implicit) {
    state.useDecoder = state.useDecoder.clone();
    state.useDecoder._baseState.implicit = state.implicit;
  }
  return state.useDecoder;
};

Node.prototype._decodeChoice = function decodeChoice(input, options) {
  const state = this._baseState;
  let result = null;
  let match = false;

  Object.keys(state.choice).some(function(key) {
    const save = input.save();
    const node = state.choice[key];
    try {
      const value = node._decode(input, options);
      if (input.isError(value))
        return false;

      result = { type: key, value: value };
      match = true;
    } catch (e) {
      input.restore(save);
      return false;
    }
    return true;
  }, this);

  if (!match)
    return input.error('Choice not matched');

  return result;
};

//
// Encoding
//

Node.prototype._createEncoderBuffer = function createEncoderBuffer(data) {
  return new EncoderBuffer(data, this.reporter);
};

Node.prototype._encode = function encode(data, reporter, parent) {
  const state = this._baseState;
  if (state['default'] !== null && state['default'] === data)
    return;

  const result = this._encodeValue(data, reporter, parent);
  if (result === undefined)
    return;

  if (this._skipDefault(result, reporter, parent))
    return;

  return result;
};

Node.prototype._encodeValue = function encode(data, reporter, parent) {
  const state = this._baseState;

  // Decode root node
  if (state.parent === null)
    return state.children[0]._encode(data, reporter || new Reporter());

  let result = null;

  // Set reporter to share it with a child class
  this.reporter = reporter;

  // Check if data is there
  if (state.optional && data === undefined) {
    if (state['default'] !== null)
      data = state['default'];
    else
      return;
  }

  // Encode children first
  let content = null;
  let primitive = false;
  if (state.any) {
    // Anything that was given is translated to buffer
    result = this._createEncoderBuffer(data);
  } else if (state.choice) {
    result = this._encodeChoice(data, reporter);
  } else if (state.contains) {
    content = this._getUse(state.contains, parent)._encode(data, reporter);
    primitive = true;
  } else if (state.children) {
    content = state.children.map(function(child) {
      if (child._baseState.tag === 'null_')
        return child._encode(null, reporter, data);

      if (child._baseState.key === null)
        return reporter.error('Child should have a key');
      const prevKey = reporter.enterKey(child._baseState.key);

      if (typeof data !== 'object')
        return reporter.error('Child expected, but input is not object');

      const res = child._encode(data[child._baseState.key], reporter, data);
      reporter.leaveKey(prevKey);

      return res;
    }, this).filter(function(child) {
      return child;
    });
    content = this._createEncoderBuffer(content);
  } else {
    if (state.tag === 'seqof' || state.tag === 'setof') {
      // TODO(indutny): this should be thrown on DSL level
      if (!(state.args && state.args.length === 1))
        return reporter.error('Too many args for : ' + state.tag);

      if (!Array.isArray(data))
        return reporter.error('seqof/setof, but data is not Array');

      const child = this.clone();
      child._baseState.implicit = null;
      content = this._createEncoderBuffer(data.map(function(item) {
        const state = this._baseState;

        return this._getUse(state.args[0], data)._encode(item, reporter);
      }, child));
    } else if (state.use !== null) {
      result = this._getUse(state.use, parent)._encode(data, reporter);
    } else {
      content = this._encodePrimitive(state.tag, data);
      primitive = true;
    }
  }

  // Encode data itself
  if (!state.any && state.choice === null) {
    const tag = state.implicit !== null ? state.implicit : state.tag;
    const cls = state.implicit === null ? 'universal' : 'context';

    if (tag === null) {
      if (state.use === null)
        reporter.error('Tag could be omitted only for .use()');
    } else {
      if (state.use === null)
        result = this._encodeComposite(tag, primitive, cls, content);
    }
  }

  // Wrap in explicit
  if (state.explicit !== null)
    result = this._encodeComposite(state.explicit, false, 'context', result);

  return result;
};

Node.prototype._encodeChoice = function encodeChoice(data, reporter) {
  const state = this._baseState;

  const node = state.choice[data.type];
  if (!node) {
    assert(
      false,
      data.type + ' not found in ' +
            JSON.stringify(Object.keys(state.choice)));
  }
  return node._encode(data.value, reporter);
};

Node.prototype._encodePrimitive = function encodePrimitive(tag, data) {
  const state = this._baseState;

  if (/str$/.test(tag))
    return this._encodeStr(data, tag);
  else if (tag === 'objid' && state.args)
    return this._encodeObjid(data, state.reverseArgs[0], state.args[1]);
  else if (tag === 'objid')
    return this._encodeObjid(data, null, null);
  else if (tag === 'gentime' || tag === 'utctime')
    return this._encodeTime(data, tag);
  else if (tag === 'null_')
    return this._encodeNull();
  else if (tag === 'int' || tag === 'enum')
    return this._encodeInt(data, state.args && state.reverseArgs[0]);
  else if (tag === 'bool')
    return this._encodeBool(data);
  else if (tag === 'objDesc')
    return this._encodeStr(data, tag);
  else
    throw new Error('Unsupported tag: ' + tag);
};

Node.prototype._isNumstr = function isNumstr(str) {
  return /^[0-9 ]*$/.test(str);
};

Node.prototype._isPrintstr = function isPrintstr(str) {
  return /^[A-Za-z0-9 '()+,-./:=?]*$/.test(str);
};

},{"../base/buffer":29,"../base/reporter":32,"minimalistic-assert":164}],32:[function(require,module,exports){
'use strict';

const inherits = require('inherits');

function Reporter(options) {
  this._reporterState = {
    obj: null,
    path: [],
    options: options || {},
    errors: []
  };
}
exports.Reporter = Reporter;

Reporter.prototype.isError = function isError(obj) {
  return obj instanceof ReporterError;
};

Reporter.prototype.save = function save() {
  const state = this._reporterState;

  return { obj: state.obj, pathLen: state.path.length };
};

Reporter.prototype.restore = function restore(data) {
  const state = this._reporterState;

  state.obj = data.obj;
  state.path = state.path.slice(0, data.pathLen);
};

Reporter.prototype.enterKey = function enterKey(key) {
  return this._reporterState.path.push(key);
};

Reporter.prototype.exitKey = function exitKey(index) {
  const state = this._reporterState;

  state.path = state.path.slice(0, index - 1);
};

Reporter.prototype.leaveKey = function leaveKey(index, key, value) {
  const state = this._reporterState;

  this.exitKey(index);
  if (state.obj !== null)
    state.obj[key] = value;
};

Reporter.prototype.path = function path() {
  return this._reporterState.path.join('/');
};

Reporter.prototype.enterObject = function enterObject() {
  const state = this._reporterState;

  const prev = state.obj;
  state.obj = {};
  return prev;
};

Reporter.prototype.leaveObject = function leaveObject(prev) {
  const state = this._reporterState;

  const now = state.obj;
  state.obj = prev;
  return now;
};

Reporter.prototype.error = function error(msg) {
  let err;
  const state = this._reporterState;

  const inherited = msg instanceof ReporterError;
  if (inherited) {
    err = msg;
  } else {
    err = new ReporterError(state.path.map(function(elem) {
      return '[' + JSON.stringify(elem) + ']';
    }).join(''), msg.message || msg, msg.stack);
  }

  if (!state.options.partial)
    throw err;

  if (!inherited)
    state.errors.push(err);

  return err;
};

Reporter.prototype.wrapResult = function wrapResult(result) {
  const state = this._reporterState;
  if (!state.options.partial)
    return result;

  return {
    result: this.isError(result) ? null : result,
    errors: state.errors
  };
};

function ReporterError(path, msg) {
  this.path = path;
  this.rethrow(msg);
}
inherits(ReporterError, Error);

ReporterError.prototype.rethrow = function rethrow(msg) {
  this.message = msg + ' at: ' + (this.path || '(shallow)');
  if (Error.captureStackTrace)
    Error.captureStackTrace(this, ReporterError);

  if (!this.stack) {
    try {
      // IE only adds stack when thrown
      throw new Error(this.message);
    } catch (e) {
      this.stack = e.stack;
    }
  }
  return this;
};

},{"inherits":136}],33:[function(require,module,exports){
'use strict';

// Helper
function reverse(map) {
  const res = {};

  Object.keys(map).forEach(function(key) {
    // Convert key to integer if it is stringified
    if ((key | 0) == key)
      key = key | 0;

    const value = map[key];
    res[value] = key;
  });

  return res;
}

exports.tagClass = {
  0: 'universal',
  1: 'application',
  2: 'context',
  3: 'private'
};
exports.tagClassByName = reverse(exports.tagClass);

exports.tag = {
  0x00: 'end',
  0x01: 'bool',
  0x02: 'int',
  0x03: 'bitstr',
  0x04: 'octstr',
  0x05: 'null_',
  0x06: 'objid',
  0x07: 'objDesc',
  0x08: 'external',
  0x09: 'real',
  0x0a: 'enum',
  0x0b: 'embed',
  0x0c: 'utf8str',
  0x0d: 'relativeOid',
  0x10: 'seq',
  0x11: 'set',
  0x12: 'numstr',
  0x13: 'printstr',
  0x14: 't61str',
  0x15: 'videostr',
  0x16: 'ia5str',
  0x17: 'utctime',
  0x18: 'gentime',
  0x19: 'graphstr',
  0x1a: 'iso646str',
  0x1b: 'genstr',
  0x1c: 'unistr',
  0x1d: 'charstr',
  0x1e: 'bmpstr'
};
exports.tagByName = reverse(exports.tag);

},{}],34:[function(require,module,exports){
'use strict';

const constants = exports;

// Helper
constants._reverse = function reverse(map) {
  const res = {};

  Object.keys(map).forEach(function(key) {
    // Convert key to integer if it is stringified
    if ((key | 0) == key)
      key = key | 0;

    const value = map[key];
    res[value] = key;
  });

  return res;
};

constants.der = require('./der');

},{"./der":33}],35:[function(require,module,exports){
'use strict';

const inherits = require('inherits');

const bignum = require('bn.js');
const DecoderBuffer = require('../base/buffer').DecoderBuffer;
const Node = require('../base/node');

// Import DER constants
const der = require('../constants/der');

function DERDecoder(entity) {
  this.enc = 'der';
  this.name = entity.name;
  this.entity = entity;

  // Construct base tree
  this.tree = new DERNode();
  this.tree._init(entity.body);
}
module.exports = DERDecoder;

DERDecoder.prototype.decode = function decode(data, options) {
  if (!DecoderBuffer.isDecoderBuffer(data)) {
    data = new DecoderBuffer(data, options);
  }

  return this.tree._decode(data, options);
};

// Tree methods

function DERNode(parent) {
  Node.call(this, 'der', parent);
}
inherits(DERNode, Node);

DERNode.prototype._peekTag = function peekTag(buffer, tag, any) {
  if (buffer.isEmpty())
    return false;

  const state = buffer.save();
  const decodedTag = derDecodeTag(buffer, 'Failed to peek tag: "' + tag + '"');
  if (buffer.isError(decodedTag))
    return decodedTag;

  buffer.restore(state);

  return decodedTag.tag === tag || decodedTag.tagStr === tag ||
    (decodedTag.tagStr + 'of') === tag || any;
};

DERNode.prototype._decodeTag = function decodeTag(buffer, tag, any) {
  const decodedTag = derDecodeTag(buffer,
    'Failed to decode tag of "' + tag + '"');
  if (buffer.isError(decodedTag))
    return decodedTag;

  let len = derDecodeLen(buffer,
    decodedTag.primitive,
    'Failed to get length of "' + tag + '"');

  // Failure
  if (buffer.isError(len))
    return len;

  if (!any &&
      decodedTag.tag !== tag &&
      decodedTag.tagStr !== tag &&
      decodedTag.tagStr + 'of' !== tag) {
    return buffer.error('Failed to match tag: "' + tag + '"');
  }

  if (decodedTag.primitive || len !== null)
    return buffer.skip(len, 'Failed to match body of: "' + tag + '"');

  // Indefinite length... find END tag
  const state = buffer.save();
  const res = this._skipUntilEnd(
    buffer,
    'Failed to skip indefinite length body: "' + this.tag + '"');
  if (buffer.isError(res))
    return res;

  len = buffer.offset - state.offset;
  buffer.restore(state);
  return buffer.skip(len, 'Failed to match body of: "' + tag + '"');
};

DERNode.prototype._skipUntilEnd = function skipUntilEnd(buffer, fail) {
  for (;;) {
    const tag = derDecodeTag(buffer, fail);
    if (buffer.isError(tag))
      return tag;
    const len = derDecodeLen(buffer, tag.primitive, fail);
    if (buffer.isError(len))
      return len;

    let res;
    if (tag.primitive || len !== null)
      res = buffer.skip(len);
    else
      res = this._skipUntilEnd(buffer, fail);

    // Failure
    if (buffer.isError(res))
      return res;

    if (tag.tagStr === 'end')
      break;
  }
};

DERNode.prototype._decodeList = function decodeList(buffer, tag, decoder,
  options) {
  const result = [];
  while (!buffer.isEmpty()) {
    const possibleEnd = this._peekTag(buffer, 'end');
    if (buffer.isError(possibleEnd))
      return possibleEnd;

    const res = decoder.decode(buffer, 'der', options);
    if (buffer.isError(res) && possibleEnd)
      break;
    result.push(res);
  }
  return result;
};

DERNode.prototype._decodeStr = function decodeStr(buffer, tag) {
  if (tag === 'bitstr') {
    const unused = buffer.readUInt8();
    if (buffer.isError(unused))
      return unused;
    return { unused: unused, data: buffer.raw() };
  } else if (tag === 'bmpstr') {
    const raw = buffer.raw();
    if (raw.length % 2 === 1)
      return buffer.error('Decoding of string type: bmpstr length mismatch');

    let str = '';
    for (let i = 0; i < raw.length / 2; i++) {
      str += String.fromCharCode(raw.readUInt16BE(i * 2));
    }
    return str;
  } else if (tag === 'numstr') {
    const numstr = buffer.raw().toString('ascii');
    if (!this._isNumstr(numstr)) {
      return buffer.error('Decoding of string type: ' +
                          'numstr unsupported characters');
    }
    return numstr;
  } else if (tag === 'octstr') {
    return buffer.raw();
  } else if (tag === 'objDesc') {
    return buffer.raw();
  } else if (tag === 'printstr') {
    const printstr = buffer.raw().toString('ascii');
    if (!this._isPrintstr(printstr)) {
      return buffer.error('Decoding of string type: ' +
                          'printstr unsupported characters');
    }
    return printstr;
  } else if (/str$/.test(tag)) {
    return buffer.raw().toString();
  } else {
    return buffer.error('Decoding of string type: ' + tag + ' unsupported');
  }
};

DERNode.prototype._decodeObjid = function decodeObjid(buffer, values, relative) {
  let result;
  const identifiers = [];
  let ident = 0;
  let subident = 0;
  while (!buffer.isEmpty()) {
    subident = buffer.readUInt8();
    ident <<= 7;
    ident |= subident & 0x7f;
    if ((subident & 0x80) === 0) {
      identifiers.push(ident);
      ident = 0;
    }
  }
  if (subident & 0x80)
    identifiers.push(ident);

  const first = (identifiers[0] / 40) | 0;
  const second = identifiers[0] % 40;

  if (relative)
    result = identifiers;
  else
    result = [first, second].concat(identifiers.slice(1));

  if (values) {
    let tmp = values[result.join(' ')];
    if (tmp === undefined)
      tmp = values[result.join('.')];
    if (tmp !== undefined)
      result = tmp;
  }

  return result;
};

DERNode.prototype._decodeTime = function decodeTime(buffer, tag) {
  const str = buffer.raw().toString();

  let year;
  let mon;
  let day;
  let hour;
  let min;
  let sec;
  if (tag === 'gentime') {
    year = str.slice(0, 4) | 0;
    mon = str.slice(4, 6) | 0;
    day = str.slice(6, 8) | 0;
    hour = str.slice(8, 10) | 0;
    min = str.slice(10, 12) | 0;
    sec = str.slice(12, 14) | 0;
  } else if (tag === 'utctime') {
    year = str.slice(0, 2) | 0;
    mon = str.slice(2, 4) | 0;
    day = str.slice(4, 6) | 0;
    hour = str.slice(6, 8) | 0;
    min = str.slice(8, 10) | 0;
    sec = str.slice(10, 12) | 0;
    if (year < 70)
      year = 2000 + year;
    else
      year = 1900 + year;
  } else {
    return buffer.error('Decoding ' + tag + ' time is not supported yet');
  }

  return Date.UTC(year, mon - 1, day, hour, min, sec, 0);
};

DERNode.prototype._decodeNull = function decodeNull() {
  return null;
};

DERNode.prototype._decodeBool = function decodeBool(buffer) {
  const res = buffer.readUInt8();
  if (buffer.isError(res))
    return res;
  else
    return res !== 0;
};

DERNode.prototype._decodeInt = function decodeInt(buffer, values) {
  // Bigint, return as it is (assume big endian)
  const raw = buffer.raw();
  let res = new bignum(raw);

  if (values)
    res = values[res.toString(10)] || res;

  return res;
};

DERNode.prototype._use = function use(entity, obj) {
  if (typeof entity === 'function')
    entity = entity(obj);
  return entity._getDecoder('der').tree;
};

// Utility methods

function derDecodeTag(buf, fail) {
  let tag = buf.readUInt8(fail);
  if (buf.isError(tag))
    return tag;

  const cls = der.tagClass[tag >> 6];
  const primitive = (tag & 0x20) === 0;

  // Multi-octet tag - load
  if ((tag & 0x1f) === 0x1f) {
    let oct = tag;
    tag = 0;
    while ((oct & 0x80) === 0x80) {
      oct = buf.readUInt8(fail);
      if (buf.isError(oct))
        return oct;

      tag <<= 7;
      tag |= oct & 0x7f;
    }
  } else {
    tag &= 0x1f;
  }
  const tagStr = der.tag[tag];

  return {
    cls: cls,
    primitive: primitive,
    tag: tag,
    tagStr: tagStr
  };
}

function derDecodeLen(buf, primitive, fail) {
  let len = buf.readUInt8(fail);
  if (buf.isError(len))
    return len;

  // Indefinite form
  if (!primitive && len === 0x80)
    return null;

  // Definite form
  if ((len & 0x80) === 0) {
    // Short form
    return len;
  }

  // Long form
  const num = len & 0x7f;
  if (num > 4)
    return buf.error('length octect is too long');

  len = 0;
  for (let i = 0; i < num; i++) {
    len <<= 8;
    const j = buf.readUInt8(fail);
    if (buf.isError(j))
      return j;
    len |= j;
  }

  return len;
}

},{"../base/buffer":29,"../base/node":31,"../constants/der":33,"bn.js":41,"inherits":136}],36:[function(require,module,exports){
'use strict';

const decoders = exports;

decoders.der = require('./der');
decoders.pem = require('./pem');

},{"./der":35,"./pem":37}],37:[function(require,module,exports){
'use strict';

const inherits = require('inherits');
const Buffer = require('safer-buffer').Buffer;

const DERDecoder = require('./der');

function PEMDecoder(entity) {
  DERDecoder.call(this, entity);
  this.enc = 'pem';
}
inherits(PEMDecoder, DERDecoder);
module.exports = PEMDecoder;

PEMDecoder.prototype.decode = function decode(data, options) {
  const lines = data.toString().split(/[\r\n]+/g);

  const label = options.label.toUpperCase();

  const re = /^-----(BEGIN|END) ([^-]+)-----$/;
  let start = -1;
  let end = -1;
  for (let i = 0; i < lines.length; i++) {
    const match = lines[i].match(re);
    if (match === null)
      continue;

    if (match[2] !== label)
      continue;

    if (start === -1) {
      if (match[1] !== 'BEGIN')
        break;
      start = i;
    } else {
      if (match[1] !== 'END')
        break;
      end = i;
      break;
    }
  }
  if (start === -1 || end === -1)
    throw new Error('PEM section not found for: ' + label);

  const base64 = lines.slice(start + 1, end).join('');
  // Remove excessive symbols
  base64.replace(/[^a-z0-9+/=]+/gi, '');

  const input = Buffer.from(base64, 'base64');
  return DERDecoder.prototype.decode.call(this, input, options);
};

},{"./der":35,"inherits":136,"safer-buffer":216}],38:[function(require,module,exports){
'use strict';

const inherits = require('inherits');
const Buffer = require('safer-buffer').Buffer;
const Node = require('../base/node');

// Import DER constants
const der = require('../constants/der');

function DEREncoder(entity) {
  this.enc = 'der';
  this.name = entity.name;
  this.entity = entity;

  // Construct base tree
  this.tree = new DERNode();
  this.tree._init(entity.body);
}
module.exports = DEREncoder;

DEREncoder.prototype.encode = function encode(data, reporter) {
  return this.tree._encode(data, reporter).join();
};

// Tree methods

function DERNode(parent) {
  Node.call(this, 'der', parent);
}
inherits(DERNode, Node);

DERNode.prototype._encodeComposite = function encodeComposite(tag,
  primitive,
  cls,
  content) {
  const encodedTag = encodeTag(tag, primitive, cls, this.reporter);

  // Short form
  if (content.length < 0x80) {
    const header = Buffer.alloc(2);
    header[0] = encodedTag;
    header[1] = content.length;
    return this._createEncoderBuffer([ header, content ]);
  }

  // Long form
  // Count octets required to store length
  let lenOctets = 1;
  for (let i = content.length; i >= 0x100; i >>= 8)
    lenOctets++;

  const header = Buffer.alloc(1 + 1 + lenOctets);
  header[0] = encodedTag;
  header[1] = 0x80 | lenOctets;

  for (let i = 1 + lenOctets, j = content.length; j > 0; i--, j >>= 8)
    header[i] = j & 0xff;

  return this._createEncoderBuffer([ header, content ]);
};

DERNode.prototype._encodeStr = function encodeStr(str, tag) {
  if (tag === 'bitstr') {
    return this._createEncoderBuffer([ str.unused | 0, str.data ]);
  } else if (tag === 'bmpstr') {
    const buf = Buffer.alloc(str.length * 2);
    for (let i = 0; i < str.length; i++) {
      buf.writeUInt16BE(str.charCodeAt(i), i * 2);
    }
    return this._createEncoderBuffer(buf);
  } else if (tag === 'numstr') {
    if (!this._isNumstr(str)) {
      return this.reporter.error('Encoding of string type: numstr supports ' +
                                 'only digits and space');
    }
    return this._createEncoderBuffer(str);
  } else if (tag === 'printstr') {
    if (!this._isPrintstr(str)) {
      return this.reporter.error('Encoding of string type: printstr supports ' +
                                 'only latin upper and lower case letters, ' +
                                 'digits, space, apostrophe, left and rigth ' +
                                 'parenthesis, plus sign, comma, hyphen, ' +
                                 'dot, slash, colon, equal sign, ' +
                                 'question mark');
    }
    return this._createEncoderBuffer(str);
  } else if (/str$/.test(tag)) {
    return this._createEncoderBuffer(str);
  } else if (tag === 'objDesc') {
    return this._createEncoderBuffer(str);
  } else {
    return this.reporter.error('Encoding of string type: ' + tag +
                               ' unsupported');
  }
};

DERNode.prototype._encodeObjid = function encodeObjid(id, values, relative) {
  if (typeof id === 'string') {
    if (!values)
      return this.reporter.error('string objid given, but no values map found');
    if (!values.hasOwnProperty(id))
      return this.reporter.error('objid not found in values map');
    id = values[id].split(/[\s.]+/g);
    for (let i = 0; i < id.length; i++)
      id[i] |= 0;
  } else if (Array.isArray(id)) {
    id = id.slice();
    for (let i = 0; i < id.length; i++)
      id[i] |= 0;
  }

  if (!Array.isArray(id)) {
    return this.reporter.error('objid() should be either array or string, ' +
                               'got: ' + JSON.stringify(id));
  }

  if (!relative) {
    if (id[1] >= 40)
      return this.reporter.error('Second objid identifier OOB');
    id.splice(0, 2, id[0] * 40 + id[1]);
  }

  // Count number of octets
  let size = 0;
  for (let i = 0; i < id.length; i++) {
    let ident = id[i];
    for (size++; ident >= 0x80; ident >>= 7)
      size++;
  }

  const objid = Buffer.alloc(size);
  let offset = objid.length - 1;
  for (let i = id.length - 1; i >= 0; i--) {
    let ident = id[i];
    objid[offset--] = ident & 0x7f;
    while ((ident >>= 7) > 0)
      objid[offset--] = 0x80 | (ident & 0x7f);
  }

  return this._createEncoderBuffer(objid);
};

function two(num) {
  if (num < 10)
    return '0' + num;
  else
    return num;
}

DERNode.prototype._encodeTime = function encodeTime(time, tag) {
  let str;
  const date = new Date(time);

  if (tag === 'gentime') {
    str = [
      two(date.getUTCFullYear()),
      two(date.getUTCMonth() + 1),
      two(date.getUTCDate()),
      two(date.getUTCHours()),
      two(date.getUTCMinutes()),
      two(date.getUTCSeconds()),
      'Z'
    ].join('');
  } else if (tag === 'utctime') {
    str = [
      two(date.getUTCFullYear() % 100),
      two(date.getUTCMonth() + 1),
      two(date.getUTCDate()),
      two(date.getUTCHours()),
      two(date.getUTCMinutes()),
      two(date.getUTCSeconds()),
      'Z'
    ].join('');
  } else {
    this.reporter.error('Encoding ' + tag + ' time is not supported yet');
  }

  return this._encodeStr(str, 'octstr');
};

DERNode.prototype._encodeNull = function encodeNull() {
  return this._createEncoderBuffer('');
};

DERNode.prototype._encodeInt = function encodeInt(num, values) {
  if (typeof num === 'string') {
    if (!values)
      return this.reporter.error('String int or enum given, but no values map');
    if (!values.hasOwnProperty(num)) {
      return this.reporter.error('Values map doesn\'t contain: ' +
                                 JSON.stringify(num));
    }
    num = values[num];
  }

  // Bignum, assume big endian
  if (typeof num !== 'number' && !Buffer.isBuffer(num)) {
    const numArray = num.toArray();
    if (!num.sign && numArray[0] & 0x80) {
      numArray.unshift(0);
    }
    num = Buffer.from(numArray);
  }

  if (Buffer.isBuffer(num)) {
    let size = num.length;
    if (num.length === 0)
      size++;

    const out = Buffer.alloc(size);
    num.copy(out);
    if (num.length === 0)
      out[0] = 0;
    return this._createEncoderBuffer(out);
  }

  if (num < 0x80)
    return this._createEncoderBuffer(num);

  if (num < 0x100)
    return this._createEncoderBuffer([0, num]);

  let size = 1;
  for (let i = num; i >= 0x100; i >>= 8)
    size++;

  const out = new Array(size);
  for (let i = out.length - 1; i >= 0; i--) {
    out[i] = num & 0xff;
    num >>= 8;
  }
  if(out[0] & 0x80) {
    out.unshift(0);
  }

  return this._createEncoderBuffer(Buffer.from(out));
};

DERNode.prototype._encodeBool = function encodeBool(value) {
  return this._createEncoderBuffer(value ? 0xff : 0);
};

DERNode.prototype._use = function use(entity, obj) {
  if (typeof entity === 'function')
    entity = entity(obj);
  return entity._getEncoder('der').tree;
};

DERNode.prototype._skipDefault = function skipDefault(dataBuffer, reporter, parent) {
  const state = this._baseState;
  let i;
  if (state['default'] === null)
    return false;

  const data = dataBuffer.join();
  if (state.defaultBuffer === undefined)
    state.defaultBuffer = this._encodeValue(state['default'], reporter, parent).join();

  if (data.length !== state.defaultBuffer.length)
    return false;

  for (i=0; i < data.length; i++)
    if (data[i] !== state.defaultBuffer[i])
      return false;

  return true;
};

// Utility methods

function encodeTag(tag, primitive, cls, reporter) {
  let res;

  if (tag === 'seqof')
    tag = 'seq';
  else if (tag === 'setof')
    tag = 'set';

  if (der.tagByName.hasOwnProperty(tag))
    res = der.tagByName[tag];
  else if (typeof tag === 'number' && (tag | 0) === tag)
    res = tag;
  else
    return reporter.error('Unknown tag: ' + tag);

  if (res >= 0x1f)
    return reporter.error('Multi-octet tag encoding unsupported');

  if (!primitive)
    res |= 0x20;

  res |= (der.tagClassByName[cls || 'universal'] << 6);

  return res;
}

},{"../base/node":31,"../constants/der":33,"inherits":136,"safer-buffer":216}],39:[function(require,module,exports){
'use strict';

const encoders = exports;

encoders.der = require('./der');
encoders.pem = require('./pem');

},{"./der":38,"./pem":40}],40:[function(require,module,exports){
'use strict';

const inherits = require('inherits');

const DEREncoder = require('./der');

function PEMEncoder(entity) {
  DEREncoder.call(this, entity);
  this.enc = 'pem';
}
inherits(PEMEncoder, DEREncoder);
module.exports = PEMEncoder;

PEMEncoder.prototype.encode = function encode(data, options) {
  const buf = DEREncoder.prototype.encode.call(this, data);

  const p = buf.toString('base64');
  const out = [ '-----BEGIN ' + options.label + '-----' ];
  for (let i = 0; i < p.length; i += 64)
    out.push(p.slice(i, i + 64));
  out.push('-----END ' + options.label + '-----');
  return out.join('\n');
};

},{"./der":38,"inherits":136}],41:[function(require,module,exports){
(function (module, exports) {
  'use strict';

  // Utils
  function assert (val, msg) {
    if (!val) throw new Error(msg || 'Assertion failed');
  }

  // Could use `inherits` module, but don't want to move from single file
  // architecture yet.
  function inherits (ctor, superCtor) {
    ctor.super_ = superCtor;
    var TempCtor = function () {};
    TempCtor.prototype = superCtor.prototype;
    ctor.prototype = new TempCtor();
    ctor.prototype.constructor = ctor;
  }

  // BN

  function BN (number, base, endian) {
    if (BN.isBN(number)) {
      return number;
    }

    this.negative = 0;
    this.words = null;
    this.length = 0;

    // Reduction context
    this.red = null;

    if (number !== null) {
      if (base === 'le' || base === 'be') {
        endian = base;
        base = 10;
      }

      this._init(number || 0, base || 10, endian || 'be');
    }
  }
  if (typeof module === 'object') {
    module.exports = BN;
  } else {
    exports.BN = BN;
  }

  BN.BN = BN;
  BN.wordSize = 26;

  var Buffer;
  try {
    if (typeof window !== 'undefined' && typeof window.Buffer !== 'undefined') {
      Buffer = window.Buffer;
    } else {
      Buffer = require('buffer').Buffer;
    }
  } catch (e) {
  }

  BN.isBN = function isBN (num) {
    if (num instanceof BN) {
      return true;
    }

    return num !== null && typeof num === 'object' &&
      num.constructor.wordSize === BN.wordSize && Array.isArray(num.words);
  };

  BN.max = function max (left, right) {
    if (left.cmp(right) > 0) return left;
    return right;
  };

  BN.min = function min (left, right) {
    if (left.cmp(right) < 0) return left;
    return right;
  };

  BN.prototype._init = function init (number, base, endian) {
    if (typeof number === 'number') {
      return this._initNumber(number, base, endian);
    }

    if (typeof number === 'object') {
      return this._initArray(number, base, endian);
    }

    if (base === 'hex') {
      base = 16;
    }
    assert(base === (base | 0) && base >= 2 && base <= 36);

    number = number.toString().replace(/\s+/g, '');
    var start = 0;
    if (number[0] === '-') {
      start++;
      this.negative = 1;
    }

    if (start < number.length) {
      if (base === 16) {
        this._parseHex(number, start, endian);
      } else {
        this._parseBase(number, base, start);
        if (endian === 'le') {
          this._initArray(this.toArray(), base, endian);
        }
      }
    }
  };

  BN.prototype._initNumber = function _initNumber (number, base, endian) {
    if (number < 0) {
      this.negative = 1;
      number = -number;
    }
    if (number < 0x4000000) {
      this.words = [ number & 0x3ffffff ];
      this.length = 1;
    } else if (number < 0x10000000000000) {
      this.words = [
        number & 0x3ffffff,
        (number / 0x4000000) & 0x3ffffff
      ];
      this.length = 2;
    } else {
      assert(number < 0x20000000000000); // 2 ^ 53 (unsafe)
      this.words = [
        number & 0x3ffffff,
        (number / 0x4000000) & 0x3ffffff,
        1
      ];
      this.length = 3;
    }

    if (endian !== 'le') return;

    // Reverse the bytes
    this._initArray(this.toArray(), base, endian);
  };

  BN.prototype._initArray = function _initArray (number, base, endian) {
    // Perhaps a Uint8Array
    assert(typeof number.length === 'number');
    if (number.length <= 0) {
      this.words = [ 0 ];
      this.length = 1;
      return this;
    }

    this.length = Math.ceil(number.length / 3);
    this.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      this.words[i] = 0;
    }

    var j, w;
    var off = 0;
    if (endian === 'be') {
      for (i = number.length - 1, j = 0; i >= 0; i -= 3) {
        w = number[i] | (number[i - 1] << 8) | (number[i - 2] << 16);
        this.words[j] |= (w << off) & 0x3ffffff;
        this.words[j + 1] = (w >>> (26 - off)) & 0x3ffffff;
        off += 24;
        if (off >= 26) {
          off -= 26;
          j++;
        }
      }
    } else if (endian === 'le') {
      for (i = 0, j = 0; i < number.length; i += 3) {
        w = number[i] | (number[i + 1] << 8) | (number[i + 2] << 16);
        this.words[j] |= (w << off) & 0x3ffffff;
        this.words[j + 1] = (w >>> (26 - off)) & 0x3ffffff;
        off += 24;
        if (off >= 26) {
          off -= 26;
          j++;
        }
      }
    }
    return this.strip();
  };

  function parseHex4Bits (string, index) {
    var c = string.charCodeAt(index);
    // 'A' - 'F'
    if (c >= 65 && c <= 70) {
      return c - 55;
    // 'a' - 'f'
    } else if (c >= 97 && c <= 102) {
      return c - 87;
    // '0' - '9'
    } else {
      return (c - 48) & 0xf;
    }
  }

  function parseHexByte (string, lowerBound, index) {
    var r = parseHex4Bits(string, index);
    if (index - 1 >= lowerBound) {
      r |= parseHex4Bits(string, index - 1) << 4;
    }
    return r;
  }

  BN.prototype._parseHex = function _parseHex (number, start, endian) {
    // Create possibly bigger array to ensure that it fits the number
    this.length = Math.ceil((number.length - start) / 6);
    this.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      this.words[i] = 0;
    }

    // 24-bits chunks
    var off = 0;
    var j = 0;

    var w;
    if (endian === 'be') {
      for (i = number.length - 1; i >= start; i -= 2) {
        w = parseHexByte(number, start, i) << off;
        this.words[j] |= w & 0x3ffffff;
        if (off >= 18) {
          off -= 18;
          j += 1;
          this.words[j] |= w >>> 26;
        } else {
          off += 8;
        }
      }
    } else {
      var parseLength = number.length - start;
      for (i = parseLength % 2 === 0 ? start + 1 : start; i < number.length; i += 2) {
        w = parseHexByte(number, start, i) << off;
        this.words[j] |= w & 0x3ffffff;
        if (off >= 18) {
          off -= 18;
          j += 1;
          this.words[j] |= w >>> 26;
        } else {
          off += 8;
        }
      }
    }

    this.strip();
  };

  function parseBase (str, start, end, mul) {
    var r = 0;
    var len = Math.min(str.length, end);
    for (var i = start; i < len; i++) {
      var c = str.charCodeAt(i) - 48;

      r *= mul;

      // 'a'
      if (c >= 49) {
        r += c - 49 + 0xa;

      // 'A'
      } else if (c >= 17) {
        r += c - 17 + 0xa;

      // '0' - '9'
      } else {
        r += c;
      }
    }
    return r;
  }

  BN.prototype._parseBase = function _parseBase (number, base, start) {
    // Initialize as zero
    this.words = [ 0 ];
    this.length = 1;

    // Find length of limb in base
    for (var limbLen = 0, limbPow = 1; limbPow <= 0x3ffffff; limbPow *= base) {
      limbLen++;
    }
    limbLen--;
    limbPow = (limbPow / base) | 0;

    var total = number.length - start;
    var mod = total % limbLen;
    var end = Math.min(total, total - mod) + start;

    var word = 0;
    for (var i = start; i < end; i += limbLen) {
      word = parseBase(number, i, i + limbLen, base);

      this.imuln(limbPow);
      if (this.words[0] + word < 0x4000000) {
        this.words[0] += word;
      } else {
        this._iaddn(word);
      }
    }

    if (mod !== 0) {
      var pow = 1;
      word = parseBase(number, i, number.length, base);

      for (i = 0; i < mod; i++) {
        pow *= base;
      }

      this.imuln(pow);
      if (this.words[0] + word < 0x4000000) {
        this.words[0] += word;
      } else {
        this._iaddn(word);
      }
    }

    this.strip();
  };

  BN.prototype.copy = function copy (dest) {
    dest.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      dest.words[i] = this.words[i];
    }
    dest.length = this.length;
    dest.negative = this.negative;
    dest.red = this.red;
  };

  BN.prototype.clone = function clone () {
    var r = new BN(null);
    this.copy(r);
    return r;
  };

  BN.prototype._expand = function _expand (size) {
    while (this.length < size) {
      this.words[this.length++] = 0;
    }
    return this;
  };

  // Remove leading `0` from `this`
  BN.prototype.strip = function strip () {
    while (this.length > 1 && this.words[this.length - 1] === 0) {
      this.length--;
    }
    return this._normSign();
  };

  BN.prototype._normSign = function _normSign () {
    // -0 = 0
    if (this.length === 1 && this.words[0] === 0) {
      this.negative = 0;
    }
    return this;
  };

  BN.prototype.inspect = function inspect () {
    return (this.red ? '<BN-R: ' : '<BN: ') + this.toString(16) + '>';
  };

  /*

  var zeros = [];
  var groupSizes = [];
  var groupBases = [];

  var s = '';
  var i = -1;
  while (++i < BN.wordSize) {
    zeros[i] = s;
    s += '0';
  }
  groupSizes[0] = 0;
  groupSizes[1] = 0;
  groupBases[0] = 0;
  groupBases[1] = 0;
  var base = 2 - 1;
  while (++base < 36 + 1) {
    var groupSize = 0;
    var groupBase = 1;
    while (groupBase < (1 << BN.wordSize) / base) {
      groupBase *= base;
      groupSize += 1;
    }
    groupSizes[base] = groupSize;
    groupBases[base] = groupBase;
  }

  */

  var zeros = [
    '',
    '0',
    '00',
    '000',
    '0000',
    '00000',
    '000000',
    '0000000',
    '00000000',
    '000000000',
    '0000000000',
    '00000000000',
    '000000000000',
    '0000000000000',
    '00000000000000',
    '000000000000000',
    '0000000000000000',
    '00000000000000000',
    '000000000000000000',
    '0000000000000000000',
    '00000000000000000000',
    '000000000000000000000',
    '0000000000000000000000',
    '00000000000000000000000',
    '000000000000000000000000',
    '0000000000000000000000000'
  ];

  var groupSizes = [
    0, 0,
    25, 16, 12, 11, 10, 9, 8,
    8, 7, 7, 7, 7, 6, 6,
    6, 6, 6, 6, 6, 5, 5,
    5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5
  ];

  var groupBases = [
    0, 0,
    33554432, 43046721, 16777216, 48828125, 60466176, 40353607, 16777216,
    43046721, 10000000, 19487171, 35831808, 62748517, 7529536, 11390625,
    16777216, 24137569, 34012224, 47045881, 64000000, 4084101, 5153632,
    6436343, 7962624, 9765625, 11881376, 14348907, 17210368, 20511149,
    24300000, 28629151, 33554432, 39135393, 45435424, 52521875, 60466176
  ];

  BN.prototype.toString = function toString (base, padding) {
    base = base || 10;
    padding = padding | 0 || 1;

    var out;
    if (base === 16 || base === 'hex') {
      out = '';
      var off = 0;
      var carry = 0;
      for (var i = 0; i < this.length; i++) {
        var w = this.words[i];
        var word = (((w << off) | carry) & 0xffffff).toString(16);
        carry = (w >>> (24 - off)) & 0xffffff;
        if (carry !== 0 || i !== this.length - 1) {
          out = zeros[6 - word.length] + word + out;
        } else {
          out = word + out;
        }
        off += 2;
        if (off >= 26) {
          off -= 26;
          i--;
        }
      }
      if (carry !== 0) {
        out = carry.toString(16) + out;
      }
      while (out.length % padding !== 0) {
        out = '0' + out;
      }
      if (this.negative !== 0) {
        out = '-' + out;
      }
      return out;
    }

    if (base === (base | 0) && base >= 2 && base <= 36) {
      // var groupSize = Math.floor(BN.wordSize * Math.LN2 / Math.log(base));
      var groupSize = groupSizes[base];
      // var groupBase = Math.pow(base, groupSize);
      var groupBase = groupBases[base];
      out = '';
      var c = this.clone();
      c.negative = 0;
      while (!c.isZero()) {
        var r = c.modn(groupBase).toString(base);
        c = c.idivn(groupBase);

        if (!c.isZero()) {
          out = zeros[groupSize - r.length] + r + out;
        } else {
          out = r + out;
        }
      }
      if (this.isZero()) {
        out = '0' + out;
      }
      while (out.length % padding !== 0) {
        out = '0' + out;
      }
      if (this.negative !== 0) {
        out = '-' + out;
      }
      return out;
    }

    assert(false, 'Base should be between 2 and 36');
  };

  BN.prototype.toNumber = function toNumber () {
    var ret = this.words[0];
    if (this.length === 2) {
      ret += this.words[1] * 0x4000000;
    } else if (this.length === 3 && this.words[2] === 0x01) {
      // NOTE: at this stage it is known that the top bit is set
      ret += 0x10000000000000 + (this.words[1] * 0x4000000);
    } else if (this.length > 2) {
      assert(false, 'Number can only safely store up to 53 bits');
    }
    return (this.negative !== 0) ? -ret : ret;
  };

  BN.prototype.toJSON = function toJSON () {
    return this.toString(16);
  };

  BN.prototype.toBuffer = function toBuffer (endian, length) {
    assert(typeof Buffer !== 'undefined');
    return this.toArrayLike(Buffer, endian, length);
  };

  BN.prototype.toArray = function toArray (endian, length) {
    return this.toArrayLike(Array, endian, length);
  };

  BN.prototype.toArrayLike = function toArrayLike (ArrayType, endian, length) {
    var byteLength = this.byteLength();
    var reqLength = length || Math.max(1, byteLength);
    assert(byteLength <= reqLength, 'byte array longer than desired length');
    assert(reqLength > 0, 'Requested array length <= 0');

    this.strip();
    var littleEndian = endian === 'le';
    var res = new ArrayType(reqLength);

    var b, i;
    var q = this.clone();
    if (!littleEndian) {
      // Assume big-endian
      for (i = 0; i < reqLength - byteLength; i++) {
        res[i] = 0;
      }

      for (i = 0; !q.isZero(); i++) {
        b = q.andln(0xff);
        q.iushrn(8);

        res[reqLength - i - 1] = b;
      }
    } else {
      for (i = 0; !q.isZero(); i++) {
        b = q.andln(0xff);
        q.iushrn(8);

        res[i] = b;
      }

      for (; i < reqLength; i++) {
        res[i] = 0;
      }
    }

    return res;
  };

  if (Math.clz32) {
    BN.prototype._countBits = function _countBits (w) {
      return 32 - Math.clz32(w);
    };
  } else {
    BN.prototype._countBits = function _countBits (w) {
      var t = w;
      var r = 0;
      if (t >= 0x1000) {
        r += 13;
        t >>>= 13;
      }
      if (t >= 0x40) {
        r += 7;
        t >>>= 7;
      }
      if (t >= 0x8) {
        r += 4;
        t >>>= 4;
      }
      if (t >= 0x02) {
        r += 2;
        t >>>= 2;
      }
      return r + t;
    };
  }

  BN.prototype._zeroBits = function _zeroBits (w) {
    // Short-cut
    if (w === 0) return 26;

    var t = w;
    var r = 0;
    if ((t & 0x1fff) === 0) {
      r += 13;
      t >>>= 13;
    }
    if ((t & 0x7f) === 0) {
      r += 7;
      t >>>= 7;
    }
    if ((t & 0xf) === 0) {
      r += 4;
      t >>>= 4;
    }
    if ((t & 0x3) === 0) {
      r += 2;
      t >>>= 2;
    }
    if ((t & 0x1) === 0) {
      r++;
    }
    return r;
  };

  // Return number of used bits in a BN
  BN.prototype.bitLength = function bitLength () {
    var w = this.words[this.length - 1];
    var hi = this._countBits(w);
    return (this.length - 1) * 26 + hi;
  };

  function toBitArray (num) {
    var w = new Array(num.bitLength());

    for (var bit = 0; bit < w.length; bit++) {
      var off = (bit / 26) | 0;
      var wbit = bit % 26;

      w[bit] = (num.words[off] & (1 << wbit)) >>> wbit;
    }

    return w;
  }

  // Number of trailing zero bits
  BN.prototype.zeroBits = function zeroBits () {
    if (this.isZero()) return 0;

    var r = 0;
    for (var i = 0; i < this.length; i++) {
      var b = this._zeroBits(this.words[i]);
      r += b;
      if (b !== 26) break;
    }
    return r;
  };

  BN.prototype.byteLength = function byteLength () {
    return Math.ceil(this.bitLength() / 8);
  };

  BN.prototype.toTwos = function toTwos (width) {
    if (this.negative !== 0) {
      return this.abs().inotn(width).iaddn(1);
    }
    return this.clone();
  };

  BN.prototype.fromTwos = function fromTwos (width) {
    if (this.testn(width - 1)) {
      return this.notn(width).iaddn(1).ineg();
    }
    return this.clone();
  };

  BN.prototype.isNeg = function isNeg () {
    return this.negative !== 0;
  };

  // Return negative clone of `this`
  BN.prototype.neg = function neg () {
    return this.clone().ineg();
  };

  BN.prototype.ineg = function ineg () {
    if (!this.isZero()) {
      this.negative ^= 1;
    }

    return this;
  };

  // Or `num` with `this` in-place
  BN.prototype.iuor = function iuor (num) {
    while (this.length < num.length) {
      this.words[this.length++] = 0;
    }

    for (var i = 0; i < num.length; i++) {
      this.words[i] = this.words[i] | num.words[i];
    }

    return this.strip();
  };

  BN.prototype.ior = function ior (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuor(num);
  };

  // Or `num` with `this`
  BN.prototype.or = function or (num) {
    if (this.length > num.length) return this.clone().ior(num);
    return num.clone().ior(this);
  };

  BN.prototype.uor = function uor (num) {
    if (this.length > num.length) return this.clone().iuor(num);
    return num.clone().iuor(this);
  };

  // And `num` with `this` in-place
  BN.prototype.iuand = function iuand (num) {
    // b = min-length(num, this)
    var b;
    if (this.length > num.length) {
      b = num;
    } else {
      b = this;
    }

    for (var i = 0; i < b.length; i++) {
      this.words[i] = this.words[i] & num.words[i];
    }

    this.length = b.length;

    return this.strip();
  };

  BN.prototype.iand = function iand (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuand(num);
  };

  // And `num` with `this`
  BN.prototype.and = function and (num) {
    if (this.length > num.length) return this.clone().iand(num);
    return num.clone().iand(this);
  };

  BN.prototype.uand = function uand (num) {
    if (this.length > num.length) return this.clone().iuand(num);
    return num.clone().iuand(this);
  };

  // Xor `num` with `this` in-place
  BN.prototype.iuxor = function iuxor (num) {
    // a.length > b.length
    var a;
    var b;
    if (this.length > num.length) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    for (var i = 0; i < b.length; i++) {
      this.words[i] = a.words[i] ^ b.words[i];
    }

    if (this !== a) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    this.length = a.length;

    return this.strip();
  };

  BN.prototype.ixor = function ixor (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuxor(num);
  };

  // Xor `num` with `this`
  BN.prototype.xor = function xor (num) {
    if (this.length > num.length) return this.clone().ixor(num);
    return num.clone().ixor(this);
  };

  BN.prototype.uxor = function uxor (num) {
    if (this.length > num.length) return this.clone().iuxor(num);
    return num.clone().iuxor(this);
  };

  // Not ``this`` with ``width`` bitwidth
  BN.prototype.inotn = function inotn (width) {
    assert(typeof width === 'number' && width >= 0);

    var bytesNeeded = Math.ceil(width / 26) | 0;
    var bitsLeft = width % 26;

    // Extend the buffer with leading zeroes
    this._expand(bytesNeeded);

    if (bitsLeft > 0) {
      bytesNeeded--;
    }

    // Handle complete words
    for (var i = 0; i < bytesNeeded; i++) {
      this.words[i] = ~this.words[i] & 0x3ffffff;
    }

    // Handle the residue
    if (bitsLeft > 0) {
      this.words[i] = ~this.words[i] & (0x3ffffff >> (26 - bitsLeft));
    }

    // And remove leading zeroes
    return this.strip();
  };

  BN.prototype.notn = function notn (width) {
    return this.clone().inotn(width);
  };

  // Set `bit` of `this`
  BN.prototype.setn = function setn (bit, val) {
    assert(typeof bit === 'number' && bit >= 0);

    var off = (bit / 26) | 0;
    var wbit = bit % 26;

    this._expand(off + 1);

    if (val) {
      this.words[off] = this.words[off] | (1 << wbit);
    } else {
      this.words[off] = this.words[off] & ~(1 << wbit);
    }

    return this.strip();
  };

  // Add `num` to `this` in-place
  BN.prototype.iadd = function iadd (num) {
    var r;

    // negative + positive
    if (this.negative !== 0 && num.negative === 0) {
      this.negative = 0;
      r = this.isub(num);
      this.negative ^= 1;
      return this._normSign();

    // positive + negative
    } else if (this.negative === 0 && num.negative !== 0) {
      num.negative = 0;
      r = this.isub(num);
      num.negative = 1;
      return r._normSign();
    }

    // a.length > b.length
    var a, b;
    if (this.length > num.length) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    var carry = 0;
    for (var i = 0; i < b.length; i++) {
      r = (a.words[i] | 0) + (b.words[i] | 0) + carry;
      this.words[i] = r & 0x3ffffff;
      carry = r >>> 26;
    }
    for (; carry !== 0 && i < a.length; i++) {
      r = (a.words[i] | 0) + carry;
      this.words[i] = r & 0x3ffffff;
      carry = r >>> 26;
    }

    this.length = a.length;
    if (carry !== 0) {
      this.words[this.length] = carry;
      this.length++;
    // Copy the rest of the words
    } else if (a !== this) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    return this;
  };

  // Add `num` to `this`
  BN.prototype.add = function add (num) {
    var res;
    if (num.negative !== 0 && this.negative === 0) {
      num.negative = 0;
      res = this.sub(num);
      num.negative ^= 1;
      return res;
    } else if (num.negative === 0 && this.negative !== 0) {
      this.negative = 0;
      res = num.sub(this);
      this.negative = 1;
      return res;
    }

    if (this.length > num.length) return this.clone().iadd(num);

    return num.clone().iadd(this);
  };

  // Subtract `num` from `this` in-place
  BN.prototype.isub = function isub (num) {
    // this - (-num) = this + num
    if (num.negative !== 0) {
      num.negative = 0;
      var r = this.iadd(num);
      num.negative = 1;
      return r._normSign();

    // -this - num = -(this + num)
    } else if (this.negative !== 0) {
      this.negative = 0;
      this.iadd(num);
      this.negative = 1;
      return this._normSign();
    }

    // At this point both numbers are positive
    var cmp = this.cmp(num);

    // Optimization - zeroify
    if (cmp === 0) {
      this.negative = 0;
      this.length = 1;
      this.words[0] = 0;
      return this;
    }

    // a > b
    var a, b;
    if (cmp > 0) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    var carry = 0;
    for (var i = 0; i < b.length; i++) {
      r = (a.words[i] | 0) - (b.words[i] | 0) + carry;
      carry = r >> 26;
      this.words[i] = r & 0x3ffffff;
    }
    for (; carry !== 0 && i < a.length; i++) {
      r = (a.words[i] | 0) + carry;
      carry = r >> 26;
      this.words[i] = r & 0x3ffffff;
    }

    // Copy rest of the words
    if (carry === 0 && i < a.length && a !== this) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    this.length = Math.max(this.length, i);

    if (a !== this) {
      this.negative = 1;
    }

    return this.strip();
  };

  // Subtract `num` from `this`
  BN.prototype.sub = function sub (num) {
    return this.clone().isub(num);
  };

  function smallMulTo (self, num, out) {
    out.negative = num.negative ^ self.negative;
    var len = (self.length + num.length) | 0;
    out.length = len;
    len = (len - 1) | 0;

    // Peel one iteration (compiler can't do it, because of code complexity)
    var a = self.words[0] | 0;
    var b = num.words[0] | 0;
    var r = a * b;

    var lo = r & 0x3ffffff;
    var carry = (r / 0x4000000) | 0;
    out.words[0] = lo;

    for (var k = 1; k < len; k++) {
      // Sum all words with the same `i + j = k` and accumulate `ncarry`,
      // note that ncarry could be >= 0x3ffffff
      var ncarry = carry >>> 26;
      var rword = carry & 0x3ffffff;
      var maxJ = Math.min(k, num.length - 1);
      for (var j = Math.max(0, k - self.length + 1); j <= maxJ; j++) {
        var i = (k - j) | 0;
        a = self.words[i] | 0;
        b = num.words[j] | 0;
        r = a * b + rword;
        ncarry += (r / 0x4000000) | 0;
        rword = r & 0x3ffffff;
      }
      out.words[k] = rword | 0;
      carry = ncarry | 0;
    }
    if (carry !== 0) {
      out.words[k] = carry | 0;
    } else {
      out.length--;
    }

    return out.strip();
  }

  // TODO(indutny): it may be reasonable to omit it for users who don't need
  // to work with 256-bit numbers, otherwise it gives 20% improvement for 256-bit
  // multiplication (like elliptic secp256k1).
  var comb10MulTo = function comb10MulTo (self, num, out) {
    var a = self.words;
    var b = num.words;
    var o = out.words;
    var c = 0;
    var lo;
    var mid;
    var hi;
    var a0 = a[0] | 0;
    var al0 = a0 & 0x1fff;
    var ah0 = a0 >>> 13;
    var a1 = a[1] | 0;
    var al1 = a1 & 0x1fff;
    var ah1 = a1 >>> 13;
    var a2 = a[2] | 0;
    var al2 = a2 & 0x1fff;
    var ah2 = a2 >>> 13;
    var a3 = a[3] | 0;
    var al3 = a3 & 0x1fff;
    var ah3 = a3 >>> 13;
    var a4 = a[4] | 0;
    var al4 = a4 & 0x1fff;
    var ah4 = a4 >>> 13;
    var a5 = a[5] | 0;
    var al5 = a5 & 0x1fff;
    var ah5 = a5 >>> 13;
    var a6 = a[6] | 0;
    var al6 = a6 & 0x1fff;
    var ah6 = a6 >>> 13;
    var a7 = a[7] | 0;
    var al7 = a7 & 0x1fff;
    var ah7 = a7 >>> 13;
    var a8 = a[8] | 0;
    var al8 = a8 & 0x1fff;
    var ah8 = a8 >>> 13;
    var a9 = a[9] | 0;
    var al9 = a9 & 0x1fff;
    var ah9 = a9 >>> 13;
    var b0 = b[0] | 0;
    var bl0 = b0 & 0x1fff;
    var bh0 = b0 >>> 13;
    var b1 = b[1] | 0;
    var bl1 = b1 & 0x1fff;
    var bh1 = b1 >>> 13;
    var b2 = b[2] | 0;
    var bl2 = b2 & 0x1fff;
    var bh2 = b2 >>> 13;
    var b3 = b[3] | 0;
    var bl3 = b3 & 0x1fff;
    var bh3 = b3 >>> 13;
    var b4 = b[4] | 0;
    var bl4 = b4 & 0x1fff;
    var bh4 = b4 >>> 13;
    var b5 = b[5] | 0;
    var bl5 = b5 & 0x1fff;
    var bh5 = b5 >>> 13;
    var b6 = b[6] | 0;
    var bl6 = b6 & 0x1fff;
    var bh6 = b6 >>> 13;
    var b7 = b[7] | 0;
    var bl7 = b7 & 0x1fff;
    var bh7 = b7 >>> 13;
    var b8 = b[8] | 0;
    var bl8 = b8 & 0x1fff;
    var bh8 = b8 >>> 13;
    var b9 = b[9] | 0;
    var bl9 = b9 & 0x1fff;
    var bh9 = b9 >>> 13;

    out.negative = self.negative ^ num.negative;
    out.length = 19;
    /* k = 0 */
    lo = Math.imul(al0, bl0);
    mid = Math.imul(al0, bh0);
    mid = (mid + Math.imul(ah0, bl0)) | 0;
    hi = Math.imul(ah0, bh0);
    var w0 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w0 >>> 26)) | 0;
    w0 &= 0x3ffffff;
    /* k = 1 */
    lo = Math.imul(al1, bl0);
    mid = Math.imul(al1, bh0);
    mid = (mid + Math.imul(ah1, bl0)) | 0;
    hi = Math.imul(ah1, bh0);
    lo = (lo + Math.imul(al0, bl1)) | 0;
    mid = (mid + Math.imul(al0, bh1)) | 0;
    mid = (mid + Math.imul(ah0, bl1)) | 0;
    hi = (hi + Math.imul(ah0, bh1)) | 0;
    var w1 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w1 >>> 26)) | 0;
    w1 &= 0x3ffffff;
    /* k = 2 */
    lo = Math.imul(al2, bl0);
    mid = Math.imul(al2, bh0);
    mid = (mid + Math.imul(ah2, bl0)) | 0;
    hi = Math.imul(ah2, bh0);
    lo = (lo + Math.imul(al1, bl1)) | 0;
    mid = (mid + Math.imul(al1, bh1)) | 0;
    mid = (mid + Math.imul(ah1, bl1)) | 0;
    hi = (hi + Math.imul(ah1, bh1)) | 0;
    lo = (lo + Math.imul(al0, bl2)) | 0;
    mid = (mid + Math.imul(al0, bh2)) | 0;
    mid = (mid + Math.imul(ah0, bl2)) | 0;
    hi = (hi + Math.imul(ah0, bh2)) | 0;
    var w2 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w2 >>> 26)) | 0;
    w2 &= 0x3ffffff;
    /* k = 3 */
    lo = Math.imul(al3, bl0);
    mid = Math.imul(al3, bh0);
    mid = (mid + Math.imul(ah3, bl0)) | 0;
    hi = Math.imul(ah3, bh0);
    lo = (lo + Math.imul(al2, bl1)) | 0;
    mid = (mid + Math.imul(al2, bh1)) | 0;
    mid = (mid + Math.imul(ah2, bl1)) | 0;
    hi = (hi + Math.imul(ah2, bh1)) | 0;
    lo = (lo + Math.imul(al1, bl2)) | 0;
    mid = (mid + Math.imul(al1, bh2)) | 0;
    mid = (mid + Math.imul(ah1, bl2)) | 0;
    hi = (hi + Math.imul(ah1, bh2)) | 0;
    lo = (lo + Math.imul(al0, bl3)) | 0;
    mid = (mid + Math.imul(al0, bh3)) | 0;
    mid = (mid + Math.imul(ah0, bl3)) | 0;
    hi = (hi + Math.imul(ah0, bh3)) | 0;
    var w3 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w3 >>> 26)) | 0;
    w3 &= 0x3ffffff;
    /* k = 4 */
    lo = Math.imul(al4, bl0);
    mid = Math.imul(al4, bh0);
    mid = (mid + Math.imul(ah4, bl0)) | 0;
    hi = Math.imul(ah4, bh0);
    lo = (lo + Math.imul(al3, bl1)) | 0;
    mid = (mid + Math.imul(al3, bh1)) | 0;
    mid = (mid + Math.imul(ah3, bl1)) | 0;
    hi = (hi + Math.imul(ah3, bh1)) | 0;
    lo = (lo + Math.imul(al2, bl2)) | 0;
    mid = (mid + Math.imul(al2, bh2)) | 0;
    mid = (mid + Math.imul(ah2, bl2)) | 0;
    hi = (hi + Math.imul(ah2, bh2)) | 0;
    lo = (lo + Math.imul(al1, bl3)) | 0;
    mid = (mid + Math.imul(al1, bh3)) | 0;
    mid = (mid + Math.imul(ah1, bl3)) | 0;
    hi = (hi + Math.imul(ah1, bh3)) | 0;
    lo = (lo + Math.imul(al0, bl4)) | 0;
    mid = (mid + Math.imul(al0, bh4)) | 0;
    mid = (mid + Math.imul(ah0, bl4)) | 0;
    hi = (hi + Math.imul(ah0, bh4)) | 0;
    var w4 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w4 >>> 26)) | 0;
    w4 &= 0x3ffffff;
    /* k = 5 */
    lo = Math.imul(al5, bl0);
    mid = Math.imul(al5, bh0);
    mid = (mid + Math.imul(ah5, bl0)) | 0;
    hi = Math.imul(ah5, bh0);
    lo = (lo + Math.imul(al4, bl1)) | 0;
    mid = (mid + Math.imul(al4, bh1)) | 0;
    mid = (mid + Math.imul(ah4, bl1)) | 0;
    hi = (hi + Math.imul(ah4, bh1)) | 0;
    lo = (lo + Math.imul(al3, bl2)) | 0;
    mid = (mid + Math.imul(al3, bh2)) | 0;
    mid = (mid + Math.imul(ah3, bl2)) | 0;
    hi = (hi + Math.imul(ah3, bh2)) | 0;
    lo = (lo + Math.imul(al2, bl3)) | 0;
    mid = (mid + Math.imul(al2, bh3)) | 0;
    mid = (mid + Math.imul(ah2, bl3)) | 0;
    hi = (hi + Math.imul(ah2, bh3)) | 0;
    lo = (lo + Math.imul(al1, bl4)) | 0;
    mid = (mid + Math.imul(al1, bh4)) | 0;
    mid = (mid + Math.imul(ah1, bl4)) | 0;
    hi = (hi + Math.imul(ah1, bh4)) | 0;
    lo = (lo + Math.imul(al0, bl5)) | 0;
    mid = (mid + Math.imul(al0, bh5)) | 0;
    mid = (mid + Math.imul(ah0, bl5)) | 0;
    hi = (hi + Math.imul(ah0, bh5)) | 0;
    var w5 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w5 >>> 26)) | 0;
    w5 &= 0x3ffffff;
    /* k = 6 */
    lo = Math.imul(al6, bl0);
    mid = Math.imul(al6, bh0);
    mid = (mid + Math.imul(ah6, bl0)) | 0;
    hi = Math.imul(ah6, bh0);
    lo = (lo + Math.imul(al5, bl1)) | 0;
    mid = (mid + Math.imul(al5, bh1)) | 0;
    mid = (mid + Math.imul(ah5, bl1)) | 0;
    hi = (hi + Math.imul(ah5, bh1)) | 0;
    lo = (lo + Math.imul(al4, bl2)) | 0;
    mid = (mid + Math.imul(al4, bh2)) | 0;
    mid = (mid + Math.imul(ah4, bl2)) | 0;
    hi = (hi + Math.imul(ah4, bh2)) | 0;
    lo = (lo + Math.imul(al3, bl3)) | 0;
    mid = (mid + Math.imul(al3, bh3)) | 0;
    mid = (mid + Math.imul(ah3, bl3)) | 0;
    hi = (hi + Math.imul(ah3, bh3)) | 0;
    lo = (lo + Math.imul(al2, bl4)) | 0;
    mid = (mid + Math.imul(al2, bh4)) | 0;
    mid = (mid + Math.imul(ah2, bl4)) | 0;
    hi = (hi + Math.imul(ah2, bh4)) | 0;
    lo = (lo + Math.imul(al1, bl5)) | 0;
    mid = (mid + Math.imul(al1, bh5)) | 0;
    mid = (mid + Math.imul(ah1, bl5)) | 0;
    hi = (hi + Math.imul(ah1, bh5)) | 0;
    lo = (lo + Math.imul(al0, bl6)) | 0;
    mid = (mid + Math.imul(al0, bh6)) | 0;
    mid = (mid + Math.imul(ah0, bl6)) | 0;
    hi = (hi + Math.imul(ah0, bh6)) | 0;
    var w6 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w6 >>> 26)) | 0;
    w6 &= 0x3ffffff;
    /* k = 7 */
    lo = Math.imul(al7, bl0);
    mid = Math.imul(al7, bh0);
    mid = (mid + Math.imul(ah7, bl0)) | 0;
    hi = Math.imul(ah7, bh0);
    lo = (lo + Math.imul(al6, bl1)) | 0;
    mid = (mid + Math.imul(al6, bh1)) | 0;
    mid = (mid + Math.imul(ah6, bl1)) | 0;
    hi = (hi + Math.imul(ah6, bh1)) | 0;
    lo = (lo + Math.imul(al5, bl2)) | 0;
    mid = (mid + Math.imul(al5, bh2)) | 0;
    mid = (mid + Math.imul(ah5, bl2)) | 0;
    hi = (hi + Math.imul(ah5, bh2)) | 0;
    lo = (lo + Math.imul(al4, bl3)) | 0;
    mid = (mid + Math.imul(al4, bh3)) | 0;
    mid = (mid + Math.imul(ah4, bl3)) | 0;
    hi = (hi + Math.imul(ah4, bh3)) | 0;
    lo = (lo + Math.imul(al3, bl4)) | 0;
    mid = (mid + Math.imul(al3, bh4)) | 0;
    mid = (mid + Math.imul(ah3, bl4)) | 0;
    hi = (hi + Math.imul(ah3, bh4)) | 0;
    lo = (lo + Math.imul(al2, bl5)) | 0;
    mid = (mid + Math.imul(al2, bh5)) | 0;
    mid = (mid + Math.imul(ah2, bl5)) | 0;
    hi = (hi + Math.imul(ah2, bh5)) | 0;
    lo = (lo + Math.imul(al1, bl6)) | 0;
    mid = (mid + Math.imul(al1, bh6)) | 0;
    mid = (mid + Math.imul(ah1, bl6)) | 0;
    hi = (hi + Math.imul(ah1, bh6)) | 0;
    lo = (lo + Math.imul(al0, bl7)) | 0;
    mid = (mid + Math.imul(al0, bh7)) | 0;
    mid = (mid + Math.imul(ah0, bl7)) | 0;
    hi = (hi + Math.imul(ah0, bh7)) | 0;
    var w7 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w7 >>> 26)) | 0;
    w7 &= 0x3ffffff;
    /* k = 8 */
    lo = Math.imul(al8, bl0);
    mid = Math.imul(al8, bh0);
    mid = (mid + Math.imul(ah8, bl0)) | 0;
    hi = Math.imul(ah8, bh0);
    lo = (lo + Math.imul(al7, bl1)) | 0;
    mid = (mid + Math.imul(al7, bh1)) | 0;
    mid = (mid + Math.imul(ah7, bl1)) | 0;
    hi = (hi + Math.imul(ah7, bh1)) | 0;
    lo = (lo + Math.imul(al6, bl2)) | 0;
    mid = (mid + Math.imul(al6, bh2)) | 0;
    mid = (mid + Math.imul(ah6, bl2)) | 0;
    hi = (hi + Math.imul(ah6, bh2)) | 0;
    lo = (lo + Math.imul(al5, bl3)) | 0;
    mid = (mid + Math.imul(al5, bh3)) | 0;
    mid = (mid + Math.imul(ah5, bl3)) | 0;
    hi = (hi + Math.imul(ah5, bh3)) | 0;
    lo = (lo + Math.imul(al4, bl4)) | 0;
    mid = (mid + Math.imul(al4, bh4)) | 0;
    mid = (mid + Math.imul(ah4, bl4)) | 0;
    hi = (hi + Math.imul(ah4, bh4)) | 0;
    lo = (lo + Math.imul(al3, bl5)) | 0;
    mid = (mid + Math.imul(al3, bh5)) | 0;
    mid = (mid + Math.imul(ah3, bl5)) | 0;
    hi = (hi + Math.imul(ah3, bh5)) | 0;
    lo = (lo + Math.imul(al2, bl6)) | 0;
    mid = (mid + Math.imul(al2, bh6)) | 0;
    mid = (mid + Math.imul(ah2, bl6)) | 0;
    hi = (hi + Math.imul(ah2, bh6)) | 0;
    lo = (lo + Math.imul(al1, bl7)) | 0;
    mid = (mid + Math.imul(al1, bh7)) | 0;
    mid = (mid + Math.imul(ah1, bl7)) | 0;
    hi = (hi + Math.imul(ah1, bh7)) | 0;
    lo = (lo + Math.imul(al0, bl8)) | 0;
    mid = (mid + Math.imul(al0, bh8)) | 0;
    mid = (mid + Math.imul(ah0, bl8)) | 0;
    hi = (hi + Math.imul(ah0, bh8)) | 0;
    var w8 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w8 >>> 26)) | 0;
    w8 &= 0x3ffffff;
    /* k = 9 */
    lo = Math.imul(al9, bl0);
    mid = Math.imul(al9, bh0);
    mid = (mid + Math.imul(ah9, bl0)) | 0;
    hi = Math.imul(ah9, bh0);
    lo = (lo + Math.imul(al8, bl1)) | 0;
    mid = (mid + Math.imul(al8, bh1)) | 0;
    mid = (mid + Math.imul(ah8, bl1)) | 0;
    hi = (hi + Math.imul(ah8, bh1)) | 0;
    lo = (lo + Math.imul(al7, bl2)) | 0;
    mid = (mid + Math.imul(al7, bh2)) | 0;
    mid = (mid + Math.imul(ah7, bl2)) | 0;
    hi = (hi + Math.imul(ah7, bh2)) | 0;
    lo = (lo + Math.imul(al6, bl3)) | 0;
    mid = (mid + Math.imul(al6, bh3)) | 0;
    mid = (mid + Math.imul(ah6, bl3)) | 0;
    hi = (hi + Math.imul(ah6, bh3)) | 0;
    lo = (lo + Math.imul(al5, bl4)) | 0;
    mid = (mid + Math.imul(al5, bh4)) | 0;
    mid = (mid + Math.imul(ah5, bl4)) | 0;
    hi = (hi + Math.imul(ah5, bh4)) | 0;
    lo = (lo + Math.imul(al4, bl5)) | 0;
    mid = (mid + Math.imul(al4, bh5)) | 0;
    mid = (mid + Math.imul(ah4, bl5)) | 0;
    hi = (hi + Math.imul(ah4, bh5)) | 0;
    lo = (lo + Math.imul(al3, bl6)) | 0;
    mid = (mid + Math.imul(al3, bh6)) | 0;
    mid = (mid + Math.imul(ah3, bl6)) | 0;
    hi = (hi + Math.imul(ah3, bh6)) | 0;
    lo = (lo + Math.imul(al2, bl7)) | 0;
    mid = (mid + Math.imul(al2, bh7)) | 0;
    mid = (mid + Math.imul(ah2, bl7)) | 0;
    hi = (hi + Math.imul(ah2, bh7)) | 0;
    lo = (lo + Math.imul(al1, bl8)) | 0;
    mid = (mid + Math.imul(al1, bh8)) | 0;
    mid = (mid + Math.imul(ah1, bl8)) | 0;
    hi = (hi + Math.imul(ah1, bh8)) | 0;
    lo = (lo + Math.imul(al0, bl9)) | 0;
    mid = (mid + Math.imul(al0, bh9)) | 0;
    mid = (mid + Math.imul(ah0, bl9)) | 0;
    hi = (hi + Math.imul(ah0, bh9)) | 0;
    var w9 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w9 >>> 26)) | 0;
    w9 &= 0x3ffffff;
    /* k = 10 */
    lo = Math.imul(al9, bl1);
    mid = Math.imul(al9, bh1);
    mid = (mid + Math.imul(ah9, bl1)) | 0;
    hi = Math.imul(ah9, bh1);
    lo = (lo + Math.imul(al8, bl2)) | 0;
    mid = (mid + Math.imul(al8, bh2)) | 0;
    mid = (mid + Math.imul(ah8, bl2)) | 0;
    hi = (hi + Math.imul(ah8, bh2)) | 0;
    lo = (lo + Math.imul(al7, bl3)) | 0;
    mid = (mid + Math.imul(al7, bh3)) | 0;
    mid = (mid + Math.imul(ah7, bl3)) | 0;
    hi = (hi + Math.imul(ah7, bh3)) | 0;
    lo = (lo + Math.imul(al6, bl4)) | 0;
    mid = (mid + Math.imul(al6, bh4)) | 0;
    mid = (mid + Math.imul(ah6, bl4)) | 0;
    hi = (hi + Math.imul(ah6, bh4)) | 0;
    lo = (lo + Math.imul(al5, bl5)) | 0;
    mid = (mid + Math.imul(al5, bh5)) | 0;
    mid = (mid + Math.imul(ah5, bl5)) | 0;
    hi = (hi + Math.imul(ah5, bh5)) | 0;
    lo = (lo + Math.imul(al4, bl6)) | 0;
    mid = (mid + Math.imul(al4, bh6)) | 0;
    mid = (mid + Math.imul(ah4, bl6)) | 0;
    hi = (hi + Math.imul(ah4, bh6)) | 0;
    lo = (lo + Math.imul(al3, bl7)) | 0;
    mid = (mid + Math.imul(al3, bh7)) | 0;
    mid = (mid + Math.imul(ah3, bl7)) | 0;
    hi = (hi + Math.imul(ah3, bh7)) | 0;
    lo = (lo + Math.imul(al2, bl8)) | 0;
    mid = (mid + Math.imul(al2, bh8)) | 0;
    mid = (mid + Math.imul(ah2, bl8)) | 0;
    hi = (hi + Math.imul(ah2, bh8)) | 0;
    lo = (lo + Math.imul(al1, bl9)) | 0;
    mid = (mid + Math.imul(al1, bh9)) | 0;
    mid = (mid + Math.imul(ah1, bl9)) | 0;
    hi = (hi + Math.imul(ah1, bh9)) | 0;
    var w10 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w10 >>> 26)) | 0;
    w10 &= 0x3ffffff;
    /* k = 11 */
    lo = Math.imul(al9, bl2);
    mid = Math.imul(al9, bh2);
    mid = (mid + Math.imul(ah9, bl2)) | 0;
    hi = Math.imul(ah9, bh2);
    lo = (lo + Math.imul(al8, bl3)) | 0;
    mid = (mid + Math.imul(al8, bh3)) | 0;
    mid = (mid + Math.imul(ah8, bl3)) | 0;
    hi = (hi + Math.imul(ah8, bh3)) | 0;
    lo = (lo + Math.imul(al7, bl4)) | 0;
    mid = (mid + Math.imul(al7, bh4)) | 0;
    mid = (mid + Math.imul(ah7, bl4)) | 0;
    hi = (hi + Math.imul(ah7, bh4)) | 0;
    lo = (lo + Math.imul(al6, bl5)) | 0;
    mid = (mid + Math.imul(al6, bh5)) | 0;
    mid = (mid + Math.imul(ah6, bl5)) | 0;
    hi = (hi + Math.imul(ah6, bh5)) | 0;
    lo = (lo + Math.imul(al5, bl6)) | 0;
    mid = (mid + Math.imul(al5, bh6)) | 0;
    mid = (mid + Math.imul(ah5, bl6)) | 0;
    hi = (hi + Math.imul(ah5, bh6)) | 0;
    lo = (lo + Math.imul(al4, bl7)) | 0;
    mid = (mid + Math.imul(al4, bh7)) | 0;
    mid = (mid + Math.imul(ah4, bl7)) | 0;
    hi = (hi + Math.imul(ah4, bh7)) | 0;
    lo = (lo + Math.imul(al3, bl8)) | 0;
    mid = (mid + Math.imul(al3, bh8)) | 0;
    mid = (mid + Math.imul(ah3, bl8)) | 0;
    hi = (hi + Math.imul(ah3, bh8)) | 0;
    lo = (lo + Math.imul(al2, bl9)) | 0;
    mid = (mid + Math.imul(al2, bh9)) | 0;
    mid = (mid + Math.imul(ah2, bl9)) | 0;
    hi = (hi + Math.imul(ah2, bh9)) | 0;
    var w11 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w11 >>> 26)) | 0;
    w11 &= 0x3ffffff;
    /* k = 12 */
    lo = Math.imul(al9, bl3);
    mid = Math.imul(al9, bh3);
    mid = (mid + Math.imul(ah9, bl3)) | 0;
    hi = Math.imul(ah9, bh3);
    lo = (lo + Math.imul(al8, bl4)) | 0;
    mid = (mid + Math.imul(al8, bh4)) | 0;
    mid = (mid + Math.imul(ah8, bl4)) | 0;
    hi = (hi + Math.imul(ah8, bh4)) | 0;
    lo = (lo + Math.imul(al7, bl5)) | 0;
    mid = (mid + Math.imul(al7, bh5)) | 0;
    mid = (mid + Math.imul(ah7, bl5)) | 0;
    hi = (hi + Math.imul(ah7, bh5)) | 0;
    lo = (lo + Math.imul(al6, bl6)) | 0;
    mid = (mid + Math.imul(al6, bh6)) | 0;
    mid = (mid + Math.imul(ah6, bl6)) | 0;
    hi = (hi + Math.imul(ah6, bh6)) | 0;
    lo = (lo + Math.imul(al5, bl7)) | 0;
    mid = (mid + Math.imul(al5, bh7)) | 0;
    mid = (mid + Math.imul(ah5, bl7)) | 0;
    hi = (hi + Math.imul(ah5, bh7)) | 0;
    lo = (lo + Math.imul(al4, bl8)) | 0;
    mid = (mid + Math.imul(al4, bh8)) | 0;
    mid = (mid + Math.imul(ah4, bl8)) | 0;
    hi = (hi + Math.imul(ah4, bh8)) | 0;
    lo = (lo + Math.imul(al3, bl9)) | 0;
    mid = (mid + Math.imul(al3, bh9)) | 0;
    mid = (mid + Math.imul(ah3, bl9)) | 0;
    hi = (hi + Math.imul(ah3, bh9)) | 0;
    var w12 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w12 >>> 26)) | 0;
    w12 &= 0x3ffffff;
    /* k = 13 */
    lo = Math.imul(al9, bl4);
    mid = Math.imul(al9, bh4);
    mid = (mid + Math.imul(ah9, bl4)) | 0;
    hi = Math.imul(ah9, bh4);
    lo = (lo + Math.imul(al8, bl5)) | 0;
    mid = (mid + Math.imul(al8, bh5)) | 0;
    mid = (mid + Math.imul(ah8, bl5)) | 0;
    hi = (hi + Math.imul(ah8, bh5)) | 0;
    lo = (lo + Math.imul(al7, bl6)) | 0;
    mid = (mid + Math.imul(al7, bh6)) | 0;
    mid = (mid + Math.imul(ah7, bl6)) | 0;
    hi = (hi + Math.imul(ah7, bh6)) | 0;
    lo = (lo + Math.imul(al6, bl7)) | 0;
    mid = (mid + Math.imul(al6, bh7)) | 0;
    mid = (mid + Math.imul(ah6, bl7)) | 0;
    hi = (hi + Math.imul(ah6, bh7)) | 0;
    lo = (lo + Math.imul(al5, bl8)) | 0;
    mid = (mid + Math.imul(al5, bh8)) | 0;
    mid = (mid + Math.imul(ah5, bl8)) | 0;
    hi = (hi + Math.imul(ah5, bh8)) | 0;
    lo = (lo + Math.imul(al4, bl9)) | 0;
    mid = (mid + Math.imul(al4, bh9)) | 0;
    mid = (mid + Math.imul(ah4, bl9)) | 0;
    hi = (hi + Math.imul(ah4, bh9)) | 0;
    var w13 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w13 >>> 26)) | 0;
    w13 &= 0x3ffffff;
    /* k = 14 */
    lo = Math.imul(al9, bl5);
    mid = Math.imul(al9, bh5);
    mid = (mid + Math.imul(ah9, bl5)) | 0;
    hi = Math.imul(ah9, bh5);
    lo = (lo + Math.imul(al8, bl6)) | 0;
    mid = (mid + Math.imul(al8, bh6)) | 0;
    mid = (mid + Math.imul(ah8, bl6)) | 0;
    hi = (hi + Math.imul(ah8, bh6)) | 0;
    lo = (lo + Math.imul(al7, bl7)) | 0;
    mid = (mid + Math.imul(al7, bh7)) | 0;
    mid = (mid + Math.imul(ah7, bl7)) | 0;
    hi = (hi + Math.imul(ah7, bh7)) | 0;
    lo = (lo + Math.imul(al6, bl8)) | 0;
    mid = (mid + Math.imul(al6, bh8)) | 0;
    mid = (mid + Math.imul(ah6, bl8)) | 0;
    hi = (hi + Math.imul(ah6, bh8)) | 0;
    lo = (lo + Math.imul(al5, bl9)) | 0;
    mid = (mid + Math.imul(al5, bh9)) | 0;
    mid = (mid + Math.imul(ah5, bl9)) | 0;
    hi = (hi + Math.imul(ah5, bh9)) | 0;
    var w14 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w14 >>> 26)) | 0;
    w14 &= 0x3ffffff;
    /* k = 15 */
    lo = Math.imul(al9, bl6);
    mid = Math.imul(al9, bh6);
    mid = (mid + Math.imul(ah9, bl6)) | 0;
    hi = Math.imul(ah9, bh6);
    lo = (lo + Math.imul(al8, bl7)) | 0;
    mid = (mid + Math.imul(al8, bh7)) | 0;
    mid = (mid + Math.imul(ah8, bl7)) | 0;
    hi = (hi + Math.imul(ah8, bh7)) | 0;
    lo = (lo + Math.imul(al7, bl8)) | 0;
    mid = (mid + Math.imul(al7, bh8)) | 0;
    mid = (mid + Math.imul(ah7, bl8)) | 0;
    hi = (hi + Math.imul(ah7, bh8)) | 0;
    lo = (lo + Math.imul(al6, bl9)) | 0;
    mid = (mid + Math.imul(al6, bh9)) | 0;
    mid = (mid + Math.imul(ah6, bl9)) | 0;
    hi = (hi + Math.imul(ah6, bh9)) | 0;
    var w15 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w15 >>> 26)) | 0;
    w15 &= 0x3ffffff;
    /* k = 16 */
    lo = Math.imul(al9, bl7);
    mid = Math.imul(al9, bh7);
    mid = (mid + Math.imul(ah9, bl7)) | 0;
    hi = Math.imul(ah9, bh7);
    lo = (lo + Math.imul(al8, bl8)) | 0;
    mid = (mid + Math.imul(al8, bh8)) | 0;
    mid = (mid + Math.imul(ah8, bl8)) | 0;
    hi = (hi + Math.imul(ah8, bh8)) | 0;
    lo = (lo + Math.imul(al7, bl9)) | 0;
    mid = (mid + Math.imul(al7, bh9)) | 0;
    mid = (mid + Math.imul(ah7, bl9)) | 0;
    hi = (hi + Math.imul(ah7, bh9)) | 0;
    var w16 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w16 >>> 26)) | 0;
    w16 &= 0x3ffffff;
    /* k = 17 */
    lo = Math.imul(al9, bl8);
    mid = Math.imul(al9, bh8);
    mid = (mid + Math.imul(ah9, bl8)) | 0;
    hi = Math.imul(ah9, bh8);
    lo = (lo + Math.imul(al8, bl9)) | 0;
    mid = (mid + Math.imul(al8, bh9)) | 0;
    mid = (mid + Math.imul(ah8, bl9)) | 0;
    hi = (hi + Math.imul(ah8, bh9)) | 0;
    var w17 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w17 >>> 26)) | 0;
    w17 &= 0x3ffffff;
    /* k = 18 */
    lo = Math.imul(al9, bl9);
    mid = Math.imul(al9, bh9);
    mid = (mid + Math.imul(ah9, bl9)) | 0;
    hi = Math.imul(ah9, bh9);
    var w18 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w18 >>> 26)) | 0;
    w18 &= 0x3ffffff;
    o[0] = w0;
    o[1] = w1;
    o[2] = w2;
    o[3] = w3;
    o[4] = w4;
    o[5] = w5;
    o[6] = w6;
    o[7] = w7;
    o[8] = w8;
    o[9] = w9;
    o[10] = w10;
    o[11] = w11;
    o[12] = w12;
    o[13] = w13;
    o[14] = w14;
    o[15] = w15;
    o[16] = w16;
    o[17] = w17;
    o[18] = w18;
    if (c !== 0) {
      o[19] = c;
      out.length++;
    }
    return out;
  };

  // Polyfill comb
  if (!Math.imul) {
    comb10MulTo = smallMulTo;
  }

  function bigMulTo (self, num, out) {
    out.negative = num.negative ^ self.negative;
    out.length = self.length + num.length;

    var carry = 0;
    var hncarry = 0;
    for (var k = 0; k < out.length - 1; k++) {
      // Sum all words with the same `i + j = k` and accumulate `ncarry`,
      // note that ncarry could be >= 0x3ffffff
      var ncarry = hncarry;
      hncarry = 0;
      var rword = carry & 0x3ffffff;
      var maxJ = Math.min(k, num.length - 1);
      for (var j = Math.max(0, k - self.length + 1); j <= maxJ; j++) {
        var i = k - j;
        var a = self.words[i] | 0;
        var b = num.words[j] | 0;
        var r = a * b;

        var lo = r & 0x3ffffff;
        ncarry = (ncarry + ((r / 0x4000000) | 0)) | 0;
        lo = (lo + rword) | 0;
        rword = lo & 0x3ffffff;
        ncarry = (ncarry + (lo >>> 26)) | 0;

        hncarry += ncarry >>> 26;
        ncarry &= 0x3ffffff;
      }
      out.words[k] = rword;
      carry = ncarry;
      ncarry = hncarry;
    }
    if (carry !== 0) {
      out.words[k] = carry;
    } else {
      out.length--;
    }

    return out.strip();
  }

  function jumboMulTo (self, num, out) {
    var fftm = new FFTM();
    return fftm.mulp(self, num, out);
  }

  BN.prototype.mulTo = function mulTo (num, out) {
    var res;
    var len = this.length + num.length;
    if (this.length === 10 && num.length === 10) {
      res = comb10MulTo(this, num, out);
    } else if (len < 63) {
      res = smallMulTo(this, num, out);
    } else if (len < 1024) {
      res = bigMulTo(this, num, out);
    } else {
      res = jumboMulTo(this, num, out);
    }

    return res;
  };

  // Cooley-Tukey algorithm for FFT
  // slightly revisited to rely on looping instead of recursion

  function FFTM (x, y) {
    this.x = x;
    this.y = y;
  }

  FFTM.prototype.makeRBT = function makeRBT (N) {
    var t = new Array(N);
    var l = BN.prototype._countBits(N) - 1;
    for (var i = 0; i < N; i++) {
      t[i] = this.revBin(i, l, N);
    }

    return t;
  };

  // Returns binary-reversed representation of `x`
  FFTM.prototype.revBin = function revBin (x, l, N) {
    if (x === 0 || x === N - 1) return x;

    var rb = 0;
    for (var i = 0; i < l; i++) {
      rb |= (x & 1) << (l - i - 1);
      x >>= 1;
    }

    return rb;
  };

  // Performs "tweedling" phase, therefore 'emulating'
  // behaviour of the recursive algorithm
  FFTM.prototype.permute = function permute (rbt, rws, iws, rtws, itws, N) {
    for (var i = 0; i < N; i++) {
      rtws[i] = rws[rbt[i]];
      itws[i] = iws[rbt[i]];
    }
  };

  FFTM.prototype.transform = function transform (rws, iws, rtws, itws, N, rbt) {
    this.permute(rbt, rws, iws, rtws, itws, N);

    for (var s = 1; s < N; s <<= 1) {
      var l = s << 1;

      var rtwdf = Math.cos(2 * Math.PI / l);
      var itwdf = Math.sin(2 * Math.PI / l);

      for (var p = 0; p < N; p += l) {
        var rtwdf_ = rtwdf;
        var itwdf_ = itwdf;

        for (var j = 0; j < s; j++) {
          var re = rtws[p + j];
          var ie = itws[p + j];

          var ro = rtws[p + j + s];
          var io = itws[p + j + s];

          var rx = rtwdf_ * ro - itwdf_ * io;

          io = rtwdf_ * io + itwdf_ * ro;
          ro = rx;

          rtws[p + j] = re + ro;
          itws[p + j] = ie + io;

          rtws[p + j + s] = re - ro;
          itws[p + j + s] = ie - io;

          /* jshint maxdepth : false */
          if (j !== l) {
            rx = rtwdf * rtwdf_ - itwdf * itwdf_;

            itwdf_ = rtwdf * itwdf_ + itwdf * rtwdf_;
            rtwdf_ = rx;
          }
        }
      }
    }
  };

  FFTM.prototype.guessLen13b = function guessLen13b (n, m) {
    var N = Math.max(m, n) | 1;
    var odd = N & 1;
    var i = 0;
    for (N = N / 2 | 0; N; N = N >>> 1) {
      i++;
    }

    return 1 << i + 1 + odd;
  };

  FFTM.prototype.conjugate = function conjugate (rws, iws, N) {
    if (N <= 1) return;

    for (var i = 0; i < N / 2; i++) {
      var t = rws[i];

      rws[i] = rws[N - i - 1];
      rws[N - i - 1] = t;

      t = iws[i];

      iws[i] = -iws[N - i - 1];
      iws[N - i - 1] = -t;
    }
  };

  FFTM.prototype.normalize13b = function normalize13b (ws, N) {
    var carry = 0;
    for (var i = 0; i < N / 2; i++) {
      var w = Math.round(ws[2 * i + 1] / N) * 0x2000 +
        Math.round(ws[2 * i] / N) +
        carry;

      ws[i] = w & 0x3ffffff;

      if (w < 0x4000000) {
        carry = 0;
      } else {
        carry = w / 0x4000000 | 0;
      }
    }

    return ws;
  };

  FFTM.prototype.convert13b = function convert13b (ws, len, rws, N) {
    var carry = 0;
    for (var i = 0; i < len; i++) {
      carry = carry + (ws[i] | 0);

      rws[2 * i] = carry & 0x1fff; carry = carry >>> 13;
      rws[2 * i + 1] = carry & 0x1fff; carry = carry >>> 13;
    }

    // Pad with zeroes
    for (i = 2 * len; i < N; ++i) {
      rws[i] = 0;
    }

    assert(carry === 0);
    assert((carry & ~0x1fff) === 0);
  };

  FFTM.prototype.stub = function stub (N) {
    var ph = new Array(N);
    for (var i = 0; i < N; i++) {
      ph[i] = 0;
    }

    return ph;
  };

  FFTM.prototype.mulp = function mulp (x, y, out) {
    var N = 2 * this.guessLen13b(x.length, y.length);

    var rbt = this.makeRBT(N);

    var _ = this.stub(N);

    var rws = new Array(N);
    var rwst = new Array(N);
    var iwst = new Array(N);

    var nrws = new Array(N);
    var nrwst = new Array(N);
    var niwst = new Array(N);

    var rmws = out.words;
    rmws.length = N;

    this.convert13b(x.words, x.length, rws, N);
    this.convert13b(y.words, y.length, nrws, N);

    this.transform(rws, _, rwst, iwst, N, rbt);
    this.transform(nrws, _, nrwst, niwst, N, rbt);

    for (var i = 0; i < N; i++) {
      var rx = rwst[i] * nrwst[i] - iwst[i] * niwst[i];
      iwst[i] = rwst[i] * niwst[i] + iwst[i] * nrwst[i];
      rwst[i] = rx;
    }

    this.conjugate(rwst, iwst, N);
    this.transform(rwst, iwst, rmws, _, N, rbt);
    this.conjugate(rmws, _, N);
    this.normalize13b(rmws, N);

    out.negative = x.negative ^ y.negative;
    out.length = x.length + y.length;
    return out.strip();
  };

  // Multiply `this` by `num`
  BN.prototype.mul = function mul (num) {
    var out = new BN(null);
    out.words = new Array(this.length + num.length);
    return this.mulTo(num, out);
  };

  // Multiply employing FFT
  BN.prototype.mulf = function mulf (num) {
    var out = new BN(null);
    out.words = new Array(this.length + num.length);
    return jumboMulTo(this, num, out);
  };

  // In-place Multiplication
  BN.prototype.imul = function imul (num) {
    return this.clone().mulTo(num, this);
  };

  BN.prototype.imuln = function imuln (num) {
    assert(typeof num === 'number');
    assert(num < 0x4000000);

    // Carry
    var carry = 0;
    for (var i = 0; i < this.length; i++) {
      var w = (this.words[i] | 0) * num;
      var lo = (w & 0x3ffffff) + (carry & 0x3ffffff);
      carry >>= 26;
      carry += (w / 0x4000000) | 0;
      // NOTE: lo is 27bit maximum
      carry += lo >>> 26;
      this.words[i] = lo & 0x3ffffff;
    }

    if (carry !== 0) {
      this.words[i] = carry;
      this.length++;
    }

    return this;
  };

  BN.prototype.muln = function muln (num) {
    return this.clone().imuln(num);
  };

  // `this` * `this`
  BN.prototype.sqr = function sqr () {
    return this.mul(this);
  };

  // `this` * `this` in-place
  BN.prototype.isqr = function isqr () {
    return this.imul(this.clone());
  };

  // Math.pow(`this`, `num`)
  BN.prototype.pow = function pow (num) {
    var w = toBitArray(num);
    if (w.length === 0) return new BN(1);

    // Skip leading zeroes
    var res = this;
    for (var i = 0; i < w.length; i++, res = res.sqr()) {
      if (w[i] !== 0) break;
    }

    if (++i < w.length) {
      for (var q = res.sqr(); i < w.length; i++, q = q.sqr()) {
        if (w[i] === 0) continue;

        res = res.mul(q);
      }
    }

    return res;
  };

  // Shift-left in-place
  BN.prototype.iushln = function iushln (bits) {
    assert(typeof bits === 'number' && bits >= 0);
    var r = bits % 26;
    var s = (bits - r) / 26;
    var carryMask = (0x3ffffff >>> (26 - r)) << (26 - r);
    var i;

    if (r !== 0) {
      var carry = 0;

      for (i = 0; i < this.length; i++) {
        var newCarry = this.words[i] & carryMask;
        var c = ((this.words[i] | 0) - newCarry) << r;
        this.words[i] = c | carry;
        carry = newCarry >>> (26 - r);
      }

      if (carry) {
        this.words[i] = carry;
        this.length++;
      }
    }

    if (s !== 0) {
      for (i = this.length - 1; i >= 0; i--) {
        this.words[i + s] = this.words[i];
      }

      for (i = 0; i < s; i++) {
        this.words[i] = 0;
      }

      this.length += s;
    }

    return this.strip();
  };

  BN.prototype.ishln = function ishln (bits) {
    // TODO(indutny): implement me
    assert(this.negative === 0);
    return this.iushln(bits);
  };

  // Shift-right in-place
  // NOTE: `hint` is a lowest bit before trailing zeroes
  // NOTE: if `extended` is present - it will be filled with destroyed bits
  BN.prototype.iushrn = function iushrn (bits, hint, extended) {
    assert(typeof bits === 'number' && bits >= 0);
    var h;
    if (hint) {
      h = (hint - (hint % 26)) / 26;
    } else {
      h = 0;
    }

    var r = bits % 26;
    var s = Math.min((bits - r) / 26, this.length);
    var mask = 0x3ffffff ^ ((0x3ffffff >>> r) << r);
    var maskedWords = extended;

    h -= s;
    h = Math.max(0, h);

    // Extended mode, copy masked part
    if (maskedWords) {
      for (var i = 0; i < s; i++) {
        maskedWords.words[i] = this.words[i];
      }
      maskedWords.length = s;
    }

    if (s === 0) {
      // No-op, we should not move anything at all
    } else if (this.length > s) {
      this.length -= s;
      for (i = 0; i < this.length; i++) {
        this.words[i] = this.words[i + s];
      }
    } else {
      this.words[0] = 0;
      this.length = 1;
    }

    var carry = 0;
    for (i = this.length - 1; i >= 0 && (carry !== 0 || i >= h); i--) {
      var word = this.words[i] | 0;
      this.words[i] = (carry << (26 - r)) | (word >>> r);
      carry = word & mask;
    }

    // Push carried bits as a mask
    if (maskedWords && carry !== 0) {
      maskedWords.words[maskedWords.length++] = carry;
    }

    if (this.length === 0) {
      this.words[0] = 0;
      this.length = 1;
    }

    return this.strip();
  };

  BN.prototype.ishrn = function ishrn (bits, hint, extended) {
    // TODO(indutny): implement me
    assert(this.negative === 0);
    return this.iushrn(bits, hint, extended);
  };

  // Shift-left
  BN.prototype.shln = function shln (bits) {
    return this.clone().ishln(bits);
  };

  BN.prototype.ushln = function ushln (bits) {
    return this.clone().iushln(bits);
  };

  // Shift-right
  BN.prototype.shrn = function shrn (bits) {
    return this.clone().ishrn(bits);
  };

  BN.prototype.ushrn = function ushrn (bits) {
    return this.clone().iushrn(bits);
  };

  // Test if n bit is set
  BN.prototype.testn = function testn (bit) {
    assert(typeof bit === 'number' && bit >= 0);
    var r = bit % 26;
    var s = (bit - r) / 26;
    var q = 1 << r;

    // Fast case: bit is much higher than all existing words
    if (this.length <= s) return false;

    // Check bit and return
    var w = this.words[s];

    return !!(w & q);
  };

  // Return only lowers bits of number (in-place)
  BN.prototype.imaskn = function imaskn (bits) {
    assert(typeof bits === 'number' && bits >= 0);
    var r = bits % 26;
    var s = (bits - r) / 26;

    assert(this.negative === 0, 'imaskn works only with positive numbers');

    if (this.length <= s) {
      return this;
    }

    if (r !== 0) {
      s++;
    }
    this.length = Math.min(s, this.length);

    if (r !== 0) {
      var mask = 0x3ffffff ^ ((0x3ffffff >>> r) << r);
      this.words[this.length - 1] &= mask;
    }

    return this.strip();
  };

  // Return only lowers bits of number
  BN.prototype.maskn = function maskn (bits) {
    return this.clone().imaskn(bits);
  };

  // Add plain number `num` to `this`
  BN.prototype.iaddn = function iaddn (num) {
    assert(typeof num === 'number');
    assert(num < 0x4000000);
    if (num < 0) return this.isubn(-num);

    // Possible sign change
    if (this.negative !== 0) {
      if (this.length === 1 && (this.words[0] | 0) < num) {
        this.words[0] = num - (this.words[0] | 0);
        this.negative = 0;
        return this;
      }

      this.negative = 0;
      this.isubn(num);
      this.negative = 1;
      return this;
    }

    // Add without checks
    return this._iaddn(num);
  };

  BN.prototype._iaddn = function _iaddn (num) {
    this.words[0] += num;

    // Carry
    for (var i = 0; i < this.length && this.words[i] >= 0x4000000; i++) {
      this.words[i] -= 0x4000000;
      if (i === this.length - 1) {
        this.words[i + 1] = 1;
      } else {
        this.words[i + 1]++;
      }
    }
    this.length = Math.max(this.length, i + 1);

    return this;
  };

  // Subtract plain number `num` from `this`
  BN.prototype.isubn = function isubn (num) {
    assert(typeof num === 'number');
    assert(num < 0x4000000);
    if (num < 0) return this.iaddn(-num);

    if (this.negative !== 0) {
      this.negative = 0;
      this.iaddn(num);
      this.negative = 1;
      return this;
    }

    this.words[0] -= num;

    if (this.length === 1 && this.words[0] < 0) {
      this.words[0] = -this.words[0];
      this.negative = 1;
    } else {
      // Carry
      for (var i = 0; i < this.length && this.words[i] < 0; i++) {
        this.words[i] += 0x4000000;
        this.words[i + 1] -= 1;
      }
    }

    return this.strip();
  };

  BN.prototype.addn = function addn (num) {
    return this.clone().iaddn(num);
  };

  BN.prototype.subn = function subn (num) {
    return this.clone().isubn(num);
  };

  BN.prototype.iabs = function iabs () {
    this.negative = 0;

    return this;
  };

  BN.prototype.abs = function abs () {
    return this.clone().iabs();
  };

  BN.prototype._ishlnsubmul = function _ishlnsubmul (num, mul, shift) {
    var len = num.length + shift;
    var i;

    this._expand(len);

    var w;
    var carry = 0;
    for (i = 0; i < num.length; i++) {
      w = (this.words[i + shift] | 0) + carry;
      var right = (num.words[i] | 0) * mul;
      w -= right & 0x3ffffff;
      carry = (w >> 26) - ((right / 0x4000000) | 0);
      this.words[i + shift] = w & 0x3ffffff;
    }
    for (; i < this.length - shift; i++) {
      w = (this.words[i + shift] | 0) + carry;
      carry = w >> 26;
      this.words[i + shift] = w & 0x3ffffff;
    }

    if (carry === 0) return this.strip();

    // Subtraction overflow
    assert(carry === -1);
    carry = 0;
    for (i = 0; i < this.length; i++) {
      w = -(this.words[i] | 0) + carry;
      carry = w >> 26;
      this.words[i] = w & 0x3ffffff;
    }
    this.negative = 1;

    return this.strip();
  };

  BN.prototype._wordDiv = function _wordDiv (num, mode) {
    var shift = this.length - num.length;

    var a = this.clone();
    var b = num;

    // Normalize
    var bhi = b.words[b.length - 1] | 0;
    var bhiBits = this._countBits(bhi);
    shift = 26 - bhiBits;
    if (shift !== 0) {
      b = b.ushln(shift);
      a.iushln(shift);
      bhi = b.words[b.length - 1] | 0;
    }

    // Initialize quotient
    var m = a.length - b.length;
    var q;

    if (mode !== 'mod') {
      q = new BN(null);
      q.length = m + 1;
      q.words = new Array(q.length);
      for (var i = 0; i < q.length; i++) {
        q.words[i] = 0;
      }
    }

    var diff = a.clone()._ishlnsubmul(b, 1, m);
    if (diff.negative === 0) {
      a = diff;
      if (q) {
        q.words[m] = 1;
      }
    }

    for (var j = m - 1; j >= 0; j--) {
      var qj = (a.words[b.length + j] | 0) * 0x4000000 +
        (a.words[b.length + j - 1] | 0);

      // NOTE: (qj / bhi) is (0x3ffffff * 0x4000000 + 0x3ffffff) / 0x2000000 max
      // (0x7ffffff)
      qj = Math.min((qj / bhi) | 0, 0x3ffffff);

      a._ishlnsubmul(b, qj, j);
      while (a.negative !== 0) {
        qj--;
        a.negative = 0;
        a._ishlnsubmul(b, 1, j);
        if (!a.isZero()) {
          a.negative ^= 1;
        }
      }
      if (q) {
        q.words[j] = qj;
      }
    }
    if (q) {
      q.strip();
    }
    a.strip();

    // Denormalize
    if (mode !== 'div' && shift !== 0) {
      a.iushrn(shift);
    }

    return {
      div: q || null,
      mod: a
    };
  };

  // NOTE: 1) `mode` can be set to `mod` to request mod only,
  //       to `div` to request div only, or be absent to
  //       request both div & mod
  //       2) `positive` is true if unsigned mod is requested
  BN.prototype.divmod = function divmod (num, mode, positive) {
    assert(!num.isZero());

    if (this.isZero()) {
      return {
        div: new BN(0),
        mod: new BN(0)
      };
    }

    var div, mod, res;
    if (this.negative !== 0 && num.negative === 0) {
      res = this.neg().divmod(num, mode);

      if (mode !== 'mod') {
        div = res.div.neg();
      }

      if (mode !== 'div') {
        mod = res.mod.neg();
        if (positive && mod.negative !== 0) {
          mod.iadd(num);
        }
      }

      return {
        div: div,
        mod: mod
      };
    }

    if (this.negative === 0 && num.negative !== 0) {
      res = this.divmod(num.neg(), mode);

      if (mode !== 'mod') {
        div = res.div.neg();
      }

      return {
        div: div,
        mod: res.mod
      };
    }

    if ((this.negative & num.negative) !== 0) {
      res = this.neg().divmod(num.neg(), mode);

      if (mode !== 'div') {
        mod = res.mod.neg();
        if (positive && mod.negative !== 0) {
          mod.isub(num);
        }
      }

      return {
        div: res.div,
        mod: mod
      };
    }

    // Both numbers are positive at this point

    // Strip both numbers to approximate shift value
    if (num.length > this.length || this.cmp(num) < 0) {
      return {
        div: new BN(0),
        mod: this
      };
    }

    // Very short reduction
    if (num.length === 1) {
      if (mode === 'div') {
        return {
          div: this.divn(num.words[0]),
          mod: null
        };
      }

      if (mode === 'mod') {
        return {
          div: null,
          mod: new BN(this.modn(num.words[0]))
        };
      }

      return {
        div: this.divn(num.words[0]),
        mod: new BN(this.modn(num.words[0]))
      };
    }

    return this._wordDiv(num, mode);
  };

  // Find `this` / `num`
  BN.prototype.div = function div (num) {
    return this.divmod(num, 'div', false).div;
  };

  // Find `this` % `num`
  BN.prototype.mod = function mod (num) {
    return this.divmod(num, 'mod', false).mod;
  };

  BN.prototype.umod = function umod (num) {
    return this.divmod(num, 'mod', true).mod;
  };

  // Find Round(`this` / `num`)
  BN.prototype.divRound = function divRound (num) {
    var dm = this.divmod(num);

    // Fast case - exact division
    if (dm.mod.isZero()) return dm.div;

    var mod = dm.div.negative !== 0 ? dm.mod.isub(num) : dm.mod;

    var half = num.ushrn(1);
    var r2 = num.andln(1);
    var cmp = mod.cmp(half);

    // Round down
    if (cmp < 0 || r2 === 1 && cmp === 0) return dm.div;

    // Round up
    return dm.div.negative !== 0 ? dm.div.isubn(1) : dm.div.iaddn(1);
  };

  BN.prototype.modn = function modn (num) {
    assert(num <= 0x3ffffff);
    var p = (1 << 26) % num;

    var acc = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      acc = (p * acc + (this.words[i] | 0)) % num;
    }

    return acc;
  };

  // In-place division by number
  BN.prototype.idivn = function idivn (num) {
    assert(num <= 0x3ffffff);

    var carry = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      var w = (this.words[i] | 0) + carry * 0x4000000;
      this.words[i] = (w / num) | 0;
      carry = w % num;
    }

    return this.strip();
  };

  BN.prototype.divn = function divn (num) {
    return this.clone().idivn(num);
  };

  BN.prototype.egcd = function egcd (p) {
    assert(p.negative === 0);
    assert(!p.isZero());

    var x = this;
    var y = p.clone();

    if (x.negative !== 0) {
      x = x.umod(p);
    } else {
      x = x.clone();
    }

    // A * x + B * y = x
    var A = new BN(1);
    var B = new BN(0);

    // C * x + D * y = y
    var C = new BN(0);
    var D = new BN(1);

    var g = 0;

    while (x.isEven() && y.isEven()) {
      x.iushrn(1);
      y.iushrn(1);
      ++g;
    }

    var yp = y.clone();
    var xp = x.clone();

    while (!x.isZero()) {
      for (var i = 0, im = 1; (x.words[0] & im) === 0 && i < 26; ++i, im <<= 1);
      if (i > 0) {
        x.iushrn(i);
        while (i-- > 0) {
          if (A.isOdd() || B.isOdd()) {
            A.iadd(yp);
            B.isub(xp);
          }

          A.iushrn(1);
          B.iushrn(1);
        }
      }

      for (var j = 0, jm = 1; (y.words[0] & jm) === 0 && j < 26; ++j, jm <<= 1);
      if (j > 0) {
        y.iushrn(j);
        while (j-- > 0) {
          if (C.isOdd() || D.isOdd()) {
            C.iadd(yp);
            D.isub(xp);
          }

          C.iushrn(1);
          D.iushrn(1);
        }
      }

      if (x.cmp(y) >= 0) {
        x.isub(y);
        A.isub(C);
        B.isub(D);
      } else {
        y.isub(x);
        C.isub(A);
        D.isub(B);
      }
    }

    return {
      a: C,
      b: D,
      gcd: y.iushln(g)
    };
  };

  // This is reduced incarnation of the binary EEA
  // above, designated to invert members of the
  // _prime_ fields F(p) at a maximal speed
  BN.prototype._invmp = function _invmp (p) {
    assert(p.negative === 0);
    assert(!p.isZero());

    var a = this;
    var b = p.clone();

    if (a.negative !== 0) {
      a = a.umod(p);
    } else {
      a = a.clone();
    }

    var x1 = new BN(1);
    var x2 = new BN(0);

    var delta = b.clone();

    while (a.cmpn(1) > 0 && b.cmpn(1) > 0) {
      for (var i = 0, im = 1; (a.words[0] & im) === 0 && i < 26; ++i, im <<= 1);
      if (i > 0) {
        a.iushrn(i);
        while (i-- > 0) {
          if (x1.isOdd()) {
            x1.iadd(delta);
          }

          x1.iushrn(1);
        }
      }

      for (var j = 0, jm = 1; (b.words[0] & jm) === 0 && j < 26; ++j, jm <<= 1);
      if (j > 0) {
        b.iushrn(j);
        while (j-- > 0) {
          if (x2.isOdd()) {
            x2.iadd(delta);
          }

          x2.iushrn(1);
        }
      }

      if (a.cmp(b) >= 0) {
        a.isub(b);
        x1.isub(x2);
      } else {
        b.isub(a);
        x2.isub(x1);
      }
    }

    var res;
    if (a.cmpn(1) === 0) {
      res = x1;
    } else {
      res = x2;
    }

    if (res.cmpn(0) < 0) {
      res.iadd(p);
    }

    return res;
  };

  BN.prototype.gcd = function gcd (num) {
    if (this.isZero()) return num.abs();
    if (num.isZero()) return this.abs();

    var a = this.clone();
    var b = num.clone();
    a.negative = 0;
    b.negative = 0;

    // Remove common factor of two
    for (var shift = 0; a.isEven() && b.isEven(); shift++) {
      a.iushrn(1);
      b.iushrn(1);
    }

    do {
      while (a.isEven()) {
        a.iushrn(1);
      }
      while (b.isEven()) {
        b.iushrn(1);
      }

      var r = a.cmp(b);
      if (r < 0) {
        // Swap `a` and `b` to make `a` always bigger than `b`
        var t = a;
        a = b;
        b = t;
      } else if (r === 0 || b.cmpn(1) === 0) {
        break;
      }

      a.isub(b);
    } while (true);

    return b.iushln(shift);
  };

  // Invert number in the field F(num)
  BN.prototype.invm = function invm (num) {
    return this.egcd(num).a.umod(num);
  };

  BN.prototype.isEven = function isEven () {
    return (this.words[0] & 1) === 0;
  };

  BN.prototype.isOdd = function isOdd () {
    return (this.words[0] & 1) === 1;
  };

  // And first word and num
  BN.prototype.andln = function andln (num) {
    return this.words[0] & num;
  };

  // Increment at the bit position in-line
  BN.prototype.bincn = function bincn (bit) {
    assert(typeof bit === 'number');
    var r = bit % 26;
    var s = (bit - r) / 26;
    var q = 1 << r;

    // Fast case: bit is much higher than all existing words
    if (this.length <= s) {
      this._expand(s + 1);
      this.words[s] |= q;
      return this;
    }

    // Add bit and propagate, if needed
    var carry = q;
    for (var i = s; carry !== 0 && i < this.length; i++) {
      var w = this.words[i] | 0;
      w += carry;
      carry = w >>> 26;
      w &= 0x3ffffff;
      this.words[i] = w;
    }
    if (carry !== 0) {
      this.words[i] = carry;
      this.length++;
    }
    return this;
  };

  BN.prototype.isZero = function isZero () {
    return this.length === 1 && this.words[0] === 0;
  };

  BN.prototype.cmpn = function cmpn (num) {
    var negative = num < 0;

    if (this.negative !== 0 && !negative) return -1;
    if (this.negative === 0 && negative) return 1;

    this.strip();

    var res;
    if (this.length > 1) {
      res = 1;
    } else {
      if (negative) {
        num = -num;
      }

      assert(num <= 0x3ffffff, 'Number is too big');

      var w = this.words[0] | 0;
      res = w === num ? 0 : w < num ? -1 : 1;
    }
    if (this.negative !== 0) return -res | 0;
    return res;
  };

  // Compare two numbers and return:
  // 1 - if `this` > `num`
  // 0 - if `this` == `num`
  // -1 - if `this` < `num`
  BN.prototype.cmp = function cmp (num) {
    if (this.negative !== 0 && num.negative === 0) return -1;
    if (this.negative === 0 && num.negative !== 0) return 1;

    var res = this.ucmp(num);
    if (this.negative !== 0) return -res | 0;
    return res;
  };

  // Unsigned comparison
  BN.prototype.ucmp = function ucmp (num) {
    // At this point both numbers have the same sign
    if (this.length > num.length) return 1;
    if (this.length < num.length) return -1;

    var res = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      var a = this.words[i] | 0;
      var b = num.words[i] | 0;

      if (a === b) continue;
      if (a < b) {
        res = -1;
      } else if (a > b) {
        res = 1;
      }
      break;
    }
    return res;
  };

  BN.prototype.gtn = function gtn (num) {
    return this.cmpn(num) === 1;
  };

  BN.prototype.gt = function gt (num) {
    return this.cmp(num) === 1;
  };

  BN.prototype.gten = function gten (num) {
    return this.cmpn(num) >= 0;
  };

  BN.prototype.gte = function gte (num) {
    return this.cmp(num) >= 0;
  };

  BN.prototype.ltn = function ltn (num) {
    return this.cmpn(num) === -1;
  };

  BN.prototype.lt = function lt (num) {
    return this.cmp(num) === -1;
  };

  BN.prototype.lten = function lten (num) {
    return this.cmpn(num) <= 0;
  };

  BN.prototype.lte = function lte (num) {
    return this.cmp(num) <= 0;
  };

  BN.prototype.eqn = function eqn (num) {
    return this.cmpn(num) === 0;
  };

  BN.prototype.eq = function eq (num) {
    return this.cmp(num) === 0;
  };

  //
  // A reduce context, could be using montgomery or something better, depending
  // on the `m` itself.
  //
  BN.red = function red (num) {
    return new Red(num);
  };

  BN.prototype.toRed = function toRed (ctx) {
    assert(!this.red, 'Already a number in reduction context');
    assert(this.negative === 0, 'red works only with positives');
    return ctx.convertTo(this)._forceRed(ctx);
  };

  BN.prototype.fromRed = function fromRed () {
    assert(this.red, 'fromRed works only with numbers in reduction context');
    return this.red.convertFrom(this);
  };

  BN.prototype._forceRed = function _forceRed (ctx) {
    this.red = ctx;
    return this;
  };

  BN.prototype.forceRed = function forceRed (ctx) {
    assert(!this.red, 'Already a number in reduction context');
    return this._forceRed(ctx);
  };

  BN.prototype.redAdd = function redAdd (num) {
    assert(this.red, 'redAdd works only with red numbers');
    return this.red.add(this, num);
  };

  BN.prototype.redIAdd = function redIAdd (num) {
    assert(this.red, 'redIAdd works only with red numbers');
    return this.red.iadd(this, num);
  };

  BN.prototype.redSub = function redSub (num) {
    assert(this.red, 'redSub works only with red numbers');
    return this.red.sub(this, num);
  };

  BN.prototype.redISub = function redISub (num) {
    assert(this.red, 'redISub works only with red numbers');
    return this.red.isub(this, num);
  };

  BN.prototype.redShl = function redShl (num) {
    assert(this.red, 'redShl works only with red numbers');
    return this.red.shl(this, num);
  };

  BN.prototype.redMul = function redMul (num) {
    assert(this.red, 'redMul works only with red numbers');
    this.red._verify2(this, num);
    return this.red.mul(this, num);
  };

  BN.prototype.redIMul = function redIMul (num) {
    assert(this.red, 'redMul works only with red numbers');
    this.red._verify2(this, num);
    return this.red.imul(this, num);
  };

  BN.prototype.redSqr = function redSqr () {
    assert(this.red, 'redSqr works only with red numbers');
    this.red._verify1(this);
    return this.red.sqr(this);
  };

  BN.prototype.redISqr = function redISqr () {
    assert(this.red, 'redISqr works only with red numbers');
    this.red._verify1(this);
    return this.red.isqr(this);
  };

  // Square root over p
  BN.prototype.redSqrt = function redSqrt () {
    assert(this.red, 'redSqrt works only with red numbers');
    this.red._verify1(this);
    return this.red.sqrt(this);
  };

  BN.prototype.redInvm = function redInvm () {
    assert(this.red, 'redInvm works only with red numbers');
    this.red._verify1(this);
    return this.red.invm(this);
  };

  // Return negative clone of `this` % `red modulo`
  BN.prototype.redNeg = function redNeg () {
    assert(this.red, 'redNeg works only with red numbers');
    this.red._verify1(this);
    return this.red.neg(this);
  };

  BN.prototype.redPow = function redPow (num) {
    assert(this.red && !num.red, 'redPow(normalNum)');
    this.red._verify1(this);
    return this.red.pow(this, num);
  };

  // Prime numbers with efficient reduction
  var primes = {
    k256: null,
    p224: null,
    p192: null,
    p25519: null
  };

  // Pseudo-Mersenne prime
  function MPrime (name, p) {
    // P = 2 ^ N - K
    this.name = name;
    this.p = new BN(p, 16);
    this.n = this.p.bitLength();
    this.k = new BN(1).iushln(this.n).isub(this.p);

    this.tmp = this._tmp();
  }

  MPrime.prototype._tmp = function _tmp () {
    var tmp = new BN(null);
    tmp.words = new Array(Math.ceil(this.n / 13));
    return tmp;
  };

  MPrime.prototype.ireduce = function ireduce (num) {
    // Assumes that `num` is less than `P^2`
    // num = HI * (2 ^ N - K) + HI * K + LO = HI * K + LO (mod P)
    var r = num;
    var rlen;

    do {
      this.split(r, this.tmp);
      r = this.imulK(r);
      r = r.iadd(this.tmp);
      rlen = r.bitLength();
    } while (rlen > this.n);

    var cmp = rlen < this.n ? -1 : r.ucmp(this.p);
    if (cmp === 0) {
      r.words[0] = 0;
      r.length = 1;
    } else if (cmp > 0) {
      r.isub(this.p);
    } else {
      if (r.strip !== undefined) {
        // r is BN v4 instance
        r.strip();
      } else {
        // r is BN v5 instance
        r._strip();
      }
    }

    return r;
  };

  MPrime.prototype.split = function split (input, out) {
    input.iushrn(this.n, 0, out);
  };

  MPrime.prototype.imulK = function imulK (num) {
    return num.imul(this.k);
  };

  function K256 () {
    MPrime.call(
      this,
      'k256',
      'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe fffffc2f');
  }
  inherits(K256, MPrime);

  K256.prototype.split = function split (input, output) {
    // 256 = 9 * 26 + 22
    var mask = 0x3fffff;

    var outLen = Math.min(input.length, 9);
    for (var i = 0; i < outLen; i++) {
      output.words[i] = input.words[i];
    }
    output.length = outLen;

    if (input.length <= 9) {
      input.words[0] = 0;
      input.length = 1;
      return;
    }

    // Shift by 9 limbs
    var prev = input.words[9];
    output.words[output.length++] = prev & mask;

    for (i = 10; i < input.length; i++) {
      var next = input.words[i] | 0;
      input.words[i - 10] = ((next & mask) << 4) | (prev >>> 22);
      prev = next;
    }
    prev >>>= 22;
    input.words[i - 10] = prev;
    if (prev === 0 && input.length > 10) {
      input.length -= 10;
    } else {
      input.length -= 9;
    }
  };

  K256.prototype.imulK = function imulK (num) {
    // K = 0x1000003d1 = [ 0x40, 0x3d1 ]
    num.words[num.length] = 0;
    num.words[num.length + 1] = 0;
    num.length += 2;

    // bounded at: 0x40 * 0x3ffffff + 0x3d0 = 0x100000390
    var lo = 0;
    for (var i = 0; i < num.length; i++) {
      var w = num.words[i] | 0;
      lo += w * 0x3d1;
      num.words[i] = lo & 0x3ffffff;
      lo = w * 0x40 + ((lo / 0x4000000) | 0);
    }

    // Fast length reduction
    if (num.words[num.length - 1] === 0) {
      num.length--;
      if (num.words[num.length - 1] === 0) {
        num.length--;
      }
    }
    return num;
  };

  function P224 () {
    MPrime.call(
      this,
      'p224',
      'ffffffff ffffffff ffffffff ffffffff 00000000 00000000 00000001');
  }
  inherits(P224, MPrime);

  function P192 () {
    MPrime.call(
      this,
      'p192',
      'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff');
  }
  inherits(P192, MPrime);

  function P25519 () {
    // 2 ^ 255 - 19
    MPrime.call(
      this,
      '25519',
      '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed');
  }
  inherits(P25519, MPrime);

  P25519.prototype.imulK = function imulK (num) {
    // K = 0x13
    var carry = 0;
    for (var i = 0; i < num.length; i++) {
      var hi = (num.words[i] | 0) * 0x13 + carry;
      var lo = hi & 0x3ffffff;
      hi >>>= 26;

      num.words[i] = lo;
      carry = hi;
    }
    if (carry !== 0) {
      num.words[num.length++] = carry;
    }
    return num;
  };

  // Exported mostly for testing purposes, use plain name instead
  BN._prime = function prime (name) {
    // Cached version of prime
    if (primes[name]) return primes[name];

    var prime;
    if (name === 'k256') {
      prime = new K256();
    } else if (name === 'p224') {
      prime = new P224();
    } else if (name === 'p192') {
      prime = new P192();
    } else if (name === 'p25519') {
      prime = new P25519();
    } else {
      throw new Error('Unknown prime ' + name);
    }
    primes[name] = prime;

    return prime;
  };

  //
  // Base reduction engine
  //
  function Red (m) {
    if (typeof m === 'string') {
      var prime = BN._prime(m);
      this.m = prime.p;
      this.prime = prime;
    } else {
      assert(m.gtn(1), 'modulus must be greater than 1');
      this.m = m;
      this.prime = null;
    }
  }

  Red.prototype._verify1 = function _verify1 (a) {
    assert(a.negative === 0, 'red works only with positives');
    assert(a.red, 'red works only with red numbers');
  };

  Red.prototype._verify2 = function _verify2 (a, b) {
    assert((a.negative | b.negative) === 0, 'red works only with positives');
    assert(a.red && a.red === b.red,
      'red works only with red numbers');
  };

  Red.prototype.imod = function imod (a) {
    if (this.prime) return this.prime.ireduce(a)._forceRed(this);
    return a.umod(this.m)._forceRed(this);
  };

  Red.prototype.neg = function neg (a) {
    if (a.isZero()) {
      return a.clone();
    }

    return this.m.sub(a)._forceRed(this);
  };

  Red.prototype.add = function add (a, b) {
    this._verify2(a, b);

    var res = a.add(b);
    if (res.cmp(this.m) >= 0) {
      res.isub(this.m);
    }
    return res._forceRed(this);
  };

  Red.prototype.iadd = function iadd (a, b) {
    this._verify2(a, b);

    var res = a.iadd(b);
    if (res.cmp(this.m) >= 0) {
      res.isub(this.m);
    }
    return res;
  };

  Red.prototype.sub = function sub (a, b) {
    this._verify2(a, b);

    var res = a.sub(b);
    if (res.cmpn(0) < 0) {
      res.iadd(this.m);
    }
    return res._forceRed(this);
  };

  Red.prototype.isub = function isub (a, b) {
    this._verify2(a, b);

    var res = a.isub(b);
    if (res.cmpn(0) < 0) {
      res.iadd(this.m);
    }
    return res;
  };

  Red.prototype.shl = function shl (a, num) {
    this._verify1(a);
    return this.imod(a.ushln(num));
  };

  Red.prototype.imul = function imul (a, b) {
    this._verify2(a, b);
    return this.imod(a.imul(b));
  };

  Red.prototype.mul = function mul (a, b) {
    this._verify2(a, b);
    return this.imod(a.mul(b));
  };

  Red.prototype.isqr = function isqr (a) {
    return this.imul(a, a.clone());
  };

  Red.prototype.sqr = function sqr (a) {
    return this.mul(a, a);
  };

  Red.prototype.sqrt = function sqrt (a) {
    if (a.isZero()) return a.clone();

    var mod3 = this.m.andln(3);
    assert(mod3 % 2 === 1);

    // Fast case
    if (mod3 === 3) {
      var pow = this.m.add(new BN(1)).iushrn(2);
      return this.pow(a, pow);
    }

    // Tonelli-Shanks algorithm (Totally unoptimized and slow)
    //
    // Find Q and S, that Q * 2 ^ S = (P - 1)
    var q = this.m.subn(1);
    var s = 0;
    while (!q.isZero() && q.andln(1) === 0) {
      s++;
      q.iushrn(1);
    }
    assert(!q.isZero());

    var one = new BN(1).toRed(this);
    var nOne = one.redNeg();

    // Find quadratic non-residue
    // NOTE: Max is such because of generalized Riemann hypothesis.
    var lpow = this.m.subn(1).iushrn(1);
    var z = this.m.bitLength();
    z = new BN(2 * z * z).toRed(this);

    while (this.pow(z, lpow).cmp(nOne) !== 0) {
      z.redIAdd(nOne);
    }

    var c = this.pow(z, q);
    var r = this.pow(a, q.addn(1).iushrn(1));
    var t = this.pow(a, q);
    var m = s;
    while (t.cmp(one) !== 0) {
      var tmp = t;
      for (var i = 0; tmp.cmp(one) !== 0; i++) {
        tmp = tmp.redSqr();
      }
      assert(i < m);
      var b = this.pow(c, new BN(1).iushln(m - i - 1));

      r = r.redMul(b);
      c = b.redSqr();
      t = t.redMul(c);
      m = i;
    }

    return r;
  };

  Red.prototype.invm = function invm (a) {
    var inv = a._invmp(this.m);
    if (inv.negative !== 0) {
      inv.negative = 0;
      return this.imod(inv).redNeg();
    } else {
      return this.imod(inv);
    }
  };

  Red.prototype.pow = function pow (a, num) {
    if (num.isZero()) return new BN(1).toRed(this);
    if (num.cmpn(1) === 0) return a.clone();

    var windowSize = 4;
    var wnd = new Array(1 << windowSize);
    wnd[0] = new BN(1).toRed(this);
    wnd[1] = a;
    for (var i = 2; i < wnd.length; i++) {
      wnd[i] = this.mul(wnd[i - 1], a);
    }

    var res = wnd[0];
    var current = 0;
    var currentLen = 0;
    var start = num.bitLength() % 26;
    if (start === 0) {
      start = 26;
    }

    for (i = num.length - 1; i >= 0; i--) {
      var word = num.words[i];
      for (var j = start - 1; j >= 0; j--) {
        var bit = (word >> j) & 1;
        if (res !== wnd[0]) {
          res = this.sqr(res);
        }

        if (bit === 0 && current === 0) {
          currentLen = 0;
          continue;
        }

        current <<= 1;
        current |= bit;
        currentLen++;
        if (currentLen !== windowSize && (i !== 0 || j !== 0)) continue;

        res = this.mul(res, wnd[current]);
        currentLen = 0;
        current = 0;
      }
      start = 26;
    }

    return res;
  };

  Red.prototype.convertTo = function convertTo (num) {
    var r = num.umod(this.m);

    return r === num ? r.clone() : r;
  };

  Red.prototype.convertFrom = function convertFrom (num) {
    var res = num.clone();
    res.red = null;
    return res;
  };

  //
  // Montgomery method engine
  //

  BN.mont = function mont (num) {
    return new Mont(num);
  };

  function Mont (m) {
    Red.call(this, m);

    this.shift = this.m.bitLength();
    if (this.shift % 26 !== 0) {
      this.shift += 26 - (this.shift % 26);
    }

    this.r = new BN(1).iushln(this.shift);
    this.r2 = this.imod(this.r.sqr());
    this.rinv = this.r._invmp(this.m);

    this.minv = this.rinv.mul(this.r).isubn(1).div(this.m);
    this.minv = this.minv.umod(this.r);
    this.minv = this.r.sub(this.minv);
  }
  inherits(Mont, Red);

  Mont.prototype.convertTo = function convertTo (num) {
    return this.imod(num.ushln(this.shift));
  };

  Mont.prototype.convertFrom = function convertFrom (num) {
    var r = this.imod(num.mul(this.rinv));
    r.red = null;
    return r;
  };

  Mont.prototype.imul = function imul (a, b) {
    if (a.isZero() || b.isZero()) {
      a.words[0] = 0;
      a.length = 1;
      return a;
    }

    var t = a.imul(b);
    var c = t.maskn(this.shift).mul(this.minv).imaskn(this.shift).mul(this.m);
    var u = t.isub(c).iushrn(this.shift);
    var res = u;

    if (u.cmp(this.m) >= 0) {
      res = u.isub(this.m);
    } else if (u.cmpn(0) < 0) {
      res = u.iadd(this.m);
    }

    return res._forceRed(this);
  };

  Mont.prototype.mul = function mul (a, b) {
    if (a.isZero() || b.isZero()) return new BN(0)._forceRed(this);

    var t = a.mul(b);
    var c = t.maskn(this.shift).mul(this.minv).imaskn(this.shift).mul(this.m);
    var u = t.isub(c).iushrn(this.shift);
    var res = u;
    if (u.cmp(this.m) >= 0) {
      res = u.isub(this.m);
    } else if (u.cmpn(0) < 0) {
      res = u.iadd(this.m);
    }

    return res._forceRed(this);
  };

  Mont.prototype.invm = function invm (a) {
    // (AR)^-1 * R^2 = (A^-1 * R^-1) * R^2 = A^-1 * R
    var res = this.imod(a._invmp(this.m).mul(this.r2));
    return res._forceRed(this);
  };
})(typeof module === 'undefined' || module, this);

},{"buffer":45}],42:[function(require,module,exports){
'use strict'

exports.byteLength = byteLength
exports.toByteArray = toByteArray
exports.fromByteArray = fromByteArray

var lookup = []
var revLookup = []
var Arr = typeof Uint8Array !== 'undefined' ? Uint8Array : Array

var code = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'
for (var i = 0, len = code.length; i < len; ++i) {
  lookup[i] = code[i]
  revLookup[code.charCodeAt(i)] = i
}

// Support decoding URL-safe base64 strings, as Node.js does.
// See: https://en.wikipedia.org/wiki/Base64#URL_applications
revLookup['-'.charCodeAt(0)] = 62
revLookup['_'.charCodeAt(0)] = 63

function getLens (b64) {
  var len = b64.length

  if (len % 4 > 0) {
    throw new Error('Invalid string. Length must be a multiple of 4')
  }

  // Trim off extra bytes after placeholder bytes are found
  // See: https://github.com/beatgammit/base64-js/issues/42
  var validLen = b64.indexOf('=')
  if (validLen === -1) validLen = len

  var placeHoldersLen = validLen === len
    ? 0
    : 4 - (validLen % 4)

  return [validLen, placeHoldersLen]
}

// base64 is 4/3 + up to two characters of the original data
function byteLength (b64) {
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function _byteLength (b64, validLen, placeHoldersLen) {
  return ((validLen + placeHoldersLen) * 3 / 4) - placeHoldersLen
}

function toByteArray (b64) {
  var tmp
  var lens = getLens(b64)
  var validLen = lens[0]
  var placeHoldersLen = lens[1]

  var arr = new Arr(_byteLength(b64, validLen, placeHoldersLen))

  var curByte = 0

  // if there are placeholders, only get up to the last complete 4 chars
  var len = placeHoldersLen > 0
    ? validLen - 4
    : validLen

  var i
  for (i = 0; i < len; i += 4) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 18) |
      (revLookup[b64.charCodeAt(i + 1)] << 12) |
      (revLookup[b64.charCodeAt(i + 2)] << 6) |
      revLookup[b64.charCodeAt(i + 3)]
    arr[curByte++] = (tmp >> 16) & 0xFF
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 2) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 2) |
      (revLookup[b64.charCodeAt(i + 1)] >> 4)
    arr[curByte++] = tmp & 0xFF
  }

  if (placeHoldersLen === 1) {
    tmp =
      (revLookup[b64.charCodeAt(i)] << 10) |
      (revLookup[b64.charCodeAt(i + 1)] << 4) |
      (revLookup[b64.charCodeAt(i + 2)] >> 2)
    arr[curByte++] = (tmp >> 8) & 0xFF
    arr[curByte++] = tmp & 0xFF
  }

  return arr
}

function tripletToBase64 (num) {
  return lookup[num >> 18 & 0x3F] +
    lookup[num >> 12 & 0x3F] +
    lookup[num >> 6 & 0x3F] +
    lookup[num & 0x3F]
}

function encodeChunk (uint8, start, end) {
  var tmp
  var output = []
  for (var i = start; i < end; i += 3) {
    tmp =
      ((uint8[i] << 16) & 0xFF0000) +
      ((uint8[i + 1] << 8) & 0xFF00) +
      (uint8[i + 2] & 0xFF)
    output.push(tripletToBase64(tmp))
  }
  return output.join('')
}

function fromByteArray (uint8) {
  var tmp
  var len = uint8.length
  var extraBytes = len % 3 // if we have 1 byte left, pad 2 bytes
  var parts = []
  var maxChunkLength = 16383 // must be multiple of 3

  // go through the array every three bytes, we'll deal with trailing stuff later
  for (var i = 0, len2 = len - extraBytes; i < len2; i += maxChunkLength) {
    parts.push(encodeChunk(uint8, i, (i + maxChunkLength) > len2 ? len2 : (i + maxChunkLength)))
  }

  // pad the end with zeros, but make sure to not forget the extra bytes
  if (extraBytes === 1) {
    tmp = uint8[len - 1]
    parts.push(
      lookup[tmp >> 2] +
      lookup[(tmp << 4) & 0x3F] +
      '=='
    )
  } else if (extraBytes === 2) {
    tmp = (uint8[len - 2] << 8) + uint8[len - 1]
    parts.push(
      lookup[tmp >> 10] +
      lookup[(tmp >> 4) & 0x3F] +
      lookup[(tmp << 2) & 0x3F] +
      '='
    )
  }

  return parts.join('')
}

},{}],43:[function(require,module,exports){
(function (module, exports) {
  'use strict';

  // Utils
  function assert (val, msg) {
    if (!val) throw new Error(msg || 'Assertion failed');
  }

  // Could use `inherits` module, but don't want to move from single file
  // architecture yet.
  function inherits (ctor, superCtor) {
    ctor.super_ = superCtor;
    var TempCtor = function () {};
    TempCtor.prototype = superCtor.prototype;
    ctor.prototype = new TempCtor();
    ctor.prototype.constructor = ctor;
  }

  // BN

  function BN (number, base, endian) {
    if (BN.isBN(number)) {
      return number;
    }

    this.negative = 0;
    this.words = null;
    this.length = 0;

    // Reduction context
    this.red = null;

    if (number !== null) {
      if (base === 'le' || base === 'be') {
        endian = base;
        base = 10;
      }

      this._init(number || 0, base || 10, endian || 'be');
    }
  }
  if (typeof module === 'object') {
    module.exports = BN;
  } else {
    exports.BN = BN;
  }

  BN.BN = BN;
  BN.wordSize = 26;

  var Buffer;
  try {
    if (typeof window !== 'undefined' && typeof window.Buffer !== 'undefined') {
      Buffer = window.Buffer;
    } else {
      Buffer = require('buffer').Buffer;
    }
  } catch (e) {
  }

  BN.isBN = function isBN (num) {
    if (num instanceof BN) {
      return true;
    }

    return num !== null && typeof num === 'object' &&
      num.constructor.wordSize === BN.wordSize && Array.isArray(num.words);
  };

  BN.max = function max (left, right) {
    if (left.cmp(right) > 0) return left;
    return right;
  };

  BN.min = function min (left, right) {
    if (left.cmp(right) < 0) return left;
    return right;
  };

  BN.prototype._init = function init (number, base, endian) {
    if (typeof number === 'number') {
      return this._initNumber(number, base, endian);
    }

    if (typeof number === 'object') {
      return this._initArray(number, base, endian);
    }

    if (base === 'hex') {
      base = 16;
    }
    assert(base === (base | 0) && base >= 2 && base <= 36);

    number = number.toString().replace(/\s+/g, '');
    var start = 0;
    if (number[0] === '-') {
      start++;
      this.negative = 1;
    }

    if (start < number.length) {
      if (base === 16) {
        this._parseHex(number, start, endian);
      } else {
        this._parseBase(number, base, start);
        if (endian === 'le') {
          this._initArray(this.toArray(), base, endian);
        }
      }
    }
  };

  BN.prototype._initNumber = function _initNumber (number, base, endian) {
    if (number < 0) {
      this.negative = 1;
      number = -number;
    }
    if (number < 0x4000000) {
      this.words = [number & 0x3ffffff];
      this.length = 1;
    } else if (number < 0x10000000000000) {
      this.words = [
        number & 0x3ffffff,
        (number / 0x4000000) & 0x3ffffff
      ];
      this.length = 2;
    } else {
      assert(number < 0x20000000000000); // 2 ^ 53 (unsafe)
      this.words = [
        number & 0x3ffffff,
        (number / 0x4000000) & 0x3ffffff,
        1
      ];
      this.length = 3;
    }

    if (endian !== 'le') return;

    // Reverse the bytes
    this._initArray(this.toArray(), base, endian);
  };

  BN.prototype._initArray = function _initArray (number, base, endian) {
    // Perhaps a Uint8Array
    assert(typeof number.length === 'number');
    if (number.length <= 0) {
      this.words = [0];
      this.length = 1;
      return this;
    }

    this.length = Math.ceil(number.length / 3);
    this.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      this.words[i] = 0;
    }

    var j, w;
    var off = 0;
    if (endian === 'be') {
      for (i = number.length - 1, j = 0; i >= 0; i -= 3) {
        w = number[i] | (number[i - 1] << 8) | (number[i - 2] << 16);
        this.words[j] |= (w << off) & 0x3ffffff;
        this.words[j + 1] = (w >>> (26 - off)) & 0x3ffffff;
        off += 24;
        if (off >= 26) {
          off -= 26;
          j++;
        }
      }
    } else if (endian === 'le') {
      for (i = 0, j = 0; i < number.length; i += 3) {
        w = number[i] | (number[i + 1] << 8) | (number[i + 2] << 16);
        this.words[j] |= (w << off) & 0x3ffffff;
        this.words[j + 1] = (w >>> (26 - off)) & 0x3ffffff;
        off += 24;
        if (off >= 26) {
          off -= 26;
          j++;
        }
      }
    }
    return this._strip();
  };

  function parseHex4Bits (string, index) {
    var c = string.charCodeAt(index);
    // '0' - '9'
    if (c >= 48 && c <= 57) {
      return c - 48;
    // 'A' - 'F'
    } else if (c >= 65 && c <= 70) {
      return c - 55;
    // 'a' - 'f'
    } else if (c >= 97 && c <= 102) {
      return c - 87;
    } else {
      assert(false, 'Invalid character in ' + string);
    }
  }

  function parseHexByte (string, lowerBound, index) {
    var r = parseHex4Bits(string, index);
    if (index - 1 >= lowerBound) {
      r |= parseHex4Bits(string, index - 1) << 4;
    }
    return r;
  }

  BN.prototype._parseHex = function _parseHex (number, start, endian) {
    // Create possibly bigger array to ensure that it fits the number
    this.length = Math.ceil((number.length - start) / 6);
    this.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      this.words[i] = 0;
    }

    // 24-bits chunks
    var off = 0;
    var j = 0;

    var w;
    if (endian === 'be') {
      for (i = number.length - 1; i >= start; i -= 2) {
        w = parseHexByte(number, start, i) << off;
        this.words[j] |= w & 0x3ffffff;
        if (off >= 18) {
          off -= 18;
          j += 1;
          this.words[j] |= w >>> 26;
        } else {
          off += 8;
        }
      }
    } else {
      var parseLength = number.length - start;
      for (i = parseLength % 2 === 0 ? start + 1 : start; i < number.length; i += 2) {
        w = parseHexByte(number, start, i) << off;
        this.words[j] |= w & 0x3ffffff;
        if (off >= 18) {
          off -= 18;
          j += 1;
          this.words[j] |= w >>> 26;
        } else {
          off += 8;
        }
      }
    }

    this._strip();
  };

  function parseBase (str, start, end, mul) {
    var r = 0;
    var b = 0;
    var len = Math.min(str.length, end);
    for (var i = start; i < len; i++) {
      var c = str.charCodeAt(i) - 48;

      r *= mul;

      // 'a'
      if (c >= 49) {
        b = c - 49 + 0xa;

      // 'A'
      } else if (c >= 17) {
        b = c - 17 + 0xa;

      // '0' - '9'
      } else {
        b = c;
      }
      assert(c >= 0 && b < mul, 'Invalid character');
      r += b;
    }
    return r;
  }

  BN.prototype._parseBase = function _parseBase (number, base, start) {
    // Initialize as zero
    this.words = [0];
    this.length = 1;

    // Find length of limb in base
    for (var limbLen = 0, limbPow = 1; limbPow <= 0x3ffffff; limbPow *= base) {
      limbLen++;
    }
    limbLen--;
    limbPow = (limbPow / base) | 0;

    var total = number.length - start;
    var mod = total % limbLen;
    var end = Math.min(total, total - mod) + start;

    var word = 0;
    for (var i = start; i < end; i += limbLen) {
      word = parseBase(number, i, i + limbLen, base);

      this.imuln(limbPow);
      if (this.words[0] + word < 0x4000000) {
        this.words[0] += word;
      } else {
        this._iaddn(word);
      }
    }

    if (mod !== 0) {
      var pow = 1;
      word = parseBase(number, i, number.length, base);

      for (i = 0; i < mod; i++) {
        pow *= base;
      }

      this.imuln(pow);
      if (this.words[0] + word < 0x4000000) {
        this.words[0] += word;
      } else {
        this._iaddn(word);
      }
    }

    this._strip();
  };

  BN.prototype.copy = function copy (dest) {
    dest.words = new Array(this.length);
    for (var i = 0; i < this.length; i++) {
      dest.words[i] = this.words[i];
    }
    dest.length = this.length;
    dest.negative = this.negative;
    dest.red = this.red;
  };

  function move (dest, src) {
    dest.words = src.words;
    dest.length = src.length;
    dest.negative = src.negative;
    dest.red = src.red;
  }

  BN.prototype._move = function _move (dest) {
    move(dest, this);
  };

  BN.prototype.clone = function clone () {
    var r = new BN(null);
    this.copy(r);
    return r;
  };

  BN.prototype._expand = function _expand (size) {
    while (this.length < size) {
      this.words[this.length++] = 0;
    }
    return this;
  };

  // Remove leading `0` from `this`
  BN.prototype._strip = function strip () {
    while (this.length > 1 && this.words[this.length - 1] === 0) {
      this.length--;
    }
    return this._normSign();
  };

  BN.prototype._normSign = function _normSign () {
    // -0 = 0
    if (this.length === 1 && this.words[0] === 0) {
      this.negative = 0;
    }
    return this;
  };

  // Check Symbol.for because not everywhere where Symbol defined
  // See https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Symbol#Browser_compatibility
  if (typeof Symbol !== 'undefined' && typeof Symbol.for === 'function') {
    try {
      BN.prototype[Symbol.for('nodejs.util.inspect.custom')] = inspect;
    } catch (e) {
      BN.prototype.inspect = inspect;
    }
  } else {
    BN.prototype.inspect = inspect;
  }

  function inspect () {
    return (this.red ? '<BN-R: ' : '<BN: ') + this.toString(16) + '>';
  }

  /*

  var zeros = [];
  var groupSizes = [];
  var groupBases = [];

  var s = '';
  var i = -1;
  while (++i < BN.wordSize) {
    zeros[i] = s;
    s += '0';
  }
  groupSizes[0] = 0;
  groupSizes[1] = 0;
  groupBases[0] = 0;
  groupBases[1] = 0;
  var base = 2 - 1;
  while (++base < 36 + 1) {
    var groupSize = 0;
    var groupBase = 1;
    while (groupBase < (1 << BN.wordSize) / base) {
      groupBase *= base;
      groupSize += 1;
    }
    groupSizes[base] = groupSize;
    groupBases[base] = groupBase;
  }

  */

  var zeros = [
    '',
    '0',
    '00',
    '000',
    '0000',
    '00000',
    '000000',
    '0000000',
    '00000000',
    '000000000',
    '0000000000',
    '00000000000',
    '000000000000',
    '0000000000000',
    '00000000000000',
    '000000000000000',
    '0000000000000000',
    '00000000000000000',
    '000000000000000000',
    '0000000000000000000',
    '00000000000000000000',
    '000000000000000000000',
    '0000000000000000000000',
    '00000000000000000000000',
    '000000000000000000000000',
    '0000000000000000000000000'
  ];

  var groupSizes = [
    0, 0,
    25, 16, 12, 11, 10, 9, 8,
    8, 7, 7, 7, 7, 6, 6,
    6, 6, 6, 6, 6, 5, 5,
    5, 5, 5, 5, 5, 5, 5,
    5, 5, 5, 5, 5, 5, 5
  ];

  var groupBases = [
    0, 0,
    33554432, 43046721, 16777216, 48828125, 60466176, 40353607, 16777216,
    43046721, 10000000, 19487171, 35831808, 62748517, 7529536, 11390625,
    16777216, 24137569, 34012224, 47045881, 64000000, 4084101, 5153632,
    6436343, 7962624, 9765625, 11881376, 14348907, 17210368, 20511149,
    24300000, 28629151, 33554432, 39135393, 45435424, 52521875, 60466176
  ];

  BN.prototype.toString = function toString (base, padding) {
    base = base || 10;
    padding = padding | 0 || 1;

    var out;
    if (base === 16 || base === 'hex') {
      out = '';
      var off = 0;
      var carry = 0;
      for (var i = 0; i < this.length; i++) {
        var w = this.words[i];
        var word = (((w << off) | carry) & 0xffffff).toString(16);
        carry = (w >>> (24 - off)) & 0xffffff;
        if (carry !== 0 || i !== this.length - 1) {
          out = zeros[6 - word.length] + word + out;
        } else {
          out = word + out;
        }
        off += 2;
        if (off >= 26) {
          off -= 26;
          i--;
        }
      }
      if (carry !== 0) {
        out = carry.toString(16) + out;
      }
      while (out.length % padding !== 0) {
        out = '0' + out;
      }
      if (this.negative !== 0) {
        out = '-' + out;
      }
      return out;
    }

    if (base === (base | 0) && base >= 2 && base <= 36) {
      // var groupSize = Math.floor(BN.wordSize * Math.LN2 / Math.log(base));
      var groupSize = groupSizes[base];
      // var groupBase = Math.pow(base, groupSize);
      var groupBase = groupBases[base];
      out = '';
      var c = this.clone();
      c.negative = 0;
      while (!c.isZero()) {
        var r = c.modrn(groupBase).toString(base);
        c = c.idivn(groupBase);

        if (!c.isZero()) {
          out = zeros[groupSize - r.length] + r + out;
        } else {
          out = r + out;
        }
      }
      if (this.isZero()) {
        out = '0' + out;
      }
      while (out.length % padding !== 0) {
        out = '0' + out;
      }
      if (this.negative !== 0) {
        out = '-' + out;
      }
      return out;
    }

    assert(false, 'Base should be between 2 and 36');
  };

  BN.prototype.toNumber = function toNumber () {
    var ret = this.words[0];
    if (this.length === 2) {
      ret += this.words[1] * 0x4000000;
    } else if (this.length === 3 && this.words[2] === 0x01) {
      // NOTE: at this stage it is known that the top bit is set
      ret += 0x10000000000000 + (this.words[1] * 0x4000000);
    } else if (this.length > 2) {
      assert(false, 'Number can only safely store up to 53 bits');
    }
    return (this.negative !== 0) ? -ret : ret;
  };

  BN.prototype.toJSON = function toJSON () {
    return this.toString(16, 2);
  };

  if (Buffer) {
    BN.prototype.toBuffer = function toBuffer (endian, length) {
      return this.toArrayLike(Buffer, endian, length);
    };
  }

  BN.prototype.toArray = function toArray (endian, length) {
    return this.toArrayLike(Array, endian, length);
  };

  var allocate = function allocate (ArrayType, size) {
    if (ArrayType.allocUnsafe) {
      return ArrayType.allocUnsafe(size);
    }
    return new ArrayType(size);
  };

  BN.prototype.toArrayLike = function toArrayLike (ArrayType, endian, length) {
    this._strip();

    var byteLength = this.byteLength();
    var reqLength = length || Math.max(1, byteLength);
    assert(byteLength <= reqLength, 'byte array longer than desired length');
    assert(reqLength > 0, 'Requested array length <= 0');

    var res = allocate(ArrayType, reqLength);
    var postfix = endian === 'le' ? 'LE' : 'BE';
    this['_toArrayLike' + postfix](res, byteLength);
    return res;
  };

  BN.prototype._toArrayLikeLE = function _toArrayLikeLE (res, byteLength) {
    var position = 0;
    var carry = 0;

    for (var i = 0, shift = 0; i < this.length; i++) {
      var word = (this.words[i] << shift) | carry;

      res[position++] = word & 0xff;
      if (position < res.length) {
        res[position++] = (word >> 8) & 0xff;
      }
      if (position < res.length) {
        res[position++] = (word >> 16) & 0xff;
      }

      if (shift === 6) {
        if (position < res.length) {
          res[position++] = (word >> 24) & 0xff;
        }
        carry = 0;
        shift = 0;
      } else {
        carry = word >>> 24;
        shift += 2;
      }
    }

    if (position < res.length) {
      res[position++] = carry;

      while (position < res.length) {
        res[position++] = 0;
      }
    }
  };

  BN.prototype._toArrayLikeBE = function _toArrayLikeBE (res, byteLength) {
    var position = res.length - 1;
    var carry = 0;

    for (var i = 0, shift = 0; i < this.length; i++) {
      var word = (this.words[i] << shift) | carry;

      res[position--] = word & 0xff;
      if (position >= 0) {
        res[position--] = (word >> 8) & 0xff;
      }
      if (position >= 0) {
        res[position--] = (word >> 16) & 0xff;
      }

      if (shift === 6) {
        if (position >= 0) {
          res[position--] = (word >> 24) & 0xff;
        }
        carry = 0;
        shift = 0;
      } else {
        carry = word >>> 24;
        shift += 2;
      }
    }

    if (position >= 0) {
      res[position--] = carry;

      while (position >= 0) {
        res[position--] = 0;
      }
    }
  };

  if (Math.clz32) {
    BN.prototype._countBits = function _countBits (w) {
      return 32 - Math.clz32(w);
    };
  } else {
    BN.prototype._countBits = function _countBits (w) {
      var t = w;
      var r = 0;
      if (t >= 0x1000) {
        r += 13;
        t >>>= 13;
      }
      if (t >= 0x40) {
        r += 7;
        t >>>= 7;
      }
      if (t >= 0x8) {
        r += 4;
        t >>>= 4;
      }
      if (t >= 0x02) {
        r += 2;
        t >>>= 2;
      }
      return r + t;
    };
  }

  BN.prototype._zeroBits = function _zeroBits (w) {
    // Short-cut
    if (w === 0) return 26;

    var t = w;
    var r = 0;
    if ((t & 0x1fff) === 0) {
      r += 13;
      t >>>= 13;
    }
    if ((t & 0x7f) === 0) {
      r += 7;
      t >>>= 7;
    }
    if ((t & 0xf) === 0) {
      r += 4;
      t >>>= 4;
    }
    if ((t & 0x3) === 0) {
      r += 2;
      t >>>= 2;
    }
    if ((t & 0x1) === 0) {
      r++;
    }
    return r;
  };

  // Return number of used bits in a BN
  BN.prototype.bitLength = function bitLength () {
    var w = this.words[this.length - 1];
    var hi = this._countBits(w);
    return (this.length - 1) * 26 + hi;
  };

  function toBitArray (num) {
    var w = new Array(num.bitLength());

    for (var bit = 0; bit < w.length; bit++) {
      var off = (bit / 26) | 0;
      var wbit = bit % 26;

      w[bit] = (num.words[off] >>> wbit) & 0x01;
    }

    return w;
  }

  // Number of trailing zero bits
  BN.prototype.zeroBits = function zeroBits () {
    if (this.isZero()) return 0;

    var r = 0;
    for (var i = 0; i < this.length; i++) {
      var b = this._zeroBits(this.words[i]);
      r += b;
      if (b !== 26) break;
    }
    return r;
  };

  BN.prototype.byteLength = function byteLength () {
    return Math.ceil(this.bitLength() / 8);
  };

  BN.prototype.toTwos = function toTwos (width) {
    if (this.negative !== 0) {
      return this.abs().inotn(width).iaddn(1);
    }
    return this.clone();
  };

  BN.prototype.fromTwos = function fromTwos (width) {
    if (this.testn(width - 1)) {
      return this.notn(width).iaddn(1).ineg();
    }
    return this.clone();
  };

  BN.prototype.isNeg = function isNeg () {
    return this.negative !== 0;
  };

  // Return negative clone of `this`
  BN.prototype.neg = function neg () {
    return this.clone().ineg();
  };

  BN.prototype.ineg = function ineg () {
    if (!this.isZero()) {
      this.negative ^= 1;
    }

    return this;
  };

  // Or `num` with `this` in-place
  BN.prototype.iuor = function iuor (num) {
    while (this.length < num.length) {
      this.words[this.length++] = 0;
    }

    for (var i = 0; i < num.length; i++) {
      this.words[i] = this.words[i] | num.words[i];
    }

    return this._strip();
  };

  BN.prototype.ior = function ior (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuor(num);
  };

  // Or `num` with `this`
  BN.prototype.or = function or (num) {
    if (this.length > num.length) return this.clone().ior(num);
    return num.clone().ior(this);
  };

  BN.prototype.uor = function uor (num) {
    if (this.length > num.length) return this.clone().iuor(num);
    return num.clone().iuor(this);
  };

  // And `num` with `this` in-place
  BN.prototype.iuand = function iuand (num) {
    // b = min-length(num, this)
    var b;
    if (this.length > num.length) {
      b = num;
    } else {
      b = this;
    }

    for (var i = 0; i < b.length; i++) {
      this.words[i] = this.words[i] & num.words[i];
    }

    this.length = b.length;

    return this._strip();
  };

  BN.prototype.iand = function iand (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuand(num);
  };

  // And `num` with `this`
  BN.prototype.and = function and (num) {
    if (this.length > num.length) return this.clone().iand(num);
    return num.clone().iand(this);
  };

  BN.prototype.uand = function uand (num) {
    if (this.length > num.length) return this.clone().iuand(num);
    return num.clone().iuand(this);
  };

  // Xor `num` with `this` in-place
  BN.prototype.iuxor = function iuxor (num) {
    // a.length > b.length
    var a;
    var b;
    if (this.length > num.length) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    for (var i = 0; i < b.length; i++) {
      this.words[i] = a.words[i] ^ b.words[i];
    }

    if (this !== a) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    this.length = a.length;

    return this._strip();
  };

  BN.prototype.ixor = function ixor (num) {
    assert((this.negative | num.negative) === 0);
    return this.iuxor(num);
  };

  // Xor `num` with `this`
  BN.prototype.xor = function xor (num) {
    if (this.length > num.length) return this.clone().ixor(num);
    return num.clone().ixor(this);
  };

  BN.prototype.uxor = function uxor (num) {
    if (this.length > num.length) return this.clone().iuxor(num);
    return num.clone().iuxor(this);
  };

  // Not ``this`` with ``width`` bitwidth
  BN.prototype.inotn = function inotn (width) {
    assert(typeof width === 'number' && width >= 0);

    var bytesNeeded = Math.ceil(width / 26) | 0;
    var bitsLeft = width % 26;

    // Extend the buffer with leading zeroes
    this._expand(bytesNeeded);

    if (bitsLeft > 0) {
      bytesNeeded--;
    }

    // Handle complete words
    for (var i = 0; i < bytesNeeded; i++) {
      this.words[i] = ~this.words[i] & 0x3ffffff;
    }

    // Handle the residue
    if (bitsLeft > 0) {
      this.words[i] = ~this.words[i] & (0x3ffffff >> (26 - bitsLeft));
    }

    // And remove leading zeroes
    return this._strip();
  };

  BN.prototype.notn = function notn (width) {
    return this.clone().inotn(width);
  };

  // Set `bit` of `this`
  BN.prototype.setn = function setn (bit, val) {
    assert(typeof bit === 'number' && bit >= 0);

    var off = (bit / 26) | 0;
    var wbit = bit % 26;

    this._expand(off + 1);

    if (val) {
      this.words[off] = this.words[off] | (1 << wbit);
    } else {
      this.words[off] = this.words[off] & ~(1 << wbit);
    }

    return this._strip();
  };

  // Add `num` to `this` in-place
  BN.prototype.iadd = function iadd (num) {
    var r;

    // negative + positive
    if (this.negative !== 0 && num.negative === 0) {
      this.negative = 0;
      r = this.isub(num);
      this.negative ^= 1;
      return this._normSign();

    // positive + negative
    } else if (this.negative === 0 && num.negative !== 0) {
      num.negative = 0;
      r = this.isub(num);
      num.negative = 1;
      return r._normSign();
    }

    // a.length > b.length
    var a, b;
    if (this.length > num.length) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    var carry = 0;
    for (var i = 0; i < b.length; i++) {
      r = (a.words[i] | 0) + (b.words[i] | 0) + carry;
      this.words[i] = r & 0x3ffffff;
      carry = r >>> 26;
    }
    for (; carry !== 0 && i < a.length; i++) {
      r = (a.words[i] | 0) + carry;
      this.words[i] = r & 0x3ffffff;
      carry = r >>> 26;
    }

    this.length = a.length;
    if (carry !== 0) {
      this.words[this.length] = carry;
      this.length++;
    // Copy the rest of the words
    } else if (a !== this) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    return this;
  };

  // Add `num` to `this`
  BN.prototype.add = function add (num) {
    var res;
    if (num.negative !== 0 && this.negative === 0) {
      num.negative = 0;
      res = this.sub(num);
      num.negative ^= 1;
      return res;
    } else if (num.negative === 0 && this.negative !== 0) {
      this.negative = 0;
      res = num.sub(this);
      this.negative = 1;
      return res;
    }

    if (this.length > num.length) return this.clone().iadd(num);

    return num.clone().iadd(this);
  };

  // Subtract `num` from `this` in-place
  BN.prototype.isub = function isub (num) {
    // this - (-num) = this + num
    if (num.negative !== 0) {
      num.negative = 0;
      var r = this.iadd(num);
      num.negative = 1;
      return r._normSign();

    // -this - num = -(this + num)
    } else if (this.negative !== 0) {
      this.negative = 0;
      this.iadd(num);
      this.negative = 1;
      return this._normSign();
    }

    // At this point both numbers are positive
    var cmp = this.cmp(num);

    // Optimization - zeroify
    if (cmp === 0) {
      this.negative = 0;
      this.length = 1;
      this.words[0] = 0;
      return this;
    }

    // a > b
    var a, b;
    if (cmp > 0) {
      a = this;
      b = num;
    } else {
      a = num;
      b = this;
    }

    var carry = 0;
    for (var i = 0; i < b.length; i++) {
      r = (a.words[i] | 0) - (b.words[i] | 0) + carry;
      carry = r >> 26;
      this.words[i] = r & 0x3ffffff;
    }
    for (; carry !== 0 && i < a.length; i++) {
      r = (a.words[i] | 0) + carry;
      carry = r >> 26;
      this.words[i] = r & 0x3ffffff;
    }

    // Copy rest of the words
    if (carry === 0 && i < a.length && a !== this) {
      for (; i < a.length; i++) {
        this.words[i] = a.words[i];
      }
    }

    this.length = Math.max(this.length, i);

    if (a !== this) {
      this.negative = 1;
    }

    return this._strip();
  };

  // Subtract `num` from `this`
  BN.prototype.sub = function sub (num) {
    return this.clone().isub(num);
  };

  function smallMulTo (self, num, out) {
    out.negative = num.negative ^ self.negative;
    var len = (self.length + num.length) | 0;
    out.length = len;
    len = (len - 1) | 0;

    // Peel one iteration (compiler can't do it, because of code complexity)
    var a = self.words[0] | 0;
    var b = num.words[0] | 0;
    var r = a * b;

    var lo = r & 0x3ffffff;
    var carry = (r / 0x4000000) | 0;
    out.words[0] = lo;

    for (var k = 1; k < len; k++) {
      // Sum all words with the same `i + j = k` and accumulate `ncarry`,
      // note that ncarry could be >= 0x3ffffff
      var ncarry = carry >>> 26;
      var rword = carry & 0x3ffffff;
      var maxJ = Math.min(k, num.length - 1);
      for (var j = Math.max(0, k - self.length + 1); j <= maxJ; j++) {
        var i = (k - j) | 0;
        a = self.words[i] | 0;
        b = num.words[j] | 0;
        r = a * b + rword;
        ncarry += (r / 0x4000000) | 0;
        rword = r & 0x3ffffff;
      }
      out.words[k] = rword | 0;
      carry = ncarry | 0;
    }
    if (carry !== 0) {
      out.words[k] = carry | 0;
    } else {
      out.length--;
    }

    return out._strip();
  }

  // TODO(indutny): it may be reasonable to omit it for users who don't need
  // to work with 256-bit numbers, otherwise it gives 20% improvement for 256-bit
  // multiplication (like elliptic secp256k1).
  var comb10MulTo = function comb10MulTo (self, num, out) {
    var a = self.words;
    var b = num.words;
    var o = out.words;
    var c = 0;
    var lo;
    var mid;
    var hi;
    var a0 = a[0] | 0;
    var al0 = a0 & 0x1fff;
    var ah0 = a0 >>> 13;
    var a1 = a[1] | 0;
    var al1 = a1 & 0x1fff;
    var ah1 = a1 >>> 13;
    var a2 = a[2] | 0;
    var al2 = a2 & 0x1fff;
    var ah2 = a2 >>> 13;
    var a3 = a[3] | 0;
    var al3 = a3 & 0x1fff;
    var ah3 = a3 >>> 13;
    var a4 = a[4] | 0;
    var al4 = a4 & 0x1fff;
    var ah4 = a4 >>> 13;
    var a5 = a[5] | 0;
    var al5 = a5 & 0x1fff;
    var ah5 = a5 >>> 13;
    var a6 = a[6] | 0;
    var al6 = a6 & 0x1fff;
    var ah6 = a6 >>> 13;
    var a7 = a[7] | 0;
    var al7 = a7 & 0x1fff;
    var ah7 = a7 >>> 13;
    var a8 = a[8] | 0;
    var al8 = a8 & 0x1fff;
    var ah8 = a8 >>> 13;
    var a9 = a[9] | 0;
    var al9 = a9 & 0x1fff;
    var ah9 = a9 >>> 13;
    var b0 = b[0] | 0;
    var bl0 = b0 & 0x1fff;
    var bh0 = b0 >>> 13;
    var b1 = b[1] | 0;
    var bl1 = b1 & 0x1fff;
    var bh1 = b1 >>> 13;
    var b2 = b[2] | 0;
    var bl2 = b2 & 0x1fff;
    var bh2 = b2 >>> 13;
    var b3 = b[3] | 0;
    var bl3 = b3 & 0x1fff;
    var bh3 = b3 >>> 13;
    var b4 = b[4] | 0;
    var bl4 = b4 & 0x1fff;
    var bh4 = b4 >>> 13;
    var b5 = b[5] | 0;
    var bl5 = b5 & 0x1fff;
    var bh5 = b5 >>> 13;
    var b6 = b[6] | 0;
    var bl6 = b6 & 0x1fff;
    var bh6 = b6 >>> 13;
    var b7 = b[7] | 0;
    var bl7 = b7 & 0x1fff;
    var bh7 = b7 >>> 13;
    var b8 = b[8] | 0;
    var bl8 = b8 & 0x1fff;
    var bh8 = b8 >>> 13;
    var b9 = b[9] | 0;
    var bl9 = b9 & 0x1fff;
    var bh9 = b9 >>> 13;

    out.negative = self.negative ^ num.negative;
    out.length = 19;
    /* k = 0 */
    lo = Math.imul(al0, bl0);
    mid = Math.imul(al0, bh0);
    mid = (mid + Math.imul(ah0, bl0)) | 0;
    hi = Math.imul(ah0, bh0);
    var w0 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w0 >>> 26)) | 0;
    w0 &= 0x3ffffff;
    /* k = 1 */
    lo = Math.imul(al1, bl0);
    mid = Math.imul(al1, bh0);
    mid = (mid + Math.imul(ah1, bl0)) | 0;
    hi = Math.imul(ah1, bh0);
    lo = (lo + Math.imul(al0, bl1)) | 0;
    mid = (mid + Math.imul(al0, bh1)) | 0;
    mid = (mid + Math.imul(ah0, bl1)) | 0;
    hi = (hi + Math.imul(ah0, bh1)) | 0;
    var w1 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w1 >>> 26)) | 0;
    w1 &= 0x3ffffff;
    /* k = 2 */
    lo = Math.imul(al2, bl0);
    mid = Math.imul(al2, bh0);
    mid = (mid + Math.imul(ah2, bl0)) | 0;
    hi = Math.imul(ah2, bh0);
    lo = (lo + Math.imul(al1, bl1)) | 0;
    mid = (mid + Math.imul(al1, bh1)) | 0;
    mid = (mid + Math.imul(ah1, bl1)) | 0;
    hi = (hi + Math.imul(ah1, bh1)) | 0;
    lo = (lo + Math.imul(al0, bl2)) | 0;
    mid = (mid + Math.imul(al0, bh2)) | 0;
    mid = (mid + Math.imul(ah0, bl2)) | 0;
    hi = (hi + Math.imul(ah0, bh2)) | 0;
    var w2 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w2 >>> 26)) | 0;
    w2 &= 0x3ffffff;
    /* k = 3 */
    lo = Math.imul(al3, bl0);
    mid = Math.imul(al3, bh0);
    mid = (mid + Math.imul(ah3, bl0)) | 0;
    hi = Math.imul(ah3, bh0);
    lo = (lo + Math.imul(al2, bl1)) | 0;
    mid = (mid + Math.imul(al2, bh1)) | 0;
    mid = (mid + Math.imul(ah2, bl1)) | 0;
    hi = (hi + Math.imul(ah2, bh1)) | 0;
    lo = (lo + Math.imul(al1, bl2)) | 0;
    mid = (mid + Math.imul(al1, bh2)) | 0;
    mid = (mid + Math.imul(ah1, bl2)) | 0;
    hi = (hi + Math.imul(ah1, bh2)) | 0;
    lo = (lo + Math.imul(al0, bl3)) | 0;
    mid = (mid + Math.imul(al0, bh3)) | 0;
    mid = (mid + Math.imul(ah0, bl3)) | 0;
    hi = (hi + Math.imul(ah0, bh3)) | 0;
    var w3 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w3 >>> 26)) | 0;
    w3 &= 0x3ffffff;
    /* k = 4 */
    lo = Math.imul(al4, bl0);
    mid = Math.imul(al4, bh0);
    mid = (mid + Math.imul(ah4, bl0)) | 0;
    hi = Math.imul(ah4, bh0);
    lo = (lo + Math.imul(al3, bl1)) | 0;
    mid = (mid + Math.imul(al3, bh1)) | 0;
    mid = (mid + Math.imul(ah3, bl1)) | 0;
    hi = (hi + Math.imul(ah3, bh1)) | 0;
    lo = (lo + Math.imul(al2, bl2)) | 0;
    mid = (mid + Math.imul(al2, bh2)) | 0;
    mid = (mid + Math.imul(ah2, bl2)) | 0;
    hi = (hi + Math.imul(ah2, bh2)) | 0;
    lo = (lo + Math.imul(al1, bl3)) | 0;
    mid = (mid + Math.imul(al1, bh3)) | 0;
    mid = (mid + Math.imul(ah1, bl3)) | 0;
    hi = (hi + Math.imul(ah1, bh3)) | 0;
    lo = (lo + Math.imul(al0, bl4)) | 0;
    mid = (mid + Math.imul(al0, bh4)) | 0;
    mid = (mid + Math.imul(ah0, bl4)) | 0;
    hi = (hi + Math.imul(ah0, bh4)) | 0;
    var w4 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w4 >>> 26)) | 0;
    w4 &= 0x3ffffff;
    /* k = 5 */
    lo = Math.imul(al5, bl0);
    mid = Math.imul(al5, bh0);
    mid = (mid + Math.imul(ah5, bl0)) | 0;
    hi = Math.imul(ah5, bh0);
    lo = (lo + Math.imul(al4, bl1)) | 0;
    mid = (mid + Math.imul(al4, bh1)) | 0;
    mid = (mid + Math.imul(ah4, bl1)) | 0;
    hi = (hi + Math.imul(ah4, bh1)) | 0;
    lo = (lo + Math.imul(al3, bl2)) | 0;
    mid = (mid + Math.imul(al3, bh2)) | 0;
    mid = (mid + Math.imul(ah3, bl2)) | 0;
    hi = (hi + Math.imul(ah3, bh2)) | 0;
    lo = (lo + Math.imul(al2, bl3)) | 0;
    mid = (mid + Math.imul(al2, bh3)) | 0;
    mid = (mid + Math.imul(ah2, bl3)) | 0;
    hi = (hi + Math.imul(ah2, bh3)) | 0;
    lo = (lo + Math.imul(al1, bl4)) | 0;
    mid = (mid + Math.imul(al1, bh4)) | 0;
    mid = (mid + Math.imul(ah1, bl4)) | 0;
    hi = (hi + Math.imul(ah1, bh4)) | 0;
    lo = (lo + Math.imul(al0, bl5)) | 0;
    mid = (mid + Math.imul(al0, bh5)) | 0;
    mid = (mid + Math.imul(ah0, bl5)) | 0;
    hi = (hi + Math.imul(ah0, bh5)) | 0;
    var w5 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w5 >>> 26)) | 0;
    w5 &= 0x3ffffff;
    /* k = 6 */
    lo = Math.imul(al6, bl0);
    mid = Math.imul(al6, bh0);
    mid = (mid + Math.imul(ah6, bl0)) | 0;
    hi = Math.imul(ah6, bh0);
    lo = (lo + Math.imul(al5, bl1)) | 0;
    mid = (mid + Math.imul(al5, bh1)) | 0;
    mid = (mid + Math.imul(ah5, bl1)) | 0;
    hi = (hi + Math.imul(ah5, bh1)) | 0;
    lo = (lo + Math.imul(al4, bl2)) | 0;
    mid = (mid + Math.imul(al4, bh2)) | 0;
    mid = (mid + Math.imul(ah4, bl2)) | 0;
    hi = (hi + Math.imul(ah4, bh2)) | 0;
    lo = (lo + Math.imul(al3, bl3)) | 0;
    mid = (mid + Math.imul(al3, bh3)) | 0;
    mid = (mid + Math.imul(ah3, bl3)) | 0;
    hi = (hi + Math.imul(ah3, bh3)) | 0;
    lo = (lo + Math.imul(al2, bl4)) | 0;
    mid = (mid + Math.imul(al2, bh4)) | 0;
    mid = (mid + Math.imul(ah2, bl4)) | 0;
    hi = (hi + Math.imul(ah2, bh4)) | 0;
    lo = (lo + Math.imul(al1, bl5)) | 0;
    mid = (mid + Math.imul(al1, bh5)) | 0;
    mid = (mid + Math.imul(ah1, bl5)) | 0;
    hi = (hi + Math.imul(ah1, bh5)) | 0;
    lo = (lo + Math.imul(al0, bl6)) | 0;
    mid = (mid + Math.imul(al0, bh6)) | 0;
    mid = (mid + Math.imul(ah0, bl6)) | 0;
    hi = (hi + Math.imul(ah0, bh6)) | 0;
    var w6 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w6 >>> 26)) | 0;
    w6 &= 0x3ffffff;
    /* k = 7 */
    lo = Math.imul(al7, bl0);
    mid = Math.imul(al7, bh0);
    mid = (mid + Math.imul(ah7, bl0)) | 0;
    hi = Math.imul(ah7, bh0);
    lo = (lo + Math.imul(al6, bl1)) | 0;
    mid = (mid + Math.imul(al6, bh1)) | 0;
    mid = (mid + Math.imul(ah6, bl1)) | 0;
    hi = (hi + Math.imul(ah6, bh1)) | 0;
    lo = (lo + Math.imul(al5, bl2)) | 0;
    mid = (mid + Math.imul(al5, bh2)) | 0;
    mid = (mid + Math.imul(ah5, bl2)) | 0;
    hi = (hi + Math.imul(ah5, bh2)) | 0;
    lo = (lo + Math.imul(al4, bl3)) | 0;
    mid = (mid + Math.imul(al4, bh3)) | 0;
    mid = (mid + Math.imul(ah4, bl3)) | 0;
    hi = (hi + Math.imul(ah4, bh3)) | 0;
    lo = (lo + Math.imul(al3, bl4)) | 0;
    mid = (mid + Math.imul(al3, bh4)) | 0;
    mid = (mid + Math.imul(ah3, bl4)) | 0;
    hi = (hi + Math.imul(ah3, bh4)) | 0;
    lo = (lo + Math.imul(al2, bl5)) | 0;
    mid = (mid + Math.imul(al2, bh5)) | 0;
    mid = (mid + Math.imul(ah2, bl5)) | 0;
    hi = (hi + Math.imul(ah2, bh5)) | 0;
    lo = (lo + Math.imul(al1, bl6)) | 0;
    mid = (mid + Math.imul(al1, bh6)) | 0;
    mid = (mid + Math.imul(ah1, bl6)) | 0;
    hi = (hi + Math.imul(ah1, bh6)) | 0;
    lo = (lo + Math.imul(al0, bl7)) | 0;
    mid = (mid + Math.imul(al0, bh7)) | 0;
    mid = (mid + Math.imul(ah0, bl7)) | 0;
    hi = (hi + Math.imul(ah0, bh7)) | 0;
    var w7 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w7 >>> 26)) | 0;
    w7 &= 0x3ffffff;
    /* k = 8 */
    lo = Math.imul(al8, bl0);
    mid = Math.imul(al8, bh0);
    mid = (mid + Math.imul(ah8, bl0)) | 0;
    hi = Math.imul(ah8, bh0);
    lo = (lo + Math.imul(al7, bl1)) | 0;
    mid = (mid + Math.imul(al7, bh1)) | 0;
    mid = (mid + Math.imul(ah7, bl1)) | 0;
    hi = (hi + Math.imul(ah7, bh1)) | 0;
    lo = (lo + Math.imul(al6, bl2)) | 0;
    mid = (mid + Math.imul(al6, bh2)) | 0;
    mid = (mid + Math.imul(ah6, bl2)) | 0;
    hi = (hi + Math.imul(ah6, bh2)) | 0;
    lo = (lo + Math.imul(al5, bl3)) | 0;
    mid = (mid + Math.imul(al5, bh3)) | 0;
    mid = (mid + Math.imul(ah5, bl3)) | 0;
    hi = (hi + Math.imul(ah5, bh3)) | 0;
    lo = (lo + Math.imul(al4, bl4)) | 0;
    mid = (mid + Math.imul(al4, bh4)) | 0;
    mid = (mid + Math.imul(ah4, bl4)) | 0;
    hi = (hi + Math.imul(ah4, bh4)) | 0;
    lo = (lo + Math.imul(al3, bl5)) | 0;
    mid = (mid + Math.imul(al3, bh5)) | 0;
    mid = (mid + Math.imul(ah3, bl5)) | 0;
    hi = (hi + Math.imul(ah3, bh5)) | 0;
    lo = (lo + Math.imul(al2, bl6)) | 0;
    mid = (mid + Math.imul(al2, bh6)) | 0;
    mid = (mid + Math.imul(ah2, bl6)) | 0;
    hi = (hi + Math.imul(ah2, bh6)) | 0;
    lo = (lo + Math.imul(al1, bl7)) | 0;
    mid = (mid + Math.imul(al1, bh7)) | 0;
    mid = (mid + Math.imul(ah1, bl7)) | 0;
    hi = (hi + Math.imul(ah1, bh7)) | 0;
    lo = (lo + Math.imul(al0, bl8)) | 0;
    mid = (mid + Math.imul(al0, bh8)) | 0;
    mid = (mid + Math.imul(ah0, bl8)) | 0;
    hi = (hi + Math.imul(ah0, bh8)) | 0;
    var w8 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w8 >>> 26)) | 0;
    w8 &= 0x3ffffff;
    /* k = 9 */
    lo = Math.imul(al9, bl0);
    mid = Math.imul(al9, bh0);
    mid = (mid + Math.imul(ah9, bl0)) | 0;
    hi = Math.imul(ah9, bh0);
    lo = (lo + Math.imul(al8, bl1)) | 0;
    mid = (mid + Math.imul(al8, bh1)) | 0;
    mid = (mid + Math.imul(ah8, bl1)) | 0;
    hi = (hi + Math.imul(ah8, bh1)) | 0;
    lo = (lo + Math.imul(al7, bl2)) | 0;
    mid = (mid + Math.imul(al7, bh2)) | 0;
    mid = (mid + Math.imul(ah7, bl2)) | 0;
    hi = (hi + Math.imul(ah7, bh2)) | 0;
    lo = (lo + Math.imul(al6, bl3)) | 0;
    mid = (mid + Math.imul(al6, bh3)) | 0;
    mid = (mid + Math.imul(ah6, bl3)) | 0;
    hi = (hi + Math.imul(ah6, bh3)) | 0;
    lo = (lo + Math.imul(al5, bl4)) | 0;
    mid = (mid + Math.imul(al5, bh4)) | 0;
    mid = (mid + Math.imul(ah5, bl4)) | 0;
    hi = (hi + Math.imul(ah5, bh4)) | 0;
    lo = (lo + Math.imul(al4, bl5)) | 0;
    mid = (mid + Math.imul(al4, bh5)) | 0;
    mid = (mid + Math.imul(ah4, bl5)) | 0;
    hi = (hi + Math.imul(ah4, bh5)) | 0;
    lo = (lo + Math.imul(al3, bl6)) | 0;
    mid = (mid + Math.imul(al3, bh6)) | 0;
    mid = (mid + Math.imul(ah3, bl6)) | 0;
    hi = (hi + Math.imul(ah3, bh6)) | 0;
    lo = (lo + Math.imul(al2, bl7)) | 0;
    mid = (mid + Math.imul(al2, bh7)) | 0;
    mid = (mid + Math.imul(ah2, bl7)) | 0;
    hi = (hi + Math.imul(ah2, bh7)) | 0;
    lo = (lo + Math.imul(al1, bl8)) | 0;
    mid = (mid + Math.imul(al1, bh8)) | 0;
    mid = (mid + Math.imul(ah1, bl8)) | 0;
    hi = (hi + Math.imul(ah1, bh8)) | 0;
    lo = (lo + Math.imul(al0, bl9)) | 0;
    mid = (mid + Math.imul(al0, bh9)) | 0;
    mid = (mid + Math.imul(ah0, bl9)) | 0;
    hi = (hi + Math.imul(ah0, bh9)) | 0;
    var w9 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w9 >>> 26)) | 0;
    w9 &= 0x3ffffff;
    /* k = 10 */
    lo = Math.imul(al9, bl1);
    mid = Math.imul(al9, bh1);
    mid = (mid + Math.imul(ah9, bl1)) | 0;
    hi = Math.imul(ah9, bh1);
    lo = (lo + Math.imul(al8, bl2)) | 0;
    mid = (mid + Math.imul(al8, bh2)) | 0;
    mid = (mid + Math.imul(ah8, bl2)) | 0;
    hi = (hi + Math.imul(ah8, bh2)) | 0;
    lo = (lo + Math.imul(al7, bl3)) | 0;
    mid = (mid + Math.imul(al7, bh3)) | 0;
    mid = (mid + Math.imul(ah7, bl3)) | 0;
    hi = (hi + Math.imul(ah7, bh3)) | 0;
    lo = (lo + Math.imul(al6, bl4)) | 0;
    mid = (mid + Math.imul(al6, bh4)) | 0;
    mid = (mid + Math.imul(ah6, bl4)) | 0;
    hi = (hi + Math.imul(ah6, bh4)) | 0;
    lo = (lo + Math.imul(al5, bl5)) | 0;
    mid = (mid + Math.imul(al5, bh5)) | 0;
    mid = (mid + Math.imul(ah5, bl5)) | 0;
    hi = (hi + Math.imul(ah5, bh5)) | 0;
    lo = (lo + Math.imul(al4, bl6)) | 0;
    mid = (mid + Math.imul(al4, bh6)) | 0;
    mid = (mid + Math.imul(ah4, bl6)) | 0;
    hi = (hi + Math.imul(ah4, bh6)) | 0;
    lo = (lo + Math.imul(al3, bl7)) | 0;
    mid = (mid + Math.imul(al3, bh7)) | 0;
    mid = (mid + Math.imul(ah3, bl7)) | 0;
    hi = (hi + Math.imul(ah3, bh7)) | 0;
    lo = (lo + Math.imul(al2, bl8)) | 0;
    mid = (mid + Math.imul(al2, bh8)) | 0;
    mid = (mid + Math.imul(ah2, bl8)) | 0;
    hi = (hi + Math.imul(ah2, bh8)) | 0;
    lo = (lo + Math.imul(al1, bl9)) | 0;
    mid = (mid + Math.imul(al1, bh9)) | 0;
    mid = (mid + Math.imul(ah1, bl9)) | 0;
    hi = (hi + Math.imul(ah1, bh9)) | 0;
    var w10 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w10 >>> 26)) | 0;
    w10 &= 0x3ffffff;
    /* k = 11 */
    lo = Math.imul(al9, bl2);
    mid = Math.imul(al9, bh2);
    mid = (mid + Math.imul(ah9, bl2)) | 0;
    hi = Math.imul(ah9, bh2);
    lo = (lo + Math.imul(al8, bl3)) | 0;
    mid = (mid + Math.imul(al8, bh3)) | 0;
    mid = (mid + Math.imul(ah8, bl3)) | 0;
    hi = (hi + Math.imul(ah8, bh3)) | 0;
    lo = (lo + Math.imul(al7, bl4)) | 0;
    mid = (mid + Math.imul(al7, bh4)) | 0;
    mid = (mid + Math.imul(ah7, bl4)) | 0;
    hi = (hi + Math.imul(ah7, bh4)) | 0;
    lo = (lo + Math.imul(al6, bl5)) | 0;
    mid = (mid + Math.imul(al6, bh5)) | 0;
    mid = (mid + Math.imul(ah6, bl5)) | 0;
    hi = (hi + Math.imul(ah6, bh5)) | 0;
    lo = (lo + Math.imul(al5, bl6)) | 0;
    mid = (mid + Math.imul(al5, bh6)) | 0;
    mid = (mid + Math.imul(ah5, bl6)) | 0;
    hi = (hi + Math.imul(ah5, bh6)) | 0;
    lo = (lo + Math.imul(al4, bl7)) | 0;
    mid = (mid + Math.imul(al4, bh7)) | 0;
    mid = (mid + Math.imul(ah4, bl7)) | 0;
    hi = (hi + Math.imul(ah4, bh7)) | 0;
    lo = (lo + Math.imul(al3, bl8)) | 0;
    mid = (mid + Math.imul(al3, bh8)) | 0;
    mid = (mid + Math.imul(ah3, bl8)) | 0;
    hi = (hi + Math.imul(ah3, bh8)) | 0;
    lo = (lo + Math.imul(al2, bl9)) | 0;
    mid = (mid + Math.imul(al2, bh9)) | 0;
    mid = (mid + Math.imul(ah2, bl9)) | 0;
    hi = (hi + Math.imul(ah2, bh9)) | 0;
    var w11 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w11 >>> 26)) | 0;
    w11 &= 0x3ffffff;
    /* k = 12 */
    lo = Math.imul(al9, bl3);
    mid = Math.imul(al9, bh3);
    mid = (mid + Math.imul(ah9, bl3)) | 0;
    hi = Math.imul(ah9, bh3);
    lo = (lo + Math.imul(al8, bl4)) | 0;
    mid = (mid + Math.imul(al8, bh4)) | 0;
    mid = (mid + Math.imul(ah8, bl4)) | 0;
    hi = (hi + Math.imul(ah8, bh4)) | 0;
    lo = (lo + Math.imul(al7, bl5)) | 0;
    mid = (mid + Math.imul(al7, bh5)) | 0;
    mid = (mid + Math.imul(ah7, bl5)) | 0;
    hi = (hi + Math.imul(ah7, bh5)) | 0;
    lo = (lo + Math.imul(al6, bl6)) | 0;
    mid = (mid + Math.imul(al6, bh6)) | 0;
    mid = (mid + Math.imul(ah6, bl6)) | 0;
    hi = (hi + Math.imul(ah6, bh6)) | 0;
    lo = (lo + Math.imul(al5, bl7)) | 0;
    mid = (mid + Math.imul(al5, bh7)) | 0;
    mid = (mid + Math.imul(ah5, bl7)) | 0;
    hi = (hi + Math.imul(ah5, bh7)) | 0;
    lo = (lo + Math.imul(al4, bl8)) | 0;
    mid = (mid + Math.imul(al4, bh8)) | 0;
    mid = (mid + Math.imul(ah4, bl8)) | 0;
    hi = (hi + Math.imul(ah4, bh8)) | 0;
    lo = (lo + Math.imul(al3, bl9)) | 0;
    mid = (mid + Math.imul(al3, bh9)) | 0;
    mid = (mid + Math.imul(ah3, bl9)) | 0;
    hi = (hi + Math.imul(ah3, bh9)) | 0;
    var w12 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w12 >>> 26)) | 0;
    w12 &= 0x3ffffff;
    /* k = 13 */
    lo = Math.imul(al9, bl4);
    mid = Math.imul(al9, bh4);
    mid = (mid + Math.imul(ah9, bl4)) | 0;
    hi = Math.imul(ah9, bh4);
    lo = (lo + Math.imul(al8, bl5)) | 0;
    mid = (mid + Math.imul(al8, bh5)) | 0;
    mid = (mid + Math.imul(ah8, bl5)) | 0;
    hi = (hi + Math.imul(ah8, bh5)) | 0;
    lo = (lo + Math.imul(al7, bl6)) | 0;
    mid = (mid + Math.imul(al7, bh6)) | 0;
    mid = (mid + Math.imul(ah7, bl6)) | 0;
    hi = (hi + Math.imul(ah7, bh6)) | 0;
    lo = (lo + Math.imul(al6, bl7)) | 0;
    mid = (mid + Math.imul(al6, bh7)) | 0;
    mid = (mid + Math.imul(ah6, bl7)) | 0;
    hi = (hi + Math.imul(ah6, bh7)) | 0;
    lo = (lo + Math.imul(al5, bl8)) | 0;
    mid = (mid + Math.imul(al5, bh8)) | 0;
    mid = (mid + Math.imul(ah5, bl8)) | 0;
    hi = (hi + Math.imul(ah5, bh8)) | 0;
    lo = (lo + Math.imul(al4, bl9)) | 0;
    mid = (mid + Math.imul(al4, bh9)) | 0;
    mid = (mid + Math.imul(ah4, bl9)) | 0;
    hi = (hi + Math.imul(ah4, bh9)) | 0;
    var w13 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w13 >>> 26)) | 0;
    w13 &= 0x3ffffff;
    /* k = 14 */
    lo = Math.imul(al9, bl5);
    mid = Math.imul(al9, bh5);
    mid = (mid + Math.imul(ah9, bl5)) | 0;
    hi = Math.imul(ah9, bh5);
    lo = (lo + Math.imul(al8, bl6)) | 0;
    mid = (mid + Math.imul(al8, bh6)) | 0;
    mid = (mid + Math.imul(ah8, bl6)) | 0;
    hi = (hi + Math.imul(ah8, bh6)) | 0;
    lo = (lo + Math.imul(al7, bl7)) | 0;
    mid = (mid + Math.imul(al7, bh7)) | 0;
    mid = (mid + Math.imul(ah7, bl7)) | 0;
    hi = (hi + Math.imul(ah7, bh7)) | 0;
    lo = (lo + Math.imul(al6, bl8)) | 0;
    mid = (mid + Math.imul(al6, bh8)) | 0;
    mid = (mid + Math.imul(ah6, bl8)) | 0;
    hi = (hi + Math.imul(ah6, bh8)) | 0;
    lo = (lo + Math.imul(al5, bl9)) | 0;
    mid = (mid + Math.imul(al5, bh9)) | 0;
    mid = (mid + Math.imul(ah5, bl9)) | 0;
    hi = (hi + Math.imul(ah5, bh9)) | 0;
    var w14 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w14 >>> 26)) | 0;
    w14 &= 0x3ffffff;
    /* k = 15 */
    lo = Math.imul(al9, bl6);
    mid = Math.imul(al9, bh6);
    mid = (mid + Math.imul(ah9, bl6)) | 0;
    hi = Math.imul(ah9, bh6);
    lo = (lo + Math.imul(al8, bl7)) | 0;
    mid = (mid + Math.imul(al8, bh7)) | 0;
    mid = (mid + Math.imul(ah8, bl7)) | 0;
    hi = (hi + Math.imul(ah8, bh7)) | 0;
    lo = (lo + Math.imul(al7, bl8)) | 0;
    mid = (mid + Math.imul(al7, bh8)) | 0;
    mid = (mid + Math.imul(ah7, bl8)) | 0;
    hi = (hi + Math.imul(ah7, bh8)) | 0;
    lo = (lo + Math.imul(al6, bl9)) | 0;
    mid = (mid + Math.imul(al6, bh9)) | 0;
    mid = (mid + Math.imul(ah6, bl9)) | 0;
    hi = (hi + Math.imul(ah6, bh9)) | 0;
    var w15 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w15 >>> 26)) | 0;
    w15 &= 0x3ffffff;
    /* k = 16 */
    lo = Math.imul(al9, bl7);
    mid = Math.imul(al9, bh7);
    mid = (mid + Math.imul(ah9, bl7)) | 0;
    hi = Math.imul(ah9, bh7);
    lo = (lo + Math.imul(al8, bl8)) | 0;
    mid = (mid + Math.imul(al8, bh8)) | 0;
    mid = (mid + Math.imul(ah8, bl8)) | 0;
    hi = (hi + Math.imul(ah8, bh8)) | 0;
    lo = (lo + Math.imul(al7, bl9)) | 0;
    mid = (mid + Math.imul(al7, bh9)) | 0;
    mid = (mid + Math.imul(ah7, bl9)) | 0;
    hi = (hi + Math.imul(ah7, bh9)) | 0;
    var w16 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w16 >>> 26)) | 0;
    w16 &= 0x3ffffff;
    /* k = 17 */
    lo = Math.imul(al9, bl8);
    mid = Math.imul(al9, bh8);
    mid = (mid + Math.imul(ah9, bl8)) | 0;
    hi = Math.imul(ah9, bh8);
    lo = (lo + Math.imul(al8, bl9)) | 0;
    mid = (mid + Math.imul(al8, bh9)) | 0;
    mid = (mid + Math.imul(ah8, bl9)) | 0;
    hi = (hi + Math.imul(ah8, bh9)) | 0;
    var w17 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w17 >>> 26)) | 0;
    w17 &= 0x3ffffff;
    /* k = 18 */
    lo = Math.imul(al9, bl9);
    mid = Math.imul(al9, bh9);
    mid = (mid + Math.imul(ah9, bl9)) | 0;
    hi = Math.imul(ah9, bh9);
    var w18 = (((c + lo) | 0) + ((mid & 0x1fff) << 13)) | 0;
    c = (((hi + (mid >>> 13)) | 0) + (w18 >>> 26)) | 0;
    w18 &= 0x3ffffff;
    o[0] = w0;
    o[1] = w1;
    o[2] = w2;
    o[3] = w3;
    o[4] = w4;
    o[5] = w5;
    o[6] = w6;
    o[7] = w7;
    o[8] = w8;
    o[9] = w9;
    o[10] = w10;
    o[11] = w11;
    o[12] = w12;
    o[13] = w13;
    o[14] = w14;
    o[15] = w15;
    o[16] = w16;
    o[17] = w17;
    o[18] = w18;
    if (c !== 0) {
      o[19] = c;
      out.length++;
    }
    return out;
  };

  // Polyfill comb
  if (!Math.imul) {
    comb10MulTo = smallMulTo;
  }

  function bigMulTo (self, num, out) {
    out.negative = num.negative ^ self.negative;
    out.length = self.length + num.length;

    var carry = 0;
    var hncarry = 0;
    for (var k = 0; k < out.length - 1; k++) {
      // Sum all words with the same `i + j = k` and accumulate `ncarry`,
      // note that ncarry could be >= 0x3ffffff
      var ncarry = hncarry;
      hncarry = 0;
      var rword = carry & 0x3ffffff;
      var maxJ = Math.min(k, num.length - 1);
      for (var j = Math.max(0, k - self.length + 1); j <= maxJ; j++) {
        var i = k - j;
        var a = self.words[i] | 0;
        var b = num.words[j] | 0;
        var r = a * b;

        var lo = r & 0x3ffffff;
        ncarry = (ncarry + ((r / 0x4000000) | 0)) | 0;
        lo = (lo + rword) | 0;
        rword = lo & 0x3ffffff;
        ncarry = (ncarry + (lo >>> 26)) | 0;

        hncarry += ncarry >>> 26;
        ncarry &= 0x3ffffff;
      }
      out.words[k] = rword;
      carry = ncarry;
      ncarry = hncarry;
    }
    if (carry !== 0) {
      out.words[k] = carry;
    } else {
      out.length--;
    }

    return out._strip();
  }

  function jumboMulTo (self, num, out) {
    // Temporary disable, see https://github.com/indutny/bn.js/issues/211
    // var fftm = new FFTM();
    // return fftm.mulp(self, num, out);
    return bigMulTo(self, num, out);
  }

  BN.prototype.mulTo = function mulTo (num, out) {
    var res;
    var len = this.length + num.length;
    if (this.length === 10 && num.length === 10) {
      res = comb10MulTo(this, num, out);
    } else if (len < 63) {
      res = smallMulTo(this, num, out);
    } else if (len < 1024) {
      res = bigMulTo(this, num, out);
    } else {
      res = jumboMulTo(this, num, out);
    }

    return res;
  };

  // Cooley-Tukey algorithm for FFT
  // slightly revisited to rely on looping instead of recursion

  function FFTM (x, y) {
    this.x = x;
    this.y = y;
  }

  FFTM.prototype.makeRBT = function makeRBT (N) {
    var t = new Array(N);
    var l = BN.prototype._countBits(N) - 1;
    for (var i = 0; i < N; i++) {
      t[i] = this.revBin(i, l, N);
    }

    return t;
  };

  // Returns binary-reversed representation of `x`
  FFTM.prototype.revBin = function revBin (x, l, N) {
    if (x === 0 || x === N - 1) return x;

    var rb = 0;
    for (var i = 0; i < l; i++) {
      rb |= (x & 1) << (l - i - 1);
      x >>= 1;
    }

    return rb;
  };

  // Performs "tweedling" phase, therefore 'emulating'
  // behaviour of the recursive algorithm
  FFTM.prototype.permute = function permute (rbt, rws, iws, rtws, itws, N) {
    for (var i = 0; i < N; i++) {
      rtws[i] = rws[rbt[i]];
      itws[i] = iws[rbt[i]];
    }
  };

  FFTM.prototype.transform = function transform (rws, iws, rtws, itws, N, rbt) {
    this.permute(rbt, rws, iws, rtws, itws, N);

    for (var s = 1; s < N; s <<= 1) {
      var l = s << 1;

      var rtwdf = Math.cos(2 * Math.PI / l);
      var itwdf = Math.sin(2 * Math.PI / l);

      for (var p = 0; p < N; p += l) {
        var rtwdf_ = rtwdf;
        var itwdf_ = itwdf;

        for (var j = 0; j < s; j++) {
          var re = rtws[p + j];
          var ie = itws[p + j];

          var ro = rtws[p + j + s];
          var io = itws[p + j + s];

          var rx = rtwdf_ * ro - itwdf_ * io;

          io = rtwdf_ * io + itwdf_ * ro;
          ro = rx;

          rtws[p + j] = re + ro;
          itws[p + j] = ie + io;

          rtws[p + j + s] = re - ro;
          itws[p + j + s] = ie - io;

          /* jshint maxdepth : false */
          if (j !== l) {
            rx = rtwdf * rtwdf_ - itwdf * itwdf_;

            itwdf_ = rtwdf * itwdf_ + itwdf * rtwdf_;
            rtwdf_ = rx;
          }
        }
      }
    }
  };

  FFTM.prototype.guessLen13b = function guessLen13b (n, m) {
    var N = Math.max(m, n) | 1;
    var odd = N & 1;
    var i = 0;
    for (N = N / 2 | 0; N; N = N >>> 1) {
      i++;
    }

    return 1 << i + 1 + odd;
  };

  FFTM.prototype.conjugate = function conjugate (rws, iws, N) {
    if (N <= 1) return;

    for (var i = 0; i < N / 2; i++) {
      var t = rws[i];

      rws[i] = rws[N - i - 1];
      rws[N - i - 1] = t;

      t = iws[i];

      iws[i] = -iws[N - i - 1];
      iws[N - i - 1] = -t;
    }
  };

  FFTM.prototype.normalize13b = function normalize13b (ws, N) {
    var carry = 0;
    for (var i = 0; i < N / 2; i++) {
      var w = Math.round(ws[2 * i + 1] / N) * 0x2000 +
        Math.round(ws[2 * i] / N) +
        carry;

      ws[i] = w & 0x3ffffff;

      if (w < 0x4000000) {
        carry = 0;
      } else {
        carry = w / 0x4000000 | 0;
      }
    }

    return ws;
  };

  FFTM.prototype.convert13b = function convert13b (ws, len, rws, N) {
    var carry = 0;
    for (var i = 0; i < len; i++) {
      carry = carry + (ws[i] | 0);

      rws[2 * i] = carry & 0x1fff; carry = carry >>> 13;
      rws[2 * i + 1] = carry & 0x1fff; carry = carry >>> 13;
    }

    // Pad with zeroes
    for (i = 2 * len; i < N; ++i) {
      rws[i] = 0;
    }

    assert(carry === 0);
    assert((carry & ~0x1fff) === 0);
  };

  FFTM.prototype.stub = function stub (N) {
    var ph = new Array(N);
    for (var i = 0; i < N; i++) {
      ph[i] = 0;
    }

    return ph;
  };

  FFTM.prototype.mulp = function mulp (x, y, out) {
    var N = 2 * this.guessLen13b(x.length, y.length);

    var rbt = this.makeRBT(N);

    var _ = this.stub(N);

    var rws = new Array(N);
    var rwst = new Array(N);
    var iwst = new Array(N);

    var nrws = new Array(N);
    var nrwst = new Array(N);
    var niwst = new Array(N);

    var rmws = out.words;
    rmws.length = N;

    this.convert13b(x.words, x.length, rws, N);
    this.convert13b(y.words, y.length, nrws, N);

    this.transform(rws, _, rwst, iwst, N, rbt);
    this.transform(nrws, _, nrwst, niwst, N, rbt);

    for (var i = 0; i < N; i++) {
      var rx = rwst[i] * nrwst[i] - iwst[i] * niwst[i];
      iwst[i] = rwst[i] * niwst[i] + iwst[i] * nrwst[i];
      rwst[i] = rx;
    }

    this.conjugate(rwst, iwst, N);
    this.transform(rwst, iwst, rmws, _, N, rbt);
    this.conjugate(rmws, _, N);
    this.normalize13b(rmws, N);

    out.negative = x.negative ^ y.negative;
    out.length = x.length + y.length;
    return out._strip();
  };

  // Multiply `this` by `num`
  BN.prototype.mul = function mul (num) {
    var out = new BN(null);
    out.words = new Array(this.length + num.length);
    return this.mulTo(num, out);
  };

  // Multiply employing FFT
  BN.prototype.mulf = function mulf (num) {
    var out = new BN(null);
    out.words = new Array(this.length + num.length);
    return jumboMulTo(this, num, out);
  };

  // In-place Multiplication
  BN.prototype.imul = function imul (num) {
    return this.clone().mulTo(num, this);
  };

  BN.prototype.imuln = function imuln (num) {
    var isNegNum = num < 0;
    if (isNegNum) num = -num;

    assert(typeof num === 'number');
    assert(num < 0x4000000);

    // Carry
    var carry = 0;
    for (var i = 0; i < this.length; i++) {
      var w = (this.words[i] | 0) * num;
      var lo = (w & 0x3ffffff) + (carry & 0x3ffffff);
      carry >>= 26;
      carry += (w / 0x4000000) | 0;
      // NOTE: lo is 27bit maximum
      carry += lo >>> 26;
      this.words[i] = lo & 0x3ffffff;
    }

    if (carry !== 0) {
      this.words[i] = carry;
      this.length++;
    }

    return isNegNum ? this.ineg() : this;
  };

  BN.prototype.muln = function muln (num) {
    return this.clone().imuln(num);
  };

  // `this` * `this`
  BN.prototype.sqr = function sqr () {
    return this.mul(this);
  };

  // `this` * `this` in-place
  BN.prototype.isqr = function isqr () {
    return this.imul(this.clone());
  };

  // Math.pow(`this`, `num`)
  BN.prototype.pow = function pow (num) {
    var w = toBitArray(num);
    if (w.length === 0) return new BN(1);

    // Skip leading zeroes
    var res = this;
    for (var i = 0; i < w.length; i++, res = res.sqr()) {
      if (w[i] !== 0) break;
    }

    if (++i < w.length) {
      for (var q = res.sqr(); i < w.length; i++, q = q.sqr()) {
        if (w[i] === 0) continue;

        res = res.mul(q);
      }
    }

    return res;
  };

  // Shift-left in-place
  BN.prototype.iushln = function iushln (bits) {
    assert(typeof bits === 'number' && bits >= 0);
    var r = bits % 26;
    var s = (bits - r) / 26;
    var carryMask = (0x3ffffff >>> (26 - r)) << (26 - r);
    var i;

    if (r !== 0) {
      var carry = 0;

      for (i = 0; i < this.length; i++) {
        var newCarry = this.words[i] & carryMask;
        var c = ((this.words[i] | 0) - newCarry) << r;
        this.words[i] = c | carry;
        carry = newCarry >>> (26 - r);
      }

      if (carry) {
        this.words[i] = carry;
        this.length++;
      }
    }

    if (s !== 0) {
      for (i = this.length - 1; i >= 0; i--) {
        this.words[i + s] = this.words[i];
      }

      for (i = 0; i < s; i++) {
        this.words[i] = 0;
      }

      this.length += s;
    }

    return this._strip();
  };

  BN.prototype.ishln = function ishln (bits) {
    // TODO(indutny): implement me
    assert(this.negative === 0);
    return this.iushln(bits);
  };

  // Shift-right in-place
  // NOTE: `hint` is a lowest bit before trailing zeroes
  // NOTE: if `extended` is present - it will be filled with destroyed bits
  BN.prototype.iushrn = function iushrn (bits, hint, extended) {
    assert(typeof bits === 'number' && bits >= 0);
    var h;
    if (hint) {
      h = (hint - (hint % 26)) / 26;
    } else {
      h = 0;
    }

    var r = bits % 26;
    var s = Math.min((bits - r) / 26, this.length);
    var mask = 0x3ffffff ^ ((0x3ffffff >>> r) << r);
    var maskedWords = extended;

    h -= s;
    h = Math.max(0, h);

    // Extended mode, copy masked part
    if (maskedWords) {
      for (var i = 0; i < s; i++) {
        maskedWords.words[i] = this.words[i];
      }
      maskedWords.length = s;
    }

    if (s === 0) {
      // No-op, we should not move anything at all
    } else if (this.length > s) {
      this.length -= s;
      for (i = 0; i < this.length; i++) {
        this.words[i] = this.words[i + s];
      }
    } else {
      this.words[0] = 0;
      this.length = 1;
    }

    var carry = 0;
    for (i = this.length - 1; i >= 0 && (carry !== 0 || i >= h); i--) {
      var word = this.words[i] | 0;
      this.words[i] = (carry << (26 - r)) | (word >>> r);
      carry = word & mask;
    }

    // Push carried bits as a mask
    if (maskedWords && carry !== 0) {
      maskedWords.words[maskedWords.length++] = carry;
    }

    if (this.length === 0) {
      this.words[0] = 0;
      this.length = 1;
    }

    return this._strip();
  };

  BN.prototype.ishrn = function ishrn (bits, hint, extended) {
    // TODO(indutny): implement me
    assert(this.negative === 0);
    return this.iushrn(bits, hint, extended);
  };

  // Shift-left
  BN.prototype.shln = function shln (bits) {
    return this.clone().ishln(bits);
  };

  BN.prototype.ushln = function ushln (bits) {
    return this.clone().iushln(bits);
  };

  // Shift-right
  BN.prototype.shrn = function shrn (bits) {
    return this.clone().ishrn(bits);
  };

  BN.prototype.ushrn = function ushrn (bits) {
    return this.clone().iushrn(bits);
  };

  // Test if n bit is set
  BN.prototype.testn = function testn (bit) {
    assert(typeof bit === 'number' && bit >= 0);
    var r = bit % 26;
    var s = (bit - r) / 26;
    var q = 1 << r;

    // Fast case: bit is much higher than all existing words
    if (this.length <= s) return false;

    // Check bit and return
    var w = this.words[s];

    return !!(w & q);
  };

  // Return only lowers bits of number (in-place)
  BN.prototype.imaskn = function imaskn (bits) {
    assert(typeof bits === 'number' && bits >= 0);
    var r = bits % 26;
    var s = (bits - r) / 26;

    assert(this.negative === 0, 'imaskn works only with positive numbers');

    if (this.length <= s) {
      return this;
    }

    if (r !== 0) {
      s++;
    }
    this.length = Math.min(s, this.length);

    if (r !== 0) {
      var mask = 0x3ffffff ^ ((0x3ffffff >>> r) << r);
      this.words[this.length - 1] &= mask;
    }

    return this._strip();
  };

  // Return only lowers bits of number
  BN.prototype.maskn = function maskn (bits) {
    return this.clone().imaskn(bits);
  };

  // Add plain number `num` to `this`
  BN.prototype.iaddn = function iaddn (num) {
    assert(typeof num === 'number');
    assert(num < 0x4000000);
    if (num < 0) return this.isubn(-num);

    // Possible sign change
    if (this.negative !== 0) {
      if (this.length === 1 && (this.words[0] | 0) <= num) {
        this.words[0] = num - (this.words[0] | 0);
        this.negative = 0;
        return this;
      }

      this.negative = 0;
      this.isubn(num);
      this.negative = 1;
      return this;
    }

    // Add without checks
    return this._iaddn(num);
  };

  BN.prototype._iaddn = function _iaddn (num) {
    this.words[0] += num;

    // Carry
    for (var i = 0; i < this.length && this.words[i] >= 0x4000000; i++) {
      this.words[i] -= 0x4000000;
      if (i === this.length - 1) {
        this.words[i + 1] = 1;
      } else {
        this.words[i + 1]++;
      }
    }
    this.length = Math.max(this.length, i + 1);

    return this;
  };

  // Subtract plain number `num` from `this`
  BN.prototype.isubn = function isubn (num) {
    assert(typeof num === 'number');
    assert(num < 0x4000000);
    if (num < 0) return this.iaddn(-num);

    if (this.negative !== 0) {
      this.negative = 0;
      this.iaddn(num);
      this.negative = 1;
      return this;
    }

    this.words[0] -= num;

    if (this.length === 1 && this.words[0] < 0) {
      this.words[0] = -this.words[0];
      this.negative = 1;
    } else {
      // Carry
      for (var i = 0; i < this.length && this.words[i] < 0; i++) {
        this.words[i] += 0x4000000;
        this.words[i + 1] -= 1;
      }
    }

    return this._strip();
  };

  BN.prototype.addn = function addn (num) {
    return this.clone().iaddn(num);
  };

  BN.prototype.subn = function subn (num) {
    return this.clone().isubn(num);
  };

  BN.prototype.iabs = function iabs () {
    this.negative = 0;

    return this;
  };

  BN.prototype.abs = function abs () {
    return this.clone().iabs();
  };

  BN.prototype._ishlnsubmul = function _ishlnsubmul (num, mul, shift) {
    var len = num.length + shift;
    var i;

    this._expand(len);

    var w;
    var carry = 0;
    for (i = 0; i < num.length; i++) {
      w = (this.words[i + shift] | 0) + carry;
      var right = (num.words[i] | 0) * mul;
      w -= right & 0x3ffffff;
      carry = (w >> 26) - ((right / 0x4000000) | 0);
      this.words[i + shift] = w & 0x3ffffff;
    }
    for (; i < this.length - shift; i++) {
      w = (this.words[i + shift] | 0) + carry;
      carry = w >> 26;
      this.words[i + shift] = w & 0x3ffffff;
    }

    if (carry === 0) return this._strip();

    // Subtraction overflow
    assert(carry === -1);
    carry = 0;
    for (i = 0; i < this.length; i++) {
      w = -(this.words[i] | 0) + carry;
      carry = w >> 26;
      this.words[i] = w & 0x3ffffff;
    }
    this.negative = 1;

    return this._strip();
  };

  BN.prototype._wordDiv = function _wordDiv (num, mode) {
    var shift = this.length - num.length;

    var a = this.clone();
    var b = num;

    // Normalize
    var bhi = b.words[b.length - 1] | 0;
    var bhiBits = this._countBits(bhi);
    shift = 26 - bhiBits;
    if (shift !== 0) {
      b = b.ushln(shift);
      a.iushln(shift);
      bhi = b.words[b.length - 1] | 0;
    }

    // Initialize quotient
    var m = a.length - b.length;
    var q;

    if (mode !== 'mod') {
      q = new BN(null);
      q.length = m + 1;
      q.words = new Array(q.length);
      for (var i = 0; i < q.length; i++) {
        q.words[i] = 0;
      }
    }

    var diff = a.clone()._ishlnsubmul(b, 1, m);
    if (diff.negative === 0) {
      a = diff;
      if (q) {
        q.words[m] = 1;
      }
    }

    for (var j = m - 1; j >= 0; j--) {
      var qj = (a.words[b.length + j] | 0) * 0x4000000 +
        (a.words[b.length + j - 1] | 0);

      // NOTE: (qj / bhi) is (0x3ffffff * 0x4000000 + 0x3ffffff) / 0x2000000 max
      // (0x7ffffff)
      qj = Math.min((qj / bhi) | 0, 0x3ffffff);

      a._ishlnsubmul(b, qj, j);
      while (a.negative !== 0) {
        qj--;
        a.negative = 0;
        a._ishlnsubmul(b, 1, j);
        if (!a.isZero()) {
          a.negative ^= 1;
        }
      }
      if (q) {
        q.words[j] = qj;
      }
    }
    if (q) {
      q._strip();
    }
    a._strip();

    // Denormalize
    if (mode !== 'div' && shift !== 0) {
      a.iushrn(shift);
    }

    return {
      div: q || null,
      mod: a
    };
  };

  // NOTE: 1) `mode` can be set to `mod` to request mod only,
  //       to `div` to request div only, or be absent to
  //       request both div & mod
  //       2) `positive` is true if unsigned mod is requested
  BN.prototype.divmod = function divmod (num, mode, positive) {
    assert(!num.isZero());

    if (this.isZero()) {
      return {
        div: new BN(0),
        mod: new BN(0)
      };
    }

    var div, mod, res;
    if (this.negative !== 0 && num.negative === 0) {
      res = this.neg().divmod(num, mode);

      if (mode !== 'mod') {
        div = res.div.neg();
      }

      if (mode !== 'div') {
        mod = res.mod.neg();
        if (positive && mod.negative !== 0) {
          mod.iadd(num);
        }
      }

      return {
        div: div,
        mod: mod
      };
    }

    if (this.negative === 0 && num.negative !== 0) {
      res = this.divmod(num.neg(), mode);

      if (mode !== 'mod') {
        div = res.div.neg();
      }

      return {
        div: div,
        mod: res.mod
      };
    }

    if ((this.negative & num.negative) !== 0) {
      res = this.neg().divmod(num.neg(), mode);

      if (mode !== 'div') {
        mod = res.mod.neg();
        if (positive && mod.negative !== 0) {
          mod.isub(num);
        }
      }

      return {
        div: res.div,
        mod: mod
      };
    }

    // Both numbers are positive at this point

    // Strip both numbers to approximate shift value
    if (num.length > this.length || this.cmp(num) < 0) {
      return {
        div: new BN(0),
        mod: this
      };
    }

    // Very short reduction
    if (num.length === 1) {
      if (mode === 'div') {
        return {
          div: this.divn(num.words[0]),
          mod: null
        };
      }

      if (mode === 'mod') {
        return {
          div: null,
          mod: new BN(this.modrn(num.words[0]))
        };
      }

      return {
        div: this.divn(num.words[0]),
        mod: new BN(this.modrn(num.words[0]))
      };
    }

    return this._wordDiv(num, mode);
  };

  // Find `this` / `num`
  BN.prototype.div = function div (num) {
    return this.divmod(num, 'div', false).div;
  };

  // Find `this` % `num`
  BN.prototype.mod = function mod (num) {
    return this.divmod(num, 'mod', false).mod;
  };

  BN.prototype.umod = function umod (num) {
    return this.divmod(num, 'mod', true).mod;
  };

  // Find Round(`this` / `num`)
  BN.prototype.divRound = function divRound (num) {
    var dm = this.divmod(num);

    // Fast case - exact division
    if (dm.mod.isZero()) return dm.div;

    var mod = dm.div.negative !== 0 ? dm.mod.isub(num) : dm.mod;

    var half = num.ushrn(1);
    var r2 = num.andln(1);
    var cmp = mod.cmp(half);

    // Round down
    if (cmp < 0 || (r2 === 1 && cmp === 0)) return dm.div;

    // Round up
    return dm.div.negative !== 0 ? dm.div.isubn(1) : dm.div.iaddn(1);
  };

  BN.prototype.modrn = function modrn (num) {
    var isNegNum = num < 0;
    if (isNegNum) num = -num;

    assert(num <= 0x3ffffff);
    var p = (1 << 26) % num;

    var acc = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      acc = (p * acc + (this.words[i] | 0)) % num;
    }

    return isNegNum ? -acc : acc;
  };

  // WARNING: DEPRECATED
  BN.prototype.modn = function modn (num) {
    return this.modrn(num);
  };

  // In-place division by number
  BN.prototype.idivn = function idivn (num) {
    var isNegNum = num < 0;
    if (isNegNum) num = -num;

    assert(num <= 0x3ffffff);

    var carry = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      var w = (this.words[i] | 0) + carry * 0x4000000;
      this.words[i] = (w / num) | 0;
      carry = w % num;
    }

    this._strip();
    return isNegNum ? this.ineg() : this;
  };

  BN.prototype.divn = function divn (num) {
    return this.clone().idivn(num);
  };

  BN.prototype.egcd = function egcd (p) {
    assert(p.negative === 0);
    assert(!p.isZero());

    var x = this;
    var y = p.clone();

    if (x.negative !== 0) {
      x = x.umod(p);
    } else {
      x = x.clone();
    }

    // A * x + B * y = x
    var A = new BN(1);
    var B = new BN(0);

    // C * x + D * y = y
    var C = new BN(0);
    var D = new BN(1);

    var g = 0;

    while (x.isEven() && y.isEven()) {
      x.iushrn(1);
      y.iushrn(1);
      ++g;
    }

    var yp = y.clone();
    var xp = x.clone();

    while (!x.isZero()) {
      for (var i = 0, im = 1; (x.words[0] & im) === 0 && i < 26; ++i, im <<= 1);
      if (i > 0) {
        x.iushrn(i);
        while (i-- > 0) {
          if (A.isOdd() || B.isOdd()) {
            A.iadd(yp);
            B.isub(xp);
          }

          A.iushrn(1);
          B.iushrn(1);
        }
      }

      for (var j = 0, jm = 1; (y.words[0] & jm) === 0 && j < 26; ++j, jm <<= 1);
      if (j > 0) {
        y.iushrn(j);
        while (j-- > 0) {
          if (C.isOdd() || D.isOdd()) {
            C.iadd(yp);
            D.isub(xp);
          }

          C.iushrn(1);
          D.iushrn(1);
        }
      }

      if (x.cmp(y) >= 0) {
        x.isub(y);
        A.isub(C);
        B.isub(D);
      } else {
        y.isub(x);
        C.isub(A);
        D.isub(B);
      }
    }

    return {
      a: C,
      b: D,
      gcd: y.iushln(g)
    };
  };

  // This is reduced incarnation of the binary EEA
  // above, designated to invert members of the
  // _prime_ fields F(p) at a maximal speed
  BN.prototype._invmp = function _invmp (p) {
    assert(p.negative === 0);
    assert(!p.isZero());

    var a = this;
    var b = p.clone();

    if (a.negative !== 0) {
      a = a.umod(p);
    } else {
      a = a.clone();
    }

    var x1 = new BN(1);
    var x2 = new BN(0);

    var delta = b.clone();

    while (a.cmpn(1) > 0 && b.cmpn(1) > 0) {
      for (var i = 0, im = 1; (a.words[0] & im) === 0 && i < 26; ++i, im <<= 1);
      if (i > 0) {
        a.iushrn(i);
        while (i-- > 0) {
          if (x1.isOdd()) {
            x1.iadd(delta);
          }

          x1.iushrn(1);
        }
      }

      for (var j = 0, jm = 1; (b.words[0] & jm) === 0 && j < 26; ++j, jm <<= 1);
      if (j > 0) {
        b.iushrn(j);
        while (j-- > 0) {
          if (x2.isOdd()) {
            x2.iadd(delta);
          }

          x2.iushrn(1);
        }
      }

      if (a.cmp(b) >= 0) {
        a.isub(b);
        x1.isub(x2);
      } else {
        b.isub(a);
        x2.isub(x1);
      }
    }

    var res;
    if (a.cmpn(1) === 0) {
      res = x1;
    } else {
      res = x2;
    }

    if (res.cmpn(0) < 0) {
      res.iadd(p);
    }

    return res;
  };

  BN.prototype.gcd = function gcd (num) {
    if (this.isZero()) return num.abs();
    if (num.isZero()) return this.abs();

    var a = this.clone();
    var b = num.clone();
    a.negative = 0;
    b.negative = 0;

    // Remove common factor of two
    for (var shift = 0; a.isEven() && b.isEven(); shift++) {
      a.iushrn(1);
      b.iushrn(1);
    }

    do {
      while (a.isEven()) {
        a.iushrn(1);
      }
      while (b.isEven()) {
        b.iushrn(1);
      }

      var r = a.cmp(b);
      if (r < 0) {
        // Swap `a` and `b` to make `a` always bigger than `b`
        var t = a;
        a = b;
        b = t;
      } else if (r === 0 || b.cmpn(1) === 0) {
        break;
      }

      a.isub(b);
    } while (true);

    return b.iushln(shift);
  };

  // Invert number in the field F(num)
  BN.prototype.invm = function invm (num) {
    return this.egcd(num).a.umod(num);
  };

  BN.prototype.isEven = function isEven () {
    return (this.words[0] & 1) === 0;
  };

  BN.prototype.isOdd = function isOdd () {
    return (this.words[0] & 1) === 1;
  };

  // And first word and num
  BN.prototype.andln = function andln (num) {
    return this.words[0] & num;
  };

  // Increment at the bit position in-line
  BN.prototype.bincn = function bincn (bit) {
    assert(typeof bit === 'number');
    var r = bit % 26;
    var s = (bit - r) / 26;
    var q = 1 << r;

    // Fast case: bit is much higher than all existing words
    if (this.length <= s) {
      this._expand(s + 1);
      this.words[s] |= q;
      return this;
    }

    // Add bit and propagate, if needed
    var carry = q;
    for (var i = s; carry !== 0 && i < this.length; i++) {
      var w = this.words[i] | 0;
      w += carry;
      carry = w >>> 26;
      w &= 0x3ffffff;
      this.words[i] = w;
    }
    if (carry !== 0) {
      this.words[i] = carry;
      this.length++;
    }
    return this;
  };

  BN.prototype.isZero = function isZero () {
    return this.length === 1 && this.words[0] === 0;
  };

  BN.prototype.cmpn = function cmpn (num) {
    var negative = num < 0;

    if (this.negative !== 0 && !negative) return -1;
    if (this.negative === 0 && negative) return 1;

    this._strip();

    var res;
    if (this.length > 1) {
      res = 1;
    } else {
      if (negative) {
        num = -num;
      }

      assert(num <= 0x3ffffff, 'Number is too big');

      var w = this.words[0] | 0;
      res = w === num ? 0 : w < num ? -1 : 1;
    }
    if (this.negative !== 0) return -res | 0;
    return res;
  };

  // Compare two numbers and return:
  // 1 - if `this` > `num`
  // 0 - if `this` == `num`
  // -1 - if `this` < `num`
  BN.prototype.cmp = function cmp (num) {
    if (this.negative !== 0 && num.negative === 0) return -1;
    if (this.negative === 0 && num.negative !== 0) return 1;

    var res = this.ucmp(num);
    if (this.negative !== 0) return -res | 0;
    return res;
  };

  // Unsigned comparison
  BN.prototype.ucmp = function ucmp (num) {
    // At this point both numbers have the same sign
    if (this.length > num.length) return 1;
    if (this.length < num.length) return -1;

    var res = 0;
    for (var i = this.length - 1; i >= 0; i--) {
      var a = this.words[i] | 0;
      var b = num.words[i] | 0;

      if (a === b) continue;
      if (a < b) {
        res = -1;
      } else if (a > b) {
        res = 1;
      }
      break;
    }
    return res;
  };

  BN.prototype.gtn = function gtn (num) {
    return this.cmpn(num) === 1;
  };

  BN.prototype.gt = function gt (num) {
    return this.cmp(num) === 1;
  };

  BN.prototype.gten = function gten (num) {
    return this.cmpn(num) >= 0;
  };

  BN.prototype.gte = function gte (num) {
    return this.cmp(num) >= 0;
  };

  BN.prototype.ltn = function ltn (num) {
    return this.cmpn(num) === -1;
  };

  BN.prototype.lt = function lt (num) {
    return this.cmp(num) === -1;
  };

  BN.prototype.lten = function lten (num) {
    return this.cmpn(num) <= 0;
  };

  BN.prototype.lte = function lte (num) {
    return this.cmp(num) <= 0;
  };

  BN.prototype.eqn = function eqn (num) {
    return this.cmpn(num) === 0;
  };

  BN.prototype.eq = function eq (num) {
    return this.cmp(num) === 0;
  };

  //
  // A reduce context, could be using montgomery or something better, depending
  // on the `m` itself.
  //
  BN.red = function red (num) {
    return new Red(num);
  };

  BN.prototype.toRed = function toRed (ctx) {
    assert(!this.red, 'Already a number in reduction context');
    assert(this.negative === 0, 'red works only with positives');
    return ctx.convertTo(this)._forceRed(ctx);
  };

  BN.prototype.fromRed = function fromRed () {
    assert(this.red, 'fromRed works only with numbers in reduction context');
    return this.red.convertFrom(this);
  };

  BN.prototype._forceRed = function _forceRed (ctx) {
    this.red = ctx;
    return this;
  };

  BN.prototype.forceRed = function forceRed (ctx) {
    assert(!this.red, 'Already a number in reduction context');
    return this._forceRed(ctx);
  };

  BN.prototype.redAdd = function redAdd (num) {
    assert(this.red, 'redAdd works only with red numbers');
    return this.red.add(this, num);
  };

  BN.prototype.redIAdd = function redIAdd (num) {
    assert(this.red, 'redIAdd works only with red numbers');
    return this.red.iadd(this, num);
  };

  BN.prototype.redSub = function redSub (num) {
    assert(this.red, 'redSub works only with red numbers');
    return this.red.sub(this, num);
  };

  BN.prototype.redISub = function redISub (num) {
    assert(this.red, 'redISub works only with red numbers');
    return this.red.isub(this, num);
  };

  BN.prototype.redShl = function redShl (num) {
    assert(this.red, 'redShl works only with red numbers');
    return this.red.shl(this, num);
  };

  BN.prototype.redMul = function redMul (num) {
    assert(this.red, 'redMul works only with red numbers');
    this.red._verify2(this, num);
    return this.red.mul(this, num);
  };

  BN.prototype.redIMul = function redIMul (num) {
    assert(this.red, 'redMul works only with red numbers');
    this.red._verify2(this, num);
    return this.red.imul(this, num);
  };

  BN.prototype.redSqr = function redSqr () {
    assert(this.red, 'redSqr works only with red numbers');
    this.red._verify1(this);
    return this.red.sqr(this);
  };

  BN.prototype.redISqr = function redISqr () {
    assert(this.red, 'redISqr works only with red numbers');
    this.red._verify1(this);
    return this.red.isqr(this);
  };

  // Square root over p
  BN.prototype.redSqrt = function redSqrt () {
    assert(this.red, 'redSqrt works only with red numbers');
    this.red._verify1(this);
    return this.red.sqrt(this);
  };

  BN.prototype.redInvm = function redInvm () {
    assert(this.red, 'redInvm works only with red numbers');
    this.red._verify1(this);
    return this.red.invm(this);
  };

  // Return negative clone of `this` % `red modulo`
  BN.prototype.redNeg = function redNeg () {
    assert(this.red, 'redNeg works only with red numbers');
    this.red._verify1(this);
    return this.red.neg(this);
  };

  BN.prototype.redPow = function redPow (num) {
    assert(this.red && !num.red, 'redPow(normalNum)');
    this.red._verify1(this);
    return this.red.pow(this, num);
  };

  // Prime numbers with efficient reduction
  var primes = {
    k256: null,
    p224: null,
    p192: null,
    p25519: null
  };

  // Pseudo-Mersenne prime
  function MPrime (name, p) {
    // P = 2 ^ N - K
    this.name = name;
    this.p = new BN(p, 16);
    this.n = this.p.bitLength();
    this.k = new BN(1).iushln(this.n).isub(this.p);

    this.tmp = this._tmp();
  }

  MPrime.prototype._tmp = function _tmp () {
    var tmp = new BN(null);
    tmp.words = new Array(Math.ceil(this.n / 13));
    return tmp;
  };

  MPrime.prototype.ireduce = function ireduce (num) {
    // Assumes that `num` is less than `P^2`
    // num = HI * (2 ^ N - K) + HI * K + LO = HI * K + LO (mod P)
    var r = num;
    var rlen;

    do {
      this.split(r, this.tmp);
      r = this.imulK(r);
      r = r.iadd(this.tmp);
      rlen = r.bitLength();
    } while (rlen > this.n);

    var cmp = rlen < this.n ? -1 : r.ucmp(this.p);
    if (cmp === 0) {
      r.words[0] = 0;
      r.length = 1;
    } else if (cmp > 0) {
      r.isub(this.p);
    } else {
      if (r.strip !== undefined) {
        // r is a BN v4 instance
        r.strip();
      } else {
        // r is a BN v5 instance
        r._strip();
      }
    }

    return r;
  };

  MPrime.prototype.split = function split (input, out) {
    input.iushrn(this.n, 0, out);
  };

  MPrime.prototype.imulK = function imulK (num) {
    return num.imul(this.k);
  };

  function K256 () {
    MPrime.call(
      this,
      'k256',
      'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe fffffc2f');
  }
  inherits(K256, MPrime);

  K256.prototype.split = function split (input, output) {
    // 256 = 9 * 26 + 22
    var mask = 0x3fffff;

    var outLen = Math.min(input.length, 9);
    for (var i = 0; i < outLen; i++) {
      output.words[i] = input.words[i];
    }
    output.length = outLen;

    if (input.length <= 9) {
      input.words[0] = 0;
      input.length = 1;
      return;
    }

    // Shift by 9 limbs
    var prev = input.words[9];
    output.words[output.length++] = prev & mask;

    for (i = 10; i < input.length; i++) {
      var next = input.words[i] | 0;
      input.words[i - 10] = ((next & mask) << 4) | (prev >>> 22);
      prev = next;
    }
    prev >>>= 22;
    input.words[i - 10] = prev;
    if (prev === 0 && input.length > 10) {
      input.length -= 10;
    } else {
      input.length -= 9;
    }
  };

  K256.prototype.imulK = function imulK (num) {
    // K = 0x1000003d1 = [ 0x40, 0x3d1 ]
    num.words[num.length] = 0;
    num.words[num.length + 1] = 0;
    num.length += 2;

    // bounded at: 0x40 * 0x3ffffff + 0x3d0 = 0x100000390
    var lo = 0;
    for (var i = 0; i < num.length; i++) {
      var w = num.words[i] | 0;
      lo += w * 0x3d1;
      num.words[i] = lo & 0x3ffffff;
      lo = w * 0x40 + ((lo / 0x4000000) | 0);
    }

    // Fast length reduction
    if (num.words[num.length - 1] === 0) {
      num.length--;
      if (num.words[num.length - 1] === 0) {
        num.length--;
      }
    }
    return num;
  };

  function P224 () {
    MPrime.call(
      this,
      'p224',
      'ffffffff ffffffff ffffffff ffffffff 00000000 00000000 00000001');
  }
  inherits(P224, MPrime);

  function P192 () {
    MPrime.call(
      this,
      'p192',
      'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff');
  }
  inherits(P192, MPrime);

  function P25519 () {
    // 2 ^ 255 - 19
    MPrime.call(
      this,
      '25519',
      '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed');
  }
  inherits(P25519, MPrime);

  P25519.prototype.imulK = function imulK (num) {
    // K = 0x13
    var carry = 0;
    for (var i = 0; i < num.length; i++) {
      var hi = (num.words[i] | 0) * 0x13 + carry;
      var lo = hi & 0x3ffffff;
      hi >>>= 26;

      num.words[i] = lo;
      carry = hi;
    }
    if (carry !== 0) {
      num.words[num.length++] = carry;
    }
    return num;
  };

  // Exported mostly for testing purposes, use plain name instead
  BN._prime = function prime (name) {
    // Cached version of prime
    if (primes[name]) return primes[name];

    var prime;
    if (name === 'k256') {
      prime = new K256();
    } else if (name === 'p224') {
      prime = new P224();
    } else if (name === 'p192') {
      prime = new P192();
    } else if (name === 'p25519') {
      prime = new P25519();
    } else {
      throw new Error('Unknown prime ' + name);
    }
    primes[name] = prime;

    return prime;
  };

  //
  // Base reduction engine
  //
  function Red (m) {
    if (typeof m === 'string') {
      var prime = BN._prime(m);
      this.m = prime.p;
      this.prime = prime;
    } else {
      assert(m.gtn(1), 'modulus must be greater than 1');
      this.m = m;
      this.prime = null;
    }
  }

  Red.prototype._verify1 = function _verify1 (a) {
    assert(a.negative === 0, 'red works only with positives');
    assert(a.red, 'red works only with red numbers');
  };

  Red.prototype._verify2 = function _verify2 (a, b) {
    assert((a.negative | b.negative) === 0, 'red works only with positives');
    assert(a.red && a.red === b.red,
      'red works only with red numbers');
  };

  Red.prototype.imod = function imod (a) {
    if (this.prime) return this.prime.ireduce(a)._forceRed(this);

    move(a, a.umod(this.m)._forceRed(this));
    return a;
  };

  Red.prototype.neg = function neg (a) {
    if (a.isZero()) {
      return a.clone();
    }

    return this.m.sub(a)._forceRed(this);
  };

  Red.prototype.add = function add (a, b) {
    this._verify2(a, b);

    var res = a.add(b);
    if (res.cmp(this.m) >= 0) {
      res.isub(this.m);
    }
    return res._forceRed(this);
  };

  Red.prototype.iadd = function iadd (a, b) {
    this._verify2(a, b);

    var res = a.iadd(b);
    if (res.cmp(this.m) >= 0) {
      res.isub(this.m);
    }
    return res;
  };

  Red.prototype.sub = function sub (a, b) {
    this._verify2(a, b);

    var res = a.sub(b);
    if (res.cmpn(0) < 0) {
      res.iadd(this.m);
    }
    return res._forceRed(this);
  };

  Red.prototype.isub = function isub (a, b) {
    this._verify2(a, b);

    var res = a.isub(b);
    if (res.cmpn(0) < 0) {
      res.iadd(this.m);
    }
    return res;
  };

  Red.prototype.shl = function shl (a, num) {
    this._verify1(a);
    return this.imod(a.ushln(num));
  };

  Red.prototype.imul = function imul (a, b) {
    this._verify2(a, b);
    return this.imod(a.imul(b));
  };

  Red.prototype.mul = function mul (a, b) {
    this._verify2(a, b);
    return this.imod(a.mul(b));
  };

  Red.prototype.isqr = function isqr (a) {
    return this.imul(a, a.clone());
  };

  Red.prototype.sqr = function sqr (a) {
    return this.mul(a, a);
  };

  Red.prototype.sqrt = function sqrt (a) {
    if (a.isZero()) return a.clone();

    var mod3 = this.m.andln(3);
    assert(mod3 % 2 === 1);

    // Fast case
    if (mod3 === 3) {
      var pow = this.m.add(new BN(1)).iushrn(2);
      return this.pow(a, pow);
    }

    // Tonelli-Shanks algorithm (Totally unoptimized and slow)
    //
    // Find Q and S, that Q * 2 ^ S = (P - 1)
    var q = this.m.subn(1);
    var s = 0;
    while (!q.isZero() && q.andln(1) === 0) {
      s++;
      q.iushrn(1);
    }
    assert(!q.isZero());

    var one = new BN(1).toRed(this);
    var nOne = one.redNeg();

    // Find quadratic non-residue
    // NOTE: Max is such because of generalized Riemann hypothesis.
    var lpow = this.m.subn(1).iushrn(1);
    var z = this.m.bitLength();
    z = new BN(2 * z * z).toRed(this);

    while (this.pow(z, lpow).cmp(nOne) !== 0) {
      z.redIAdd(nOne);
    }

    var c = this.pow(z, q);
    var r = this.pow(a, q.addn(1).iushrn(1));
    var t = this.pow(a, q);
    var m = s;
    while (t.cmp(one) !== 0) {
      var tmp = t;
      for (var i = 0; tmp.cmp(one) !== 0; i++) {
        tmp = tmp.redSqr();
      }
      assert(i < m);
      var b = this.pow(c, new BN(1).iushln(m - i - 1));

      r = r.redMul(b);
      c = b.redSqr();
      t = t.redMul(c);
      m = i;
    }

    return r;
  };

  Red.prototype.invm = function invm (a) {
    var inv = a._invmp(this.m);
    if (inv.negative !== 0) {
      inv.negative = 0;
      return this.imod(inv).redNeg();
    } else {
      return this.imod(inv);
    }
  };

  Red.prototype.pow = function pow (a, num) {
    if (num.isZero()) return new BN(1).toRed(this);
    if (num.cmpn(1) === 0) return a.clone();

    var windowSize = 4;
    var wnd = new Array(1 << windowSize);
    wnd[0] = new BN(1).toRed(this);
    wnd[1] = a;
    for (var i = 2; i < wnd.length; i++) {
      wnd[i] = this.mul(wnd[i - 1], a);
    }

    var res = wnd[0];
    var current = 0;
    var currentLen = 0;
    var start = num.bitLength() % 26;
    if (start === 0) {
      start = 26;
    }

    for (i = num.length - 1; i >= 0; i--) {
      var word = num.words[i];
      for (var j = start - 1; j >= 0; j--) {
        var bit = (word >> j) & 1;
        if (res !== wnd[0]) {
          res = this.sqr(res);
        }

        if (bit === 0 && current === 0) {
          currentLen = 0;
          continue;
        }

        current <<= 1;
        current |= bit;
        currentLen++;
        if (currentLen !== windowSize && (i !== 0 || j !== 0)) continue;

        res = this.mul(res, wnd[current]);
        currentLen = 0;
        current = 0;
      }
      start = 26;
    }

    return res;
  };

  Red.prototype.convertTo = function convertTo (num) {
    var r = num.umod(this.m);

    return r === num ? r.clone() : r;
  };

  Red.prototype.convertFrom = function convertFrom (num) {
    var res = num.clone();
    res.red = null;
    return res;
  };

  //
  // Montgomery method engine
  //

  BN.mont = function mont (num) {
    return new Mont(num);
  };

  function Mont (m) {
    Red.call(this, m);

    this.shift = this.m.bitLength();
    if (this.shift % 26 !== 0) {
      this.shift += 26 - (this.shift % 26);
    }

    this.r = new BN(1).iushln(this.shift);
    this.r2 = this.imod(this.r.sqr());
    this.rinv = this.r._invmp(this.m);

    this.minv = this.rinv.mul(this.r).isubn(1).div(this.m);
    this.minv = this.minv.umod(this.r);
    this.minv = this.r.sub(this.minv);
  }
  inherits(Mont, Red);

  Mont.prototype.convertTo = function convertTo (num) {
    return this.imod(num.ushln(this.shift));
  };

  Mont.prototype.convertFrom = function convertFrom (num) {
    var r = this.imod(num.mul(this.rinv));
    r.red = null;
    return r;
  };

  Mont.prototype.imul = function imul (a, b) {
    if (a.isZero() || b.isZero()) {
      a.words[0] = 0;
      a.length = 1;
      return a;
    }

    var t = a.imul(b);
    var c = t.maskn(this.shift).mul(this.minv).imaskn(this.shift).mul(this.m);
    var u = t.isub(c).iushrn(this.shift);
    var res = u;

    if (u.cmp(this.m) >= 0) {
      res = u.isub(this.m);
    } else if (u.cmpn(0) < 0) {
      res = u.iadd(this.m);
    }

    return res._forceRed(this);
  };

  Mont.prototype.mul = function mul (a, b) {
    if (a.isZero() || b.isZero()) return new BN(0)._forceRed(this);

    var t = a.mul(b);
    var c = t.maskn(this.shift).mul(this.minv).imaskn(this.shift).mul(this.m);
    var u = t.isub(c).iushrn(this.shift);
    var res = u;
    if (u.cmp(this.m) >= 0) {
      res = u.isub(this.m);
    } else if (u.cmpn(0) < 0) {
      res = u.iadd(this.m);
    }

    return res._forceRed(this);
  };

  Mont.prototype.invm = function invm (a) {
    // (AR)^-1 * R^2 = (A^-1 * R^-1) * R^2 = A^-1 * R
    var res = this.imod(a._invmp(this.m).mul(this.r2));
    return res._forceRed(this);
  };
})(typeof module === 'undefined' || module, this);

},{"buffer":45}],44:[function(require,module,exports){
var r;

module.exports = function rand(len) {
  if (!r)
    r = new Rand(null);

  return r.generate(len);
};

function Rand(rand) {
  this.rand = rand;
}
module.exports.Rand = Rand;

Rand.prototype.generate = function generate(len) {
  return this._rand(len);
};

// Emulate crypto API using randy
Rand.prototype._rand = function _rand(n) {
  if (this.rand.getBytes)
    return this.rand.getBytes(n);

  var res = new Uint8Array(n);
  for (var i = 0; i < res.length; i++)
    res[i] = this.rand.getByte();
  return res;
};

if (typeof self === 'object') {
  if (self.crypto && self.crypto.getRandomValues) {
    // Modern browsers
    Rand.prototype._rand = function _rand(n) {
      var arr = new Uint8Array(n);
      self.crypto.getRandomValues(arr);
      return arr;
    };
  } else if (self.msCrypto && self.msCrypto.getRandomValues) {
    // IE
    Rand.prototype._rand = function _rand(n) {
      var arr = new Uint8Array(n);
      self.msCrypto.getRandomValues(arr);
      return arr;
    };

  // Safari's WebWorkers do not have `crypto`
  } else if (typeof window === 'object') {
    // Old junk
    Rand.prototype._rand = function() {
      throw new Error('Not implemented yet');
    };
  }
} else {
  // Node.js or Web worker with no crypto support
  try {
    var crypto = require('crypto');
    if (typeof crypto.randomBytes !== 'function')
      throw new Error('Not supported');

    Rand.prototype._rand = function _rand(n) {
      return crypto.randomBytes(n);
    };
  } catch (e) {
  }
}

},{"crypto":45}],45:[function(require,module,exports){

},{}],46:[function(require,module,exports){
// based on the aes implimentation in triple sec
// https://github.com/keybase/triplesec
// which is in turn based on the one from crypto-js
// https://code.google.com/p/crypto-js/

var Buffer = require('safe-buffer').Buffer

function asUInt32Array (buf) {
  if (!Buffer.isBuffer(buf)) buf = Buffer.from(buf)

  var len = (buf.length / 4) | 0
  var out = new Array(len)

  for (var i = 0; i < len; i++) {
    out[i] = buf.readUInt32BE(i * 4)
  }

  return out
}

function scrubVec (v) {
  for (var i = 0; i < v.length; v++) {
    v[i] = 0
  }
}

function cryptBlock (M, keySchedule, SUB_MIX, SBOX, nRounds) {
  var SUB_MIX0 = SUB_MIX[0]
  var SUB_MIX1 = SUB_MIX[1]
  var SUB_MIX2 = SUB_MIX[2]
  var SUB_MIX3 = SUB_MIX[3]

  var s0 = M[0] ^ keySchedule[0]
  var s1 = M[1] ^ keySchedule[1]
  var s2 = M[2] ^ keySchedule[2]
  var s3 = M[3] ^ keySchedule[3]
  var t0, t1, t2, t3
  var ksRow = 4

  for (var round = 1; round < nRounds; round++) {
    t0 = SUB_MIX0[s0 >>> 24] ^ SUB_MIX1[(s1 >>> 16) & 0xff] ^ SUB_MIX2[(s2 >>> 8) & 0xff] ^ SUB_MIX3[s3 & 0xff] ^ keySchedule[ksRow++]
    t1 = SUB_MIX0[s1 >>> 24] ^ SUB_MIX1[(s2 >>> 16) & 0xff] ^ SUB_MIX2[(s3 >>> 8) & 0xff] ^ SUB_MIX3[s0 & 0xff] ^ keySchedule[ksRow++]
    t2 = SUB_MIX0[s2 >>> 24] ^ SUB_MIX1[(s3 >>> 16) & 0xff] ^ SUB_MIX2[(s0 >>> 8) & 0xff] ^ SUB_MIX3[s1 & 0xff] ^ keySchedule[ksRow++]
    t3 = SUB_MIX0[s3 >>> 24] ^ SUB_MIX1[(s0 >>> 16) & 0xff] ^ SUB_MIX2[(s1 >>> 8) & 0xff] ^ SUB_MIX3[s2 & 0xff] ^ keySchedule[ksRow++]
    s0 = t0
    s1 = t1
    s2 = t2
    s3 = t3
  }

  t0 = ((SBOX[s0 >>> 24] << 24) | (SBOX[(s1 >>> 16) & 0xff] << 16) | (SBOX[(s2 >>> 8) & 0xff] << 8) | SBOX[s3 & 0xff]) ^ keySchedule[ksRow++]
  t1 = ((SBOX[s1 >>> 24] << 24) | (SBOX[(s2 >>> 16) & 0xff] << 16) | (SBOX[(s3 >>> 8) & 0xff] << 8) | SBOX[s0 & 0xff]) ^ keySchedule[ksRow++]
  t2 = ((SBOX[s2 >>> 24] << 24) | (SBOX[(s3 >>> 16) & 0xff] << 16) | (SBOX[(s0 >>> 8) & 0xff] << 8) | SBOX[s1 & 0xff]) ^ keySchedule[ksRow++]
  t3 = ((SBOX[s3 >>> 24] << 24) | (SBOX[(s0 >>> 16) & 0xff] << 16) | (SBOX[(s1 >>> 8) & 0xff] << 8) | SBOX[s2 & 0xff]) ^ keySchedule[ksRow++]
  t0 = t0 >>> 0
  t1 = t1 >>> 0
  t2 = t2 >>> 0
  t3 = t3 >>> 0

  return [t0, t1, t2, t3]
}

// AES constants
var RCON = [0x00, 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36]
var G = (function () {
  // Compute double table
  var d = new Array(256)
  for (var j = 0; j < 256; j++) {
    if (j < 128) {
      d[j] = j << 1
    } else {
      d[j] = (j << 1) ^ 0x11b
    }
  }

  var SBOX = []
  var INV_SBOX = []
  var SUB_MIX = [[], [], [], []]
  var INV_SUB_MIX = [[], [], [], []]

  // Walk GF(2^8)
  var x = 0
  var xi = 0
  for (var i = 0; i < 256; ++i) {
    // Compute sbox
    var sx = xi ^ (xi << 1) ^ (xi << 2) ^ (xi << 3) ^ (xi << 4)
    sx = (sx >>> 8) ^ (sx & 0xff) ^ 0x63
    SBOX[x] = sx
    INV_SBOX[sx] = x

    // Compute multiplication
    var x2 = d[x]
    var x4 = d[x2]
    var x8 = d[x4]

    // Compute sub bytes, mix columns tables
    var t = (d[sx] * 0x101) ^ (sx * 0x1010100)
    SUB_MIX[0][x] = (t << 24) | (t >>> 8)
    SUB_MIX[1][x] = (t << 16) | (t >>> 16)
    SUB_MIX[2][x] = (t << 8) | (t >>> 24)
    SUB_MIX[3][x] = t

    // Compute inv sub bytes, inv mix columns tables
    t = (x8 * 0x1010101) ^ (x4 * 0x10001) ^ (x2 * 0x101) ^ (x * 0x1010100)
    INV_SUB_MIX[0][sx] = (t << 24) | (t >>> 8)
    INV_SUB_MIX[1][sx] = (t << 16) | (t >>> 16)
    INV_SUB_MIX[2][sx] = (t << 8) | (t >>> 24)
    INV_SUB_MIX[3][sx] = t

    if (x === 0) {
      x = xi = 1
    } else {
      x = x2 ^ d[d[d[x8 ^ x2]]]
      xi ^= d[d[xi]]
    }
  }

  return {
    SBOX: SBOX,
    INV_SBOX: INV_SBOX,
    SUB_MIX: SUB_MIX,
    INV_SUB_MIX: INV_SUB_MIX
  }
})()

function AES (key) {
  this._key = asUInt32Array(key)
  this._reset()
}

AES.blockSize = 4 * 4
AES.keySize = 256 / 8
AES.prototype.blockSize = AES.blockSize
AES.prototype.keySize = AES.keySize
AES.prototype._reset = function () {
  var keyWords = this._key
  var keySize = keyWords.length
  var nRounds = keySize + 6
  var ksRows = (nRounds + 1) * 4

  var keySchedule = []
  for (var k = 0; k < keySize; k++) {
    keySchedule[k] = keyWords[k]
  }

  for (k = keySize; k < ksRows; k++) {
    var t = keySchedule[k - 1]

    if (k % keySize === 0) {
      t = (t << 8) | (t >>> 24)
      t =
        (G.SBOX[t >>> 24] << 24) |
        (G.SBOX[(t >>> 16) & 0xff] << 16) |
        (G.SBOX[(t >>> 8) & 0xff] << 8) |
        (G.SBOX[t & 0xff])

      t ^= RCON[(k / keySize) | 0] << 24
    } else if (keySize > 6 && k % keySize === 4) {
      t =
        (G.SBOX[t >>> 24] << 24) |
        (G.SBOX[(t >>> 16) & 0xff] << 16) |
        (G.SBOX[(t >>> 8) & 0xff] << 8) |
        (G.SBOX[t & 0xff])
    }

    keySchedule[k] = keySchedule[k - keySize] ^ t
  }

  var invKeySchedule = []
  for (var ik = 0; ik < ksRows; ik++) {
    var ksR = ksRows - ik
    var tt = keySchedule[ksR - (ik % 4 ? 0 : 4)]

    if (ik < 4 || ksR <= 4) {
      invKeySchedule[ik] = tt
    } else {
      invKeySchedule[ik] =
        G.INV_SUB_MIX[0][G.SBOX[tt >>> 24]] ^
        G.INV_SUB_MIX[1][G.SBOX[(tt >>> 16) & 0xff]] ^
        G.INV_SUB_MIX[2][G.SBOX[(tt >>> 8) & 0xff]] ^
        G.INV_SUB_MIX[3][G.SBOX[tt & 0xff]]
    }
  }

  this._nRounds = nRounds
  this._keySchedule = keySchedule
  this._invKeySchedule = invKeySchedule
}

AES.prototype.encryptBlockRaw = function (M) {
  M = asUInt32Array(M)
  return cryptBlock(M, this._keySchedule, G.SUB_MIX, G.SBOX, this._nRounds)
}

AES.prototype.encryptBlock = function (M) {
  var out = this.encryptBlockRaw(M)
  var buf = Buffer.allocUnsafe(16)
  buf.writeUInt32BE(out[0], 0)
  buf.writeUInt32BE(out[1], 4)
  buf.writeUInt32BE(out[2], 8)
  buf.writeUInt32BE(out[3], 12)
  return buf
}

AES.prototype.decryptBlock = function (M) {
  M = asUInt32Array(M)

  // swap
  var m1 = M[1]
  M[1] = M[3]
  M[3] = m1

  var out = cryptBlock(M, this._invKeySchedule, G.INV_SUB_MIX, G.INV_SBOX, this._nRounds)
  var buf = Buffer.allocUnsafe(16)
  buf.writeUInt32BE(out[0], 0)
  buf.writeUInt32BE(out[3], 4)
  buf.writeUInt32BE(out[2], 8)
  buf.writeUInt32BE(out[1], 12)
  return buf
}

AES.prototype.scrub = function () {
  scrubVec(this._keySchedule)
  scrubVec(this._invKeySchedule)
  scrubVec(this._key)
}

module.exports.AES = AES

},{"safe-buffer":215}],47:[function(require,module,exports){
var aes = require('./aes')
var Buffer = require('safe-buffer').Buffer
var Transform = require('cipher-base')
var inherits = require('inherits')
var GHASH = require('./ghash')
var xor = require('buffer-xor')
var incr32 = require('./incr32')

function xorTest (a, b) {
  var out = 0
  if (a.length !== b.length) out++

  var len = Math.min(a.length, b.length)
  for (var i = 0; i < len; ++i) {
    out += (a[i] ^ b[i])
  }

  return out
}

function calcIv (self, iv, ck) {
  if (iv.length === 12) {
    self._finID = Buffer.concat([iv, Buffer.from([0, 0, 0, 1])])
    return Buffer.concat([iv, Buffer.from([0, 0, 0, 2])])
  }
  var ghash = new GHASH(ck)
  var len = iv.length
  var toPad = len % 16
  ghash.update(iv)
  if (toPad) {
    toPad = 16 - toPad
    ghash.update(Buffer.alloc(toPad, 0))
  }
  ghash.update(Buffer.alloc(8, 0))
  var ivBits = len * 8
  var tail = Buffer.alloc(8)
  tail.writeUIntBE(ivBits, 0, 8)
  ghash.update(tail)
  self._finID = ghash.state
  var out = Buffer.from(self._finID)
  incr32(out)
  return out
}
function StreamCipher (mode, key, iv, decrypt) {
  Transform.call(this)

  var h = Buffer.alloc(4, 0)

  this._cipher = new aes.AES(key)
  var ck = this._cipher.encryptBlock(h)
  this._ghash = new GHASH(ck)
  iv = calcIv(this, iv, ck)

  this._prev = Buffer.from(iv)
  this._cache = Buffer.allocUnsafe(0)
  this._secCache = Buffer.allocUnsafe(0)
  this._decrypt = decrypt
  this._alen = 0
  this._len = 0
  this._mode = mode

  this._authTag = null
  this._called = false
}

inherits(StreamCipher, Transform)

StreamCipher.prototype._update = function (chunk) {
  if (!this._called && this._alen) {
    var rump = 16 - (this._alen % 16)
    if (rump < 16) {
      rump = Buffer.alloc(rump, 0)
      this._ghash.update(rump)
    }
  }

  this._called = true
  var out = this._mode.encrypt(this, chunk)
  if (this._decrypt) {
    this._ghash.update(chunk)
  } else {
    this._ghash.update(out)
  }
  this._len += chunk.length
  return out
}

StreamCipher.prototype._final = function () {
  if (this._decrypt && !this._authTag) throw new Error('Unsupported state or unable to authenticate data')

  var tag = xor(this._ghash.final(this._alen * 8, this._len * 8), this._cipher.encryptBlock(this._finID))
  if (this._decrypt && xorTest(tag, this._authTag)) throw new Error('Unsupported state or unable to authenticate data')

  this._authTag = tag
  this._cipher.scrub()
}

StreamCipher.prototype.getAuthTag = function getAuthTag () {
  if (this._decrypt || !Buffer.isBuffer(this._authTag)) throw new Error('Attempting to get auth tag in unsupported state')

  return this._authTag
}

StreamCipher.prototype.setAuthTag = function setAuthTag (tag) {
  if (!this._decrypt) throw new Error('Attempting to set auth tag in unsupported state')

  this._authTag = tag
}

StreamCipher.prototype.setAAD = function setAAD (buf) {
  if (this._called) throw new Error('Attempting to set AAD in unsupported state')

  this._ghash.update(buf)
  this._alen += buf.length
}

module.exports = StreamCipher

},{"./aes":46,"./ghash":51,"./incr32":52,"buffer-xor":77,"cipher-base":79,"inherits":136,"safe-buffer":215}],48:[function(require,module,exports){
var ciphers = require('./encrypter')
var deciphers = require('./decrypter')
var modes = require('./modes/list.json')

function getCiphers () {
  return Object.keys(modes)
}

exports.createCipher = exports.Cipher = ciphers.createCipher
exports.createCipheriv = exports.Cipheriv = ciphers.createCipheriv
exports.createDecipher = exports.Decipher = deciphers.createDecipher
exports.createDecipheriv = exports.Decipheriv = deciphers.createDecipheriv
exports.listCiphers = exports.getCiphers = getCiphers

},{"./decrypter":49,"./encrypter":50,"./modes/list.json":60}],49:[function(require,module,exports){
var AuthCipher = require('./authCipher')
var Buffer = require('safe-buffer').Buffer
var MODES = require('./modes')
var StreamCipher = require('./streamCipher')
var Transform = require('cipher-base')
var aes = require('./aes')
var ebtk = require('evp_bytestokey')
var inherits = require('inherits')

function Decipher (mode, key, iv) {
  Transform.call(this)

  this._cache = new Splitter()
  this._last = void 0
  this._cipher = new aes.AES(key)
  this._prev = Buffer.from(iv)
  this._mode = mode
  this._autopadding = true
}

inherits(Decipher, Transform)

Decipher.prototype._update = function (data) {
  this._cache.add(data)
  var chunk
  var thing
  var out = []
  while ((chunk = this._cache.get(this._autopadding))) {
    thing = this._mode.decrypt(this, chunk)
    out.push(thing)
  }
  return Buffer.concat(out)
}

Decipher.prototype._final = function () {
  var chunk = this._cache.flush()
  if (this._autopadding) {
    return unpad(this._mode.decrypt(this, chunk))
  } else if (chunk) {
    throw new Error('data not multiple of block length')
  }
}

Decipher.prototype.setAutoPadding = function (setTo) {
  this._autopadding = !!setTo
  return this
}

function Splitter () {
  this.cache = Buffer.allocUnsafe(0)
}

Splitter.prototype.add = function (data) {
  this.cache = Buffer.concat([this.cache, data])
}

Splitter.prototype.get = function (autoPadding) {
  var out
  if (autoPadding) {
    if (this.cache.length > 16) {
      out = this.cache.slice(0, 16)
      this.cache = this.cache.slice(16)
      return out
    }
  } else {
    if (this.cache.length >= 16) {
      out = this.cache.slice(0, 16)
      this.cache = this.cache.slice(16)
      return out
    }
  }

  return null
}

Splitter.prototype.flush = function () {
  if (this.cache.length) return this.cache
}

function unpad (last) {
  var padded = last[15]
  if (padded < 1 || padded > 16) {
    throw new Error('unable to decrypt data')
  }
  var i = -1
  while (++i < padded) {
    if (last[(i + (16 - padded))] !== padded) {
      throw new Error('unable to decrypt data')
    }
  }
  if (padded === 16) return

  return last.slice(0, 16 - padded)
}

function createDecipheriv (suite, password, iv) {
  var config = MODES[suite.toLowerCase()]
  if (!config) throw new TypeError('invalid suite type')

  if (typeof iv === 'string') iv = Buffer.from(iv)
  if (config.mode !== 'GCM' && iv.length !== config.iv) throw new TypeError('invalid iv length ' + iv.length)

  if (typeof password === 'string') password = Buffer.from(password)
  if (password.length !== config.key / 8) throw new TypeError('invalid key length ' + password.length)

  if (config.type === 'stream') {
    return new StreamCipher(config.module, password, iv, true)
  } else if (config.type === 'auth') {
    return new AuthCipher(config.module, password, iv, true)
  }

  return new Decipher(config.module, password, iv)
}

function createDecipher (suite, password) {
  var config = MODES[suite.toLowerCase()]
  if (!config) throw new TypeError('invalid suite type')

  var keys = ebtk(password, false, config.key, config.iv)
  return createDecipheriv(suite, keys.key, keys.iv)
}

exports.createDecipher = createDecipher
exports.createDecipheriv = createDecipheriv

},{"./aes":46,"./authCipher":47,"./modes":59,"./streamCipher":62,"cipher-base":79,"evp_bytestokey":119,"inherits":136,"safe-buffer":215}],50:[function(require,module,exports){
var MODES = require('./modes')
var AuthCipher = require('./authCipher')
var Buffer = require('safe-buffer').Buffer
var StreamCipher = require('./streamCipher')
var Transform = require('cipher-base')
var aes = require('./aes')
var ebtk = require('evp_bytestokey')
var inherits = require('inherits')

function Cipher (mode, key, iv) {
  Transform.call(this)

  this._cache = new Splitter()
  this._cipher = new aes.AES(key)
  this._prev = Buffer.from(iv)
  this._mode = mode
  this._autopadding = true
}

inherits(Cipher, Transform)

Cipher.prototype._update = function (data) {
  this._cache.add(data)
  var chunk
  var thing
  var out = []

  while ((chunk = this._cache.get())) {
    thing = this._mode.encrypt(this, chunk)
    out.push(thing)
  }

  return Buffer.concat(out)
}

var PADDING = Buffer.alloc(16, 0x10)

Cipher.prototype._final = function () {
  var chunk = this._cache.flush()
  if (this._autopadding) {
    chunk = this._mode.encrypt(this, chunk)
    this._cipher.scrub()
    return chunk
  }

  if (!chunk.equals(PADDING)) {
    this._cipher.scrub()
    throw new Error('data not multiple of block length')
  }
}

Cipher.prototype.setAutoPadding = function (setTo) {
  this._autopadding = !!setTo
  return this
}

function Splitter () {
  this.cache = Buffer.allocUnsafe(0)
}

Splitter.prototype.add = function (data) {
  this.cache = Buffer.concat([this.cache, data])
}

Splitter.prototype.get = function () {
  if (this.cache.length > 15) {
    var out = this.cache.slice(0, 16)
    this.cache = this.cache.slice(16)
    return out
  }
  return null
}

Splitter.prototype.flush = function () {
  var len = 16 - this.cache.length
  var padBuff = Buffer.allocUnsafe(len)

  var i = -1
  while (++i < len) {
    padBuff.writeUInt8(len, i)
  }

  return Buffer.concat([this.cache, padBuff])
}

function createCipheriv (suite, password, iv) {
  var config = MODES[suite.toLowerCase()]
  if (!config) throw new TypeError('invalid suite type')

  if (typeof password === 'string') password = Buffer.from(password)
  if (password.length !== config.key / 8) throw new TypeError('invalid key length ' + password.length)

  if (typeof iv === 'string') iv = Buffer.from(iv)
  if (config.mode !== 'GCM' && iv.length !== config.iv) throw new TypeError('invalid iv length ' + iv.length)

  if (config.type === 'stream') {
    return new StreamCipher(config.module, password, iv)
  } else if (config.type === 'auth') {
    return new AuthCipher(config.module, password, iv)
  }

  return new Cipher(config.module, password, iv)
}

function createCipher (suite, password) {
  var config = MODES[suite.toLowerCase()]
  if (!config) throw new TypeError('invalid suite type')

  var keys = ebtk(password, false, config.key, config.iv)
  return createCipheriv(suite, keys.key, keys.iv)
}

exports.createCipheriv = createCipheriv
exports.createCipher = createCipher

},{"./aes":46,"./authCipher":47,"./modes":59,"./streamCipher":62,"cipher-base":79,"evp_bytestokey":119,"inherits":136,"safe-buffer":215}],51:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer
var ZEROES = Buffer.alloc(16, 0)

function toArray (buf) {
  return [
    buf.readUInt32BE(0),
    buf.readUInt32BE(4),
    buf.readUInt32BE(8),
    buf.readUInt32BE(12)
  ]
}

function fromArray (out) {
  var buf = Buffer.allocUnsafe(16)
  buf.writeUInt32BE(out[0] >>> 0, 0)
  buf.writeUInt32BE(out[1] >>> 0, 4)
  buf.writeUInt32BE(out[2] >>> 0, 8)
  buf.writeUInt32BE(out[3] >>> 0, 12)
  return buf
}

function GHASH (key) {
  this.h = key
  this.state = Buffer.alloc(16, 0)
  this.cache = Buffer.allocUnsafe(0)
}

// from http://bitwiseshiftleft.github.io/sjcl/doc/symbols/src/core_gcm.js.html
// by Juho Vähä-Herttua
GHASH.prototype.ghash = function (block) {
  var i = -1
  while (++i < block.length) {
    this.state[i] ^= block[i]
  }
  this._multiply()
}

GHASH.prototype._multiply = function () {
  var Vi = toArray(this.h)
  var Zi = [0, 0, 0, 0]
  var j, xi, lsbVi
  var i = -1
  while (++i < 128) {
    xi = (this.state[~~(i / 8)] & (1 << (7 - (i % 8)))) !== 0
    if (xi) {
      // Z_i+1 = Z_i ^ V_i
      Zi[0] ^= Vi[0]
      Zi[1] ^= Vi[1]
      Zi[2] ^= Vi[2]
      Zi[3] ^= Vi[3]
    }

    // Store the value of LSB(V_i)
    lsbVi = (Vi[3] & 1) !== 0

    // V_i+1 = V_i >> 1
    for (j = 3; j > 0; j--) {
      Vi[j] = (Vi[j] >>> 1) | ((Vi[j - 1] & 1) << 31)
    }
    Vi[0] = Vi[0] >>> 1

    // If LSB(V_i) is 1, V_i+1 = (V_i >> 1) ^ R
    if (lsbVi) {
      Vi[0] = Vi[0] ^ (0xe1 << 24)
    }
  }
  this.state = fromArray(Zi)
}

GHASH.prototype.update = function (buf) {
  this.cache = Buffer.concat([this.cache, buf])
  var chunk
  while (this.cache.length >= 16) {
    chunk = this.cache.slice(0, 16)
    this.cache = this.cache.slice(16)
    this.ghash(chunk)
  }
}

GHASH.prototype.final = function (abl, bl) {
  if (this.cache.length) {
    this.ghash(Buffer.concat([this.cache, ZEROES], 16))
  }

  this.ghash(fromArray([0, abl, 0, bl]))
  return this.state
}

module.exports = GHASH

},{"safe-buffer":215}],52:[function(require,module,exports){
function incr32 (iv) {
  var len = iv.length
  var item
  while (len--) {
    item = iv.readUInt8(len)
    if (item === 255) {
      iv.writeUInt8(0, len)
    } else {
      item++
      iv.writeUInt8(item, len)
      break
    }
  }
}
module.exports = incr32

},{}],53:[function(require,module,exports){
var xor = require('buffer-xor')

exports.encrypt = function (self, block) {
  var data = xor(block, self._prev)

  self._prev = self._cipher.encryptBlock(data)
  return self._prev
}

exports.decrypt = function (self, block) {
  var pad = self._prev

  self._prev = block
  var out = self._cipher.decryptBlock(block)

  return xor(out, pad)
}

},{"buffer-xor":77}],54:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer
var xor = require('buffer-xor')

function encryptStart (self, data, decrypt) {
  var len = data.length
  var out = xor(data, self._cache)
  self._cache = self._cache.slice(len)
  self._prev = Buffer.concat([self._prev, decrypt ? data : out])
  return out
}

exports.encrypt = function (self, data, decrypt) {
  var out = Buffer.allocUnsafe(0)
  var len

  while (data.length) {
    if (self._cache.length === 0) {
      self._cache = self._cipher.encryptBlock(self._prev)
      self._prev = Buffer.allocUnsafe(0)
    }

    if (self._cache.length <= data.length) {
      len = self._cache.length
      out = Buffer.concat([out, encryptStart(self, data.slice(0, len), decrypt)])
      data = data.slice(len)
    } else {
      out = Buffer.concat([out, encryptStart(self, data, decrypt)])
      break
    }
  }

  return out
}

},{"buffer-xor":77,"safe-buffer":215}],55:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer

function encryptByte (self, byteParam, decrypt) {
  var pad
  var i = -1
  var len = 8
  var out = 0
  var bit, value
  while (++i < len) {
    pad = self._cipher.encryptBlock(self._prev)
    bit = (byteParam & (1 << (7 - i))) ? 0x80 : 0
    value = pad[0] ^ bit
    out += ((value & 0x80) >> (i % 8))
    self._prev = shiftIn(self._prev, decrypt ? bit : value)
  }
  return out
}

function shiftIn (buffer, value) {
  var len = buffer.length
  var i = -1
  var out = Buffer.allocUnsafe(buffer.length)
  buffer = Buffer.concat([buffer, Buffer.from([value])])

  while (++i < len) {
    out[i] = buffer[i] << 1 | buffer[i + 1] >> (7)
  }

  return out
}

exports.encrypt = function (self, chunk, decrypt) {
  var len = chunk.length
  var out = Buffer.allocUnsafe(len)
  var i = -1

  while (++i < len) {
    out[i] = encryptByte(self, chunk[i], decrypt)
  }

  return out
}

},{"safe-buffer":215}],56:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer

function encryptByte (self, byteParam, decrypt) {
  var pad = self._cipher.encryptBlock(self._prev)
  var out = pad[0] ^ byteParam

  self._prev = Buffer.concat([
    self._prev.slice(1),
    Buffer.from([decrypt ? byteParam : out])
  ])

  return out
}

exports.encrypt = function (self, chunk, decrypt) {
  var len = chunk.length
  var out = Buffer.allocUnsafe(len)
  var i = -1

  while (++i < len) {
    out[i] = encryptByte(self, chunk[i], decrypt)
  }

  return out
}

},{"safe-buffer":215}],57:[function(require,module,exports){
var xor = require('buffer-xor')
var Buffer = require('safe-buffer').Buffer
var incr32 = require('../incr32')

function getBlock (self) {
  var out = self._cipher.encryptBlockRaw(self._prev)
  incr32(self._prev)
  return out
}

var blockSize = 16
exports.encrypt = function (self, chunk) {
  var chunkNum = Math.ceil(chunk.length / blockSize)
  var start = self._cache.length
  self._cache = Buffer.concat([
    self._cache,
    Buffer.allocUnsafe(chunkNum * blockSize)
  ])
  for (var i = 0; i < chunkNum; i++) {
    var out = getBlock(self)
    var offset = start + i * blockSize
    self._cache.writeUInt32BE(out[0], offset + 0)
    self._cache.writeUInt32BE(out[1], offset + 4)
    self._cache.writeUInt32BE(out[2], offset + 8)
    self._cache.writeUInt32BE(out[3], offset + 12)
  }
  var pad = self._cache.slice(0, chunk.length)
  self._cache = self._cache.slice(chunk.length)
  return xor(chunk, pad)
}

},{"../incr32":52,"buffer-xor":77,"safe-buffer":215}],58:[function(require,module,exports){
exports.encrypt = function (self, block) {
  return self._cipher.encryptBlock(block)
}

exports.decrypt = function (self, block) {
  return self._cipher.decryptBlock(block)
}

},{}],59:[function(require,module,exports){
var modeModules = {
  ECB: require('./ecb'),
  CBC: require('./cbc'),
  CFB: require('./cfb'),
  CFB8: require('./cfb8'),
  CFB1: require('./cfb1'),
  OFB: require('./ofb'),
  CTR: require('./ctr'),
  GCM: require('./ctr')
}

var modes = require('./list.json')

for (var key in modes) {
  modes[key].module = modeModules[modes[key].mode]
}

module.exports = modes

},{"./cbc":53,"./cfb":54,"./cfb1":55,"./cfb8":56,"./ctr":57,"./ecb":58,"./list.json":60,"./ofb":61}],60:[function(require,module,exports){
module.exports={
  "aes-128-ecb": {
    "cipher": "AES",
    "key": 128,
    "iv": 0,
    "mode": "ECB",
    "type": "block"
  },
  "aes-192-ecb": {
    "cipher": "AES",
    "key": 192,
    "iv": 0,
    "mode": "ECB",
    "type": "block"
  },
  "aes-256-ecb": {
    "cipher": "AES",
    "key": 256,
    "iv": 0,
    "mode": "ECB",
    "type": "block"
  },
  "aes-128-cbc": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes-192-cbc": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes-256-cbc": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes128": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes192": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes256": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CBC",
    "type": "block"
  },
  "aes-128-cfb": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CFB",
    "type": "stream"
  },
  "aes-192-cfb": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CFB",
    "type": "stream"
  },
  "aes-256-cfb": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CFB",
    "type": "stream"
  },
  "aes-128-cfb8": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CFB8",
    "type": "stream"
  },
  "aes-192-cfb8": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CFB8",
    "type": "stream"
  },
  "aes-256-cfb8": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CFB8",
    "type": "stream"
  },
  "aes-128-cfb1": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CFB1",
    "type": "stream"
  },
  "aes-192-cfb1": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CFB1",
    "type": "stream"
  },
  "aes-256-cfb1": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CFB1",
    "type": "stream"
  },
  "aes-128-ofb": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "OFB",
    "type": "stream"
  },
  "aes-192-ofb": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "OFB",
    "type": "stream"
  },
  "aes-256-ofb": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "OFB",
    "type": "stream"
  },
  "aes-128-ctr": {
    "cipher": "AES",
    "key": 128,
    "iv": 16,
    "mode": "CTR",
    "type": "stream"
  },
  "aes-192-ctr": {
    "cipher": "AES",
    "key": 192,
    "iv": 16,
    "mode": "CTR",
    "type": "stream"
  },
  "aes-256-ctr": {
    "cipher": "AES",
    "key": 256,
    "iv": 16,
    "mode": "CTR",
    "type": "stream"
  },
  "aes-128-gcm": {
    "cipher": "AES",
    "key": 128,
    "iv": 12,
    "mode": "GCM",
    "type": "auth"
  },
  "aes-192-gcm": {
    "cipher": "AES",
    "key": 192,
    "iv": 12,
    "mode": "GCM",
    "type": "auth"
  },
  "aes-256-gcm": {
    "cipher": "AES",
    "key": 256,
    "iv": 12,
    "mode": "GCM",
    "type": "auth"
  }
}

},{}],61:[function(require,module,exports){
(function (Buffer){(function (){
var xor = require('buffer-xor')

function getBlock (self) {
  self._prev = self._cipher.encryptBlock(self._prev)
  return self._prev
}

exports.encrypt = function (self, chunk) {
  while (self._cache.length < chunk.length) {
    self._cache = Buffer.concat([self._cache, getBlock(self)])
  }

  var pad = self._cache.slice(0, chunk.length)
  self._cache = self._cache.slice(chunk.length)
  return xor(chunk, pad)
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"buffer":74,"buffer-xor":77}],62:[function(require,module,exports){
var aes = require('./aes')
var Buffer = require('safe-buffer').Buffer
var Transform = require('cipher-base')
var inherits = require('inherits')

function StreamCipher (mode, key, iv, decrypt) {
  Transform.call(this)

  this._cipher = new aes.AES(key)
  this._prev = Buffer.from(iv)
  this._cache = Buffer.allocUnsafe(0)
  this._secCache = Buffer.allocUnsafe(0)
  this._decrypt = decrypt
  this._mode = mode
}

inherits(StreamCipher, Transform)

StreamCipher.prototype._update = function (chunk) {
  return this._mode.encrypt(this, chunk, this._decrypt)
}

StreamCipher.prototype._final = function () {
  this._cipher.scrub()
}

module.exports = StreamCipher

},{"./aes":46,"cipher-base":79,"inherits":136,"safe-buffer":215}],63:[function(require,module,exports){
var DES = require('browserify-des')
var aes = require('browserify-aes/browser')
var aesModes = require('browserify-aes/modes')
var desModes = require('browserify-des/modes')
var ebtk = require('evp_bytestokey')

function createCipher (suite, password) {
  suite = suite.toLowerCase()

  var keyLen, ivLen
  if (aesModes[suite]) {
    keyLen = aesModes[suite].key
    ivLen = aesModes[suite].iv
  } else if (desModes[suite]) {
    keyLen = desModes[suite].key * 8
    ivLen = desModes[suite].iv
  } else {
    throw new TypeError('invalid suite type')
  }

  var keys = ebtk(password, false, keyLen, ivLen)
  return createCipheriv(suite, keys.key, keys.iv)
}

function createDecipher (suite, password) {
  suite = suite.toLowerCase()

  var keyLen, ivLen
  if (aesModes[suite]) {
    keyLen = aesModes[suite].key
    ivLen = aesModes[suite].iv
  } else if (desModes[suite]) {
    keyLen = desModes[suite].key * 8
    ivLen = desModes[suite].iv
  } else {
    throw new TypeError('invalid suite type')
  }

  var keys = ebtk(password, false, keyLen, ivLen)
  return createDecipheriv(suite, keys.key, keys.iv)
}

function createCipheriv (suite, key, iv) {
  suite = suite.toLowerCase()
  if (aesModes[suite]) return aes.createCipheriv(suite, key, iv)
  if (desModes[suite]) return new DES({ key: key, iv: iv, mode: suite })

  throw new TypeError('invalid suite type')
}

function createDecipheriv (suite, key, iv) {
  suite = suite.toLowerCase()
  if (aesModes[suite]) return aes.createDecipheriv(suite, key, iv)
  if (desModes[suite]) return new DES({ key: key, iv: iv, mode: suite, decrypt: true })

  throw new TypeError('invalid suite type')
}

function getCiphers () {
  return Object.keys(desModes).concat(aes.getCiphers())
}

exports.createCipher = exports.Cipher = createCipher
exports.createCipheriv = exports.Cipheriv = createCipheriv
exports.createDecipher = exports.Decipher = createDecipher
exports.createDecipheriv = exports.Decipheriv = createDecipheriv
exports.listCiphers = exports.getCiphers = getCiphers

},{"browserify-aes/browser":48,"browserify-aes/modes":59,"browserify-des":64,"browserify-des/modes":65,"evp_bytestokey":119}],64:[function(require,module,exports){
var CipherBase = require('cipher-base')
var des = require('des.js')
var inherits = require('inherits')
var Buffer = require('safe-buffer').Buffer

var modes = {
  'des-ede3-cbc': des.CBC.instantiate(des.EDE),
  'des-ede3': des.EDE,
  'des-ede-cbc': des.CBC.instantiate(des.EDE),
  'des-ede': des.EDE,
  'des-cbc': des.CBC.instantiate(des.DES),
  'des-ecb': des.DES
}
modes.des = modes['des-cbc']
modes.des3 = modes['des-ede3-cbc']
module.exports = DES
inherits(DES, CipherBase)
function DES (opts) {
  CipherBase.call(this)
  var modeName = opts.mode.toLowerCase()
  var mode = modes[modeName]
  var type
  if (opts.decrypt) {
    type = 'decrypt'
  } else {
    type = 'encrypt'
  }
  var key = opts.key
  if (!Buffer.isBuffer(key)) {
    key = Buffer.from(key)
  }
  if (modeName === 'des-ede' || modeName === 'des-ede-cbc') {
    key = Buffer.concat([key, key.slice(0, 8)])
  }
  var iv = opts.iv
  if (!Buffer.isBuffer(iv)) {
    iv = Buffer.from(iv)
  }
  this._des = mode.create({
    key: key,
    iv: iv,
    type: type
  })
}
DES.prototype._update = function (data) {
  return Buffer.from(this._des.update(data))
}
DES.prototype._final = function () {
  return Buffer.from(this._des.final())
}

},{"cipher-base":79,"des.js":90,"inherits":136,"safe-buffer":215}],65:[function(require,module,exports){
exports['des-ecb'] = {
  key: 8,
  iv: 0
}
exports['des-cbc'] = exports.des = {
  key: 8,
  iv: 8
}
exports['des-ede3-cbc'] = exports.des3 = {
  key: 24,
  iv: 8
}
exports['des-ede3'] = {
  key: 24,
  iv: 0
}
exports['des-ede-cbc'] = {
  key: 16,
  iv: 8
}
exports['des-ede'] = {
  key: 16,
  iv: 0
}

},{}],66:[function(require,module,exports){
(function (Buffer){(function (){
var BN = require('bn.js')
var randomBytes = require('randombytes')

function blind (priv) {
  var r = getr(priv)
  var blinder = r.toRed(BN.mont(priv.modulus)).redPow(new BN(priv.publicExponent)).fromRed()
  return { blinder: blinder, unblinder: r.invm(priv.modulus) }
}

function getr (priv) {
  var len = priv.modulus.byteLength()
  var r
  do {
    r = new BN(randomBytes(len))
  } while (r.cmp(priv.modulus) >= 0 || !r.umod(priv.prime1) || !r.umod(priv.prime2))
  return r
}

function crt (msg, priv) {
  var blinds = blind(priv)
  var len = priv.modulus.byteLength()
  var blinded = new BN(msg).mul(blinds.blinder).umod(priv.modulus)
  var c1 = blinded.toRed(BN.mont(priv.prime1))
  var c2 = blinded.toRed(BN.mont(priv.prime2))
  var qinv = priv.coefficient
  var p = priv.prime1
  var q = priv.prime2
  var m1 = c1.redPow(priv.exponent1).fromRed()
  var m2 = c2.redPow(priv.exponent2).fromRed()
  var h = m1.isub(m2).imul(qinv).umod(p).imul(q)
  return m2.iadd(h).imul(blinds.unblinder).umod(priv.modulus).toArrayLike(Buffer, 'be', len)
}
crt.getr = getr

module.exports = crt

}).call(this)}).call(this,require("buffer").Buffer)
},{"bn.js":43,"buffer":74,"randombytes":187}],67:[function(require,module,exports){
module.exports = require('./browser/algorithms.json')

},{"./browser/algorithms.json":68}],68:[function(require,module,exports){
module.exports={
  "sha224WithRSAEncryption": {
    "sign": "rsa",
    "hash": "sha224",
    "id": "302d300d06096086480165030402040500041c"
  },
  "RSA-SHA224": {
    "sign": "ecdsa/rsa",
    "hash": "sha224",
    "id": "302d300d06096086480165030402040500041c"
  },
  "sha256WithRSAEncryption": {
    "sign": "rsa",
    "hash": "sha256",
    "id": "3031300d060960864801650304020105000420"
  },
  "RSA-SHA256": {
    "sign": "ecdsa/rsa",
    "hash": "sha256",
    "id": "3031300d060960864801650304020105000420"
  },
  "sha384WithRSAEncryption": {
    "sign": "rsa",
    "hash": "sha384",
    "id": "3041300d060960864801650304020205000430"
  },
  "RSA-SHA384": {
    "sign": "ecdsa/rsa",
    "hash": "sha384",
    "id": "3041300d060960864801650304020205000430"
  },
  "sha512WithRSAEncryption": {
    "sign": "rsa",
    "hash": "sha512",
    "id": "3051300d060960864801650304020305000440"
  },
  "RSA-SHA512": {
    "sign": "ecdsa/rsa",
    "hash": "sha512",
    "id": "3051300d060960864801650304020305000440"
  },
  "RSA-SHA1": {
    "sign": "rsa",
    "hash": "sha1",
    "id": "3021300906052b0e03021a05000414"
  },
  "ecdsa-with-SHA1": {
    "sign": "ecdsa",
    "hash": "sha1",
    "id": ""
  },
  "sha256": {
    "sign": "ecdsa",
    "hash": "sha256",
    "id": ""
  },
  "sha224": {
    "sign": "ecdsa",
    "hash": "sha224",
    "id": ""
  },
  "sha384": {
    "sign": "ecdsa",
    "hash": "sha384",
    "id": ""
  },
  "sha512": {
    "sign": "ecdsa",
    "hash": "sha512",
    "id": ""
  },
  "DSA-SHA": {
    "sign": "dsa",
    "hash": "sha1",
    "id": ""
  },
  "DSA-SHA1": {
    "sign": "dsa",
    "hash": "sha1",
    "id": ""
  },
  "DSA": {
    "sign": "dsa",
    "hash": "sha1",
    "id": ""
  },
  "DSA-WITH-SHA224": {
    "sign": "dsa",
    "hash": "sha224",
    "id": ""
  },
  "DSA-SHA224": {
    "sign": "dsa",
    "hash": "sha224",
    "id": ""
  },
  "DSA-WITH-SHA256": {
    "sign": "dsa",
    "hash": "sha256",
    "id": ""
  },
  "DSA-SHA256": {
    "sign": "dsa",
    "hash": "sha256",
    "id": ""
  },
  "DSA-WITH-SHA384": {
    "sign": "dsa",
    "hash": "sha384",
    "id": ""
  },
  "DSA-SHA384": {
    "sign": "dsa",
    "hash": "sha384",
    "id": ""
  },
  "DSA-WITH-SHA512": {
    "sign": "dsa",
    "hash": "sha512",
    "id": ""
  },
  "DSA-SHA512": {
    "sign": "dsa",
    "hash": "sha512",
    "id": ""
  },
  "DSA-RIPEMD160": {
    "sign": "dsa",
    "hash": "rmd160",
    "id": ""
  },
  "ripemd160WithRSA": {
    "sign": "rsa",
    "hash": "rmd160",
    "id": "3021300906052b2403020105000414"
  },
  "RSA-RIPEMD160": {
    "sign": "rsa",
    "hash": "rmd160",
    "id": "3021300906052b2403020105000414"
  },
  "md5WithRSAEncryption": {
    "sign": "rsa",
    "hash": "md5",
    "id": "3020300c06082a864886f70d020505000410"
  },
  "RSA-MD5": {
    "sign": "rsa",
    "hash": "md5",
    "id": "3020300c06082a864886f70d020505000410"
  }
}

},{}],69:[function(require,module,exports){
module.exports={
  "1.3.132.0.10": "secp256k1",
  "1.3.132.0.33": "p224",
  "1.2.840.10045.3.1.1": "p192",
  "1.2.840.10045.3.1.7": "p256",
  "1.3.132.0.34": "p384",
  "1.3.132.0.35": "p521"
}

},{}],70:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer
var createHash = require('create-hash')
var stream = require('readable-stream')
var inherits = require('inherits')
var sign = require('./sign')
var verify = require('./verify')

var algorithms = require('./algorithms.json')
Object.keys(algorithms).forEach(function (key) {
  algorithms[key].id = Buffer.from(algorithms[key].id, 'hex')
  algorithms[key.toLowerCase()] = algorithms[key]
})

function Sign (algorithm) {
  stream.Writable.call(this)

  var data = algorithms[algorithm]
  if (!data) throw new Error('Unknown message digest')

  this._hashType = data.hash
  this._hash = createHash(data.hash)
  this._tag = data.id
  this._signType = data.sign
}
inherits(Sign, stream.Writable)

Sign.prototype._write = function _write (data, _, done) {
  this._hash.update(data)
  done()
}

Sign.prototype.update = function update (data, enc) {
  if (typeof data === 'string') data = Buffer.from(data, enc)

  this._hash.update(data)
  return this
}

Sign.prototype.sign = function signMethod (key, enc) {
  this.end()
  var hash = this._hash.digest()
  var sig = sign(hash, key, this._hashType, this._signType, this._tag)

  return enc ? sig.toString(enc) : sig
}

function Verify (algorithm) {
  stream.Writable.call(this)

  var data = algorithms[algorithm]
  if (!data) throw new Error('Unknown message digest')

  this._hash = createHash(data.hash)
  this._tag = data.id
  this._signType = data.sign
}
inherits(Verify, stream.Writable)

Verify.prototype._write = function _write (data, _, done) {
  this._hash.update(data)
  done()
}

Verify.prototype.update = function update (data, enc) {
  if (typeof data === 'string') data = Buffer.from(data, enc)

  this._hash.update(data)
  return this
}

Verify.prototype.verify = function verifyMethod (key, sig, enc) {
  if (typeof sig === 'string') sig = Buffer.from(sig, enc)

  this.end()
  var hash = this._hash.digest()
  return verify(sig, hash, key, this._signType, this._tag)
}

function createSign (algorithm) {
  return new Sign(algorithm)
}

function createVerify (algorithm) {
  return new Verify(algorithm)
}

module.exports = {
  Sign: createSign,
  Verify: createVerify,
  createSign: createSign,
  createVerify: createVerify
}

},{"./algorithms.json":68,"./sign":71,"./verify":72,"create-hash":82,"inherits":136,"readable-stream":213,"safe-buffer":215}],71:[function(require,module,exports){
// much of this based on https://github.com/indutny/self-signed/blob/gh-pages/lib/rsa.js
var Buffer = require('safe-buffer').Buffer
var createHmac = require('create-hmac')
var crt = require('browserify-rsa')
var EC = require('elliptic').ec
var BN = require('bn.js')
var parseKeys = require('parse-asn1')
var curves = require('./curves.json')

function sign (hash, key, hashType, signType, tag) {
  var priv = parseKeys(key)
  if (priv.curve) {
    // rsa keys can be interpreted as ecdsa ones in openssl
    if (signType !== 'ecdsa' && signType !== 'ecdsa/rsa') throw new Error('wrong private key type')
    return ecSign(hash, priv)
  } else if (priv.type === 'dsa') {
    if (signType !== 'dsa') throw new Error('wrong private key type')
    return dsaSign(hash, priv, hashType)
  } else {
    if (signType !== 'rsa' && signType !== 'ecdsa/rsa') throw new Error('wrong private key type')
  }
  hash = Buffer.concat([tag, hash])
  var len = priv.modulus.byteLength()
  var pad = [0, 1]
  while (hash.length + pad.length + 1 < len) pad.push(0xff)
  pad.push(0x00)
  var i = -1
  while (++i < hash.length) pad.push(hash[i])

  var out = crt(pad, priv)
  return out
}

function ecSign (hash, priv) {
  var curveId = curves[priv.curve.join('.')]
  if (!curveId) throw new Error('unknown curve ' + priv.curve.join('.'))

  var curve = new EC(curveId)
  var key = curve.keyFromPrivate(priv.privateKey)
  var out = key.sign(hash)

  return Buffer.from(out.toDER())
}

function dsaSign (hash, priv, algo) {
  var x = priv.params.priv_key
  var p = priv.params.p
  var q = priv.params.q
  var g = priv.params.g
  var r = new BN(0)
  var k
  var H = bits2int(hash, q).mod(q)
  var s = false
  var kv = getKey(x, q, hash, algo)
  while (s === false) {
    k = makeKey(q, kv, algo)
    r = makeR(g, k, p, q)
    s = k.invm(q).imul(H.add(x.mul(r))).mod(q)
    if (s.cmpn(0) === 0) {
      s = false
      r = new BN(0)
    }
  }
  return toDER(r, s)
}

function toDER (r, s) {
  r = r.toArray()
  s = s.toArray()

  // Pad values
  if (r[0] & 0x80) r = [0].concat(r)
  if (s[0] & 0x80) s = [0].concat(s)

  var total = r.length + s.length + 4
  var res = [0x30, total, 0x02, r.length]
  res = res.concat(r, [0x02, s.length], s)
  return Buffer.from(res)
}

function getKey (x, q, hash, algo) {
  x = Buffer.from(x.toArray())
  if (x.length < q.byteLength()) {
    var zeros = Buffer.alloc(q.byteLength() - x.length)
    x = Buffer.concat([zeros, x])
  }
  var hlen = hash.length
  var hbits = bits2octets(hash, q)
  var v = Buffer.alloc(hlen)
  v.fill(1)
  var k = Buffer.alloc(hlen)
  k = createHmac(algo, k).update(v).update(Buffer.from([0])).update(x).update(hbits).digest()
  v = createHmac(algo, k).update(v).digest()
  k = createHmac(algo, k).update(v).update(Buffer.from([1])).update(x).update(hbits).digest()
  v = createHmac(algo, k).update(v).digest()
  return { k: k, v: v }
}

function bits2int (obits, q) {
  var bits = new BN(obits)
  var shift = (obits.length << 3) - q.bitLength()
  if (shift > 0) bits.ishrn(shift)
  return bits
}

function bits2octets (bits, q) {
  bits = bits2int(bits, q)
  bits = bits.mod(q)
  var out = Buffer.from(bits.toArray())
  if (out.length < q.byteLength()) {
    var zeros = Buffer.alloc(q.byteLength() - out.length)
    out = Buffer.concat([zeros, out])
  }
  return out
}

function makeKey (q, kv, algo) {
  var t
  var k

  do {
    t = Buffer.alloc(0)

    while (t.length * 8 < q.bitLength()) {
      kv.v = createHmac(algo, kv.k).update(kv.v).digest()
      t = Buffer.concat([t, kv.v])
    }

    k = bits2int(t, q)
    kv.k = createHmac(algo, kv.k).update(kv.v).update(Buffer.from([0])).digest()
    kv.v = createHmac(algo, kv.k).update(kv.v).digest()
  } while (k.cmp(q) !== -1)

  return k
}

function makeR (g, k, p, q) {
  return g.toRed(BN.mont(p)).redPow(k).fromRed().mod(q)
}

module.exports = sign
module.exports.getKey = getKey
module.exports.makeKey = makeKey

},{"./curves.json":69,"bn.js":43,"browserify-rsa":66,"create-hmac":84,"elliptic":101,"parse-asn1":171,"safe-buffer":215}],72:[function(require,module,exports){
// much of this based on https://github.com/indutny/self-signed/blob/gh-pages/lib/rsa.js
var Buffer = require('safe-buffer').Buffer
var BN = require('bn.js')
var EC = require('elliptic').ec
var parseKeys = require('parse-asn1')
var curves = require('./curves.json')

function verify (sig, hash, key, signType, tag) {
  var pub = parseKeys(key)
  if (pub.type === 'ec') {
    // rsa keys can be interpreted as ecdsa ones in openssl
    if (signType !== 'ecdsa' && signType !== 'ecdsa/rsa') throw new Error('wrong public key type')
    return ecVerify(sig, hash, pub)
  } else if (pub.type === 'dsa') {
    if (signType !== 'dsa') throw new Error('wrong public key type')
    return dsaVerify(sig, hash, pub)
  } else {
    if (signType !== 'rsa' && signType !== 'ecdsa/rsa') throw new Error('wrong public key type')
  }
  hash = Buffer.concat([tag, hash])
  var len = pub.modulus.byteLength()
  var pad = [1]
  var padNum = 0
  while (hash.length + pad.length + 2 < len) {
    pad.push(0xff)
    padNum++
  }
  pad.push(0x00)
  var i = -1
  while (++i < hash.length) {
    pad.push(hash[i])
  }
  pad = Buffer.from(pad)
  var red = BN.mont(pub.modulus)
  sig = new BN(sig).toRed(red)

  sig = sig.redPow(new BN(pub.publicExponent))
  sig = Buffer.from(sig.fromRed().toArray())
  var out = padNum < 8 ? 1 : 0
  len = Math.min(sig.length, pad.length)
  if (sig.length !== pad.length) out = 1

  i = -1
  while (++i < len) out |= sig[i] ^ pad[i]
  return out === 0
}

function ecVerify (sig, hash, pub) {
  var curveId = curves[pub.data.algorithm.curve.join('.')]
  if (!curveId) throw new Error('unknown curve ' + pub.data.algorithm.curve.join('.'))

  var curve = new EC(curveId)
  var pubkey = pub.data.subjectPrivateKey.data

  return curve.verify(hash, sig, pubkey)
}

function dsaVerify (sig, hash, pub) {
  var p = pub.data.p
  var q = pub.data.q
  var g = pub.data.g
  var y = pub.data.pub_key
  var unpacked = parseKeys.signature.decode(sig, 'der')
  var s = unpacked.s
  var r = unpacked.r
  checkValue(s, q)
  checkValue(r, q)
  var montp = BN.mont(p)
  var w = s.invm(q)
  var v = g.toRed(montp)
    .redPow(new BN(hash).mul(w).mod(q))
    .fromRed()
    .mul(y.toRed(montp).redPow(r.mul(w).mod(q)).fromRed())
    .mod(p)
    .mod(q)
  return v.cmp(r) === 0
}

function checkValue (b, q) {
  if (b.cmpn(0) <= 0) throw new Error('invalid sig')
  if (b.cmp(q) >= q) throw new Error('invalid sig')
}

module.exports = verify

},{"./curves.json":69,"bn.js":43,"elliptic":101,"parse-asn1":171,"safe-buffer":215}],73:[function(require,module,exports){
arguments[4][45][0].apply(exports,arguments)
},{"dup":45}],74:[function(require,module,exports){
(function (Buffer){(function (){
/*!
 * The buffer module from node.js, for the browser.
 *
 * @author   Feross Aboukhadijeh <https://feross.org>
 * @license  MIT
 */
/* eslint-disable no-proto */

'use strict'

var base64 = require('base64-js')
var ieee754 = require('ieee754')

exports.Buffer = Buffer
exports.SlowBuffer = SlowBuffer
exports.INSPECT_MAX_BYTES = 50

var K_MAX_LENGTH = 0x7fffffff
exports.kMaxLength = K_MAX_LENGTH

/**
 * If `Buffer.TYPED_ARRAY_SUPPORT`:
 *   === true    Use Uint8Array implementation (fastest)
 *   === false   Print warning and recommend using `buffer` v4.x which has an Object
 *               implementation (most compatible, even IE6)
 *
 * Browsers that support typed arrays are IE 10+, Firefox 4+, Chrome 7+, Safari 5.1+,
 * Opera 11.6+, iOS 4.2+.
 *
 * We report that the browser does not support typed arrays if the are not subclassable
 * using __proto__. Firefox 4-29 lacks support for adding new properties to `Uint8Array`
 * (See: https://bugzilla.mozilla.org/show_bug.cgi?id=695438). IE 10 lacks support
 * for __proto__ and has a buggy typed array implementation.
 */
Buffer.TYPED_ARRAY_SUPPORT = typedArraySupport()

if (!Buffer.TYPED_ARRAY_SUPPORT && typeof console !== 'undefined' &&
    typeof console.error === 'function') {
  console.error(
    'This browser lacks typed array (Uint8Array) support which is required by ' +
    '`buffer` v5.x. Use `buffer` v4.x if you require old browser support.'
  )
}

function typedArraySupport () {
  // Can typed array instances can be augmented?
  try {
    var arr = new Uint8Array(1)
    arr.__proto__ = { __proto__: Uint8Array.prototype, foo: function () { return 42 } }
    return arr.foo() === 42
  } catch (e) {
    return false
  }
}

Object.defineProperty(Buffer.prototype, 'parent', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.buffer
  }
})

Object.defineProperty(Buffer.prototype, 'offset', {
  enumerable: true,
  get: function () {
    if (!Buffer.isBuffer(this)) return undefined
    return this.byteOffset
  }
})

function createBuffer (length) {
  if (length > K_MAX_LENGTH) {
    throw new RangeError('The value "' + length + '" is invalid for option "size"')
  }
  // Return an augmented `Uint8Array` instance
  var buf = new Uint8Array(length)
  buf.__proto__ = Buffer.prototype
  return buf
}

/**
 * The Buffer constructor returns instances of `Uint8Array` that have their
 * prototype changed to `Buffer.prototype`. Furthermore, `Buffer` is a subclass of
 * `Uint8Array`, so the returned instances will have all the node `Buffer` methods
 * and the `Uint8Array` methods. Square bracket notation works as expected -- it
 * returns a single octet.
 *
 * The `Uint8Array` prototype remains unmodified.
 */

function Buffer (arg, encodingOrOffset, length) {
  // Common case.
  if (typeof arg === 'number') {
    if (typeof encodingOrOffset === 'string') {
      throw new TypeError(
        'The "string" argument must be of type string. Received type number'
      )
    }
    return allocUnsafe(arg)
  }
  return from(arg, encodingOrOffset, length)
}

// Fix subarray() in ES2016. See: https://github.com/feross/buffer/pull/97
if (typeof Symbol !== 'undefined' && Symbol.species != null &&
    Buffer[Symbol.species] === Buffer) {
  Object.defineProperty(Buffer, Symbol.species, {
    value: null,
    configurable: true,
    enumerable: false,
    writable: false
  })
}

Buffer.poolSize = 8192 // not used by this implementation

function from (value, encodingOrOffset, length) {
  if (typeof value === 'string') {
    return fromString(value, encodingOrOffset)
  }

  if (ArrayBuffer.isView(value)) {
    return fromArrayLike(value)
  }

  if (value == null) {
    throw TypeError(
      'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
      'or Array-like Object. Received type ' + (typeof value)
    )
  }

  if (isInstance(value, ArrayBuffer) ||
      (value && isInstance(value.buffer, ArrayBuffer))) {
    return fromArrayBuffer(value, encodingOrOffset, length)
  }

  if (typeof value === 'number') {
    throw new TypeError(
      'The "value" argument must not be of type number. Received type number'
    )
  }

  var valueOf = value.valueOf && value.valueOf()
  if (valueOf != null && valueOf !== value) {
    return Buffer.from(valueOf, encodingOrOffset, length)
  }

  var b = fromObject(value)
  if (b) return b

  if (typeof Symbol !== 'undefined' && Symbol.toPrimitive != null &&
      typeof value[Symbol.toPrimitive] === 'function') {
    return Buffer.from(
      value[Symbol.toPrimitive]('string'), encodingOrOffset, length
    )
  }

  throw new TypeError(
    'The first argument must be one of type string, Buffer, ArrayBuffer, Array, ' +
    'or Array-like Object. Received type ' + (typeof value)
  )
}

/**
 * Functionally equivalent to Buffer(arg, encoding) but throws a TypeError
 * if value is a number.
 * Buffer.from(str[, encoding])
 * Buffer.from(array)
 * Buffer.from(buffer)
 * Buffer.from(arrayBuffer[, byteOffset[, length]])
 **/
Buffer.from = function (value, encodingOrOffset, length) {
  return from(value, encodingOrOffset, length)
}

// Note: Change prototype *after* Buffer.from is defined to workaround Chrome bug:
// https://github.com/feross/buffer/pull/148
Buffer.prototype.__proto__ = Uint8Array.prototype
Buffer.__proto__ = Uint8Array

function assertSize (size) {
  if (typeof size !== 'number') {
    throw new TypeError('"size" argument must be of type number')
  } else if (size < 0) {
    throw new RangeError('The value "' + size + '" is invalid for option "size"')
  }
}

function alloc (size, fill, encoding) {
  assertSize(size)
  if (size <= 0) {
    return createBuffer(size)
  }
  if (fill !== undefined) {
    // Only pay attention to encoding if it's a string. This
    // prevents accidentally sending in a number that would
    // be interpretted as a start offset.
    return typeof encoding === 'string'
      ? createBuffer(size).fill(fill, encoding)
      : createBuffer(size).fill(fill)
  }
  return createBuffer(size)
}

/**
 * Creates a new filled Buffer instance.
 * alloc(size[, fill[, encoding]])
 **/
Buffer.alloc = function (size, fill, encoding) {
  return alloc(size, fill, encoding)
}

function allocUnsafe (size) {
  assertSize(size)
  return createBuffer(size < 0 ? 0 : checked(size) | 0)
}

/**
 * Equivalent to Buffer(num), by default creates a non-zero-filled Buffer instance.
 * */
Buffer.allocUnsafe = function (size) {
  return allocUnsafe(size)
}
/**
 * Equivalent to SlowBuffer(num), by default creates a non-zero-filled Buffer instance.
 */
Buffer.allocUnsafeSlow = function (size) {
  return allocUnsafe(size)
}

function fromString (string, encoding) {
  if (typeof encoding !== 'string' || encoding === '') {
    encoding = 'utf8'
  }

  if (!Buffer.isEncoding(encoding)) {
    throw new TypeError('Unknown encoding: ' + encoding)
  }

  var length = byteLength(string, encoding) | 0
  var buf = createBuffer(length)

  var actual = buf.write(string, encoding)

  if (actual !== length) {
    // Writing a hex string, for example, that contains invalid characters will
    // cause everything after the first invalid character to be ignored. (e.g.
    // 'abxxcd' will be treated as 'ab')
    buf = buf.slice(0, actual)
  }

  return buf
}

function fromArrayLike (array) {
  var length = array.length < 0 ? 0 : checked(array.length) | 0
  var buf = createBuffer(length)
  for (var i = 0; i < length; i += 1) {
    buf[i] = array[i] & 255
  }
  return buf
}

function fromArrayBuffer (array, byteOffset, length) {
  if (byteOffset < 0 || array.byteLength < byteOffset) {
    throw new RangeError('"offset" is outside of buffer bounds')
  }

  if (array.byteLength < byteOffset + (length || 0)) {
    throw new RangeError('"length" is outside of buffer bounds')
  }

  var buf
  if (byteOffset === undefined && length === undefined) {
    buf = new Uint8Array(array)
  } else if (length === undefined) {
    buf = new Uint8Array(array, byteOffset)
  } else {
    buf = new Uint8Array(array, byteOffset, length)
  }

  // Return an augmented `Uint8Array` instance
  buf.__proto__ = Buffer.prototype
  return buf
}

function fromObject (obj) {
  if (Buffer.isBuffer(obj)) {
    var len = checked(obj.length) | 0
    var buf = createBuffer(len)

    if (buf.length === 0) {
      return buf
    }

    obj.copy(buf, 0, 0, len)
    return buf
  }

  if (obj.length !== undefined) {
    if (typeof obj.length !== 'number' || numberIsNaN(obj.length)) {
      return createBuffer(0)
    }
    return fromArrayLike(obj)
  }

  if (obj.type === 'Buffer' && Array.isArray(obj.data)) {
    return fromArrayLike(obj.data)
  }
}

function checked (length) {
  // Note: cannot use `length < K_MAX_LENGTH` here because that fails when
  // length is NaN (which is otherwise coerced to zero.)
  if (length >= K_MAX_LENGTH) {
    throw new RangeError('Attempt to allocate Buffer larger than maximum ' +
                         'size: 0x' + K_MAX_LENGTH.toString(16) + ' bytes')
  }
  return length | 0
}

function SlowBuffer (length) {
  if (+length != length) { // eslint-disable-line eqeqeq
    length = 0
  }
  return Buffer.alloc(+length)
}

Buffer.isBuffer = function isBuffer (b) {
  return b != null && b._isBuffer === true &&
    b !== Buffer.prototype // so Buffer.isBuffer(Buffer.prototype) will be false
}

Buffer.compare = function compare (a, b) {
  if (isInstance(a, Uint8Array)) a = Buffer.from(a, a.offset, a.byteLength)
  if (isInstance(b, Uint8Array)) b = Buffer.from(b, b.offset, b.byteLength)
  if (!Buffer.isBuffer(a) || !Buffer.isBuffer(b)) {
    throw new TypeError(
      'The "buf1", "buf2" arguments must be one of type Buffer or Uint8Array'
    )
  }

  if (a === b) return 0

  var x = a.length
  var y = b.length

  for (var i = 0, len = Math.min(x, y); i < len; ++i) {
    if (a[i] !== b[i]) {
      x = a[i]
      y = b[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

Buffer.isEncoding = function isEncoding (encoding) {
  switch (String(encoding).toLowerCase()) {
    case 'hex':
    case 'utf8':
    case 'utf-8':
    case 'ascii':
    case 'latin1':
    case 'binary':
    case 'base64':
    case 'ucs2':
    case 'ucs-2':
    case 'utf16le':
    case 'utf-16le':
      return true
    default:
      return false
  }
}

Buffer.concat = function concat (list, length) {
  if (!Array.isArray(list)) {
    throw new TypeError('"list" argument must be an Array of Buffers')
  }

  if (list.length === 0) {
    return Buffer.alloc(0)
  }

  var i
  if (length === undefined) {
    length = 0
    for (i = 0; i < list.length; ++i) {
      length += list[i].length
    }
  }

  var buffer = Buffer.allocUnsafe(length)
  var pos = 0
  for (i = 0; i < list.length; ++i) {
    var buf = list[i]
    if (isInstance(buf, Uint8Array)) {
      buf = Buffer.from(buf)
    }
    if (!Buffer.isBuffer(buf)) {
      throw new TypeError('"list" argument must be an Array of Buffers')
    }
    buf.copy(buffer, pos)
    pos += buf.length
  }
  return buffer
}

function byteLength (string, encoding) {
  if (Buffer.isBuffer(string)) {
    return string.length
  }
  if (ArrayBuffer.isView(string) || isInstance(string, ArrayBuffer)) {
    return string.byteLength
  }
  if (typeof string !== 'string') {
    throw new TypeError(
      'The "string" argument must be one of type string, Buffer, or ArrayBuffer. ' +
      'Received type ' + typeof string
    )
  }

  var len = string.length
  var mustMatch = (arguments.length > 2 && arguments[2] === true)
  if (!mustMatch && len === 0) return 0

  // Use a for loop to avoid recursion
  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'ascii':
      case 'latin1':
      case 'binary':
        return len
      case 'utf8':
      case 'utf-8':
        return utf8ToBytes(string).length
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return len * 2
      case 'hex':
        return len >>> 1
      case 'base64':
        return base64ToBytes(string).length
      default:
        if (loweredCase) {
          return mustMatch ? -1 : utf8ToBytes(string).length // assume utf8
        }
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}
Buffer.byteLength = byteLength

function slowToString (encoding, start, end) {
  var loweredCase = false

  // No need to verify that "this.length <= MAX_UINT32" since it's a read-only
  // property of a typed array.

  // This behaves neither like String nor Uint8Array in that we set start/end
  // to their upper/lower bounds if the value passed is out of range.
  // undefined is handled specially as per ECMA-262 6th Edition,
  // Section 13.3.3.7 Runtime Semantics: KeyedBindingInitialization.
  if (start === undefined || start < 0) {
    start = 0
  }
  // Return early if start > this.length. Done here to prevent potential uint32
  // coercion fail below.
  if (start > this.length) {
    return ''
  }

  if (end === undefined || end > this.length) {
    end = this.length
  }

  if (end <= 0) {
    return ''
  }

  // Force coersion to uint32. This will also coerce falsey/NaN values to 0.
  end >>>= 0
  start >>>= 0

  if (end <= start) {
    return ''
  }

  if (!encoding) encoding = 'utf8'

  while (true) {
    switch (encoding) {
      case 'hex':
        return hexSlice(this, start, end)

      case 'utf8':
      case 'utf-8':
        return utf8Slice(this, start, end)

      case 'ascii':
        return asciiSlice(this, start, end)

      case 'latin1':
      case 'binary':
        return latin1Slice(this, start, end)

      case 'base64':
        return base64Slice(this, start, end)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return utf16leSlice(this, start, end)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = (encoding + '').toLowerCase()
        loweredCase = true
    }
  }
}

// This property is used by `Buffer.isBuffer` (and the `is-buffer` npm package)
// to detect a Buffer instance. It's not possible to use `instanceof Buffer`
// reliably in a browserify context because there could be multiple different
// copies of the 'buffer' package in use. This method works even for Buffer
// instances that were created from another copy of the `buffer` package.
// See: https://github.com/feross/buffer/issues/154
Buffer.prototype._isBuffer = true

function swap (b, n, m) {
  var i = b[n]
  b[n] = b[m]
  b[m] = i
}

Buffer.prototype.swap16 = function swap16 () {
  var len = this.length
  if (len % 2 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 16-bits')
  }
  for (var i = 0; i < len; i += 2) {
    swap(this, i, i + 1)
  }
  return this
}

Buffer.prototype.swap32 = function swap32 () {
  var len = this.length
  if (len % 4 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 32-bits')
  }
  for (var i = 0; i < len; i += 4) {
    swap(this, i, i + 3)
    swap(this, i + 1, i + 2)
  }
  return this
}

Buffer.prototype.swap64 = function swap64 () {
  var len = this.length
  if (len % 8 !== 0) {
    throw new RangeError('Buffer size must be a multiple of 64-bits')
  }
  for (var i = 0; i < len; i += 8) {
    swap(this, i, i + 7)
    swap(this, i + 1, i + 6)
    swap(this, i + 2, i + 5)
    swap(this, i + 3, i + 4)
  }
  return this
}

Buffer.prototype.toString = function toString () {
  var length = this.length
  if (length === 0) return ''
  if (arguments.length === 0) return utf8Slice(this, 0, length)
  return slowToString.apply(this, arguments)
}

Buffer.prototype.toLocaleString = Buffer.prototype.toString

Buffer.prototype.equals = function equals (b) {
  if (!Buffer.isBuffer(b)) throw new TypeError('Argument must be a Buffer')
  if (this === b) return true
  return Buffer.compare(this, b) === 0
}

Buffer.prototype.inspect = function inspect () {
  var str = ''
  var max = exports.INSPECT_MAX_BYTES
  str = this.toString('hex', 0, max).replace(/(.{2})/g, '$1 ').trim()
  if (this.length > max) str += ' ... '
  return '<Buffer ' + str + '>'
}

Buffer.prototype.compare = function compare (target, start, end, thisStart, thisEnd) {
  if (isInstance(target, Uint8Array)) {
    target = Buffer.from(target, target.offset, target.byteLength)
  }
  if (!Buffer.isBuffer(target)) {
    throw new TypeError(
      'The "target" argument must be one of type Buffer or Uint8Array. ' +
      'Received type ' + (typeof target)
    )
  }

  if (start === undefined) {
    start = 0
  }
  if (end === undefined) {
    end = target ? target.length : 0
  }
  if (thisStart === undefined) {
    thisStart = 0
  }
  if (thisEnd === undefined) {
    thisEnd = this.length
  }

  if (start < 0 || end > target.length || thisStart < 0 || thisEnd > this.length) {
    throw new RangeError('out of range index')
  }

  if (thisStart >= thisEnd && start >= end) {
    return 0
  }
  if (thisStart >= thisEnd) {
    return -1
  }
  if (start >= end) {
    return 1
  }

  start >>>= 0
  end >>>= 0
  thisStart >>>= 0
  thisEnd >>>= 0

  if (this === target) return 0

  var x = thisEnd - thisStart
  var y = end - start
  var len = Math.min(x, y)

  var thisCopy = this.slice(thisStart, thisEnd)
  var targetCopy = target.slice(start, end)

  for (var i = 0; i < len; ++i) {
    if (thisCopy[i] !== targetCopy[i]) {
      x = thisCopy[i]
      y = targetCopy[i]
      break
    }
  }

  if (x < y) return -1
  if (y < x) return 1
  return 0
}

// Finds either the first index of `val` in `buffer` at offset >= `byteOffset`,
// OR the last index of `val` in `buffer` at offset <= `byteOffset`.
//
// Arguments:
// - buffer - a Buffer to search
// - val - a string, Buffer, or number
// - byteOffset - an index into `buffer`; will be clamped to an int32
// - encoding - an optional encoding, relevant is val is a string
// - dir - true for indexOf, false for lastIndexOf
function bidirectionalIndexOf (buffer, val, byteOffset, encoding, dir) {
  // Empty buffer means no match
  if (buffer.length === 0) return -1

  // Normalize byteOffset
  if (typeof byteOffset === 'string') {
    encoding = byteOffset
    byteOffset = 0
  } else if (byteOffset > 0x7fffffff) {
    byteOffset = 0x7fffffff
  } else if (byteOffset < -0x80000000) {
    byteOffset = -0x80000000
  }
  byteOffset = +byteOffset // Coerce to Number.
  if (numberIsNaN(byteOffset)) {
    // byteOffset: it it's undefined, null, NaN, "foo", etc, search whole buffer
    byteOffset = dir ? 0 : (buffer.length - 1)
  }

  // Normalize byteOffset: negative offsets start from the end of the buffer
  if (byteOffset < 0) byteOffset = buffer.length + byteOffset
  if (byteOffset >= buffer.length) {
    if (dir) return -1
    else byteOffset = buffer.length - 1
  } else if (byteOffset < 0) {
    if (dir) byteOffset = 0
    else return -1
  }

  // Normalize val
  if (typeof val === 'string') {
    val = Buffer.from(val, encoding)
  }

  // Finally, search either indexOf (if dir is true) or lastIndexOf
  if (Buffer.isBuffer(val)) {
    // Special case: looking for empty string/buffer always fails
    if (val.length === 0) {
      return -1
    }
    return arrayIndexOf(buffer, val, byteOffset, encoding, dir)
  } else if (typeof val === 'number') {
    val = val & 0xFF // Search for a byte value [0-255]
    if (typeof Uint8Array.prototype.indexOf === 'function') {
      if (dir) {
        return Uint8Array.prototype.indexOf.call(buffer, val, byteOffset)
      } else {
        return Uint8Array.prototype.lastIndexOf.call(buffer, val, byteOffset)
      }
    }
    return arrayIndexOf(buffer, [ val ], byteOffset, encoding, dir)
  }

  throw new TypeError('val must be string, number or Buffer')
}

function arrayIndexOf (arr, val, byteOffset, encoding, dir) {
  var indexSize = 1
  var arrLength = arr.length
  var valLength = val.length

  if (encoding !== undefined) {
    encoding = String(encoding).toLowerCase()
    if (encoding === 'ucs2' || encoding === 'ucs-2' ||
        encoding === 'utf16le' || encoding === 'utf-16le') {
      if (arr.length < 2 || val.length < 2) {
        return -1
      }
      indexSize = 2
      arrLength /= 2
      valLength /= 2
      byteOffset /= 2
    }
  }

  function read (buf, i) {
    if (indexSize === 1) {
      return buf[i]
    } else {
      return buf.readUInt16BE(i * indexSize)
    }
  }

  var i
  if (dir) {
    var foundIndex = -1
    for (i = byteOffset; i < arrLength; i++) {
      if (read(arr, i) === read(val, foundIndex === -1 ? 0 : i - foundIndex)) {
        if (foundIndex === -1) foundIndex = i
        if (i - foundIndex + 1 === valLength) return foundIndex * indexSize
      } else {
        if (foundIndex !== -1) i -= i - foundIndex
        foundIndex = -1
      }
    }
  } else {
    if (byteOffset + valLength > arrLength) byteOffset = arrLength - valLength
    for (i = byteOffset; i >= 0; i--) {
      var found = true
      for (var j = 0; j < valLength; j++) {
        if (read(arr, i + j) !== read(val, j)) {
          found = false
          break
        }
      }
      if (found) return i
    }
  }

  return -1
}

Buffer.prototype.includes = function includes (val, byteOffset, encoding) {
  return this.indexOf(val, byteOffset, encoding) !== -1
}

Buffer.prototype.indexOf = function indexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, true)
}

Buffer.prototype.lastIndexOf = function lastIndexOf (val, byteOffset, encoding) {
  return bidirectionalIndexOf(this, val, byteOffset, encoding, false)
}

function hexWrite (buf, string, offset, length) {
  offset = Number(offset) || 0
  var remaining = buf.length - offset
  if (!length) {
    length = remaining
  } else {
    length = Number(length)
    if (length > remaining) {
      length = remaining
    }
  }

  var strLen = string.length

  if (length > strLen / 2) {
    length = strLen / 2
  }
  for (var i = 0; i < length; ++i) {
    var parsed = parseInt(string.substr(i * 2, 2), 16)
    if (numberIsNaN(parsed)) return i
    buf[offset + i] = parsed
  }
  return i
}

function utf8Write (buf, string, offset, length) {
  return blitBuffer(utf8ToBytes(string, buf.length - offset), buf, offset, length)
}

function asciiWrite (buf, string, offset, length) {
  return blitBuffer(asciiToBytes(string), buf, offset, length)
}

function latin1Write (buf, string, offset, length) {
  return asciiWrite(buf, string, offset, length)
}

function base64Write (buf, string, offset, length) {
  return blitBuffer(base64ToBytes(string), buf, offset, length)
}

function ucs2Write (buf, string, offset, length) {
  return blitBuffer(utf16leToBytes(string, buf.length - offset), buf, offset, length)
}

Buffer.prototype.write = function write (string, offset, length, encoding) {
  // Buffer#write(string)
  if (offset === undefined) {
    encoding = 'utf8'
    length = this.length
    offset = 0
  // Buffer#write(string, encoding)
  } else if (length === undefined && typeof offset === 'string') {
    encoding = offset
    length = this.length
    offset = 0
  // Buffer#write(string, offset[, length][, encoding])
  } else if (isFinite(offset)) {
    offset = offset >>> 0
    if (isFinite(length)) {
      length = length >>> 0
      if (encoding === undefined) encoding = 'utf8'
    } else {
      encoding = length
      length = undefined
    }
  } else {
    throw new Error(
      'Buffer.write(string, encoding, offset[, length]) is no longer supported'
    )
  }

  var remaining = this.length - offset
  if (length === undefined || length > remaining) length = remaining

  if ((string.length > 0 && (length < 0 || offset < 0)) || offset > this.length) {
    throw new RangeError('Attempt to write outside buffer bounds')
  }

  if (!encoding) encoding = 'utf8'

  var loweredCase = false
  for (;;) {
    switch (encoding) {
      case 'hex':
        return hexWrite(this, string, offset, length)

      case 'utf8':
      case 'utf-8':
        return utf8Write(this, string, offset, length)

      case 'ascii':
        return asciiWrite(this, string, offset, length)

      case 'latin1':
      case 'binary':
        return latin1Write(this, string, offset, length)

      case 'base64':
        // Warning: maxLength not taken into account in base64Write
        return base64Write(this, string, offset, length)

      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return ucs2Write(this, string, offset, length)

      default:
        if (loweredCase) throw new TypeError('Unknown encoding: ' + encoding)
        encoding = ('' + encoding).toLowerCase()
        loweredCase = true
    }
  }
}

Buffer.prototype.toJSON = function toJSON () {
  return {
    type: 'Buffer',
    data: Array.prototype.slice.call(this._arr || this, 0)
  }
}

function base64Slice (buf, start, end) {
  if (start === 0 && end === buf.length) {
    return base64.fromByteArray(buf)
  } else {
    return base64.fromByteArray(buf.slice(start, end))
  }
}

function utf8Slice (buf, start, end) {
  end = Math.min(buf.length, end)
  var res = []

  var i = start
  while (i < end) {
    var firstByte = buf[i]
    var codePoint = null
    var bytesPerSequence = (firstByte > 0xEF) ? 4
      : (firstByte > 0xDF) ? 3
        : (firstByte > 0xBF) ? 2
          : 1

    if (i + bytesPerSequence <= end) {
      var secondByte, thirdByte, fourthByte, tempCodePoint

      switch (bytesPerSequence) {
        case 1:
          if (firstByte < 0x80) {
            codePoint = firstByte
          }
          break
        case 2:
          secondByte = buf[i + 1]
          if ((secondByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0x1F) << 0x6 | (secondByte & 0x3F)
            if (tempCodePoint > 0x7F) {
              codePoint = tempCodePoint
            }
          }
          break
        case 3:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0xC | (secondByte & 0x3F) << 0x6 | (thirdByte & 0x3F)
            if (tempCodePoint > 0x7FF && (tempCodePoint < 0xD800 || tempCodePoint > 0xDFFF)) {
              codePoint = tempCodePoint
            }
          }
          break
        case 4:
          secondByte = buf[i + 1]
          thirdByte = buf[i + 2]
          fourthByte = buf[i + 3]
          if ((secondByte & 0xC0) === 0x80 && (thirdByte & 0xC0) === 0x80 && (fourthByte & 0xC0) === 0x80) {
            tempCodePoint = (firstByte & 0xF) << 0x12 | (secondByte & 0x3F) << 0xC | (thirdByte & 0x3F) << 0x6 | (fourthByte & 0x3F)
            if (tempCodePoint > 0xFFFF && tempCodePoint < 0x110000) {
              codePoint = tempCodePoint
            }
          }
      }
    }

    if (codePoint === null) {
      // we did not generate a valid codePoint so insert a
      // replacement char (U+FFFD) and advance only 1 byte
      codePoint = 0xFFFD
      bytesPerSequence = 1
    } else if (codePoint > 0xFFFF) {
      // encode to utf16 (surrogate pair dance)
      codePoint -= 0x10000
      res.push(codePoint >>> 10 & 0x3FF | 0xD800)
      codePoint = 0xDC00 | codePoint & 0x3FF
    }

    res.push(codePoint)
    i += bytesPerSequence
  }

  return decodeCodePointsArray(res)
}

// Based on http://stackoverflow.com/a/22747272/680742, the browser with
// the lowest limit is Chrome, with 0x10000 args.
// We go 1 magnitude less, for safety
var MAX_ARGUMENTS_LENGTH = 0x1000

function decodeCodePointsArray (codePoints) {
  var len = codePoints.length
  if (len <= MAX_ARGUMENTS_LENGTH) {
    return String.fromCharCode.apply(String, codePoints) // avoid extra slice()
  }

  // Decode in chunks to avoid "call stack size exceeded".
  var res = ''
  var i = 0
  while (i < len) {
    res += String.fromCharCode.apply(
      String,
      codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH)
    )
  }
  return res
}

function asciiSlice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i] & 0x7F)
  }
  return ret
}

function latin1Slice (buf, start, end) {
  var ret = ''
  end = Math.min(buf.length, end)

  for (var i = start; i < end; ++i) {
    ret += String.fromCharCode(buf[i])
  }
  return ret
}

function hexSlice (buf, start, end) {
  var len = buf.length

  if (!start || start < 0) start = 0
  if (!end || end < 0 || end > len) end = len

  var out = ''
  for (var i = start; i < end; ++i) {
    out += toHex(buf[i])
  }
  return out
}

function utf16leSlice (buf, start, end) {
  var bytes = buf.slice(start, end)
  var res = ''
  for (var i = 0; i < bytes.length; i += 2) {
    res += String.fromCharCode(bytes[i] + (bytes[i + 1] * 256))
  }
  return res
}

Buffer.prototype.slice = function slice (start, end) {
  var len = this.length
  start = ~~start
  end = end === undefined ? len : ~~end

  if (start < 0) {
    start += len
    if (start < 0) start = 0
  } else if (start > len) {
    start = len
  }

  if (end < 0) {
    end += len
    if (end < 0) end = 0
  } else if (end > len) {
    end = len
  }

  if (end < start) end = start

  var newBuf = this.subarray(start, end)
  // Return an augmented `Uint8Array` instance
  newBuf.__proto__ = Buffer.prototype
  return newBuf
}

/*
 * Need to make sure that buffer isn't trying to write out of bounds.
 */
function checkOffset (offset, ext, length) {
  if ((offset % 1) !== 0 || offset < 0) throw new RangeError('offset is not uint')
  if (offset + ext > length) throw new RangeError('Trying to access beyond buffer length')
}

Buffer.prototype.readUIntLE = function readUIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }

  return val
}

Buffer.prototype.readUIntBE = function readUIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    checkOffset(offset, byteLength, this.length)
  }

  var val = this[offset + --byteLength]
  var mul = 1
  while (byteLength > 0 && (mul *= 0x100)) {
    val += this[offset + --byteLength] * mul
  }

  return val
}

Buffer.prototype.readUInt8 = function readUInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  return this[offset]
}

Buffer.prototype.readUInt16LE = function readUInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return this[offset] | (this[offset + 1] << 8)
}

Buffer.prototype.readUInt16BE = function readUInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  return (this[offset] << 8) | this[offset + 1]
}

Buffer.prototype.readUInt32LE = function readUInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return ((this[offset]) |
      (this[offset + 1] << 8) |
      (this[offset + 2] << 16)) +
      (this[offset + 3] * 0x1000000)
}

Buffer.prototype.readUInt32BE = function readUInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] * 0x1000000) +
    ((this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    this[offset + 3])
}

Buffer.prototype.readIntLE = function readIntLE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var val = this[offset]
  var mul = 1
  var i = 0
  while (++i < byteLength && (mul *= 0x100)) {
    val += this[offset + i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readIntBE = function readIntBE (offset, byteLength, noAssert) {
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) checkOffset(offset, byteLength, this.length)

  var i = byteLength
  var mul = 1
  var val = this[offset + --i]
  while (i > 0 && (mul *= 0x100)) {
    val += this[offset + --i] * mul
  }
  mul *= 0x80

  if (val >= mul) val -= Math.pow(2, 8 * byteLength)

  return val
}

Buffer.prototype.readInt8 = function readInt8 (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 1, this.length)
  if (!(this[offset] & 0x80)) return (this[offset])
  return ((0xff - this[offset] + 1) * -1)
}

Buffer.prototype.readInt16LE = function readInt16LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset] | (this[offset + 1] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt16BE = function readInt16BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 2, this.length)
  var val = this[offset + 1] | (this[offset] << 8)
  return (val & 0x8000) ? val | 0xFFFF0000 : val
}

Buffer.prototype.readInt32LE = function readInt32LE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset]) |
    (this[offset + 1] << 8) |
    (this[offset + 2] << 16) |
    (this[offset + 3] << 24)
}

Buffer.prototype.readInt32BE = function readInt32BE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)

  return (this[offset] << 24) |
    (this[offset + 1] << 16) |
    (this[offset + 2] << 8) |
    (this[offset + 3])
}

Buffer.prototype.readFloatLE = function readFloatLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, true, 23, 4)
}

Buffer.prototype.readFloatBE = function readFloatBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 4, this.length)
  return ieee754.read(this, offset, false, 23, 4)
}

Buffer.prototype.readDoubleLE = function readDoubleLE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, true, 52, 8)
}

Buffer.prototype.readDoubleBE = function readDoubleBE (offset, noAssert) {
  offset = offset >>> 0
  if (!noAssert) checkOffset(offset, 8, this.length)
  return ieee754.read(this, offset, false, 52, 8)
}

function checkInt (buf, value, offset, ext, max, min) {
  if (!Buffer.isBuffer(buf)) throw new TypeError('"buffer" argument must be a Buffer instance')
  if (value > max || value < min) throw new RangeError('"value" argument is out of bounds')
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
}

Buffer.prototype.writeUIntLE = function writeUIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var mul = 1
  var i = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUIntBE = function writeUIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  byteLength = byteLength >>> 0
  if (!noAssert) {
    var maxBytes = Math.pow(2, 8 * byteLength) - 1
    checkInt(this, value, offset, byteLength, maxBytes, 0)
  }

  var i = byteLength - 1
  var mul = 1
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    this[offset + i] = (value / mul) & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeUInt8 = function writeUInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0xff, 0)
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeUInt16LE = function writeUInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeUInt16BE = function writeUInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0xffff, 0)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeUInt32LE = function writeUInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset + 3] = (value >>> 24)
  this[offset + 2] = (value >>> 16)
  this[offset + 1] = (value >>> 8)
  this[offset] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeUInt32BE = function writeUInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0xffffffff, 0)
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

Buffer.prototype.writeIntLE = function writeIntLE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = 0
  var mul = 1
  var sub = 0
  this[offset] = value & 0xFF
  while (++i < byteLength && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i - 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeIntBE = function writeIntBE (value, offset, byteLength, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    var limit = Math.pow(2, (8 * byteLength) - 1)

    checkInt(this, value, offset, byteLength, limit - 1, -limit)
  }

  var i = byteLength - 1
  var mul = 1
  var sub = 0
  this[offset + i] = value & 0xFF
  while (--i >= 0 && (mul *= 0x100)) {
    if (value < 0 && sub === 0 && this[offset + i + 1] !== 0) {
      sub = 1
    }
    this[offset + i] = ((value / mul) >> 0) - sub & 0xFF
  }

  return offset + byteLength
}

Buffer.prototype.writeInt8 = function writeInt8 (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 1, 0x7f, -0x80)
  if (value < 0) value = 0xff + value + 1
  this[offset] = (value & 0xff)
  return offset + 1
}

Buffer.prototype.writeInt16LE = function writeInt16LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  return offset + 2
}

Buffer.prototype.writeInt16BE = function writeInt16BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 2, 0x7fff, -0x8000)
  this[offset] = (value >>> 8)
  this[offset + 1] = (value & 0xff)
  return offset + 2
}

Buffer.prototype.writeInt32LE = function writeInt32LE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  this[offset] = (value & 0xff)
  this[offset + 1] = (value >>> 8)
  this[offset + 2] = (value >>> 16)
  this[offset + 3] = (value >>> 24)
  return offset + 4
}

Buffer.prototype.writeInt32BE = function writeInt32BE (value, offset, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) checkInt(this, value, offset, 4, 0x7fffffff, -0x80000000)
  if (value < 0) value = 0xffffffff + value + 1
  this[offset] = (value >>> 24)
  this[offset + 1] = (value >>> 16)
  this[offset + 2] = (value >>> 8)
  this[offset + 3] = (value & 0xff)
  return offset + 4
}

function checkIEEE754 (buf, value, offset, ext, max, min) {
  if (offset + ext > buf.length) throw new RangeError('Index out of range')
  if (offset < 0) throw new RangeError('Index out of range')
}

function writeFloat (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 4, 3.4028234663852886e+38, -3.4028234663852886e+38)
  }
  ieee754.write(buf, value, offset, littleEndian, 23, 4)
  return offset + 4
}

Buffer.prototype.writeFloatLE = function writeFloatLE (value, offset, noAssert) {
  return writeFloat(this, value, offset, true, noAssert)
}

Buffer.prototype.writeFloatBE = function writeFloatBE (value, offset, noAssert) {
  return writeFloat(this, value, offset, false, noAssert)
}

function writeDouble (buf, value, offset, littleEndian, noAssert) {
  value = +value
  offset = offset >>> 0
  if (!noAssert) {
    checkIEEE754(buf, value, offset, 8, 1.7976931348623157E+308, -1.7976931348623157E+308)
  }
  ieee754.write(buf, value, offset, littleEndian, 52, 8)
  return offset + 8
}

Buffer.prototype.writeDoubleLE = function writeDoubleLE (value, offset, noAssert) {
  return writeDouble(this, value, offset, true, noAssert)
}

Buffer.prototype.writeDoubleBE = function writeDoubleBE (value, offset, noAssert) {
  return writeDouble(this, value, offset, false, noAssert)
}

// copy(targetBuffer, targetStart=0, sourceStart=0, sourceEnd=buffer.length)
Buffer.prototype.copy = function copy (target, targetStart, start, end) {
  if (!Buffer.isBuffer(target)) throw new TypeError('argument should be a Buffer')
  if (!start) start = 0
  if (!end && end !== 0) end = this.length
  if (targetStart >= target.length) targetStart = target.length
  if (!targetStart) targetStart = 0
  if (end > 0 && end < start) end = start

  // Copy 0 bytes; we're done
  if (end === start) return 0
  if (target.length === 0 || this.length === 0) return 0

  // Fatal error conditions
  if (targetStart < 0) {
    throw new RangeError('targetStart out of bounds')
  }
  if (start < 0 || start >= this.length) throw new RangeError('Index out of range')
  if (end < 0) throw new RangeError('sourceEnd out of bounds')

  // Are we oob?
  if (end > this.length) end = this.length
  if (target.length - targetStart < end - start) {
    end = target.length - targetStart + start
  }

  var len = end - start

  if (this === target && typeof Uint8Array.prototype.copyWithin === 'function') {
    // Use built-in when available, missing from IE11
    this.copyWithin(targetStart, start, end)
  } else if (this === target && start < targetStart && targetStart < end) {
    // descending copy from end
    for (var i = len - 1; i >= 0; --i) {
      target[i + targetStart] = this[i + start]
    }
  } else {
    Uint8Array.prototype.set.call(
      target,
      this.subarray(start, end),
      targetStart
    )
  }

  return len
}

// Usage:
//    buffer.fill(number[, offset[, end]])
//    buffer.fill(buffer[, offset[, end]])
//    buffer.fill(string[, offset[, end]][, encoding])
Buffer.prototype.fill = function fill (val, start, end, encoding) {
  // Handle string cases:
  if (typeof val === 'string') {
    if (typeof start === 'string') {
      encoding = start
      start = 0
      end = this.length
    } else if (typeof end === 'string') {
      encoding = end
      end = this.length
    }
    if (encoding !== undefined && typeof encoding !== 'string') {
      throw new TypeError('encoding must be a string')
    }
    if (typeof encoding === 'string' && !Buffer.isEncoding(encoding)) {
      throw new TypeError('Unknown encoding: ' + encoding)
    }
    if (val.length === 1) {
      var code = val.charCodeAt(0)
      if ((encoding === 'utf8' && code < 128) ||
          encoding === 'latin1') {
        // Fast path: If `val` fits into a single byte, use that numeric value.
        val = code
      }
    }
  } else if (typeof val === 'number') {
    val = val & 255
  }

  // Invalid ranges are not set to a default, so can range check early.
  if (start < 0 || this.length < start || this.length < end) {
    throw new RangeError('Out of range index')
  }

  if (end <= start) {
    return this
  }

  start = start >>> 0
  end = end === undefined ? this.length : end >>> 0

  if (!val) val = 0

  var i
  if (typeof val === 'number') {
    for (i = start; i < end; ++i) {
      this[i] = val
    }
  } else {
    var bytes = Buffer.isBuffer(val)
      ? val
      : Buffer.from(val, encoding)
    var len = bytes.length
    if (len === 0) {
      throw new TypeError('The value "' + val +
        '" is invalid for argument "value"')
    }
    for (i = 0; i < end - start; ++i) {
      this[i + start] = bytes[i % len]
    }
  }

  return this
}

// HELPER FUNCTIONS
// ================

var INVALID_BASE64_RE = /[^+/0-9A-Za-z-_]/g

function base64clean (str) {
  // Node takes equal signs as end of the Base64 encoding
  str = str.split('=')[0]
  // Node strips out invalid characters like \n and \t from the string, base64-js does not
  str = str.trim().replace(INVALID_BASE64_RE, '')
  // Node converts strings with length < 2 to ''
  if (str.length < 2) return ''
  // Node allows for non-padded base64 strings (missing trailing ===), base64-js does not
  while (str.length % 4 !== 0) {
    str = str + '='
  }
  return str
}

function toHex (n) {
  if (n < 16) return '0' + n.toString(16)
  return n.toString(16)
}

function utf8ToBytes (string, units) {
  units = units || Infinity
  var codePoint
  var length = string.length
  var leadSurrogate = null
  var bytes = []

  for (var i = 0; i < length; ++i) {
    codePoint = string.charCodeAt(i)

    // is surrogate component
    if (codePoint > 0xD7FF && codePoint < 0xE000) {
      // last char was a lead
      if (!leadSurrogate) {
        // no lead yet
        if (codePoint > 0xDBFF) {
          // unexpected trail
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        } else if (i + 1 === length) {
          // unpaired lead
          if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
          continue
        }

        // valid lead
        leadSurrogate = codePoint

        continue
      }

      // 2 leads in a row
      if (codePoint < 0xDC00) {
        if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
        leadSurrogate = codePoint
        continue
      }

      // valid surrogate pair
      codePoint = (leadSurrogate - 0xD800 << 10 | codePoint - 0xDC00) + 0x10000
    } else if (leadSurrogate) {
      // valid bmp char, but last char was a lead
      if ((units -= 3) > -1) bytes.push(0xEF, 0xBF, 0xBD)
    }

    leadSurrogate = null

    // encode utf8
    if (codePoint < 0x80) {
      if ((units -= 1) < 0) break
      bytes.push(codePoint)
    } else if (codePoint < 0x800) {
      if ((units -= 2) < 0) break
      bytes.push(
        codePoint >> 0x6 | 0xC0,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x10000) {
      if ((units -= 3) < 0) break
      bytes.push(
        codePoint >> 0xC | 0xE0,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else if (codePoint < 0x110000) {
      if ((units -= 4) < 0) break
      bytes.push(
        codePoint >> 0x12 | 0xF0,
        codePoint >> 0xC & 0x3F | 0x80,
        codePoint >> 0x6 & 0x3F | 0x80,
        codePoint & 0x3F | 0x80
      )
    } else {
      throw new Error('Invalid code point')
    }
  }

  return bytes
}

function asciiToBytes (str) {
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    // Node's code seems to be doing this and not & 0x7F..
    byteArray.push(str.charCodeAt(i) & 0xFF)
  }
  return byteArray
}

function utf16leToBytes (str, units) {
  var c, hi, lo
  var byteArray = []
  for (var i = 0; i < str.length; ++i) {
    if ((units -= 2) < 0) break

    c = str.charCodeAt(i)
    hi = c >> 8
    lo = c % 256
    byteArray.push(lo)
    byteArray.push(hi)
  }

  return byteArray
}

function base64ToBytes (str) {
  return base64.toByteArray(base64clean(str))
}

function blitBuffer (src, dst, offset, length) {
  for (var i = 0; i < length; ++i) {
    if ((i + offset >= dst.length) || (i >= src.length)) break
    dst[i + offset] = src[i]
  }
  return i
}

// ArrayBuffer or Uint8Array objects from other contexts (i.e. iframes) do not pass
// the `instanceof` check but they should be treated as of that type.
// See: https://github.com/feross/buffer/issues/166
function isInstance (obj, type) {
  return obj instanceof type ||
    (obj != null && obj.constructor != null && obj.constructor.name != null &&
      obj.constructor.name === type.name)
}
function numberIsNaN (obj) {
  // For IE11 support
  return obj !== obj // eslint-disable-line no-self-compare
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"base64-js":42,"buffer":74,"ieee754":135}],75:[function(require,module,exports){
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},{"buffer":74}],76:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

/*<replacement>*/

var Buffer = require('safe-buffer').Buffer;
/*</replacement>*/

var isEncoding = Buffer.isEncoding || function (encoding) {
  encoding = '' + encoding;
  switch (encoding && encoding.toLowerCase()) {
    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':
      return true;
    default:
      return false;
  }
};

function _normalizeEncoding(enc) {
  if (!enc) return 'utf8';
  var retried;
  while (true) {
    switch (enc) {
      case 'utf8':
      case 'utf-8':
        return 'utf8';
      case 'ucs2':
      case 'ucs-2':
      case 'utf16le':
      case 'utf-16le':
        return 'utf16le';
      case 'latin1':
      case 'binary':
        return 'latin1';
      case 'base64':
      case 'ascii':
      case 'hex':
        return enc;
      default:
        if (retried) return; // undefined
        enc = ('' + enc).toLowerCase();
        retried = true;
    }
  }
};

// Do not cache `Buffer.isEncoding` when checking encoding names as some
// modules monkey-patch it to support additional encodings
function normalizeEncoding(enc) {
  var nenc = _normalizeEncoding(enc);
  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);
  return nenc || enc;
}

// StringDecoder provides an interface for efficiently splitting a series of
// buffers into a series of JS strings without breaking apart multi-byte
// characters.
exports.StringDecoder = StringDecoder;
function StringDecoder(encoding) {
  this.encoding = normalizeEncoding(encoding);
  var nb;
  switch (this.encoding) {
    case 'utf16le':
      this.text = utf16Text;
      this.end = utf16End;
      nb = 4;
      break;
    case 'utf8':
      this.fillLast = utf8FillLast;
      nb = 4;
      break;
    case 'base64':
      this.text = base64Text;
      this.end = base64End;
      nb = 3;
      break;
    default:
      this.write = simpleWrite;
      this.end = simpleEnd;
      return;
  }
  this.lastNeed = 0;
  this.lastTotal = 0;
  this.lastChar = Buffer.allocUnsafe(nb);
}

StringDecoder.prototype.write = function (buf) {
  if (buf.length === 0) return '';
  var r;
  var i;
  if (this.lastNeed) {
    r = this.fillLast(buf);
    if (r === undefined) return '';
    i = this.lastNeed;
    this.lastNeed = 0;
  } else {
    i = 0;
  }
  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);
  return r || '';
};

StringDecoder.prototype.end = utf8End;

// Returns only complete characters in a Buffer
StringDecoder.prototype.text = utf8Text;

// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer
StringDecoder.prototype.fillLast = function (buf) {
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);
  this.lastNeed -= buf.length;
};

// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a
// continuation byte. If an invalid byte is detected, -2 is returned.
function utf8CheckByte(byte) {
  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;
  return byte >> 6 === 0x02 ? -1 : -2;
}

// Checks at most 3 bytes at the end of a Buffer in order to detect an
// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)
// needed to complete the UTF-8 character (if applicable) are returned.
function utf8CheckIncomplete(self, buf, i) {
  var j = buf.length - 1;
  if (j < i) return 0;
  var nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 1;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) self.lastNeed = nb - 2;
    return nb;
  }
  if (--j < i || nb === -2) return 0;
  nb = utf8CheckByte(buf[j]);
  if (nb >= 0) {
    if (nb > 0) {
      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;
    }
    return nb;
  }
  return 0;
}

// Validates as many continuation bytes for a multi-byte UTF-8 character as
// needed or are available. If we see a non-continuation byte where we expect
// one, we "replace" the validated continuation bytes we've seen so far with
// a single UTF-8 replacement character ('\ufffd'), to match v8's UTF-8 decoding
// behavior. The continuation byte check is included three times in the case
// where all of the continuation bytes for a character exist in the same buffer.
// It is also done this way as a slight performance increase instead of using a
// loop.
function utf8CheckExtraBytes(self, buf, p) {
  if ((buf[0] & 0xC0) !== 0x80) {
    self.lastNeed = 0;
    return '\ufffd';
  }
  if (self.lastNeed > 1 && buf.length > 1) {
    if ((buf[1] & 0xC0) !== 0x80) {
      self.lastNeed = 1;
      return '\ufffd';
    }
    if (self.lastNeed > 2 && buf.length > 2) {
      if ((buf[2] & 0xC0) !== 0x80) {
        self.lastNeed = 2;
        return '\ufffd';
      }
    }
  }
}

// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.
function utf8FillLast(buf) {
  var p = this.lastTotal - this.lastNeed;
  var r = utf8CheckExtraBytes(this, buf, p);
  if (r !== undefined) return r;
  if (this.lastNeed <= buf.length) {
    buf.copy(this.lastChar, p, 0, this.lastNeed);
    return this.lastChar.toString(this.encoding, 0, this.lastTotal);
  }
  buf.copy(this.lastChar, p, 0, buf.length);
  this.lastNeed -= buf.length;
}

// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a
// partial character, the character's bytes are buffered until the required
// number of bytes are available.
function utf8Text(buf, i) {
  var total = utf8CheckIncomplete(this, buf, i);
  if (!this.lastNeed) return buf.toString('utf8', i);
  this.lastTotal = total;
  var end = buf.length - (total - this.lastNeed);
  buf.copy(this.lastChar, 0, end);
  return buf.toString('utf8', i, end);
}

// For UTF-8, a replacement character is added when ending on a partial
// character.
function utf8End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + '\ufffd';
  return r;
}

// UTF-16LE typically needs two bytes per character, but even if we have an even
// number of bytes available, we need to check if we end on a leading/high
// surrogate. In that case, we need to wait for the next two bytes in order to
// decode the last character properly.
function utf16Text(buf, i) {
  if ((buf.length - i) % 2 === 0) {
    var r = buf.toString('utf16le', i);
    if (r) {
      var c = r.charCodeAt(r.length - 1);
      if (c >= 0xD800 && c <= 0xDBFF) {
        this.lastNeed = 2;
        this.lastTotal = 4;
        this.lastChar[0] = buf[buf.length - 2];
        this.lastChar[1] = buf[buf.length - 1];
        return r.slice(0, -1);
      }
    }
    return r;
  }
  this.lastNeed = 1;
  this.lastTotal = 2;
  this.lastChar[0] = buf[buf.length - 1];
  return buf.toString('utf16le', i, buf.length - 1);
}

// For UTF-16LE we do not explicitly append special replacement characters if we
// end on a partial character, we simply let v8 handle that.
function utf16End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) {
    var end = this.lastTotal - this.lastNeed;
    return r + this.lastChar.toString('utf16le', 0, end);
  }
  return r;
}

function base64Text(buf, i) {
  var n = (buf.length - i) % 3;
  if (n === 0) return buf.toString('base64', i);
  this.lastNeed = 3 - n;
  this.lastTotal = 3;
  if (n === 1) {
    this.lastChar[0] = buf[buf.length - 1];
  } else {
    this.lastChar[0] = buf[buf.length - 2];
    this.lastChar[1] = buf[buf.length - 1];
  }
  return buf.toString('base64', i, buf.length - n);
}

function base64End(buf) {
  var r = buf && buf.length ? this.write(buf) : '';
  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);
  return r;
}

// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)
function simpleWrite(buf) {
  return buf.toString(this.encoding);
}

function simpleEnd(buf) {
  return buf && buf.length ? this.write(buf) : '';
}
},{"safe-buffer":75}],77:[function(require,module,exports){
(function (Buffer){(function (){
module.exports = function xor (a, b) {
  var length = Math.min(a.length, b.length)
  var buffer = new Buffer(length)

  for (var i = 0; i < length; ++i) {
    buffer[i] = a[i] ^ b[i]
  }

  return buffer
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"buffer":74}],78:[function(require,module,exports){
/* jshint esversion: 6 */
/* jslint node: true */
'use strict';

module.exports = function serialize (object) {
  if (object === null || typeof object !== 'object' || object.toJSON != null) {
    return JSON.stringify(object);
  }

  if (Array.isArray(object)) {
    return '[' + object.reduce((t, cv, ci) => {
      const comma = ci === 0 ? '' : ',';
      const value = cv === undefined || typeof cv === 'symbol' ? null : cv;
      return t + comma + serialize(value);
    }, '') + ']';
  }

  return '{' + Object.keys(object).sort().reduce((t, cv, ci) => {
    if (object[cv] === undefined ||
        typeof object[cv] === 'symbol') {
      return t;
    }
    const comma = t.length === 0 ? '' : ',';
    return t + comma + serialize(cv) + ':' + serialize(object[cv]);
  }, '') + '}';
};

},{}],79:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer
var Transform = require('stream').Transform
var StringDecoder = require('string_decoder').StringDecoder
var inherits = require('inherits')

function CipherBase (hashMode) {
  Transform.call(this)
  this.hashMode = typeof hashMode === 'string'
  if (this.hashMode) {
    this[hashMode] = this._finalOrDigest
  } else {
    this.final = this._finalOrDigest
  }
  if (this._final) {
    this.__final = this._final
    this._final = null
  }
  this._decoder = null
  this._encoding = null
}
inherits(CipherBase, Transform)

CipherBase.prototype.update = function (data, inputEnc, outputEnc) {
  if (typeof data === 'string') {
    data = Buffer.from(data, inputEnc)
  }

  var outData = this._update(data)
  if (this.hashMode) return this

  if (outputEnc) {
    outData = this._toString(outData, outputEnc)
  }

  return outData
}

CipherBase.prototype.setAutoPadding = function () {}
CipherBase.prototype.getAuthTag = function () {
  throw new Error('trying to get auth tag in unsupported state')
}

CipherBase.prototype.setAuthTag = function () {
  throw new Error('trying to set auth tag in unsupported state')
}

CipherBase.prototype.setAAD = function () {
  throw new Error('trying to set aad in unsupported state')
}

CipherBase.prototype._transform = function (data, _, next) {
  var err
  try {
    if (this.hashMode) {
      this._update(data)
    } else {
      this.push(this._update(data))
    }
  } catch (e) {
    err = e
  } finally {
    next(err)
  }
}
CipherBase.prototype._flush = function (done) {
  var err
  try {
    this.push(this.__final())
  } catch (e) {
    err = e
  }

  done(err)
}
CipherBase.prototype._finalOrDigest = function (outputEnc) {
  var outData = this.__final() || Buffer.alloc(0)
  if (outputEnc) {
    outData = this._toString(outData, outputEnc, true)
  }
  return outData
}

CipherBase.prototype._toString = function (value, enc, fin) {
  if (!this._decoder) {
    this._decoder = new StringDecoder(enc)
    this._encoding = enc
  }

  if (this._encoding !== enc) throw new Error('can\'t switch encodings')

  var out = this._decoder.write(value)
  if (fin) {
    out += this._decoder.end()
  }

  return out
}

module.exports = CipherBase

},{"inherits":136,"safe-buffer":215,"stream":226,"string_decoder":76}],80:[function(require,module,exports){
(function (Buffer){(function (){
var elliptic = require('elliptic')
var BN = require('bn.js')

module.exports = function createECDH (curve) {
  return new ECDH(curve)
}

var aliases = {
  secp256k1: {
    name: 'secp256k1',
    byteLength: 32
  },
  secp224r1: {
    name: 'p224',
    byteLength: 28
  },
  prime256v1: {
    name: 'p256',
    byteLength: 32
  },
  prime192v1: {
    name: 'p192',
    byteLength: 24
  },
  ed25519: {
    name: 'ed25519',
    byteLength: 32
  },
  secp384r1: {
    name: 'p384',
    byteLength: 48
  },
  secp521r1: {
    name: 'p521',
    byteLength: 66
  }
}

aliases.p224 = aliases.secp224r1
aliases.p256 = aliases.secp256r1 = aliases.prime256v1
aliases.p192 = aliases.secp192r1 = aliases.prime192v1
aliases.p384 = aliases.secp384r1
aliases.p521 = aliases.secp521r1

function ECDH (curve) {
  this.curveType = aliases[curve]
  if (!this.curveType) {
    this.curveType = {
      name: curve
    }
  }
  this.curve = new elliptic.ec(this.curveType.name) // eslint-disable-line new-cap
  this.keys = void 0
}

ECDH.prototype.generateKeys = function (enc, format) {
  this.keys = this.curve.genKeyPair()
  return this.getPublicKey(enc, format)
}

ECDH.prototype.computeSecret = function (other, inenc, enc) {
  inenc = inenc || 'utf8'
  if (!Buffer.isBuffer(other)) {
    other = new Buffer(other, inenc)
  }
  var otherPub = this.curve.keyFromPublic(other).getPublic()
  var out = otherPub.mul(this.keys.getPrivate()).getX()
  return formatReturnValue(out, enc, this.curveType.byteLength)
}

ECDH.prototype.getPublicKey = function (enc, format) {
  var key = this.keys.getPublic(format === 'compressed', true)
  if (format === 'hybrid') {
    if (key[key.length - 1] % 2) {
      key[0] = 7
    } else {
      key[0] = 6
    }
  }
  return formatReturnValue(key, enc)
}

ECDH.prototype.getPrivateKey = function (enc) {
  return formatReturnValue(this.keys.getPrivate(), enc)
}

ECDH.prototype.setPublicKey = function (pub, enc) {
  enc = enc || 'utf8'
  if (!Buffer.isBuffer(pub)) {
    pub = new Buffer(pub, enc)
  }
  this.keys._importPublic(pub)
  return this
}

ECDH.prototype.setPrivateKey = function (priv, enc) {
  enc = enc || 'utf8'
  if (!Buffer.isBuffer(priv)) {
    priv = new Buffer(priv, enc)
  }

  var _priv = new BN(priv)
  _priv = _priv.toString(16)
  this.keys = this.curve.genKeyPair()
  this.keys._importPrivate(_priv)
  return this
}

function formatReturnValue (bn, enc, len) {
  if (!Array.isArray(bn)) {
    bn = bn.toArray()
  }
  var buf = new Buffer(bn)
  if (len && buf.length < len) {
    var zeros = new Buffer(len - buf.length)
    zeros.fill(0)
    buf = Buffer.concat([zeros, buf])
  }
  if (!enc) {
    return buf
  } else {
    return buf.toString(enc)
  }
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"bn.js":81,"buffer":74,"elliptic":101}],81:[function(require,module,exports){
arguments[4][41][0].apply(exports,arguments)
},{"buffer":45,"dup":41}],82:[function(require,module,exports){
'use strict'
var inherits = require('inherits')
var MD5 = require('md5.js')
var RIPEMD160 = require('ripemd160')
var sha = require('sha.js')
var Base = require('cipher-base')

function Hash (hash) {
  Base.call(this, 'digest')

  this._hash = hash
}

inherits(Hash, Base)

Hash.prototype._update = function (data) {
  this._hash.update(data)
}

Hash.prototype._final = function () {
  return this._hash.digest()
}

module.exports = function createHash (alg) {
  alg = alg.toLowerCase()
  if (alg === 'md5') return new MD5()
  if (alg === 'rmd160' || alg === 'ripemd160') return new RIPEMD160()

  return new Hash(sha(alg))
}

},{"cipher-base":79,"inherits":136,"md5.js":161,"ripemd160":214,"sha.js":219}],83:[function(require,module,exports){
var MD5 = require('md5.js')

module.exports = function (buffer) {
  return new MD5().update(buffer).digest()
}

},{"md5.js":161}],84:[function(require,module,exports){
'use strict'
var inherits = require('inherits')
var Legacy = require('./legacy')
var Base = require('cipher-base')
var Buffer = require('safe-buffer').Buffer
var md5 = require('create-hash/md5')
var RIPEMD160 = require('ripemd160')

var sha = require('sha.js')

var ZEROS = Buffer.alloc(128)

function Hmac (alg, key) {
  Base.call(this, 'digest')
  if (typeof key === 'string') {
    key = Buffer.from(key)
  }

  var blocksize = (alg === 'sha512' || alg === 'sha384') ? 128 : 64

  this._alg = alg
  this._key = key
  if (key.length > blocksize) {
    var hash = alg === 'rmd160' ? new RIPEMD160() : sha(alg)
    key = hash.update(key).digest()
  } else if (key.length < blocksize) {
    key = Buffer.concat([key, ZEROS], blocksize)
  }

  var ipad = this._ipad = Buffer.allocUnsafe(blocksize)
  var opad = this._opad = Buffer.allocUnsafe(blocksize)

  for (var i = 0; i < blocksize; i++) {
    ipad[i] = key[i] ^ 0x36
    opad[i] = key[i] ^ 0x5C
  }
  this._hash = alg === 'rmd160' ? new RIPEMD160() : sha(alg)
  this._hash.update(ipad)
}

inherits(Hmac, Base)

Hmac.prototype._update = function (data) {
  this._hash.update(data)
}

Hmac.prototype._final = function () {
  var h = this._hash.digest()
  var hash = this._alg === 'rmd160' ? new RIPEMD160() : sha(this._alg)
  return hash.update(this._opad).update(h).digest()
}

module.exports = function createHmac (alg, key) {
  alg = alg.toLowerCase()
  if (alg === 'rmd160' || alg === 'ripemd160') {
    return new Hmac('rmd160', key)
  }
  if (alg === 'md5') {
    return new Legacy(md5, key)
  }
  return new Hmac(alg, key)
}

},{"./legacy":85,"cipher-base":79,"create-hash/md5":83,"inherits":136,"ripemd160":214,"safe-buffer":215,"sha.js":219}],85:[function(require,module,exports){
'use strict'
var inherits = require('inherits')
var Buffer = require('safe-buffer').Buffer

var Base = require('cipher-base')

var ZEROS = Buffer.alloc(128)
var blocksize = 64

function Hmac (alg, key) {
  Base.call(this, 'digest')
  if (typeof key === 'string') {
    key = Buffer.from(key)
  }

  this._alg = alg
  this._key = key

  if (key.length > blocksize) {
    key = alg(key)
  } else if (key.length < blocksize) {
    key = Buffer.concat([key, ZEROS], blocksize)
  }

  var ipad = this._ipad = Buffer.allocUnsafe(blocksize)
  var opad = this._opad = Buffer.allocUnsafe(blocksize)

  for (var i = 0; i < blocksize; i++) {
    ipad[i] = key[i] ^ 0x36
    opad[i] = key[i] ^ 0x5C
  }

  this._hash = [ipad]
}

inherits(Hmac, Base)

Hmac.prototype._update = function (data) {
  this._hash.push(data)
}

Hmac.prototype._final = function () {
  var h = this._alg(Buffer.concat(this._hash))
  return this._alg(Buffer.concat([this._opad, h]))
}
module.exports = Hmac

},{"cipher-base":79,"inherits":136,"safe-buffer":215}],86:[function(require,module,exports){
'use strict'

exports.randomBytes = exports.rng = exports.pseudoRandomBytes = exports.prng = require('randombytes')
exports.createHash = exports.Hash = require('create-hash')
exports.createHmac = exports.Hmac = require('create-hmac')

var algos = require('browserify-sign/algos')
var algoKeys = Object.keys(algos)
var hashes = ['sha1', 'sha224', 'sha256', 'sha384', 'sha512', 'md5', 'rmd160'].concat(algoKeys)
exports.getHashes = function () {
  return hashes
}

var p = require('pbkdf2')
exports.pbkdf2 = p.pbkdf2
exports.pbkdf2Sync = p.pbkdf2Sync

var aes = require('browserify-cipher')

exports.Cipher = aes.Cipher
exports.createCipher = aes.createCipher
exports.Cipheriv = aes.Cipheriv
exports.createCipheriv = aes.createCipheriv
exports.Decipher = aes.Decipher
exports.createDecipher = aes.createDecipher
exports.Decipheriv = aes.Decipheriv
exports.createDecipheriv = aes.createDecipheriv
exports.getCiphers = aes.getCiphers
exports.listCiphers = aes.listCiphers

var dh = require('diffie-hellman')

exports.DiffieHellmanGroup = dh.DiffieHellmanGroup
exports.createDiffieHellmanGroup = dh.createDiffieHellmanGroup
exports.getDiffieHellman = dh.getDiffieHellman
exports.createDiffieHellman = dh.createDiffieHellman
exports.DiffieHellman = dh.DiffieHellman

var sign = require('browserify-sign')

exports.createSign = sign.createSign
exports.Sign = sign.Sign
exports.createVerify = sign.createVerify
exports.Verify = sign.Verify

exports.createECDH = require('create-ecdh')

var publicEncrypt = require('public-encrypt')

exports.publicEncrypt = publicEncrypt.publicEncrypt
exports.privateEncrypt = publicEncrypt.privateEncrypt
exports.publicDecrypt = publicEncrypt.publicDecrypt
exports.privateDecrypt = publicEncrypt.privateDecrypt

// the least I can do is make error messages for the rest of the node.js/crypto api.
// ;[
//   'createCredentials'
// ].forEach(function (name) {
//   exports[name] = function () {
//     throw new Error([
//       'sorry, ' + name + ' is not implemented yet',
//       'we accept pull requests',
//       'https://github.com/crypto-browserify/crypto-browserify'
//     ].join('\n'))
//   }
// })

var rf = require('randomfill')

exports.randomFill = rf.randomFill
exports.randomFillSync = rf.randomFillSync

exports.createCredentials = function () {
  throw new Error([
    'sorry, createCredentials is not implemented yet',
    'we accept pull requests',
    'https://github.com/crypto-browserify/crypto-browserify'
  ].join('\n'))
}

exports.constants = {
  'DH_CHECK_P_NOT_SAFE_PRIME': 2,
  'DH_CHECK_P_NOT_PRIME': 1,
  'DH_UNABLE_TO_CHECK_GENERATOR': 4,
  'DH_NOT_SUITABLE_GENERATOR': 8,
  'NPN_ENABLED': 1,
  'ALPN_ENABLED': 1,
  'RSA_PKCS1_PADDING': 1,
  'RSA_SSLV23_PADDING': 2,
  'RSA_NO_PADDING': 3,
  'RSA_PKCS1_OAEP_PADDING': 4,
  'RSA_X931_PADDING': 5,
  'RSA_PKCS1_PSS_PADDING': 6,
  'POINT_CONVERSION_COMPRESSED': 2,
  'POINT_CONVERSION_UNCOMPRESSED': 4,
  'POINT_CONVERSION_HYBRID': 6
}

},{"browserify-cipher":63,"browserify-sign":70,"browserify-sign/algos":67,"create-ecdh":80,"create-hash":82,"create-hmac":84,"diffie-hellman":96,"pbkdf2":173,"public-encrypt":180,"randombytes":187,"randomfill":188}],87:[function(require,module,exports){
/*!
 * Copyright (c) 2020 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

/**
 * General purpose key generation driver for Linked Data cryptographic key
 * pairs.
 *
 * @param {Map} [suites] - Optional map of supported suites, by suite id.
 */
class CryptoLD {
  constructor({suites} = {}) {
    this.suites = suites || new Map();
  }

  /**
   * Installs support for a key type (suite).
   *
   * @param {LDKeyPair} keyPairLib - Conforming key pair library for a suite.
   */
  use(keyPairLib) {
    this.suites.set(keyPairLib.suite, keyPairLib);
  }

  /**
   * Generates a public/private LDKeyPair.
   *
   * @param {object} options - Suite-specific key options.
   * @param {string} options.type - Key suite id (for example,
   *   'Ed25519VerificationKey2020').
   * @param {string} [options.controller] - Controller DID or URL for the
   *   generated key pair. If present, used to auto-initialize the key.id.
   *
   * @returns {Promise<LDKeyPair>}
   */
  async generate(options = {}) {
    const Suite = this._suiteForType(options);
    return Suite.generate(options);
  }

  /**
   * Imports a public/private key pair from serialized data.
   *
   * @param {object} serialized - Serialized key object.
   *
   * @throws {Error} - On missing or invalid serialized key data.
   *
   * @returns {Promise<LDKeyPair>}
   */
  async from(serialized = {}) {
    const Suite = this._suiteForType(serialized);

    if(serialized['@context']) {
      // presume this may be an untrusted (fetched, etc) key document
      return Suite.fromKeyDocument({document: serialized});
    }

    return Suite.from(serialized);
  }

  /**
   * Imports a key pair instance from a provided externally fetched key
   * document (fetched via a secure JSON-LD `documentLoader` or via
   * `cryptoLd.fromKeyId()`), optionally checking it for revocation and required
   * context.
   *
   * @param {object} options - Options hashmap.
   * @param {string} options.document - Externally fetched key document.
   * @param {boolean} [options.checkContext=true] - Whether to check that the
   *   fetched key document contains the context required by the key's crypto
   *   suite.
   * @param {boolean} [options.checkRevoked=true] - Whether to check the key
   *   object for the presence of the `revoked` timestamp.
   *
   * @returns {Promise<LDKeyPair>} Resolves with the resulting key pair
   *   instance.
   */
  async fromKeyDocument({
    document, checkContext = true, checkRevoked = true
  } = {}) {
    if(!document) {
      throw new TypeError('The "document" parameter is required.');
    }
    const Suite = this._suiteForType(document);

    return Suite.fromKeyDocument({document, checkContext, checkRevoked});
  }

  /**
   * Imports a key pair instance via the provided `documentLoader` function,
   * optionally checking it for revocation and required context.
   *
   * @param {object} options - Options hashmap.
   * @param {string} options.id - Key ID or URI.
   * @param {Function} options.documentLoader - JSON-LD Document Loader.
   * @param {boolean} [options.checkContext=true] - Whether to check that the
   *   fetched key document contains the context required by the key's crypto
   *   suite.
   * @param {boolean} [options.checkRevoked=true] - Whether to check the key
   *   object for the presence of the `revoked` timestamp.
   *
   * @returns {Promise<LDKeyPair>} Resolves with the appropriate key pair
   *   instance.
   */
  async fromKeyId({
    id, documentLoader, checkContext = true, checkRevoked = true
  } = {}) {
    if(!id) {
      throw new TypeError('The "id" parameter is required.');
    }
    if(!documentLoader) {
      throw new TypeError('The "documentLoader" parameter is required.');
    }
    let keyDocument;
    try {
      ({document: keyDocument} = await documentLoader(id));
      // the supplied documentLoader may not be properly implemented
      if(!keyDocument) {
        throw new Error(
          'The "documentLoader" function must return a "document" object.');
      }
    } catch(e) {
      const error = new Error('Error fetching document: ' + e.message);
      error.cause = e;
      throw error;
    }
    const fetchedType = keyDocument.type;
    if(!fetchedType) {
      throw new Error('Key suite type not found in fetched document.');
    }
    const keySuite = this.suites.get(fetchedType);
    if(!keySuite) {
      throw new Error(`Support for suite "${fetchedType}" is not installed.`);
    }

    return keySuite.fromKeyDocument({document: keyDocument, checkContext,
      checkRevoked});
  }

  /**
   * Tests if a given key type is currently installed.
   *
   * @param {string} [type] - Key suite id ('Ed25519VerificationKey2020').
   * @private
   */
  _installed({type}) {
    return this.suites.has(type);
  }

  /**
   * Returns the installed crypto suite class for a given document's type.
   *
   * @param {object} document - A serialized key document (or options document).
   * @param {string} document.type - Key suite id (for example,
   *   'Ed25519VerificationKey2020').
   *
   * @returns {object} LDKeyPair (crypto suite) class.
   */
  _suiteForType(document) {
    const type = document && document.type;

    if(!type) {
      throw new TypeError('Missing key type.');
    }
    if(!this._installed({type})) {
      throw new Error(`Support for key type "${type}" is not installed.`);
    }

    return this.suites.get(type);
  }
}

module.exports = {
  CryptoLD
};

},{}],88:[function(require,module,exports){
/*!
 * Copyright (c) 2018-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

/**
 * When adding support for a new suite type for `crypto-ld`, developers should
 * do the following:
 *
 * 1. Create their own npm package / github repo, such as `example-key-pair`.
 * 2. Subclass LDKeyPair.
 * 3. Override relevant methods (such as `export()` and `fingerprint()`).
 * 4. Add to the key type table in the `crypto-ld` README.md (that's this repo).
 */
class LDKeyPair {
  /**
   * Creates a public/private key pair instance. This is an abstract base class,
   * actual key material and suite-specific methods are handled in the subclass.
   *
   * To generate or import a key pair, use the `cryptoLd` instance.
   * @see CryptoLD.js
   *
   * @param {string} id - The key id, typically composed of controller
   *   URL and key fingerprint as hash fragment.
   * @param {string} controller - DID/URL of the person/entity
   *   controlling this key.
   * @param {string} [revoked] - Timestamp of when the key has been revoked,
   *   in RFC3339 format. If not present, the key itself is considered not
   *   revoked. (Note that this mechanism is slightly different than DID
   *   Document key revocation, where a DID controller can revoke a key from
   *   that DID by removing it from the DID Document.)
   */
  constructor({id, controller, revoked} = {}) {
    this.id = id;
    this.controller = controller;
    this.revoked = revoked;
    // this.type is set in subclass constructor
  }

  /**
   * Generates a new public/private key pair instance.
   * Note that this method is not typically called directly by client code,
   * but instead is used through a `cryptoLd` instance.
   *
   * @param {object} options - Suite-specific options for the KeyPair. For
   *   common options, see the `LDKeyPair.constructor()` docstring.
   *
   * @returns {Promise<LDKeyPair>} An LDKeyPair instance.
   */
  static async generate(/* options */) {
    throw new Error('Abstract method, must be implemented in subclass.');
  }

  /**
   * Imports a key pair instance from a provided externally fetched key
   * document (fetched via a secure JSON-LD `documentLoader` or via
   * `cryptoLd.fromKeyId()`), optionally checking it for revocation and required
   * context.
   *
   * @param {object} options - Options hashmap.
   * @param {string} options.document - Externally fetched key document.
   * @param {boolean} [options.checkContext=true] - Whether to check that the
   *   fetched key document contains the context required by the key's crypto
   *   suite.
   * @param {boolean} [options.checkRevoked=true] - Whether to check the key
   *   object for the presence of the `revoked` timestamp.
   *
   * @returns {Promise<LDKeyPair>} Resolves with the resulting key pair
   *   instance.
   */
  static async fromKeyDocument({
    document, checkContext = true, checkRevoked = true
  } = {}) {
    if(!document) {
      throw new TypeError('The "document" parameter is required.');
    }

    if(checkContext) {
      const fetchedDocContexts = [].concat(document['@context']);
      if(!fetchedDocContexts.includes(this.SUITE_CONTEXT)) {
        throw new Error('Key document does not contain required context "' +
          this.SUITE_CONTEXT + '".');
      }
    }
    if(checkRevoked && document.revoked) {
      throw new Error(`Key has been revoked since: "${document.revoked}".`);
    }
    return this.from(document);
  }

  /**
   * Generates a KeyPair from some options.
   * @param {object} options  - Will generate a key pair
   * in multiple different formats.
   * @example
   * > const options = {
   *    type: 'Ed25519VerificationKey2020'
   *   };
   * > const edKeyPair = await LDKeyPair.from(options);
   *
   * @returns {Promise<LDKeyPair>} A LDKeyPair.
   * @throws Unsupported Key Type.
   */
  static async from(/* options */) {
    throw new Error('Abstract method from() must be implemented in subclass.');
  }

  /**
   * Exports the serialized representation of the KeyPair
   * and other information that json-ld Signatures can use to form a proof.
   *
   * NOTE: Subclasses MUST override this method (and add the exporting of
   * their public and private key material).
   *
   * @param {object} [options={}] - Options hashmap.
   * @param {boolean} [options.publicKey] - Export public key material?
   * @param {boolean} [options.privateKey] - Export private key material?
   *
   * @returns {object} A public key object
   *   information used in verification methods by signatures.
   */
  export({publicKey = false, privateKey = false} = {}) {
    if(!publicKey && !privateKey) {
      throw new Error(
        'Export requires specifying either "publicKey" or "privateKey".');
    }
    const key = {
      id: this.id,
      type: this.type,
      controller: this.controller
    };
    if(this.revoked) {
      key.revoked = this.revoked;
    }

    return key;
  }

  /**
   * Returns the public key fingerprint, multibase+multicodec encoded. The
   * specific fingerprint method is determined by the key suite, and is often
   * either a hash of the public key material (such as with RSA), or the
   * full encoded public key (for key types with sufficiently short
   * representations, such as ed25519).
   * This is frequently used in initializing the key id, or generating some
   * types of cryptonym DIDs.
   *
   * @returns {string}
   */
  fingerprint() {
    throw new Error('Abstract method, must be implemented in subclass.');
  }

  /**
   * Verifies that a given key fingerprint matches the public key material
   * belonging to this key pair.
   *
   * @param {string} fingerprint - Public key fingerprint.
   *
   * @returns {{verified: boolean}}
   */
  verifyFingerprint(/* {fingerprint} */) {
    throw new Error('Abstract method, must be implemented in subclass.');
  }

  /* eslint-disable max-len */
  /**
   * Returns a signer object for use with
   * [jsonld-signatures]{@link https://github.com/digitalbazaar/jsonld-signatures}.
   * NOTE: Applies only to verifier type keys (like ed25519).
   *
   * @example
   * > const signer = keyPair.signer();
   * > signer
   * { sign: [AsyncFunction: sign] }
   * > signer.sign({data});
   *
   * @returns {{sign: Function}} A signer for json-ld usage.
   */
  /* eslint-enable */
  signer() {
    return {
      async sign({/* data */}) {
        throw new Error('Abstract method, must be implemented in subclass.');
      }
    };
  }

  /* eslint-disable max-len */
  /**
   * Returns a verifier object for use with
   * [jsonld-signatures]{@link https://github.com/digitalbazaar/jsonld-signatures}.
   * NOTE: Applies only to verifier type keys (like ed25519).
   *
   * @example
   * > const verifier = keyPair.verifier();
   * > verifier
   * { verify: [AsyncFunction: verify] }
   * > verifier.verify(key);
   *
   * @returns {{verify: Function}} Used to verify jsonld-signatures.
   */
  /* eslint-enable */
  verifier() {
    return {
      async verify({/* data, signature */}) {
        throw new Error('Abstract method, must be implemented in subclass.');
      }
    };
  }
}

// Implementers must override this in subclasses
LDKeyPair.SUITE_CONTEXT = 'INVALID LDKeyPair CONTEXT';

module.exports = {
  LDKeyPair
};

},{}],89:[function(require,module,exports){
/*
 * Copyright (c) 2018-2020 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {CryptoLD} = require('./CryptoLD');
const {LDKeyPair} = require('./LDKeyPair');

module.exports = {
  CryptoLD,
  LDKeyPair
};

},{"./CryptoLD":87,"./LDKeyPair":88}],90:[function(require,module,exports){
'use strict';

exports.utils = require('./des/utils');
exports.Cipher = require('./des/cipher');
exports.DES = require('./des/des');
exports.CBC = require('./des/cbc');
exports.EDE = require('./des/ede');

},{"./des/cbc":91,"./des/cipher":92,"./des/des":93,"./des/ede":94,"./des/utils":95}],91:[function(require,module,exports){
'use strict';

var assert = require('minimalistic-assert');
var inherits = require('inherits');

var proto = {};

function CBCState(iv) {
  assert.equal(iv.length, 8, 'Invalid IV length');

  this.iv = new Array(8);
  for (var i = 0; i < this.iv.length; i++)
    this.iv[i] = iv[i];
}

function instantiate(Base) {
  function CBC(options) {
    Base.call(this, options);
    this._cbcInit();
  }
  inherits(CBC, Base);

  var keys = Object.keys(proto);
  for (var i = 0; i < keys.length; i++) {
    var key = keys[i];
    CBC.prototype[key] = proto[key];
  }

  CBC.create = function create(options) {
    return new CBC(options);
  };

  return CBC;
}

exports.instantiate = instantiate;

proto._cbcInit = function _cbcInit() {
  var state = new CBCState(this.options.iv);
  this._cbcState = state;
};

proto._update = function _update(inp, inOff, out, outOff) {
  var state = this._cbcState;
  var superProto = this.constructor.super_.prototype;

  var iv = state.iv;
  if (this.type === 'encrypt') {
    for (var i = 0; i < this.blockSize; i++)
      iv[i] ^= inp[inOff + i];

    superProto._update.call(this, iv, 0, out, outOff);

    for (var i = 0; i < this.blockSize; i++)
      iv[i] = out[outOff + i];
  } else {
    superProto._update.call(this, inp, inOff, out, outOff);

    for (var i = 0; i < this.blockSize; i++)
      out[outOff + i] ^= iv[i];

    for (var i = 0; i < this.blockSize; i++)
      iv[i] = inp[inOff + i];
  }
};

},{"inherits":136,"minimalistic-assert":164}],92:[function(require,module,exports){
'use strict';

var assert = require('minimalistic-assert');

function Cipher(options) {
  this.options = options;

  this.type = this.options.type;
  this.blockSize = 8;
  this._init();

  this.buffer = new Array(this.blockSize);
  this.bufferOff = 0;
}
module.exports = Cipher;

Cipher.prototype._init = function _init() {
  // Might be overrided
};

Cipher.prototype.update = function update(data) {
  if (data.length === 0)
    return [];

  if (this.type === 'decrypt')
    return this._updateDecrypt(data);
  else
    return this._updateEncrypt(data);
};

Cipher.prototype._buffer = function _buffer(data, off) {
  // Append data to buffer
  var min = Math.min(this.buffer.length - this.bufferOff, data.length - off);
  for (var i = 0; i < min; i++)
    this.buffer[this.bufferOff + i] = data[off + i];
  this.bufferOff += min;

  // Shift next
  return min;
};

Cipher.prototype._flushBuffer = function _flushBuffer(out, off) {
  this._update(this.buffer, 0, out, off);
  this.bufferOff = 0;
  return this.blockSize;
};

Cipher.prototype._updateEncrypt = function _updateEncrypt(data) {
  var inputOff = 0;
  var outputOff = 0;

  var count = ((this.bufferOff + data.length) / this.blockSize) | 0;
  var out = new Array(count * this.blockSize);

  if (this.bufferOff !== 0) {
    inputOff += this._buffer(data, inputOff);

    if (this.bufferOff === this.buffer.length)
      outputOff += this._flushBuffer(out, outputOff);
  }

  // Write blocks
  var max = data.length - ((data.length - inputOff) % this.blockSize);
  for (; inputOff < max; inputOff += this.blockSize) {
    this._update(data, inputOff, out, outputOff);
    outputOff += this.blockSize;
  }

  // Queue rest
  for (; inputOff < data.length; inputOff++, this.bufferOff++)
    this.buffer[this.bufferOff] = data[inputOff];

  return out;
};

Cipher.prototype._updateDecrypt = function _updateDecrypt(data) {
  var inputOff = 0;
  var outputOff = 0;

  var count = Math.ceil((this.bufferOff + data.length) / this.blockSize) - 1;
  var out = new Array(count * this.blockSize);

  // TODO(indutny): optimize it, this is far from optimal
  for (; count > 0; count--) {
    inputOff += this._buffer(data, inputOff);
    outputOff += this._flushBuffer(out, outputOff);
  }

  // Buffer rest of the input
  inputOff += this._buffer(data, inputOff);

  return out;
};

Cipher.prototype.final = function final(buffer) {
  var first;
  if (buffer)
    first = this.update(buffer);

  var last;
  if (this.type === 'encrypt')
    last = this._finalEncrypt();
  else
    last = this._finalDecrypt();

  if (first)
    return first.concat(last);
  else
    return last;
};

Cipher.prototype._pad = function _pad(buffer, off) {
  if (off === 0)
    return false;

  while (off < buffer.length)
    buffer[off++] = 0;

  return true;
};

Cipher.prototype._finalEncrypt = function _finalEncrypt() {
  if (!this._pad(this.buffer, this.bufferOff))
    return [];

  var out = new Array(this.blockSize);
  this._update(this.buffer, 0, out, 0);
  return out;
};

Cipher.prototype._unpad = function _unpad(buffer) {
  return buffer;
};

Cipher.prototype._finalDecrypt = function _finalDecrypt() {
  assert.equal(this.bufferOff, this.blockSize, 'Not enough data to decrypt');
  var out = new Array(this.blockSize);
  this._flushBuffer(out, 0);

  return this._unpad(out);
};

},{"minimalistic-assert":164}],93:[function(require,module,exports){
'use strict';

var assert = require('minimalistic-assert');
var inherits = require('inherits');

var utils = require('./utils');
var Cipher = require('./cipher');

function DESState() {
  this.tmp = new Array(2);
  this.keys = null;
}

function DES(options) {
  Cipher.call(this, options);

  var state = new DESState();
  this._desState = state;

  this.deriveKeys(state, options.key);
}
inherits(DES, Cipher);
module.exports = DES;

DES.create = function create(options) {
  return new DES(options);
};

var shiftTable = [
  1, 1, 2, 2, 2, 2, 2, 2,
  1, 2, 2, 2, 2, 2, 2, 1
];

DES.prototype.deriveKeys = function deriveKeys(state, key) {
  state.keys = new Array(16 * 2);

  assert.equal(key.length, this.blockSize, 'Invalid key length');

  var kL = utils.readUInt32BE(key, 0);
  var kR = utils.readUInt32BE(key, 4);

  utils.pc1(kL, kR, state.tmp, 0);
  kL = state.tmp[0];
  kR = state.tmp[1];
  for (var i = 0; i < state.keys.length; i += 2) {
    var shift = shiftTable[i >>> 1];
    kL = utils.r28shl(kL, shift);
    kR = utils.r28shl(kR, shift);
    utils.pc2(kL, kR, state.keys, i);
  }
};

DES.prototype._update = function _update(inp, inOff, out, outOff) {
  var state = this._desState;

  var l = utils.readUInt32BE(inp, inOff);
  var r = utils.readUInt32BE(inp, inOff + 4);

  // Initial Permutation
  utils.ip(l, r, state.tmp, 0);
  l = state.tmp[0];
  r = state.tmp[1];

  if (this.type === 'encrypt')
    this._encrypt(state, l, r, state.tmp, 0);
  else
    this._decrypt(state, l, r, state.tmp, 0);

  l = state.tmp[0];
  r = state.tmp[1];

  utils.writeUInt32BE(out, l, outOff);
  utils.writeUInt32BE(out, r, outOff + 4);
};

DES.prototype._pad = function _pad(buffer, off) {
  var value = buffer.length - off;
  for (var i = off; i < buffer.length; i++)
    buffer[i] = value;

  return true;
};

DES.prototype._unpad = function _unpad(buffer) {
  var pad = buffer[buffer.length - 1];
  for (var i = buffer.length - pad; i < buffer.length; i++)
    assert.equal(buffer[i], pad);

  return buffer.slice(0, buffer.length - pad);
};

DES.prototype._encrypt = function _encrypt(state, lStart, rStart, out, off) {
  var l = lStart;
  var r = rStart;

  // Apply f() x16 times
  for (var i = 0; i < state.keys.length; i += 2) {
    var keyL = state.keys[i];
    var keyR = state.keys[i + 1];

    // f(r, k)
    utils.expand(r, state.tmp, 0);

    keyL ^= state.tmp[0];
    keyR ^= state.tmp[1];
    var s = utils.substitute(keyL, keyR);
    var f = utils.permute(s);

    var t = r;
    r = (l ^ f) >>> 0;
    l = t;
  }

  // Reverse Initial Permutation
  utils.rip(r, l, out, off);
};

DES.prototype._decrypt = function _decrypt(state, lStart, rStart, out, off) {
  var l = rStart;
  var r = lStart;

  // Apply f() x16 times
  for (var i = state.keys.length - 2; i >= 0; i -= 2) {
    var keyL = state.keys[i];
    var keyR = state.keys[i + 1];

    // f(r, k)
    utils.expand(l, state.tmp, 0);

    keyL ^= state.tmp[0];
    keyR ^= state.tmp[1];
    var s = utils.substitute(keyL, keyR);
    var f = utils.permute(s);

    var t = l;
    l = (r ^ f) >>> 0;
    r = t;
  }

  // Reverse Initial Permutation
  utils.rip(l, r, out, off);
};

},{"./cipher":92,"./utils":95,"inherits":136,"minimalistic-assert":164}],94:[function(require,module,exports){
'use strict';

var assert = require('minimalistic-assert');
var inherits = require('inherits');

var Cipher = require('./cipher');
var DES = require('./des');

function EDEState(type, key) {
  assert.equal(key.length, 24, 'Invalid key length');

  var k1 = key.slice(0, 8);
  var k2 = key.slice(8, 16);
  var k3 = key.slice(16, 24);

  if (type === 'encrypt') {
    this.ciphers = [
      DES.create({ type: 'encrypt', key: k1 }),
      DES.create({ type: 'decrypt', key: k2 }),
      DES.create({ type: 'encrypt', key: k3 })
    ];
  } else {
    this.ciphers = [
      DES.create({ type: 'decrypt', key: k3 }),
      DES.create({ type: 'encrypt', key: k2 }),
      DES.create({ type: 'decrypt', key: k1 })
    ];
  }
}

function EDE(options) {
  Cipher.call(this, options);

  var state = new EDEState(this.type, this.options.key);
  this._edeState = state;
}
inherits(EDE, Cipher);

module.exports = EDE;

EDE.create = function create(options) {
  return new EDE(options);
};

EDE.prototype._update = function _update(inp, inOff, out, outOff) {
  var state = this._edeState;

  state.ciphers[0]._update(inp, inOff, out, outOff);
  state.ciphers[1]._update(out, outOff, out, outOff);
  state.ciphers[2]._update(out, outOff, out, outOff);
};

EDE.prototype._pad = DES.prototype._pad;
EDE.prototype._unpad = DES.prototype._unpad;

},{"./cipher":92,"./des":93,"inherits":136,"minimalistic-assert":164}],95:[function(require,module,exports){
'use strict';

exports.readUInt32BE = function readUInt32BE(bytes, off) {
  var res =  (bytes[0 + off] << 24) |
             (bytes[1 + off] << 16) |
             (bytes[2 + off] << 8) |
             bytes[3 + off];
  return res >>> 0;
};

exports.writeUInt32BE = function writeUInt32BE(bytes, value, off) {
  bytes[0 + off] = value >>> 24;
  bytes[1 + off] = (value >>> 16) & 0xff;
  bytes[2 + off] = (value >>> 8) & 0xff;
  bytes[3 + off] = value & 0xff;
};

exports.ip = function ip(inL, inR, out, off) {
  var outL = 0;
  var outR = 0;

  for (var i = 6; i >= 0; i -= 2) {
    for (var j = 0; j <= 24; j += 8) {
      outL <<= 1;
      outL |= (inR >>> (j + i)) & 1;
    }
    for (var j = 0; j <= 24; j += 8) {
      outL <<= 1;
      outL |= (inL >>> (j + i)) & 1;
    }
  }

  for (var i = 6; i >= 0; i -= 2) {
    for (var j = 1; j <= 25; j += 8) {
      outR <<= 1;
      outR |= (inR >>> (j + i)) & 1;
    }
    for (var j = 1; j <= 25; j += 8) {
      outR <<= 1;
      outR |= (inL >>> (j + i)) & 1;
    }
  }

  out[off + 0] = outL >>> 0;
  out[off + 1] = outR >>> 0;
};

exports.rip = function rip(inL, inR, out, off) {
  var outL = 0;
  var outR = 0;

  for (var i = 0; i < 4; i++) {
    for (var j = 24; j >= 0; j -= 8) {
      outL <<= 1;
      outL |= (inR >>> (j + i)) & 1;
      outL <<= 1;
      outL |= (inL >>> (j + i)) & 1;
    }
  }
  for (var i = 4; i < 8; i++) {
    for (var j = 24; j >= 0; j -= 8) {
      outR <<= 1;
      outR |= (inR >>> (j + i)) & 1;
      outR <<= 1;
      outR |= (inL >>> (j + i)) & 1;
    }
  }

  out[off + 0] = outL >>> 0;
  out[off + 1] = outR >>> 0;
};

exports.pc1 = function pc1(inL, inR, out, off) {
  var outL = 0;
  var outR = 0;

  // 7, 15, 23, 31, 39, 47, 55, 63
  // 6, 14, 22, 30, 39, 47, 55, 63
  // 5, 13, 21, 29, 39, 47, 55, 63
  // 4, 12, 20, 28
  for (var i = 7; i >= 5; i--) {
    for (var j = 0; j <= 24; j += 8) {
      outL <<= 1;
      outL |= (inR >> (j + i)) & 1;
    }
    for (var j = 0; j <= 24; j += 8) {
      outL <<= 1;
      outL |= (inL >> (j + i)) & 1;
    }
  }
  for (var j = 0; j <= 24; j += 8) {
    outL <<= 1;
    outL |= (inR >> (j + i)) & 1;
  }

  // 1, 9, 17, 25, 33, 41, 49, 57
  // 2, 10, 18, 26, 34, 42, 50, 58
  // 3, 11, 19, 27, 35, 43, 51, 59
  // 36, 44, 52, 60
  for (var i = 1; i <= 3; i++) {
    for (var j = 0; j <= 24; j += 8) {
      outR <<= 1;
      outR |= (inR >> (j + i)) & 1;
    }
    for (var j = 0; j <= 24; j += 8) {
      outR <<= 1;
      outR |= (inL >> (j + i)) & 1;
    }
  }
  for (var j = 0; j <= 24; j += 8) {
    outR <<= 1;
    outR |= (inL >> (j + i)) & 1;
  }

  out[off + 0] = outL >>> 0;
  out[off + 1] = outR >>> 0;
};

exports.r28shl = function r28shl(num, shift) {
  return ((num << shift) & 0xfffffff) | (num >>> (28 - shift));
};

var pc2table = [
  // inL => outL
  14, 11, 17, 4, 27, 23, 25, 0,
  13, 22, 7, 18, 5, 9, 16, 24,
  2, 20, 12, 21, 1, 8, 15, 26,

  // inR => outR
  15, 4, 25, 19, 9, 1, 26, 16,
  5, 11, 23, 8, 12, 7, 17, 0,
  22, 3, 10, 14, 6, 20, 27, 24
];

exports.pc2 = function pc2(inL, inR, out, off) {
  var outL = 0;
  var outR = 0;

  var len = pc2table.length >>> 1;
  for (var i = 0; i < len; i++) {
    outL <<= 1;
    outL |= (inL >>> pc2table[i]) & 0x1;
  }
  for (var i = len; i < pc2table.length; i++) {
    outR <<= 1;
    outR |= (inR >>> pc2table[i]) & 0x1;
  }

  out[off + 0] = outL >>> 0;
  out[off + 1] = outR >>> 0;
};

exports.expand = function expand(r, out, off) {
  var outL = 0;
  var outR = 0;

  outL = ((r & 1) << 5) | (r >>> 27);
  for (var i = 23; i >= 15; i -= 4) {
    outL <<= 6;
    outL |= (r >>> i) & 0x3f;
  }
  for (var i = 11; i >= 3; i -= 4) {
    outR |= (r >>> i) & 0x3f;
    outR <<= 6;
  }
  outR |= ((r & 0x1f) << 1) | (r >>> 31);

  out[off + 0] = outL >>> 0;
  out[off + 1] = outR >>> 0;
};

var sTable = [
  14, 0, 4, 15, 13, 7, 1, 4, 2, 14, 15, 2, 11, 13, 8, 1,
  3, 10, 10, 6, 6, 12, 12, 11, 5, 9, 9, 5, 0, 3, 7, 8,
  4, 15, 1, 12, 14, 8, 8, 2, 13, 4, 6, 9, 2, 1, 11, 7,
  15, 5, 12, 11, 9, 3, 7, 14, 3, 10, 10, 0, 5, 6, 0, 13,

  15, 3, 1, 13, 8, 4, 14, 7, 6, 15, 11, 2, 3, 8, 4, 14,
  9, 12, 7, 0, 2, 1, 13, 10, 12, 6, 0, 9, 5, 11, 10, 5,
  0, 13, 14, 8, 7, 10, 11, 1, 10, 3, 4, 15, 13, 4, 1, 2,
  5, 11, 8, 6, 12, 7, 6, 12, 9, 0, 3, 5, 2, 14, 15, 9,

  10, 13, 0, 7, 9, 0, 14, 9, 6, 3, 3, 4, 15, 6, 5, 10,
  1, 2, 13, 8, 12, 5, 7, 14, 11, 12, 4, 11, 2, 15, 8, 1,
  13, 1, 6, 10, 4, 13, 9, 0, 8, 6, 15, 9, 3, 8, 0, 7,
  11, 4, 1, 15, 2, 14, 12, 3, 5, 11, 10, 5, 14, 2, 7, 12,

  7, 13, 13, 8, 14, 11, 3, 5, 0, 6, 6, 15, 9, 0, 10, 3,
  1, 4, 2, 7, 8, 2, 5, 12, 11, 1, 12, 10, 4, 14, 15, 9,
  10, 3, 6, 15, 9, 0, 0, 6, 12, 10, 11, 1, 7, 13, 13, 8,
  15, 9, 1, 4, 3, 5, 14, 11, 5, 12, 2, 7, 8, 2, 4, 14,

  2, 14, 12, 11, 4, 2, 1, 12, 7, 4, 10, 7, 11, 13, 6, 1,
  8, 5, 5, 0, 3, 15, 15, 10, 13, 3, 0, 9, 14, 8, 9, 6,
  4, 11, 2, 8, 1, 12, 11, 7, 10, 1, 13, 14, 7, 2, 8, 13,
  15, 6, 9, 15, 12, 0, 5, 9, 6, 10, 3, 4, 0, 5, 14, 3,

  12, 10, 1, 15, 10, 4, 15, 2, 9, 7, 2, 12, 6, 9, 8, 5,
  0, 6, 13, 1, 3, 13, 4, 14, 14, 0, 7, 11, 5, 3, 11, 8,
  9, 4, 14, 3, 15, 2, 5, 12, 2, 9, 8, 5, 12, 15, 3, 10,
  7, 11, 0, 14, 4, 1, 10, 7, 1, 6, 13, 0, 11, 8, 6, 13,

  4, 13, 11, 0, 2, 11, 14, 7, 15, 4, 0, 9, 8, 1, 13, 10,
  3, 14, 12, 3, 9, 5, 7, 12, 5, 2, 10, 15, 6, 8, 1, 6,
  1, 6, 4, 11, 11, 13, 13, 8, 12, 1, 3, 4, 7, 10, 14, 7,
  10, 9, 15, 5, 6, 0, 8, 15, 0, 14, 5, 2, 9, 3, 2, 12,

  13, 1, 2, 15, 8, 13, 4, 8, 6, 10, 15, 3, 11, 7, 1, 4,
  10, 12, 9, 5, 3, 6, 14, 11, 5, 0, 0, 14, 12, 9, 7, 2,
  7, 2, 11, 1, 4, 14, 1, 7, 9, 4, 12, 10, 14, 8, 2, 13,
  0, 15, 6, 12, 10, 9, 13, 0, 15, 3, 3, 5, 5, 6, 8, 11
];

exports.substitute = function substitute(inL, inR) {
  var out = 0;
  for (var i = 0; i < 4; i++) {
    var b = (inL >>> (18 - i * 6)) & 0x3f;
    var sb = sTable[i * 0x40 + b];

    out <<= 4;
    out |= sb;
  }
  for (var i = 0; i < 4; i++) {
    var b = (inR >>> (18 - i * 6)) & 0x3f;
    var sb = sTable[4 * 0x40 + i * 0x40 + b];

    out <<= 4;
    out |= sb;
  }
  return out >>> 0;
};

var permuteTable = [
  16, 25, 12, 11, 3, 20, 4, 15, 31, 17, 9, 6, 27, 14, 1, 22,
  30, 24, 8, 18, 0, 5, 29, 23, 13, 19, 2, 26, 10, 21, 28, 7
];

exports.permute = function permute(num) {
  var out = 0;
  for (var i = 0; i < permuteTable.length; i++) {
    out <<= 1;
    out |= (num >>> permuteTable[i]) & 0x1;
  }
  return out >>> 0;
};

exports.padSplit = function padSplit(num, size, group) {
  var str = num.toString(2);
  while (str.length < size)
    str = '0' + str;

  var out = [];
  for (var i = 0; i < size; i += group)
    out.push(str.slice(i, i + group));
  return out.join(' ');
};

},{}],96:[function(require,module,exports){
(function (Buffer){(function (){
var generatePrime = require('./lib/generatePrime')
var primes = require('./lib/primes.json')

var DH = require('./lib/dh')

function getDiffieHellman (mod) {
  var prime = new Buffer(primes[mod].prime, 'hex')
  var gen = new Buffer(primes[mod].gen, 'hex')

  return new DH(prime, gen)
}

var ENCODINGS = {
  'binary': true, 'hex': true, 'base64': true
}

function createDiffieHellman (prime, enc, generator, genc) {
  if (Buffer.isBuffer(enc) || ENCODINGS[enc] === undefined) {
    return createDiffieHellman(prime, 'binary', enc, generator)
  }

  enc = enc || 'binary'
  genc = genc || 'binary'
  generator = generator || new Buffer([2])

  if (!Buffer.isBuffer(generator)) {
    generator = new Buffer(generator, genc)
  }

  if (typeof prime === 'number') {
    return new DH(generatePrime(prime, generator), generator, true)
  }

  if (!Buffer.isBuffer(prime)) {
    prime = new Buffer(prime, enc)
  }

  return new DH(prime, generator, true)
}

exports.DiffieHellmanGroup = exports.createDiffieHellmanGroup = exports.getDiffieHellman = getDiffieHellman
exports.createDiffieHellman = exports.DiffieHellman = createDiffieHellman

}).call(this)}).call(this,require("buffer").Buffer)
},{"./lib/dh":97,"./lib/generatePrime":98,"./lib/primes.json":99,"buffer":74}],97:[function(require,module,exports){
(function (Buffer){(function (){
var BN = require('bn.js');
var MillerRabin = require('miller-rabin');
var millerRabin = new MillerRabin();
var TWENTYFOUR = new BN(24);
var ELEVEN = new BN(11);
var TEN = new BN(10);
var THREE = new BN(3);
var SEVEN = new BN(7);
var primes = require('./generatePrime');
var randomBytes = require('randombytes');
module.exports = DH;

function setPublicKey(pub, enc) {
  enc = enc || 'utf8';
  if (!Buffer.isBuffer(pub)) {
    pub = new Buffer(pub, enc);
  }
  this._pub = new BN(pub);
  return this;
}

function setPrivateKey(priv, enc) {
  enc = enc || 'utf8';
  if (!Buffer.isBuffer(priv)) {
    priv = new Buffer(priv, enc);
  }
  this._priv = new BN(priv);
  return this;
}

var primeCache = {};
function checkPrime(prime, generator) {
  var gen = generator.toString('hex');
  var hex = [gen, prime.toString(16)].join('_');
  if (hex in primeCache) {
    return primeCache[hex];
  }
  var error = 0;

  if (prime.isEven() ||
    !primes.simpleSieve ||
    !primes.fermatTest(prime) ||
    !millerRabin.test(prime)) {
    //not a prime so +1
    error += 1;

    if (gen === '02' || gen === '05') {
      // we'd be able to check the generator
      // it would fail so +8
      error += 8;
    } else {
      //we wouldn't be able to test the generator
      // so +4
      error += 4;
    }
    primeCache[hex] = error;
    return error;
  }
  if (!millerRabin.test(prime.shrn(1))) {
    //not a safe prime
    error += 2;
  }
  var rem;
  switch (gen) {
    case '02':
      if (prime.mod(TWENTYFOUR).cmp(ELEVEN)) {
        // unsuidable generator
        error += 8;
      }
      break;
    case '05':
      rem = prime.mod(TEN);
      if (rem.cmp(THREE) && rem.cmp(SEVEN)) {
        // prime mod 10 needs to equal 3 or 7
        error += 8;
      }
      break;
    default:
      error += 4;
  }
  primeCache[hex] = error;
  return error;
}

function DH(prime, generator, malleable) {
  this.setGenerator(generator);
  this.__prime = new BN(prime);
  this._prime = BN.mont(this.__prime);
  this._primeLen = prime.length;
  this._pub = undefined;
  this._priv = undefined;
  this._primeCode = undefined;
  if (malleable) {
    this.setPublicKey = setPublicKey;
    this.setPrivateKey = setPrivateKey;
  } else {
    this._primeCode = 8;
  }
}
Object.defineProperty(DH.prototype, 'verifyError', {
  enumerable: true,
  get: function () {
    if (typeof this._primeCode !== 'number') {
      this._primeCode = checkPrime(this.__prime, this.__gen);
    }
    return this._primeCode;
  }
});
DH.prototype.generateKeys = function () {
  if (!this._priv) {
    this._priv = new BN(randomBytes(this._primeLen));
  }
  this._pub = this._gen.toRed(this._prime).redPow(this._priv).fromRed();
  return this.getPublicKey();
};

DH.prototype.computeSecret = function (other) {
  other = new BN(other);
  other = other.toRed(this._prime);
  var secret = other.redPow(this._priv).fromRed();
  var out = new Buffer(secret.toArray());
  var prime = this.getPrime();
  if (out.length < prime.length) {
    var front = new Buffer(prime.length - out.length);
    front.fill(0);
    out = Buffer.concat([front, out]);
  }
  return out;
};

DH.prototype.getPublicKey = function getPublicKey(enc) {
  return formatReturnValue(this._pub, enc);
};

DH.prototype.getPrivateKey = function getPrivateKey(enc) {
  return formatReturnValue(this._priv, enc);
};

DH.prototype.getPrime = function (enc) {
  return formatReturnValue(this.__prime, enc);
};

DH.prototype.getGenerator = function (enc) {
  return formatReturnValue(this._gen, enc);
};

DH.prototype.setGenerator = function (gen, enc) {
  enc = enc || 'utf8';
  if (!Buffer.isBuffer(gen)) {
    gen = new Buffer(gen, enc);
  }
  this.__gen = gen;
  this._gen = new BN(gen);
  return this;
};

function formatReturnValue(bn, enc) {
  var buf = new Buffer(bn.toArray());
  if (!enc) {
    return buf;
  } else {
    return buf.toString(enc);
  }
}

}).call(this)}).call(this,require("buffer").Buffer)
},{"./generatePrime":98,"bn.js":100,"buffer":74,"miller-rabin":162,"randombytes":187}],98:[function(require,module,exports){
var randomBytes = require('randombytes');
module.exports = findPrime;
findPrime.simpleSieve = simpleSieve;
findPrime.fermatTest = fermatTest;
var BN = require('bn.js');
var TWENTYFOUR = new BN(24);
var MillerRabin = require('miller-rabin');
var millerRabin = new MillerRabin();
var ONE = new BN(1);
var TWO = new BN(2);
var FIVE = new BN(5);
var SIXTEEN = new BN(16);
var EIGHT = new BN(8);
var TEN = new BN(10);
var THREE = new BN(3);
var SEVEN = new BN(7);
var ELEVEN = new BN(11);
var FOUR = new BN(4);
var TWELVE = new BN(12);
var primes = null;

function _getPrimes() {
  if (primes !== null)
    return primes;

  var limit = 0x100000;
  var res = [];
  res[0] = 2;
  for (var i = 1, k = 3; k < limit; k += 2) {
    var sqrt = Math.ceil(Math.sqrt(k));
    for (var j = 0; j < i && res[j] <= sqrt; j++)
      if (k % res[j] === 0)
        break;

    if (i !== j && res[j] <= sqrt)
      continue;

    res[i++] = k;
  }
  primes = res;
  return res;
}

function simpleSieve(p) {
  var primes = _getPrimes();

  for (var i = 0; i < primes.length; i++)
    if (p.modn(primes[i]) === 0) {
      if (p.cmpn(primes[i]) === 0) {
        return true;
      } else {
        return false;
      }
    }

  return true;
}

function fermatTest(p) {
  var red = BN.mont(p);
  return TWO.toRed(red).redPow(p.subn(1)).fromRed().cmpn(1) === 0;
}

function findPrime(bits, gen) {
  if (bits < 16) {
    // this is what openssl does
    if (gen === 2 || gen === 5) {
      return new BN([0x8c, 0x7b]);
    } else {
      return new BN([0x8c, 0x27]);
    }
  }
  gen = new BN(gen);

  var num, n2;

  while (true) {
    num = new BN(randomBytes(Math.ceil(bits / 8)));
    while (num.bitLength() > bits) {
      num.ishrn(1);
    }
    if (num.isEven()) {
      num.iadd(ONE);
    }
    if (!num.testn(1)) {
      num.iadd(TWO);
    }
    if (!gen.cmp(TWO)) {
      while (num.mod(TWENTYFOUR).cmp(ELEVEN)) {
        num.iadd(FOUR);
      }
    } else if (!gen.cmp(FIVE)) {
      while (num.mod(TEN).cmp(THREE)) {
        num.iadd(FOUR);
      }
    }
    n2 = num.shrn(1);
    if (simpleSieve(n2) && simpleSieve(num) &&
      fermatTest(n2) && fermatTest(num) &&
      millerRabin.test(n2) && millerRabin.test(num)) {
      return num;
    }
  }

}

},{"bn.js":100,"miller-rabin":162,"randombytes":187}],99:[function(require,module,exports){
module.exports={
    "modp1": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a63a3620ffffffffffffffff"
    },
    "modp2": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece65381ffffffffffffffff"
    },
    "modp5": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf0598da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb9ed529077096966d670c354e4abc9804f1746c08ca237327ffffffffffffffff"
    },
    "modp14": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf0598da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb9ed529077096966d670c354e4abc9804f1746c08ca18217c32905e462e36ce3be39e772c180e86039b2783a2ec07a28fb5c55df06f4c52c9de2bcbf6955817183995497cea956ae515d2261898fa051015728e5a8aacaa68ffffffffffffffff"
    },
    "modp15": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf0598da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb9ed529077096966d670c354e4abc9804f1746c08ca18217c32905e462e36ce3be39e772c180e86039b2783a2ec07a28fb5c55df06f4c52c9de2bcbf6955817183995497cea956ae515d2261898fa051015728e5a8aaac42dad33170d04507a33a85521abdf1cba64ecfb850458dbef0a8aea71575d060c7db3970f85a6e1e4c7abf5ae8cdb0933d71e8c94e04a25619dcee3d2261ad2ee6bf12ffa06d98a0864d87602733ec86a64521f2b18177b200cbbe117577a615d6c770988c0bad946e208e24fa074e5ab3143db5bfce0fd108e4b82d120a93ad2caffffffffffffffff"
    },
    "modp16": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf0598da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb9ed529077096966d670c354e4abc9804f1746c08ca18217c32905e462e36ce3be39e772c180e86039b2783a2ec07a28fb5c55df06f4c52c9de2bcbf6955817183995497cea956ae515d2261898fa051015728e5a8aaac42dad33170d04507a33a85521abdf1cba64ecfb850458dbef0a8aea71575d060c7db3970f85a6e1e4c7abf5ae8cdb0933d71e8c94e04a25619dcee3d2261ad2ee6bf12ffa06d98a0864d87602733ec86a64521f2b18177b200cbbe117577a615d6c770988c0bad946e208e24fa074e5ab3143db5bfce0fd108e4b82d120a92108011a723c12a787e6d788719a10bdba5b2699c327186af4e23c1a946834b6150bda2583e9ca2ad44ce8dbbbc2db04de8ef92e8efc141fbecaa6287c59474e6bc05d99b2964fa090c3a2233ba186515be7ed1f612970cee2d7afb81bdd762170481cd0069127d5b05aa993b4ea988d8fddc186ffb7dc90a6c08f4df435c934063199ffffffffffffffff"
    },
    "modp17": {
        "gen": "02",
        "prime": "ffffffffffffffffc90fdaa22168c234c4c6628b80dc1cd129024e088a67cc74020bbea63b139b22514a08798e3404ddef9519b3cd3a431b302b0a6df25f14374fe1356d6d51c245e485b576625e7ec6f44c42e9a637ed6b0bff5cb6f406b7edee386bfb5a899fa5ae9f24117c4b1fe649286651ece45b3dc2007cb8a163bf0598da48361c55d39a69163fa8fd24cf5f83655d23dca3ad961c62f356208552bb9ed529077096966d670c354e4abc9804f1746c08ca18217c32905e462e36ce3be39e772c180e86039b2783a2ec07a28fb5c55df06f4c52c9de2bcbf6955817183995497cea956ae515d2261898fa051015728e5a8aaac42dad33170d04507a33a85521abdf1cba64ecfb850458dbef0a8aea71575d060c7db3970f85a6e1e4c7abf5ae8cdb0933d71e8c94e04a25619dcee3d2261ad2ee6bf12ffa06d98a0864d87602733ec86a64521f2b18177b200cbbe117577a615d6c770988c0bad946e208e24fa074e5ab3143db5bfce0fd108e4b82d120a92108011a723c12a787e6d788719a10bdba5b2699c327186af4e23c1a946834b6150bda2583e9ca2ad44ce8dbbbc2db04de8ef92e8efc141fbecaa6287c59474e6bc05d99b2964fa090c3a2233ba186515be7ed1f612970cee2d7afb81bdd762170481cd0069127d5b05aa993b4ea988d8fddc186ffb7dc90a6c08f4df435c93402849236c3fab4d27c7026c1d4dcb2602646dec9751e763dba37bdf8ff9406ad9e530ee5db382f413001aeb06a53ed9027d831179727b0865a8918da3edbebcf9b14ed44ce6cbaced4bb1bdb7f1447e6cc254b332051512bd7af426fb8f401378cd2bf5983ca01c64b92ecf032ea15d1721d03f482d7ce6e74fef6d55e702f46980c82b5a84031900b1c9e59e7c97fbec7e8f323a97a7e36cc88be0f1d45b7ff585ac54bd407b22b4154aacc8f6d7ebf48e1d814cc5ed20f8037e0a79715eef29be32806a1d58bb7c5da76f550aa3d8a1fbff0eb19ccb1a313d55cda56c9ec2ef29632387fe8d76e3c0468043e8f663f4860ee12bf2d5b0b7474d6e694f91e6dcc4024ffffffffffffffff"
    },
    "modp18": {
        "gen": "02",
        "prime": "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"
    }
}
},{}],100:[function(require,module,exports){
arguments[4][41][0].apply(exports,arguments)
},{"buffer":45,"dup":41}],101:[function(require,module,exports){
'use strict';

var elliptic = exports;

elliptic.version = require('../package.json').version;
elliptic.utils = require('./elliptic/utils');
elliptic.rand = require('brorand');
elliptic.curve = require('./elliptic/curve');
elliptic.curves = require('./elliptic/curves');

// Protocols
elliptic.ec = require('./elliptic/ec');
elliptic.eddsa = require('./elliptic/eddsa');

},{"../package.json":117,"./elliptic/curve":104,"./elliptic/curves":107,"./elliptic/ec":108,"./elliptic/eddsa":111,"./elliptic/utils":115,"brorand":44}],102:[function(require,module,exports){
'use strict';

var BN = require('bn.js');
var utils = require('../utils');
var getNAF = utils.getNAF;
var getJSF = utils.getJSF;
var assert = utils.assert;

function BaseCurve(type, conf) {
  this.type = type;
  this.p = new BN(conf.p, 16);

  // Use Montgomery, when there is no fast reduction for the prime
  this.red = conf.prime ? BN.red(conf.prime) : BN.mont(this.p);

  // Useful for many curves
  this.zero = new BN(0).toRed(this.red);
  this.one = new BN(1).toRed(this.red);
  this.two = new BN(2).toRed(this.red);

  // Curve configuration, optional
  this.n = conf.n && new BN(conf.n, 16);
  this.g = conf.g && this.pointFromJSON(conf.g, conf.gRed);

  // Temporary arrays
  this._wnafT1 = new Array(4);
  this._wnafT2 = new Array(4);
  this._wnafT3 = new Array(4);
  this._wnafT4 = new Array(4);

  this._bitLength = this.n ? this.n.bitLength() : 0;

  // Generalized Greg Maxwell's trick
  var adjustCount = this.n && this.p.div(this.n);
  if (!adjustCount || adjustCount.cmpn(100) > 0) {
    this.redN = null;
  } else {
    this._maxwellTrick = true;
    this.redN = this.n.toRed(this.red);
  }
}
module.exports = BaseCurve;

BaseCurve.prototype.point = function point() {
  throw new Error('Not implemented');
};

BaseCurve.prototype.validate = function validate() {
  throw new Error('Not implemented');
};

BaseCurve.prototype._fixedNafMul = function _fixedNafMul(p, k) {
  assert(p.precomputed);
  var doubles = p._getDoubles();

  var naf = getNAF(k, 1, this._bitLength);
  var I = (1 << (doubles.step + 1)) - (doubles.step % 2 === 0 ? 2 : 1);
  I /= 3;

  // Translate into more windowed form
  var repr = [];
  var j;
  var nafW;
  for (j = 0; j < naf.length; j += doubles.step) {
    nafW = 0;
    for (var l = j + doubles.step - 1; l >= j; l--)
      nafW = (nafW << 1) + naf[l];
    repr.push(nafW);
  }

  var a = this.jpoint(null, null, null);
  var b = this.jpoint(null, null, null);
  for (var i = I; i > 0; i--) {
    for (j = 0; j < repr.length; j++) {
      nafW = repr[j];
      if (nafW === i)
        b = b.mixedAdd(doubles.points[j]);
      else if (nafW === -i)
        b = b.mixedAdd(doubles.points[j].neg());
    }
    a = a.add(b);
  }
  return a.toP();
};

BaseCurve.prototype._wnafMul = function _wnafMul(p, k) {
  var w = 4;

  // Precompute window
  var nafPoints = p._getNAFPoints(w);
  w = nafPoints.wnd;
  var wnd = nafPoints.points;

  // Get NAF form
  var naf = getNAF(k, w, this._bitLength);

  // Add `this`*(N+1) for every w-NAF index
  var acc = this.jpoint(null, null, null);
  for (var i = naf.length - 1; i >= 0; i--) {
    // Count zeroes
    for (var l = 0; i >= 0 && naf[i] === 0; i--)
      l++;
    if (i >= 0)
      l++;
    acc = acc.dblp(l);

    if (i < 0)
      break;
    var z = naf[i];
    assert(z !== 0);
    if (p.type === 'affine') {
      // J +- P
      if (z > 0)
        acc = acc.mixedAdd(wnd[(z - 1) >> 1]);
      else
        acc = acc.mixedAdd(wnd[(-z - 1) >> 1].neg());
    } else {
      // J +- J
      if (z > 0)
        acc = acc.add(wnd[(z - 1) >> 1]);
      else
        acc = acc.add(wnd[(-z - 1) >> 1].neg());
    }
  }
  return p.type === 'affine' ? acc.toP() : acc;
};

BaseCurve.prototype._wnafMulAdd = function _wnafMulAdd(defW,
  points,
  coeffs,
  len,
  jacobianResult) {
  var wndWidth = this._wnafT1;
  var wnd = this._wnafT2;
  var naf = this._wnafT3;

  // Fill all arrays
  var max = 0;
  var i;
  var j;
  var p;
  for (i = 0; i < len; i++) {
    p = points[i];
    var nafPoints = p._getNAFPoints(defW);
    wndWidth[i] = nafPoints.wnd;
    wnd[i] = nafPoints.points;
  }

  // Comb small window NAFs
  for (i = len - 1; i >= 1; i -= 2) {
    var a = i - 1;
    var b = i;
    if (wndWidth[a] !== 1 || wndWidth[b] !== 1) {
      naf[a] = getNAF(coeffs[a], wndWidth[a], this._bitLength);
      naf[b] = getNAF(coeffs[b], wndWidth[b], this._bitLength);
      max = Math.max(naf[a].length, max);
      max = Math.max(naf[b].length, max);
      continue;
    }

    var comb = [
      points[a], /* 1 */
      null, /* 3 */
      null, /* 5 */
      points[b], /* 7 */
    ];

    // Try to avoid Projective points, if possible
    if (points[a].y.cmp(points[b].y) === 0) {
      comb[1] = points[a].add(points[b]);
      comb[2] = points[a].toJ().mixedAdd(points[b].neg());
    } else if (points[a].y.cmp(points[b].y.redNeg()) === 0) {
      comb[1] = points[a].toJ().mixedAdd(points[b]);
      comb[2] = points[a].add(points[b].neg());
    } else {
      comb[1] = points[a].toJ().mixedAdd(points[b]);
      comb[2] = points[a].toJ().mixedAdd(points[b].neg());
    }

    var index = [
      -3, /* -1 -1 */
      -1, /* -1 0 */
      -5, /* -1 1 */
      -7, /* 0 -1 */
      0, /* 0 0 */
      7, /* 0 1 */
      5, /* 1 -1 */
      1, /* 1 0 */
      3,  /* 1 1 */
    ];

    var jsf = getJSF(coeffs[a], coeffs[b]);
    max = Math.max(jsf[0].length, max);
    naf[a] = new Array(max);
    naf[b] = new Array(max);
    for (j = 0; j < max; j++) {
      var ja = jsf[0][j] | 0;
      var jb = jsf[1][j] | 0;

      naf[a][j] = index[(ja + 1) * 3 + (jb + 1)];
      naf[b][j] = 0;
      wnd[a] = comb;
    }
  }

  var acc = this.jpoint(null, null, null);
  var tmp = this._wnafT4;
  for (i = max; i >= 0; i--) {
    var k = 0;

    while (i >= 0) {
      var zero = true;
      for (j = 0; j < len; j++) {
        tmp[j] = naf[j][i] | 0;
        if (tmp[j] !== 0)
          zero = false;
      }
      if (!zero)
        break;
      k++;
      i--;
    }
    if (i >= 0)
      k++;
    acc = acc.dblp(k);
    if (i < 0)
      break;

    for (j = 0; j < len; j++) {
      var z = tmp[j];
      p;
      if (z === 0)
        continue;
      else if (z > 0)
        p = wnd[j][(z - 1) >> 1];
      else if (z < 0)
        p = wnd[j][(-z - 1) >> 1].neg();

      if (p.type === 'affine')
        acc = acc.mixedAdd(p);
      else
        acc = acc.add(p);
    }
  }
  // Zeroify references
  for (i = 0; i < len; i++)
    wnd[i] = null;

  if (jacobianResult)
    return acc;
  else
    return acc.toP();
};

function BasePoint(curve, type) {
  this.curve = curve;
  this.type = type;
  this.precomputed = null;
}
BaseCurve.BasePoint = BasePoint;

BasePoint.prototype.eq = function eq(/*other*/) {
  throw new Error('Not implemented');
};

BasePoint.prototype.validate = function validate() {
  return this.curve.validate(this);
};

BaseCurve.prototype.decodePoint = function decodePoint(bytes, enc) {
  bytes = utils.toArray(bytes, enc);

  var len = this.p.byteLength();

  // uncompressed, hybrid-odd, hybrid-even
  if ((bytes[0] === 0x04 || bytes[0] === 0x06 || bytes[0] === 0x07) &&
      bytes.length - 1 === 2 * len) {
    if (bytes[0] === 0x06)
      assert(bytes[bytes.length - 1] % 2 === 0);
    else if (bytes[0] === 0x07)
      assert(bytes[bytes.length - 1] % 2 === 1);

    var res =  this.point(bytes.slice(1, 1 + len),
      bytes.slice(1 + len, 1 + 2 * len));

    return res;
  } else if ((bytes[0] === 0x02 || bytes[0] === 0x03) &&
              bytes.length - 1 === len) {
    return this.pointFromX(bytes.slice(1, 1 + len), bytes[0] === 0x03);
  }
  throw new Error('Unknown point format');
};

BasePoint.prototype.encodeCompressed = function encodeCompressed(enc) {
  return this.encode(enc, true);
};

BasePoint.prototype._encode = function _encode(compact) {
  var len = this.curve.p.byteLength();
  var x = this.getX().toArray('be', len);

  if (compact)
    return [ this.getY().isEven() ? 0x02 : 0x03 ].concat(x);

  return [ 0x04 ].concat(x, this.getY().toArray('be', len));
};

BasePoint.prototype.encode = function encode(enc, compact) {
  return utils.encode(this._encode(compact), enc);
};

BasePoint.prototype.precompute = function precompute(power) {
  if (this.precomputed)
    return this;

  var precomputed = {
    doubles: null,
    naf: null,
    beta: null,
  };
  precomputed.naf = this._getNAFPoints(8);
  precomputed.doubles = this._getDoubles(4, power);
  precomputed.beta = this._getBeta();
  this.precomputed = precomputed;

  return this;
};

BasePoint.prototype._hasDoubles = function _hasDoubles(k) {
  if (!this.precomputed)
    return false;

  var doubles = this.precomputed.doubles;
  if (!doubles)
    return false;

  return doubles.points.length >= Math.ceil((k.bitLength() + 1) / doubles.step);
};

BasePoint.prototype._getDoubles = function _getDoubles(step, power) {
  if (this.precomputed && this.precomputed.doubles)
    return this.precomputed.doubles;

  var doubles = [ this ];
  var acc = this;
  for (var i = 0; i < power; i += step) {
    for (var j = 0; j < step; j++)
      acc = acc.dbl();
    doubles.push(acc);
  }
  return {
    step: step,
    points: doubles,
  };
};

BasePoint.prototype._getNAFPoints = function _getNAFPoints(wnd) {
  if (this.precomputed && this.precomputed.naf)
    return this.precomputed.naf;

  var res = [ this ];
  var max = (1 << wnd) - 1;
  var dbl = max === 1 ? null : this.dbl();
  for (var i = 1; i < max; i++)
    res[i] = res[i - 1].add(dbl);
  return {
    wnd: wnd,
    points: res,
  };
};

BasePoint.prototype._getBeta = function _getBeta() {
  return null;
};

BasePoint.prototype.dblp = function dblp(k) {
  var r = this;
  for (var i = 0; i < k; i++)
    r = r.dbl();
  return r;
};

},{"../utils":115,"bn.js":116}],103:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var BN = require('bn.js');
var inherits = require('inherits');
var Base = require('./base');

var assert = utils.assert;

function EdwardsCurve(conf) {
  // NOTE: Important as we are creating point in Base.call()
  this.twisted = (conf.a | 0) !== 1;
  this.mOneA = this.twisted && (conf.a | 0) === -1;
  this.extended = this.mOneA;

  Base.call(this, 'edwards', conf);

  this.a = new BN(conf.a, 16).umod(this.red.m);
  this.a = this.a.toRed(this.red);
  this.c = new BN(conf.c, 16).toRed(this.red);
  this.c2 = this.c.redSqr();
  this.d = new BN(conf.d, 16).toRed(this.red);
  this.dd = this.d.redAdd(this.d);

  assert(!this.twisted || this.c.fromRed().cmpn(1) === 0);
  this.oneC = (conf.c | 0) === 1;
}
inherits(EdwardsCurve, Base);
module.exports = EdwardsCurve;

EdwardsCurve.prototype._mulA = function _mulA(num) {
  if (this.mOneA)
    return num.redNeg();
  else
    return this.a.redMul(num);
};

EdwardsCurve.prototype._mulC = function _mulC(num) {
  if (this.oneC)
    return num;
  else
    return this.c.redMul(num);
};

// Just for compatibility with Short curve
EdwardsCurve.prototype.jpoint = function jpoint(x, y, z, t) {
  return this.point(x, y, z, t);
};

EdwardsCurve.prototype.pointFromX = function pointFromX(x, odd) {
  x = new BN(x, 16);
  if (!x.red)
    x = x.toRed(this.red);

  var x2 = x.redSqr();
  var rhs = this.c2.redSub(this.a.redMul(x2));
  var lhs = this.one.redSub(this.c2.redMul(this.d).redMul(x2));

  var y2 = rhs.redMul(lhs.redInvm());
  var y = y2.redSqrt();
  if (y.redSqr().redSub(y2).cmp(this.zero) !== 0)
    throw new Error('invalid point');

  var isOdd = y.fromRed().isOdd();
  if (odd && !isOdd || !odd && isOdd)
    y = y.redNeg();

  return this.point(x, y);
};

EdwardsCurve.prototype.pointFromY = function pointFromY(y, odd) {
  y = new BN(y, 16);
  if (!y.red)
    y = y.toRed(this.red);

  // x^2 = (y^2 - c^2) / (c^2 d y^2 - a)
  var y2 = y.redSqr();
  var lhs = y2.redSub(this.c2);
  var rhs = y2.redMul(this.d).redMul(this.c2).redSub(this.a);
  var x2 = lhs.redMul(rhs.redInvm());

  if (x2.cmp(this.zero) === 0) {
    if (odd)
      throw new Error('invalid point');
    else
      return this.point(this.zero, y);
  }

  var x = x2.redSqrt();
  if (x.redSqr().redSub(x2).cmp(this.zero) !== 0)
    throw new Error('invalid point');

  if (x.fromRed().isOdd() !== odd)
    x = x.redNeg();

  return this.point(x, y);
};

EdwardsCurve.prototype.validate = function validate(point) {
  if (point.isInfinity())
    return true;

  // Curve: A * X^2 + Y^2 = C^2 * (1 + D * X^2 * Y^2)
  point.normalize();

  var x2 = point.x.redSqr();
  var y2 = point.y.redSqr();
  var lhs = x2.redMul(this.a).redAdd(y2);
  var rhs = this.c2.redMul(this.one.redAdd(this.d.redMul(x2).redMul(y2)));

  return lhs.cmp(rhs) === 0;
};

function Point(curve, x, y, z, t) {
  Base.BasePoint.call(this, curve, 'projective');
  if (x === null && y === null && z === null) {
    this.x = this.curve.zero;
    this.y = this.curve.one;
    this.z = this.curve.one;
    this.t = this.curve.zero;
    this.zOne = true;
  } else {
    this.x = new BN(x, 16);
    this.y = new BN(y, 16);
    this.z = z ? new BN(z, 16) : this.curve.one;
    this.t = t && new BN(t, 16);
    if (!this.x.red)
      this.x = this.x.toRed(this.curve.red);
    if (!this.y.red)
      this.y = this.y.toRed(this.curve.red);
    if (!this.z.red)
      this.z = this.z.toRed(this.curve.red);
    if (this.t && !this.t.red)
      this.t = this.t.toRed(this.curve.red);
    this.zOne = this.z === this.curve.one;

    // Use extended coordinates
    if (this.curve.extended && !this.t) {
      this.t = this.x.redMul(this.y);
      if (!this.zOne)
        this.t = this.t.redMul(this.z.redInvm());
    }
  }
}
inherits(Point, Base.BasePoint);

EdwardsCurve.prototype.pointFromJSON = function pointFromJSON(obj) {
  return Point.fromJSON(this, obj);
};

EdwardsCurve.prototype.point = function point(x, y, z, t) {
  return new Point(this, x, y, z, t);
};

Point.fromJSON = function fromJSON(curve, obj) {
  return new Point(curve, obj[0], obj[1], obj[2]);
};

Point.prototype.inspect = function inspect() {
  if (this.isInfinity())
    return '<EC Point Infinity>';
  return '<EC Point x: ' + this.x.fromRed().toString(16, 2) +
      ' y: ' + this.y.fromRed().toString(16, 2) +
      ' z: ' + this.z.fromRed().toString(16, 2) + '>';
};

Point.prototype.isInfinity = function isInfinity() {
  // XXX This code assumes that zero is always zero in red
  return this.x.cmpn(0) === 0 &&
    (this.y.cmp(this.z) === 0 ||
    (this.zOne && this.y.cmp(this.curve.c) === 0));
};

Point.prototype._extDbl = function _extDbl() {
  // hyperelliptic.org/EFD/g1p/auto-twisted-extended-1.html
  //     #doubling-dbl-2008-hwcd
  // 4M + 4S

  // A = X1^2
  var a = this.x.redSqr();
  // B = Y1^2
  var b = this.y.redSqr();
  // C = 2 * Z1^2
  var c = this.z.redSqr();
  c = c.redIAdd(c);
  // D = a * A
  var d = this.curve._mulA(a);
  // E = (X1 + Y1)^2 - A - B
  var e = this.x.redAdd(this.y).redSqr().redISub(a).redISub(b);
  // G = D + B
  var g = d.redAdd(b);
  // F = G - C
  var f = g.redSub(c);
  // H = D - B
  var h = d.redSub(b);
  // X3 = E * F
  var nx = e.redMul(f);
  // Y3 = G * H
  var ny = g.redMul(h);
  // T3 = E * H
  var nt = e.redMul(h);
  // Z3 = F * G
  var nz = f.redMul(g);
  return this.curve.point(nx, ny, nz, nt);
};

Point.prototype._projDbl = function _projDbl() {
  // hyperelliptic.org/EFD/g1p/auto-twisted-projective.html
  //     #doubling-dbl-2008-bbjlp
  //     #doubling-dbl-2007-bl
  // and others
  // Generally 3M + 4S or 2M + 4S

  // B = (X1 + Y1)^2
  var b = this.x.redAdd(this.y).redSqr();
  // C = X1^2
  var c = this.x.redSqr();
  // D = Y1^2
  var d = this.y.redSqr();

  var nx;
  var ny;
  var nz;
  var e;
  var h;
  var j;
  if (this.curve.twisted) {
    // E = a * C
    e = this.curve._mulA(c);
    // F = E + D
    var f = e.redAdd(d);
    if (this.zOne) {
      // X3 = (B - C - D) * (F - 2)
      nx = b.redSub(c).redSub(d).redMul(f.redSub(this.curve.two));
      // Y3 = F * (E - D)
      ny = f.redMul(e.redSub(d));
      // Z3 = F^2 - 2 * F
      nz = f.redSqr().redSub(f).redSub(f);
    } else {
      // H = Z1^2
      h = this.z.redSqr();
      // J = F - 2 * H
      j = f.redSub(h).redISub(h);
      // X3 = (B-C-D)*J
      nx = b.redSub(c).redISub(d).redMul(j);
      // Y3 = F * (E - D)
      ny = f.redMul(e.redSub(d));
      // Z3 = F * J
      nz = f.redMul(j);
    }
  } else {
    // E = C + D
    e = c.redAdd(d);
    // H = (c * Z1)^2
    h = this.curve._mulC(this.z).redSqr();
    // J = E - 2 * H
    j = e.redSub(h).redSub(h);
    // X3 = c * (B - E) * J
    nx = this.curve._mulC(b.redISub(e)).redMul(j);
    // Y3 = c * E * (C - D)
    ny = this.curve._mulC(e).redMul(c.redISub(d));
    // Z3 = E * J
    nz = e.redMul(j);
  }
  return this.curve.point(nx, ny, nz);
};

Point.prototype.dbl = function dbl() {
  if (this.isInfinity())
    return this;

  // Double in extended coordinates
  if (this.curve.extended)
    return this._extDbl();
  else
    return this._projDbl();
};

Point.prototype._extAdd = function _extAdd(p) {
  // hyperelliptic.org/EFD/g1p/auto-twisted-extended-1.html
  //     #addition-add-2008-hwcd-3
  // 8M

  // A = (Y1 - X1) * (Y2 - X2)
  var a = this.y.redSub(this.x).redMul(p.y.redSub(p.x));
  // B = (Y1 + X1) * (Y2 + X2)
  var b = this.y.redAdd(this.x).redMul(p.y.redAdd(p.x));
  // C = T1 * k * T2
  var c = this.t.redMul(this.curve.dd).redMul(p.t);
  // D = Z1 * 2 * Z2
  var d = this.z.redMul(p.z.redAdd(p.z));
  // E = B - A
  var e = b.redSub(a);
  // F = D - C
  var f = d.redSub(c);
  // G = D + C
  var g = d.redAdd(c);
  // H = B + A
  var h = b.redAdd(a);
  // X3 = E * F
  var nx = e.redMul(f);
  // Y3 = G * H
  var ny = g.redMul(h);
  // T3 = E * H
  var nt = e.redMul(h);
  // Z3 = F * G
  var nz = f.redMul(g);
  return this.curve.point(nx, ny, nz, nt);
};

Point.prototype._projAdd = function _projAdd(p) {
  // hyperelliptic.org/EFD/g1p/auto-twisted-projective.html
  //     #addition-add-2008-bbjlp
  //     #addition-add-2007-bl
  // 10M + 1S

  // A = Z1 * Z2
  var a = this.z.redMul(p.z);
  // B = A^2
  var b = a.redSqr();
  // C = X1 * X2
  var c = this.x.redMul(p.x);
  // D = Y1 * Y2
  var d = this.y.redMul(p.y);
  // E = d * C * D
  var e = this.curve.d.redMul(c).redMul(d);
  // F = B - E
  var f = b.redSub(e);
  // G = B + E
  var g = b.redAdd(e);
  // X3 = A * F * ((X1 + Y1) * (X2 + Y2) - C - D)
  var tmp = this.x.redAdd(this.y).redMul(p.x.redAdd(p.y)).redISub(c).redISub(d);
  var nx = a.redMul(f).redMul(tmp);
  var ny;
  var nz;
  if (this.curve.twisted) {
    // Y3 = A * G * (D - a * C)
    ny = a.redMul(g).redMul(d.redSub(this.curve._mulA(c)));
    // Z3 = F * G
    nz = f.redMul(g);
  } else {
    // Y3 = A * G * (D - C)
    ny = a.redMul(g).redMul(d.redSub(c));
    // Z3 = c * F * G
    nz = this.curve._mulC(f).redMul(g);
  }
  return this.curve.point(nx, ny, nz);
};

Point.prototype.add = function add(p) {
  if (this.isInfinity())
    return p;
  if (p.isInfinity())
    return this;

  if (this.curve.extended)
    return this._extAdd(p);
  else
    return this._projAdd(p);
};

Point.prototype.mul = function mul(k) {
  if (this._hasDoubles(k))
    return this.curve._fixedNafMul(this, k);
  else
    return this.curve._wnafMul(this, k);
};

Point.prototype.mulAdd = function mulAdd(k1, p, k2) {
  return this.curve._wnafMulAdd(1, [ this, p ], [ k1, k2 ], 2, false);
};

Point.prototype.jmulAdd = function jmulAdd(k1, p, k2) {
  return this.curve._wnafMulAdd(1, [ this, p ], [ k1, k2 ], 2, true);
};

Point.prototype.normalize = function normalize() {
  if (this.zOne)
    return this;

  // Normalize coordinates
  var zi = this.z.redInvm();
  this.x = this.x.redMul(zi);
  this.y = this.y.redMul(zi);
  if (this.t)
    this.t = this.t.redMul(zi);
  this.z = this.curve.one;
  this.zOne = true;
  return this;
};

Point.prototype.neg = function neg() {
  return this.curve.point(this.x.redNeg(),
    this.y,
    this.z,
    this.t && this.t.redNeg());
};

Point.prototype.getX = function getX() {
  this.normalize();
  return this.x.fromRed();
};

Point.prototype.getY = function getY() {
  this.normalize();
  return this.y.fromRed();
};

Point.prototype.eq = function eq(other) {
  return this === other ||
         this.getX().cmp(other.getX()) === 0 &&
         this.getY().cmp(other.getY()) === 0;
};

Point.prototype.eqXToP = function eqXToP(x) {
  var rx = x.toRed(this.curve.red).redMul(this.z);
  if (this.x.cmp(rx) === 0)
    return true;

  var xc = x.clone();
  var t = this.curve.redN.redMul(this.z);
  for (;;) {
    xc.iadd(this.curve.n);
    if (xc.cmp(this.curve.p) >= 0)
      return false;

    rx.redIAdd(t);
    if (this.x.cmp(rx) === 0)
      return true;
  }
};

// Compatibility with BaseCurve
Point.prototype.toP = Point.prototype.normalize;
Point.prototype.mixedAdd = Point.prototype.add;

},{"../utils":115,"./base":102,"bn.js":116,"inherits":136}],104:[function(require,module,exports){
'use strict';

var curve = exports;

curve.base = require('./base');
curve.short = require('./short');
curve.mont = require('./mont');
curve.edwards = require('./edwards');

},{"./base":102,"./edwards":103,"./mont":105,"./short":106}],105:[function(require,module,exports){
'use strict';

var BN = require('bn.js');
var inherits = require('inherits');
var Base = require('./base');

var utils = require('../utils');

function MontCurve(conf) {
  Base.call(this, 'mont', conf);

  this.a = new BN(conf.a, 16).toRed(this.red);
  this.b = new BN(conf.b, 16).toRed(this.red);
  this.i4 = new BN(4).toRed(this.red).redInvm();
  this.two = new BN(2).toRed(this.red);
  this.a24 = this.i4.redMul(this.a.redAdd(this.two));
}
inherits(MontCurve, Base);
module.exports = MontCurve;

MontCurve.prototype.validate = function validate(point) {
  var x = point.normalize().x;
  var x2 = x.redSqr();
  var rhs = x2.redMul(x).redAdd(x2.redMul(this.a)).redAdd(x);
  var y = rhs.redSqrt();

  return y.redSqr().cmp(rhs) === 0;
};

function Point(curve, x, z) {
  Base.BasePoint.call(this, curve, 'projective');
  if (x === null && z === null) {
    this.x = this.curve.one;
    this.z = this.curve.zero;
  } else {
    this.x = new BN(x, 16);
    this.z = new BN(z, 16);
    if (!this.x.red)
      this.x = this.x.toRed(this.curve.red);
    if (!this.z.red)
      this.z = this.z.toRed(this.curve.red);
  }
}
inherits(Point, Base.BasePoint);

MontCurve.prototype.decodePoint = function decodePoint(bytes, enc) {
  return this.point(utils.toArray(bytes, enc), 1);
};

MontCurve.prototype.point = function point(x, z) {
  return new Point(this, x, z);
};

MontCurve.prototype.pointFromJSON = function pointFromJSON(obj) {
  return Point.fromJSON(this, obj);
};

Point.prototype.precompute = function precompute() {
  // No-op
};

Point.prototype._encode = function _encode() {
  return this.getX().toArray('be', this.curve.p.byteLength());
};

Point.fromJSON = function fromJSON(curve, obj) {
  return new Point(curve, obj[0], obj[1] || curve.one);
};

Point.prototype.inspect = function inspect() {
  if (this.isInfinity())
    return '<EC Point Infinity>';
  return '<EC Point x: ' + this.x.fromRed().toString(16, 2) +
      ' z: ' + this.z.fromRed().toString(16, 2) + '>';
};

Point.prototype.isInfinity = function isInfinity() {
  // XXX This code assumes that zero is always zero in red
  return this.z.cmpn(0) === 0;
};

Point.prototype.dbl = function dbl() {
  // http://hyperelliptic.org/EFD/g1p/auto-montgom-xz.html#doubling-dbl-1987-m-3
  // 2M + 2S + 4A

  // A = X1 + Z1
  var a = this.x.redAdd(this.z);
  // AA = A^2
  var aa = a.redSqr();
  // B = X1 - Z1
  var b = this.x.redSub(this.z);
  // BB = B^2
  var bb = b.redSqr();
  // C = AA - BB
  var c = aa.redSub(bb);
  // X3 = AA * BB
  var nx = aa.redMul(bb);
  // Z3 = C * (BB + A24 * C)
  var nz = c.redMul(bb.redAdd(this.curve.a24.redMul(c)));
  return this.curve.point(nx, nz);
};

Point.prototype.add = function add() {
  throw new Error('Not supported on Montgomery curve');
};

Point.prototype.diffAdd = function diffAdd(p, diff) {
  // http://hyperelliptic.org/EFD/g1p/auto-montgom-xz.html#diffadd-dadd-1987-m-3
  // 4M + 2S + 6A

  // A = X2 + Z2
  var a = this.x.redAdd(this.z);
  // B = X2 - Z2
  var b = this.x.redSub(this.z);
  // C = X3 + Z3
  var c = p.x.redAdd(p.z);
  // D = X3 - Z3
  var d = p.x.redSub(p.z);
  // DA = D * A
  var da = d.redMul(a);
  // CB = C * B
  var cb = c.redMul(b);
  // X5 = Z1 * (DA + CB)^2
  var nx = diff.z.redMul(da.redAdd(cb).redSqr());
  // Z5 = X1 * (DA - CB)^2
  var nz = diff.x.redMul(da.redISub(cb).redSqr());
  return this.curve.point(nx, nz);
};

Point.prototype.mul = function mul(k) {
  var t = k.clone();
  var a = this; // (N / 2) * Q + Q
  var b = this.curve.point(null, null); // (N / 2) * Q
  var c = this; // Q

  for (var bits = []; t.cmpn(0) !== 0; t.iushrn(1))
    bits.push(t.andln(1));

  for (var i = bits.length - 1; i >= 0; i--) {
    if (bits[i] === 0) {
      // N * Q + Q = ((N / 2) * Q + Q)) + (N / 2) * Q
      a = a.diffAdd(b, c);
      // N * Q = 2 * ((N / 2) * Q + Q))
      b = b.dbl();
    } else {
      // N * Q = ((N / 2) * Q + Q) + ((N / 2) * Q)
      b = a.diffAdd(b, c);
      // N * Q + Q = 2 * ((N / 2) * Q + Q)
      a = a.dbl();
    }
  }
  return b;
};

Point.prototype.mulAdd = function mulAdd() {
  throw new Error('Not supported on Montgomery curve');
};

Point.prototype.jumlAdd = function jumlAdd() {
  throw new Error('Not supported on Montgomery curve');
};

Point.prototype.eq = function eq(other) {
  return this.getX().cmp(other.getX()) === 0;
};

Point.prototype.normalize = function normalize() {
  this.x = this.x.redMul(this.z.redInvm());
  this.z = this.curve.one;
  return this;
};

Point.prototype.getX = function getX() {
  // Normalize coordinates
  this.normalize();

  return this.x.fromRed();
};

},{"../utils":115,"./base":102,"bn.js":116,"inherits":136}],106:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var BN = require('bn.js');
var inherits = require('inherits');
var Base = require('./base');

var assert = utils.assert;

function ShortCurve(conf) {
  Base.call(this, 'short', conf);

  this.a = new BN(conf.a, 16).toRed(this.red);
  this.b = new BN(conf.b, 16).toRed(this.red);
  this.tinv = this.two.redInvm();

  this.zeroA = this.a.fromRed().cmpn(0) === 0;
  this.threeA = this.a.fromRed().sub(this.p).cmpn(-3) === 0;

  // If the curve is endomorphic, precalculate beta and lambda
  this.endo = this._getEndomorphism(conf);
  this._endoWnafT1 = new Array(4);
  this._endoWnafT2 = new Array(4);
}
inherits(ShortCurve, Base);
module.exports = ShortCurve;

ShortCurve.prototype._getEndomorphism = function _getEndomorphism(conf) {
  // No efficient endomorphism
  if (!this.zeroA || !this.g || !this.n || this.p.modn(3) !== 1)
    return;

  // Compute beta and lambda, that lambda * P = (beta * Px; Py)
  var beta;
  var lambda;
  if (conf.beta) {
    beta = new BN(conf.beta, 16).toRed(this.red);
  } else {
    var betas = this._getEndoRoots(this.p);
    // Choose the smallest beta
    beta = betas[0].cmp(betas[1]) < 0 ? betas[0] : betas[1];
    beta = beta.toRed(this.red);
  }
  if (conf.lambda) {
    lambda = new BN(conf.lambda, 16);
  } else {
    // Choose the lambda that is matching selected beta
    var lambdas = this._getEndoRoots(this.n);
    if (this.g.mul(lambdas[0]).x.cmp(this.g.x.redMul(beta)) === 0) {
      lambda = lambdas[0];
    } else {
      lambda = lambdas[1];
      assert(this.g.mul(lambda).x.cmp(this.g.x.redMul(beta)) === 0);
    }
  }

  // Get basis vectors, used for balanced length-two representation
  var basis;
  if (conf.basis) {
    basis = conf.basis.map(function(vec) {
      return {
        a: new BN(vec.a, 16),
        b: new BN(vec.b, 16),
      };
    });
  } else {
    basis = this._getEndoBasis(lambda);
  }

  return {
    beta: beta,
    lambda: lambda,
    basis: basis,
  };
};

ShortCurve.prototype._getEndoRoots = function _getEndoRoots(num) {
  // Find roots of for x^2 + x + 1 in F
  // Root = (-1 +- Sqrt(-3)) / 2
  //
  var red = num === this.p ? this.red : BN.mont(num);
  var tinv = new BN(2).toRed(red).redInvm();
  var ntinv = tinv.redNeg();

  var s = new BN(3).toRed(red).redNeg().redSqrt().redMul(tinv);

  var l1 = ntinv.redAdd(s).fromRed();
  var l2 = ntinv.redSub(s).fromRed();
  return [ l1, l2 ];
};

ShortCurve.prototype._getEndoBasis = function _getEndoBasis(lambda) {
  // aprxSqrt >= sqrt(this.n)
  var aprxSqrt = this.n.ushrn(Math.floor(this.n.bitLength() / 2));

  // 3.74
  // Run EGCD, until r(L + 1) < aprxSqrt
  var u = lambda;
  var v = this.n.clone();
  var x1 = new BN(1);
  var y1 = new BN(0);
  var x2 = new BN(0);
  var y2 = new BN(1);

  // NOTE: all vectors are roots of: a + b * lambda = 0 (mod n)
  var a0;
  var b0;
  // First vector
  var a1;
  var b1;
  // Second vector
  var a2;
  var b2;

  var prevR;
  var i = 0;
  var r;
  var x;
  while (u.cmpn(0) !== 0) {
    var q = v.div(u);
    r = v.sub(q.mul(u));
    x = x2.sub(q.mul(x1));
    var y = y2.sub(q.mul(y1));

    if (!a1 && r.cmp(aprxSqrt) < 0) {
      a0 = prevR.neg();
      b0 = x1;
      a1 = r.neg();
      b1 = x;
    } else if (a1 && ++i === 2) {
      break;
    }
    prevR = r;

    v = u;
    u = r;
    x2 = x1;
    x1 = x;
    y2 = y1;
    y1 = y;
  }
  a2 = r.neg();
  b2 = x;

  var len1 = a1.sqr().add(b1.sqr());
  var len2 = a2.sqr().add(b2.sqr());
  if (len2.cmp(len1) >= 0) {
    a2 = a0;
    b2 = b0;
  }

  // Normalize signs
  if (a1.negative) {
    a1 = a1.neg();
    b1 = b1.neg();
  }
  if (a2.negative) {
    a2 = a2.neg();
    b2 = b2.neg();
  }

  return [
    { a: a1, b: b1 },
    { a: a2, b: b2 },
  ];
};

ShortCurve.prototype._endoSplit = function _endoSplit(k) {
  var basis = this.endo.basis;
  var v1 = basis[0];
  var v2 = basis[1];

  var c1 = v2.b.mul(k).divRound(this.n);
  var c2 = v1.b.neg().mul(k).divRound(this.n);

  var p1 = c1.mul(v1.a);
  var p2 = c2.mul(v2.a);
  var q1 = c1.mul(v1.b);
  var q2 = c2.mul(v2.b);

  // Calculate answer
  var k1 = k.sub(p1).sub(p2);
  var k2 = q1.add(q2).neg();
  return { k1: k1, k2: k2 };
};

ShortCurve.prototype.pointFromX = function pointFromX(x, odd) {
  x = new BN(x, 16);
  if (!x.red)
    x = x.toRed(this.red);

  var y2 = x.redSqr().redMul(x).redIAdd(x.redMul(this.a)).redIAdd(this.b);
  var y = y2.redSqrt();
  if (y.redSqr().redSub(y2).cmp(this.zero) !== 0)
    throw new Error('invalid point');

  // XXX Is there any way to tell if the number is odd without converting it
  // to non-red form?
  var isOdd = y.fromRed().isOdd();
  if (odd && !isOdd || !odd && isOdd)
    y = y.redNeg();

  return this.point(x, y);
};

ShortCurve.prototype.validate = function validate(point) {
  if (point.inf)
    return true;

  var x = point.x;
  var y = point.y;

  var ax = this.a.redMul(x);
  var rhs = x.redSqr().redMul(x).redIAdd(ax).redIAdd(this.b);
  return y.redSqr().redISub(rhs).cmpn(0) === 0;
};

ShortCurve.prototype._endoWnafMulAdd =
    function _endoWnafMulAdd(points, coeffs, jacobianResult) {
      var npoints = this._endoWnafT1;
      var ncoeffs = this._endoWnafT2;
      for (var i = 0; i < points.length; i++) {
        var split = this._endoSplit(coeffs[i]);
        var p = points[i];
        var beta = p._getBeta();

        if (split.k1.negative) {
          split.k1.ineg();
          p = p.neg(true);
        }
        if (split.k2.negative) {
          split.k2.ineg();
          beta = beta.neg(true);
        }

        npoints[i * 2] = p;
        npoints[i * 2 + 1] = beta;
        ncoeffs[i * 2] = split.k1;
        ncoeffs[i * 2 + 1] = split.k2;
      }
      var res = this._wnafMulAdd(1, npoints, ncoeffs, i * 2, jacobianResult);

      // Clean-up references to points and coefficients
      for (var j = 0; j < i * 2; j++) {
        npoints[j] = null;
        ncoeffs[j] = null;
      }
      return res;
    };

function Point(curve, x, y, isRed) {
  Base.BasePoint.call(this, curve, 'affine');
  if (x === null && y === null) {
    this.x = null;
    this.y = null;
    this.inf = true;
  } else {
    this.x = new BN(x, 16);
    this.y = new BN(y, 16);
    // Force redgomery representation when loading from JSON
    if (isRed) {
      this.x.forceRed(this.curve.red);
      this.y.forceRed(this.curve.red);
    }
    if (!this.x.red)
      this.x = this.x.toRed(this.curve.red);
    if (!this.y.red)
      this.y = this.y.toRed(this.curve.red);
    this.inf = false;
  }
}
inherits(Point, Base.BasePoint);

ShortCurve.prototype.point = function point(x, y, isRed) {
  return new Point(this, x, y, isRed);
};

ShortCurve.prototype.pointFromJSON = function pointFromJSON(obj, red) {
  return Point.fromJSON(this, obj, red);
};

Point.prototype._getBeta = function _getBeta() {
  if (!this.curve.endo)
    return;

  var pre = this.precomputed;
  if (pre && pre.beta)
    return pre.beta;

  var beta = this.curve.point(this.x.redMul(this.curve.endo.beta), this.y);
  if (pre) {
    var curve = this.curve;
    var endoMul = function(p) {
      return curve.point(p.x.redMul(curve.endo.beta), p.y);
    };
    pre.beta = beta;
    beta.precomputed = {
      beta: null,
      naf: pre.naf && {
        wnd: pre.naf.wnd,
        points: pre.naf.points.map(endoMul),
      },
      doubles: pre.doubles && {
        step: pre.doubles.step,
        points: pre.doubles.points.map(endoMul),
      },
    };
  }
  return beta;
};

Point.prototype.toJSON = function toJSON() {
  if (!this.precomputed)
    return [ this.x, this.y ];

  return [ this.x, this.y, this.precomputed && {
    doubles: this.precomputed.doubles && {
      step: this.precomputed.doubles.step,
      points: this.precomputed.doubles.points.slice(1),
    },
    naf: this.precomputed.naf && {
      wnd: this.precomputed.naf.wnd,
      points: this.precomputed.naf.points.slice(1),
    },
  } ];
};

Point.fromJSON = function fromJSON(curve, obj, red) {
  if (typeof obj === 'string')
    obj = JSON.parse(obj);
  var res = curve.point(obj[0], obj[1], red);
  if (!obj[2])
    return res;

  function obj2point(obj) {
    return curve.point(obj[0], obj[1], red);
  }

  var pre = obj[2];
  res.precomputed = {
    beta: null,
    doubles: pre.doubles && {
      step: pre.doubles.step,
      points: [ res ].concat(pre.doubles.points.map(obj2point)),
    },
    naf: pre.naf && {
      wnd: pre.naf.wnd,
      points: [ res ].concat(pre.naf.points.map(obj2point)),
    },
  };
  return res;
};

Point.prototype.inspect = function inspect() {
  if (this.isInfinity())
    return '<EC Point Infinity>';
  return '<EC Point x: ' + this.x.fromRed().toString(16, 2) +
      ' y: ' + this.y.fromRed().toString(16, 2) + '>';
};

Point.prototype.isInfinity = function isInfinity() {
  return this.inf;
};

Point.prototype.add = function add(p) {
  // O + P = P
  if (this.inf)
    return p;

  // P + O = P
  if (p.inf)
    return this;

  // P + P = 2P
  if (this.eq(p))
    return this.dbl();

  // P + (-P) = O
  if (this.neg().eq(p))
    return this.curve.point(null, null);

  // P + Q = O
  if (this.x.cmp(p.x) === 0)
    return this.curve.point(null, null);

  var c = this.y.redSub(p.y);
  if (c.cmpn(0) !== 0)
    c = c.redMul(this.x.redSub(p.x).redInvm());
  var nx = c.redSqr().redISub(this.x).redISub(p.x);
  var ny = c.redMul(this.x.redSub(nx)).redISub(this.y);
  return this.curve.point(nx, ny);
};

Point.prototype.dbl = function dbl() {
  if (this.inf)
    return this;

  // 2P = O
  var ys1 = this.y.redAdd(this.y);
  if (ys1.cmpn(0) === 0)
    return this.curve.point(null, null);

  var a = this.curve.a;

  var x2 = this.x.redSqr();
  var dyinv = ys1.redInvm();
  var c = x2.redAdd(x2).redIAdd(x2).redIAdd(a).redMul(dyinv);

  var nx = c.redSqr().redISub(this.x.redAdd(this.x));
  var ny = c.redMul(this.x.redSub(nx)).redISub(this.y);
  return this.curve.point(nx, ny);
};

Point.prototype.getX = function getX() {
  return this.x.fromRed();
};

Point.prototype.getY = function getY() {
  return this.y.fromRed();
};

Point.prototype.mul = function mul(k) {
  k = new BN(k, 16);
  if (this.isInfinity())
    return this;
  else if (this._hasDoubles(k))
    return this.curve._fixedNafMul(this, k);
  else if (this.curve.endo)
    return this.curve._endoWnafMulAdd([ this ], [ k ]);
  else
    return this.curve._wnafMul(this, k);
};

Point.prototype.mulAdd = function mulAdd(k1, p2, k2) {
  var points = [ this, p2 ];
  var coeffs = [ k1, k2 ];
  if (this.curve.endo)
    return this.curve._endoWnafMulAdd(points, coeffs);
  else
    return this.curve._wnafMulAdd(1, points, coeffs, 2);
};

Point.prototype.jmulAdd = function jmulAdd(k1, p2, k2) {
  var points = [ this, p2 ];
  var coeffs = [ k1, k2 ];
  if (this.curve.endo)
    return this.curve._endoWnafMulAdd(points, coeffs, true);
  else
    return this.curve._wnafMulAdd(1, points, coeffs, 2, true);
};

Point.prototype.eq = function eq(p) {
  return this === p ||
         this.inf === p.inf &&
             (this.inf || this.x.cmp(p.x) === 0 && this.y.cmp(p.y) === 0);
};

Point.prototype.neg = function neg(_precompute) {
  if (this.inf)
    return this;

  var res = this.curve.point(this.x, this.y.redNeg());
  if (_precompute && this.precomputed) {
    var pre = this.precomputed;
    var negate = function(p) {
      return p.neg();
    };
    res.precomputed = {
      naf: pre.naf && {
        wnd: pre.naf.wnd,
        points: pre.naf.points.map(negate),
      },
      doubles: pre.doubles && {
        step: pre.doubles.step,
        points: pre.doubles.points.map(negate),
      },
    };
  }
  return res;
};

Point.prototype.toJ = function toJ() {
  if (this.inf)
    return this.curve.jpoint(null, null, null);

  var res = this.curve.jpoint(this.x, this.y, this.curve.one);
  return res;
};

function JPoint(curve, x, y, z) {
  Base.BasePoint.call(this, curve, 'jacobian');
  if (x === null && y === null && z === null) {
    this.x = this.curve.one;
    this.y = this.curve.one;
    this.z = new BN(0);
  } else {
    this.x = new BN(x, 16);
    this.y = new BN(y, 16);
    this.z = new BN(z, 16);
  }
  if (!this.x.red)
    this.x = this.x.toRed(this.curve.red);
  if (!this.y.red)
    this.y = this.y.toRed(this.curve.red);
  if (!this.z.red)
    this.z = this.z.toRed(this.curve.red);

  this.zOne = this.z === this.curve.one;
}
inherits(JPoint, Base.BasePoint);

ShortCurve.prototype.jpoint = function jpoint(x, y, z) {
  return new JPoint(this, x, y, z);
};

JPoint.prototype.toP = function toP() {
  if (this.isInfinity())
    return this.curve.point(null, null);

  var zinv = this.z.redInvm();
  var zinv2 = zinv.redSqr();
  var ax = this.x.redMul(zinv2);
  var ay = this.y.redMul(zinv2).redMul(zinv);

  return this.curve.point(ax, ay);
};

JPoint.prototype.neg = function neg() {
  return this.curve.jpoint(this.x, this.y.redNeg(), this.z);
};

JPoint.prototype.add = function add(p) {
  // O + P = P
  if (this.isInfinity())
    return p;

  // P + O = P
  if (p.isInfinity())
    return this;

  // 12M + 4S + 7A
  var pz2 = p.z.redSqr();
  var z2 = this.z.redSqr();
  var u1 = this.x.redMul(pz2);
  var u2 = p.x.redMul(z2);
  var s1 = this.y.redMul(pz2.redMul(p.z));
  var s2 = p.y.redMul(z2.redMul(this.z));

  var h = u1.redSub(u2);
  var r = s1.redSub(s2);
  if (h.cmpn(0) === 0) {
    if (r.cmpn(0) !== 0)
      return this.curve.jpoint(null, null, null);
    else
      return this.dbl();
  }

  var h2 = h.redSqr();
  var h3 = h2.redMul(h);
  var v = u1.redMul(h2);

  var nx = r.redSqr().redIAdd(h3).redISub(v).redISub(v);
  var ny = r.redMul(v.redISub(nx)).redISub(s1.redMul(h3));
  var nz = this.z.redMul(p.z).redMul(h);

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype.mixedAdd = function mixedAdd(p) {
  // O + P = P
  if (this.isInfinity())
    return p.toJ();

  // P + O = P
  if (p.isInfinity())
    return this;

  // 8M + 3S + 7A
  var z2 = this.z.redSqr();
  var u1 = this.x;
  var u2 = p.x.redMul(z2);
  var s1 = this.y;
  var s2 = p.y.redMul(z2).redMul(this.z);

  var h = u1.redSub(u2);
  var r = s1.redSub(s2);
  if (h.cmpn(0) === 0) {
    if (r.cmpn(0) !== 0)
      return this.curve.jpoint(null, null, null);
    else
      return this.dbl();
  }

  var h2 = h.redSqr();
  var h3 = h2.redMul(h);
  var v = u1.redMul(h2);

  var nx = r.redSqr().redIAdd(h3).redISub(v).redISub(v);
  var ny = r.redMul(v.redISub(nx)).redISub(s1.redMul(h3));
  var nz = this.z.redMul(h);

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype.dblp = function dblp(pow) {
  if (pow === 0)
    return this;
  if (this.isInfinity())
    return this;
  if (!pow)
    return this.dbl();

  var i;
  if (this.curve.zeroA || this.curve.threeA) {
    var r = this;
    for (i = 0; i < pow; i++)
      r = r.dbl();
    return r;
  }

  // 1M + 2S + 1A + N * (4S + 5M + 8A)
  // N = 1 => 6M + 6S + 9A
  var a = this.curve.a;
  var tinv = this.curve.tinv;

  var jx = this.x;
  var jy = this.y;
  var jz = this.z;
  var jz4 = jz.redSqr().redSqr();

  // Reuse results
  var jyd = jy.redAdd(jy);
  for (i = 0; i < pow; i++) {
    var jx2 = jx.redSqr();
    var jyd2 = jyd.redSqr();
    var jyd4 = jyd2.redSqr();
    var c = jx2.redAdd(jx2).redIAdd(jx2).redIAdd(a.redMul(jz4));

    var t1 = jx.redMul(jyd2);
    var nx = c.redSqr().redISub(t1.redAdd(t1));
    var t2 = t1.redISub(nx);
    var dny = c.redMul(t2);
    dny = dny.redIAdd(dny).redISub(jyd4);
    var nz = jyd.redMul(jz);
    if (i + 1 < pow)
      jz4 = jz4.redMul(jyd4);

    jx = nx;
    jz = nz;
    jyd = dny;
  }

  return this.curve.jpoint(jx, jyd.redMul(tinv), jz);
};

JPoint.prototype.dbl = function dbl() {
  if (this.isInfinity())
    return this;

  if (this.curve.zeroA)
    return this._zeroDbl();
  else if (this.curve.threeA)
    return this._threeDbl();
  else
    return this._dbl();
};

JPoint.prototype._zeroDbl = function _zeroDbl() {
  var nx;
  var ny;
  var nz;
  // Z = 1
  if (this.zOne) {
    // hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html
    //     #doubling-mdbl-2007-bl
    // 1M + 5S + 14A

    // XX = X1^2
    var xx = this.x.redSqr();
    // YY = Y1^2
    var yy = this.y.redSqr();
    // YYYY = YY^2
    var yyyy = yy.redSqr();
    // S = 2 * ((X1 + YY)^2 - XX - YYYY)
    var s = this.x.redAdd(yy).redSqr().redISub(xx).redISub(yyyy);
    s = s.redIAdd(s);
    // M = 3 * XX + a; a = 0
    var m = xx.redAdd(xx).redIAdd(xx);
    // T = M ^ 2 - 2*S
    var t = m.redSqr().redISub(s).redISub(s);

    // 8 * YYYY
    var yyyy8 = yyyy.redIAdd(yyyy);
    yyyy8 = yyyy8.redIAdd(yyyy8);
    yyyy8 = yyyy8.redIAdd(yyyy8);

    // X3 = T
    nx = t;
    // Y3 = M * (S - T) - 8 * YYYY
    ny = m.redMul(s.redISub(t)).redISub(yyyy8);
    // Z3 = 2*Y1
    nz = this.y.redAdd(this.y);
  } else {
    // hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html
    //     #doubling-dbl-2009-l
    // 2M + 5S + 13A

    // A = X1^2
    var a = this.x.redSqr();
    // B = Y1^2
    var b = this.y.redSqr();
    // C = B^2
    var c = b.redSqr();
    // D = 2 * ((X1 + B)^2 - A - C)
    var d = this.x.redAdd(b).redSqr().redISub(a).redISub(c);
    d = d.redIAdd(d);
    // E = 3 * A
    var e = a.redAdd(a).redIAdd(a);
    // F = E^2
    var f = e.redSqr();

    // 8 * C
    var c8 = c.redIAdd(c);
    c8 = c8.redIAdd(c8);
    c8 = c8.redIAdd(c8);

    // X3 = F - 2 * D
    nx = f.redISub(d).redISub(d);
    // Y3 = E * (D - X3) - 8 * C
    ny = e.redMul(d.redISub(nx)).redISub(c8);
    // Z3 = 2 * Y1 * Z1
    nz = this.y.redMul(this.z);
    nz = nz.redIAdd(nz);
  }

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype._threeDbl = function _threeDbl() {
  var nx;
  var ny;
  var nz;
  // Z = 1
  if (this.zOne) {
    // hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-3.html
    //     #doubling-mdbl-2007-bl
    // 1M + 5S + 15A

    // XX = X1^2
    var xx = this.x.redSqr();
    // YY = Y1^2
    var yy = this.y.redSqr();
    // YYYY = YY^2
    var yyyy = yy.redSqr();
    // S = 2 * ((X1 + YY)^2 - XX - YYYY)
    var s = this.x.redAdd(yy).redSqr().redISub(xx).redISub(yyyy);
    s = s.redIAdd(s);
    // M = 3 * XX + a
    var m = xx.redAdd(xx).redIAdd(xx).redIAdd(this.curve.a);
    // T = M^2 - 2 * S
    var t = m.redSqr().redISub(s).redISub(s);
    // X3 = T
    nx = t;
    // Y3 = M * (S - T) - 8 * YYYY
    var yyyy8 = yyyy.redIAdd(yyyy);
    yyyy8 = yyyy8.redIAdd(yyyy8);
    yyyy8 = yyyy8.redIAdd(yyyy8);
    ny = m.redMul(s.redISub(t)).redISub(yyyy8);
    // Z3 = 2 * Y1
    nz = this.y.redAdd(this.y);
  } else {
    // hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-3.html#doubling-dbl-2001-b
    // 3M + 5S

    // delta = Z1^2
    var delta = this.z.redSqr();
    // gamma = Y1^2
    var gamma = this.y.redSqr();
    // beta = X1 * gamma
    var beta = this.x.redMul(gamma);
    // alpha = 3 * (X1 - delta) * (X1 + delta)
    var alpha = this.x.redSub(delta).redMul(this.x.redAdd(delta));
    alpha = alpha.redAdd(alpha).redIAdd(alpha);
    // X3 = alpha^2 - 8 * beta
    var beta4 = beta.redIAdd(beta);
    beta4 = beta4.redIAdd(beta4);
    var beta8 = beta4.redAdd(beta4);
    nx = alpha.redSqr().redISub(beta8);
    // Z3 = (Y1 + Z1)^2 - gamma - delta
    nz = this.y.redAdd(this.z).redSqr().redISub(gamma).redISub(delta);
    // Y3 = alpha * (4 * beta - X3) - 8 * gamma^2
    var ggamma8 = gamma.redSqr();
    ggamma8 = ggamma8.redIAdd(ggamma8);
    ggamma8 = ggamma8.redIAdd(ggamma8);
    ggamma8 = ggamma8.redIAdd(ggamma8);
    ny = alpha.redMul(beta4.redISub(nx)).redISub(ggamma8);
  }

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype._dbl = function _dbl() {
  var a = this.curve.a;

  // 4M + 6S + 10A
  var jx = this.x;
  var jy = this.y;
  var jz = this.z;
  var jz4 = jz.redSqr().redSqr();

  var jx2 = jx.redSqr();
  var jy2 = jy.redSqr();

  var c = jx2.redAdd(jx2).redIAdd(jx2).redIAdd(a.redMul(jz4));

  var jxd4 = jx.redAdd(jx);
  jxd4 = jxd4.redIAdd(jxd4);
  var t1 = jxd4.redMul(jy2);
  var nx = c.redSqr().redISub(t1.redAdd(t1));
  var t2 = t1.redISub(nx);

  var jyd8 = jy2.redSqr();
  jyd8 = jyd8.redIAdd(jyd8);
  jyd8 = jyd8.redIAdd(jyd8);
  jyd8 = jyd8.redIAdd(jyd8);
  var ny = c.redMul(t2).redISub(jyd8);
  var nz = jy.redAdd(jy).redMul(jz);

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype.trpl = function trpl() {
  if (!this.curve.zeroA)
    return this.dbl().add(this);

  // hyperelliptic.org/EFD/g1p/auto-shortw-jacobian-0.html#tripling-tpl-2007-bl
  // 5M + 10S + ...

  // XX = X1^2
  var xx = this.x.redSqr();
  // YY = Y1^2
  var yy = this.y.redSqr();
  // ZZ = Z1^2
  var zz = this.z.redSqr();
  // YYYY = YY^2
  var yyyy = yy.redSqr();
  // M = 3 * XX + a * ZZ2; a = 0
  var m = xx.redAdd(xx).redIAdd(xx);
  // MM = M^2
  var mm = m.redSqr();
  // E = 6 * ((X1 + YY)^2 - XX - YYYY) - MM
  var e = this.x.redAdd(yy).redSqr().redISub(xx).redISub(yyyy);
  e = e.redIAdd(e);
  e = e.redAdd(e).redIAdd(e);
  e = e.redISub(mm);
  // EE = E^2
  var ee = e.redSqr();
  // T = 16*YYYY
  var t = yyyy.redIAdd(yyyy);
  t = t.redIAdd(t);
  t = t.redIAdd(t);
  t = t.redIAdd(t);
  // U = (M + E)^2 - MM - EE - T
  var u = m.redIAdd(e).redSqr().redISub(mm).redISub(ee).redISub(t);
  // X3 = 4 * (X1 * EE - 4 * YY * U)
  var yyu4 = yy.redMul(u);
  yyu4 = yyu4.redIAdd(yyu4);
  yyu4 = yyu4.redIAdd(yyu4);
  var nx = this.x.redMul(ee).redISub(yyu4);
  nx = nx.redIAdd(nx);
  nx = nx.redIAdd(nx);
  // Y3 = 8 * Y1 * (U * (T - U) - E * EE)
  var ny = this.y.redMul(u.redMul(t.redISub(u)).redISub(e.redMul(ee)));
  ny = ny.redIAdd(ny);
  ny = ny.redIAdd(ny);
  ny = ny.redIAdd(ny);
  // Z3 = (Z1 + E)^2 - ZZ - EE
  var nz = this.z.redAdd(e).redSqr().redISub(zz).redISub(ee);

  return this.curve.jpoint(nx, ny, nz);
};

JPoint.prototype.mul = function mul(k, kbase) {
  k = new BN(k, kbase);

  return this.curve._wnafMul(this, k);
};

JPoint.prototype.eq = function eq(p) {
  if (p.type === 'affine')
    return this.eq(p.toJ());

  if (this === p)
    return true;

  // x1 * z2^2 == x2 * z1^2
  var z2 = this.z.redSqr();
  var pz2 = p.z.redSqr();
  if (this.x.redMul(pz2).redISub(p.x.redMul(z2)).cmpn(0) !== 0)
    return false;

  // y1 * z2^3 == y2 * z1^3
  var z3 = z2.redMul(this.z);
  var pz3 = pz2.redMul(p.z);
  return this.y.redMul(pz3).redISub(p.y.redMul(z3)).cmpn(0) === 0;
};

JPoint.prototype.eqXToP = function eqXToP(x) {
  var zs = this.z.redSqr();
  var rx = x.toRed(this.curve.red).redMul(zs);
  if (this.x.cmp(rx) === 0)
    return true;

  var xc = x.clone();
  var t = this.curve.redN.redMul(zs);
  for (;;) {
    xc.iadd(this.curve.n);
    if (xc.cmp(this.curve.p) >= 0)
      return false;

    rx.redIAdd(t);
    if (this.x.cmp(rx) === 0)
      return true;
  }
};

JPoint.prototype.inspect = function inspect() {
  if (this.isInfinity())
    return '<EC JPoint Infinity>';
  return '<EC JPoint x: ' + this.x.toString(16, 2) +
      ' y: ' + this.y.toString(16, 2) +
      ' z: ' + this.z.toString(16, 2) + '>';
};

JPoint.prototype.isInfinity = function isInfinity() {
  // XXX This code assumes that zero is always zero in red
  return this.z.cmpn(0) === 0;
};

},{"../utils":115,"./base":102,"bn.js":116,"inherits":136}],107:[function(require,module,exports){
'use strict';

var curves = exports;

var hash = require('hash.js');
var curve = require('./curve');
var utils = require('./utils');

var assert = utils.assert;

function PresetCurve(options) {
  if (options.type === 'short')
    this.curve = new curve.short(options);
  else if (options.type === 'edwards')
    this.curve = new curve.edwards(options);
  else
    this.curve = new curve.mont(options);
  this.g = this.curve.g;
  this.n = this.curve.n;
  this.hash = options.hash;

  assert(this.g.validate(), 'Invalid curve');
  assert(this.g.mul(this.n).isInfinity(), 'Invalid curve, G*N != O');
}
curves.PresetCurve = PresetCurve;

function defineCurve(name, options) {
  Object.defineProperty(curves, name, {
    configurable: true,
    enumerable: true,
    get: function() {
      var curve = new PresetCurve(options);
      Object.defineProperty(curves, name, {
        configurable: true,
        enumerable: true,
        value: curve,
      });
      return curve;
    },
  });
}

defineCurve('p192', {
  type: 'short',
  prime: 'p192',
  p: 'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff',
  a: 'ffffffff ffffffff ffffffff fffffffe ffffffff fffffffc',
  b: '64210519 e59c80e7 0fa7e9ab 72243049 feb8deec c146b9b1',
  n: 'ffffffff ffffffff ffffffff 99def836 146bc9b1 b4d22831',
  hash: hash.sha256,
  gRed: false,
  g: [
    '188da80e b03090f6 7cbf20eb 43a18800 f4ff0afd 82ff1012',
    '07192b95 ffc8da78 631011ed 6b24cdd5 73f977a1 1e794811',
  ],
});

defineCurve('p224', {
  type: 'short',
  prime: 'p224',
  p: 'ffffffff ffffffff ffffffff ffffffff 00000000 00000000 00000001',
  a: 'ffffffff ffffffff ffffffff fffffffe ffffffff ffffffff fffffffe',
  b: 'b4050a85 0c04b3ab f5413256 5044b0b7 d7bfd8ba 270b3943 2355ffb4',
  n: 'ffffffff ffffffff ffffffff ffff16a2 e0b8f03e 13dd2945 5c5c2a3d',
  hash: hash.sha256,
  gRed: false,
  g: [
    'b70e0cbd 6bb4bf7f 321390b9 4a03c1d3 56c21122 343280d6 115c1d21',
    'bd376388 b5f723fb 4c22dfe6 cd4375a0 5a074764 44d58199 85007e34',
  ],
});

defineCurve('p256', {
  type: 'short',
  prime: null,
  p: 'ffffffff 00000001 00000000 00000000 00000000 ffffffff ffffffff ffffffff',
  a: 'ffffffff 00000001 00000000 00000000 00000000 ffffffff ffffffff fffffffc',
  b: '5ac635d8 aa3a93e7 b3ebbd55 769886bc 651d06b0 cc53b0f6 3bce3c3e 27d2604b',
  n: 'ffffffff 00000000 ffffffff ffffffff bce6faad a7179e84 f3b9cac2 fc632551',
  hash: hash.sha256,
  gRed: false,
  g: [
    '6b17d1f2 e12c4247 f8bce6e5 63a440f2 77037d81 2deb33a0 f4a13945 d898c296',
    '4fe342e2 fe1a7f9b 8ee7eb4a 7c0f9e16 2bce3357 6b315ece cbb64068 37bf51f5',
  ],
});

defineCurve('p384', {
  type: 'short',
  prime: null,
  p: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'fffffffe ffffffff 00000000 00000000 ffffffff',
  a: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'fffffffe ffffffff 00000000 00000000 fffffffc',
  b: 'b3312fa7 e23ee7e4 988e056b e3f82d19 181d9c6e fe814112 0314088f ' +
     '5013875a c656398d 8a2ed19d 2a85c8ed d3ec2aef',
  n: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff c7634d81 ' +
     'f4372ddf 581a0db2 48b0a77a ecec196a ccc52973',
  hash: hash.sha384,
  gRed: false,
  g: [
    'aa87ca22 be8b0537 8eb1c71e f320ad74 6e1d3b62 8ba79b98 59f741e0 82542a38 ' +
    '5502f25d bf55296c 3a545e38 72760ab7',
    '3617de4a 96262c6f 5d9e98bf 9292dc29 f8f41dbd 289a147c e9da3113 b5f0b8c0 ' +
    '0a60b1ce 1d7e819d 7a431d7c 90ea0e5f',
  ],
});

defineCurve('p521', {
  type: 'short',
  prime: null,
  p: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'ffffffff ffffffff ffffffff ffffffff ffffffff',
  a: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'ffffffff ffffffff ffffffff ffffffff fffffffc',
  b: '00000051 953eb961 8e1c9a1f 929a21a0 b68540ee a2da725b ' +
     '99b315f3 b8b48991 8ef109e1 56193951 ec7e937b 1652c0bd ' +
     '3bb1bf07 3573df88 3d2c34f1 ef451fd4 6b503f00',
  n: '000001ff ffffffff ffffffff ffffffff ffffffff ffffffff ' +
     'ffffffff ffffffff fffffffa 51868783 bf2f966b 7fcc0148 ' +
     'f709a5d0 3bb5c9b8 899c47ae bb6fb71e 91386409',
  hash: hash.sha512,
  gRed: false,
  g: [
    '000000c6 858e06b7 0404e9cd 9e3ecb66 2395b442 9c648139 ' +
    '053fb521 f828af60 6b4d3dba a14b5e77 efe75928 fe1dc127 ' +
    'a2ffa8de 3348b3c1 856a429b f97e7e31 c2e5bd66',
    '00000118 39296a78 9a3bc004 5c8a5fb4 2c7d1bd9 98f54449 ' +
    '579b4468 17afbd17 273e662c 97ee7299 5ef42640 c550b901 ' +
    '3fad0761 353c7086 a272c240 88be9476 9fd16650',
  ],
});

defineCurve('curve25519', {
  type: 'mont',
  prime: 'p25519',
  p: '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed',
  a: '76d06',
  b: '1',
  n: '1000000000000000 0000000000000000 14def9dea2f79cd6 5812631a5cf5d3ed',
  hash: hash.sha256,
  gRed: false,
  g: [
    '9',
  ],
});

defineCurve('ed25519', {
  type: 'edwards',
  prime: 'p25519',
  p: '7fffffffffffffff ffffffffffffffff ffffffffffffffff ffffffffffffffed',
  a: '-1',
  c: '1',
  // -121665 * (121666^(-1)) (mod P)
  d: '52036cee2b6ffe73 8cc740797779e898 00700a4d4141d8ab 75eb4dca135978a3',
  n: '1000000000000000 0000000000000000 14def9dea2f79cd6 5812631a5cf5d3ed',
  hash: hash.sha256,
  gRed: false,
  g: [
    '216936d3cd6e53fec0a4e231fdd6dc5c692cc7609525a7b2c9562d608f25d51a',

    // 4/5
    '6666666666666666666666666666666666666666666666666666666666666658',
  ],
});

var pre;
try {
  pre = require('./precomputed/secp256k1');
} catch (e) {
  pre = undefined;
}

defineCurve('secp256k1', {
  type: 'short',
  prime: 'k256',
  p: 'ffffffff ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe fffffc2f',
  a: '0',
  b: '7',
  n: 'ffffffff ffffffff ffffffff fffffffe baaedce6 af48a03b bfd25e8c d0364141',
  h: '1',
  hash: hash.sha256,

  // Precomputed endomorphism
  beta: '7ae96a2b657c07106e64479eac3434e99cf0497512f58995c1396c28719501ee',
  lambda: '5363ad4cc05c30e0a5261c028812645a122e22ea20816678df02967c1b23bd72',
  basis: [
    {
      a: '3086d221a7d46bcde86c90e49284eb15',
      b: '-e4437ed6010e88286f547fa90abfe4c3',
    },
    {
      a: '114ca50f7a8e2f3f657c1108d9d44cfd8',
      b: '3086d221a7d46bcde86c90e49284eb15',
    },
  ],

  gRed: false,
  g: [
    '79be667ef9dcbbac55a06295ce870b07029bfcdb2dce28d959f2815b16f81798',
    '483ada7726a3c4655da4fbfc0e1108a8fd17b448a68554199c47d08ffb10d4b8',
    pre,
  ],
});

},{"./curve":104,"./precomputed/secp256k1":114,"./utils":115,"hash.js":122}],108:[function(require,module,exports){
'use strict';

var BN = require('bn.js');
var HmacDRBG = require('hmac-drbg');
var utils = require('../utils');
var curves = require('../curves');
var rand = require('brorand');
var assert = utils.assert;

var KeyPair = require('./key');
var Signature = require('./signature');

function EC(options) {
  if (!(this instanceof EC))
    return new EC(options);

  // Shortcut `elliptic.ec(curve-name)`
  if (typeof options === 'string') {
    assert(Object.prototype.hasOwnProperty.call(curves, options),
      'Unknown curve ' + options);

    options = curves[options];
  }

  // Shortcut for `elliptic.ec(elliptic.curves.curveName)`
  if (options instanceof curves.PresetCurve)
    options = { curve: options };

  this.curve = options.curve.curve;
  this.n = this.curve.n;
  this.nh = this.n.ushrn(1);
  this.g = this.curve.g;

  // Point on curve
  this.g = options.curve.g;
  this.g.precompute(options.curve.n.bitLength() + 1);

  // Hash for function for DRBG
  this.hash = options.hash || options.curve.hash;
}
module.exports = EC;

EC.prototype.keyPair = function keyPair(options) {
  return new KeyPair(this, options);
};

EC.prototype.keyFromPrivate = function keyFromPrivate(priv, enc) {
  return KeyPair.fromPrivate(this, priv, enc);
};

EC.prototype.keyFromPublic = function keyFromPublic(pub, enc) {
  return KeyPair.fromPublic(this, pub, enc);
};

EC.prototype.genKeyPair = function genKeyPair(options) {
  if (!options)
    options = {};

  // Instantiate Hmac_DRBG
  var drbg = new HmacDRBG({
    hash: this.hash,
    pers: options.pers,
    persEnc: options.persEnc || 'utf8',
    entropy: options.entropy || rand(this.hash.hmacStrength),
    entropyEnc: options.entropy && options.entropyEnc || 'utf8',
    nonce: this.n.toArray(),
  });

  var bytes = this.n.byteLength();
  var ns2 = this.n.sub(new BN(2));
  for (;;) {
    var priv = new BN(drbg.generate(bytes));
    if (priv.cmp(ns2) > 0)
      continue;

    priv.iaddn(1);
    return this.keyFromPrivate(priv);
  }
};

EC.prototype._truncateToN = function _truncateToN(msg, truncOnly) {
  var delta = msg.byteLength() * 8 - this.n.bitLength();
  if (delta > 0)
    msg = msg.ushrn(delta);
  if (!truncOnly && msg.cmp(this.n) >= 0)
    return msg.sub(this.n);
  else
    return msg;
};

EC.prototype.sign = function sign(msg, key, enc, options) {
  if (typeof enc === 'object') {
    options = enc;
    enc = null;
  }
  if (!options)
    options = {};

  key = this.keyFromPrivate(key, enc);
  msg = this._truncateToN(new BN(msg, 16));

  // Zero-extend key to provide enough entropy
  var bytes = this.n.byteLength();
  var bkey = key.getPrivate().toArray('be', bytes);

  // Zero-extend nonce to have the same byte size as N
  var nonce = msg.toArray('be', bytes);

  // Instantiate Hmac_DRBG
  var drbg = new HmacDRBG({
    hash: this.hash,
    entropy: bkey,
    nonce: nonce,
    pers: options.pers,
    persEnc: options.persEnc || 'utf8',
  });

  // Number of bytes to generate
  var ns1 = this.n.sub(new BN(1));

  for (var iter = 0; ; iter++) {
    var k = options.k ?
      options.k(iter) :
      new BN(drbg.generate(this.n.byteLength()));
    k = this._truncateToN(k, true);
    if (k.cmpn(1) <= 0 || k.cmp(ns1) >= 0)
      continue;

    var kp = this.g.mul(k);
    if (kp.isInfinity())
      continue;

    var kpX = kp.getX();
    var r = kpX.umod(this.n);
    if (r.cmpn(0) === 0)
      continue;

    var s = k.invm(this.n).mul(r.mul(key.getPrivate()).iadd(msg));
    s = s.umod(this.n);
    if (s.cmpn(0) === 0)
      continue;

    var recoveryParam = (kp.getY().isOdd() ? 1 : 0) |
                        (kpX.cmp(r) !== 0 ? 2 : 0);

    // Use complement of `s`, if it is > `n / 2`
    if (options.canonical && s.cmp(this.nh) > 0) {
      s = this.n.sub(s);
      recoveryParam ^= 1;
    }

    return new Signature({ r: r, s: s, recoveryParam: recoveryParam });
  }
};

EC.prototype.verify = function verify(msg, signature, key, enc) {
  msg = this._truncateToN(new BN(msg, 16));
  key = this.keyFromPublic(key, enc);
  signature = new Signature(signature, 'hex');

  // Perform primitive values validation
  var r = signature.r;
  var s = signature.s;
  if (r.cmpn(1) < 0 || r.cmp(this.n) >= 0)
    return false;
  if (s.cmpn(1) < 0 || s.cmp(this.n) >= 0)
    return false;

  // Validate signature
  var sinv = s.invm(this.n);
  var u1 = sinv.mul(msg).umod(this.n);
  var u2 = sinv.mul(r).umod(this.n);
  var p;

  if (!this.curve._maxwellTrick) {
    p = this.g.mulAdd(u1, key.getPublic(), u2);
    if (p.isInfinity())
      return false;

    return p.getX().umod(this.n).cmp(r) === 0;
  }

  // NOTE: Greg Maxwell's trick, inspired by:
  // https://git.io/vad3K

  p = this.g.jmulAdd(u1, key.getPublic(), u2);
  if (p.isInfinity())
    return false;

  // Compare `p.x` of Jacobian point with `r`,
  // this will do `p.x == r * p.z^2` instead of multiplying `p.x` by the
  // inverse of `p.z^2`
  return p.eqXToP(r);
};

EC.prototype.recoverPubKey = function(msg, signature, j, enc) {
  assert((3 & j) === j, 'The recovery param is more than two bits');
  signature = new Signature(signature, enc);

  var n = this.n;
  var e = new BN(msg);
  var r = signature.r;
  var s = signature.s;

  // A set LSB signifies that the y-coordinate is odd
  var isYOdd = j & 1;
  var isSecondKey = j >> 1;
  if (r.cmp(this.curve.p.umod(this.curve.n)) >= 0 && isSecondKey)
    throw new Error('Unable to find sencond key candinate');

  // 1.1. Let x = r + jn.
  if (isSecondKey)
    r = this.curve.pointFromX(r.add(this.curve.n), isYOdd);
  else
    r = this.curve.pointFromX(r, isYOdd);

  var rInv = signature.r.invm(n);
  var s1 = n.sub(e).mul(rInv).umod(n);
  var s2 = s.mul(rInv).umod(n);

  // 1.6.1 Compute Q = r^-1 (sR -  eG)
  //               Q = r^-1 (sR + -eG)
  return this.g.mulAdd(s1, r, s2);
};

EC.prototype.getKeyRecoveryParam = function(e, signature, Q, enc) {
  signature = new Signature(signature, enc);
  if (signature.recoveryParam !== null)
    return signature.recoveryParam;

  for (var i = 0; i < 4; i++) {
    var Qprime;
    try {
      Qprime = this.recoverPubKey(e, signature, i);
    } catch (e) {
      continue;
    }

    if (Qprime.eq(Q))
      return i;
  }
  throw new Error('Unable to find valid recovery factor');
};

},{"../curves":107,"../utils":115,"./key":109,"./signature":110,"bn.js":116,"brorand":44,"hmac-drbg":134}],109:[function(require,module,exports){
'use strict';

var BN = require('bn.js');
var utils = require('../utils');
var assert = utils.assert;

function KeyPair(ec, options) {
  this.ec = ec;
  this.priv = null;
  this.pub = null;

  // KeyPair(ec, { priv: ..., pub: ... })
  if (options.priv)
    this._importPrivate(options.priv, options.privEnc);
  if (options.pub)
    this._importPublic(options.pub, options.pubEnc);
}
module.exports = KeyPair;

KeyPair.fromPublic = function fromPublic(ec, pub, enc) {
  if (pub instanceof KeyPair)
    return pub;

  return new KeyPair(ec, {
    pub: pub,
    pubEnc: enc,
  });
};

KeyPair.fromPrivate = function fromPrivate(ec, priv, enc) {
  if (priv instanceof KeyPair)
    return priv;

  return new KeyPair(ec, {
    priv: priv,
    privEnc: enc,
  });
};

KeyPair.prototype.validate = function validate() {
  var pub = this.getPublic();

  if (pub.isInfinity())
    return { result: false, reason: 'Invalid public key' };
  if (!pub.validate())
    return { result: false, reason: 'Public key is not a point' };
  if (!pub.mul(this.ec.curve.n).isInfinity())
    return { result: false, reason: 'Public key * N != O' };

  return { result: true, reason: null };
};

KeyPair.prototype.getPublic = function getPublic(compact, enc) {
  // compact is optional argument
  if (typeof compact === 'string') {
    enc = compact;
    compact = null;
  }

  if (!this.pub)
    this.pub = this.ec.g.mul(this.priv);

  if (!enc)
    return this.pub;

  return this.pub.encode(enc, compact);
};

KeyPair.prototype.getPrivate = function getPrivate(enc) {
  if (enc === 'hex')
    return this.priv.toString(16, 2);
  else
    return this.priv;
};

KeyPair.prototype._importPrivate = function _importPrivate(key, enc) {
  this.priv = new BN(key, enc || 16);

  // Ensure that the priv won't be bigger than n, otherwise we may fail
  // in fixed multiplication method
  this.priv = this.priv.umod(this.ec.curve.n);
};

KeyPair.prototype._importPublic = function _importPublic(key, enc) {
  if (key.x || key.y) {
    // Montgomery points only have an `x` coordinate.
    // Weierstrass/Edwards points on the other hand have both `x` and
    // `y` coordinates.
    if (this.ec.curve.type === 'mont') {
      assert(key.x, 'Need x coordinate');
    } else if (this.ec.curve.type === 'short' ||
               this.ec.curve.type === 'edwards') {
      assert(key.x && key.y, 'Need both x and y coordinate');
    }
    this.pub = this.ec.curve.point(key.x, key.y);
    return;
  }
  this.pub = this.ec.curve.decodePoint(key, enc);
};

// ECDH
KeyPair.prototype.derive = function derive(pub) {
  if(!pub.validate()) {
    assert(pub.validate(), 'public point not validated');
  }
  return pub.mul(this.priv).getX();
};

// ECDSA
KeyPair.prototype.sign = function sign(msg, enc, options) {
  return this.ec.sign(msg, this, enc, options);
};

KeyPair.prototype.verify = function verify(msg, signature) {
  return this.ec.verify(msg, signature, this);
};

KeyPair.prototype.inspect = function inspect() {
  return '<Key priv: ' + (this.priv && this.priv.toString(16, 2)) +
         ' pub: ' + (this.pub && this.pub.inspect()) + ' >';
};

},{"../utils":115,"bn.js":116}],110:[function(require,module,exports){
'use strict';

var BN = require('bn.js');

var utils = require('../utils');
var assert = utils.assert;

function Signature(options, enc) {
  if (options instanceof Signature)
    return options;

  if (this._importDER(options, enc))
    return;

  assert(options.r && options.s, 'Signature without r or s');
  this.r = new BN(options.r, 16);
  this.s = new BN(options.s, 16);
  if (options.recoveryParam === undefined)
    this.recoveryParam = null;
  else
    this.recoveryParam = options.recoveryParam;
}
module.exports = Signature;

function Position() {
  this.place = 0;
}

function getLength(buf, p) {
  var initial = buf[p.place++];
  if (!(initial & 0x80)) {
    return initial;
  }
  var octetLen = initial & 0xf;

  // Indefinite length or overflow
  if (octetLen === 0 || octetLen > 4) {
    return false;
  }

  var val = 0;
  for (var i = 0, off = p.place; i < octetLen; i++, off++) {
    val <<= 8;
    val |= buf[off];
    val >>>= 0;
  }

  // Leading zeroes
  if (val <= 0x7f) {
    return false;
  }

  p.place = off;
  return val;
}

function rmPadding(buf) {
  var i = 0;
  var len = buf.length - 1;
  while (!buf[i] && !(buf[i + 1] & 0x80) && i < len) {
    i++;
  }
  if (i === 0) {
    return buf;
  }
  return buf.slice(i);
}

Signature.prototype._importDER = function _importDER(data, enc) {
  data = utils.toArray(data, enc);
  var p = new Position();
  if (data[p.place++] !== 0x30) {
    return false;
  }
  var len = getLength(data, p);
  if (len === false) {
    return false;
  }
  if ((len + p.place) !== data.length) {
    return false;
  }
  if (data[p.place++] !== 0x02) {
    return false;
  }
  var rlen = getLength(data, p);
  if (rlen === false) {
    return false;
  }
  var r = data.slice(p.place, rlen + p.place);
  p.place += rlen;
  if (data[p.place++] !== 0x02) {
    return false;
  }
  var slen = getLength(data, p);
  if (slen === false) {
    return false;
  }
  if (data.length !== slen + p.place) {
    return false;
  }
  var s = data.slice(p.place, slen + p.place);
  if (r[0] === 0) {
    if (r[1] & 0x80) {
      r = r.slice(1);
    } else {
      // Leading zeroes
      return false;
    }
  }
  if (s[0] === 0) {
    if (s[1] & 0x80) {
      s = s.slice(1);
    } else {
      // Leading zeroes
      return false;
    }
  }

  this.r = new BN(r);
  this.s = new BN(s);
  this.recoveryParam = null;

  return true;
};

function constructLength(arr, len) {
  if (len < 0x80) {
    arr.push(len);
    return;
  }
  var octets = 1 + (Math.log(len) / Math.LN2 >>> 3);
  arr.push(octets | 0x80);
  while (--octets) {
    arr.push((len >>> (octets << 3)) & 0xff);
  }
  arr.push(len);
}

Signature.prototype.toDER = function toDER(enc) {
  var r = this.r.toArray();
  var s = this.s.toArray();

  // Pad values
  if (r[0] & 0x80)
    r = [ 0 ].concat(r);
  // Pad values
  if (s[0] & 0x80)
    s = [ 0 ].concat(s);

  r = rmPadding(r);
  s = rmPadding(s);

  while (!s[0] && !(s[1] & 0x80)) {
    s = s.slice(1);
  }
  var arr = [ 0x02 ];
  constructLength(arr, r.length);
  arr = arr.concat(r);
  arr.push(0x02);
  constructLength(arr, s.length);
  var backHalf = arr.concat(s);
  var res = [ 0x30 ];
  constructLength(res, backHalf.length);
  res = res.concat(backHalf);
  return utils.encode(res, enc);
};

},{"../utils":115,"bn.js":116}],111:[function(require,module,exports){
'use strict';

var hash = require('hash.js');
var curves = require('../curves');
var utils = require('../utils');
var assert = utils.assert;
var parseBytes = utils.parseBytes;
var KeyPair = require('./key');
var Signature = require('./signature');

function EDDSA(curve) {
  assert(curve === 'ed25519', 'only tested with ed25519 so far');

  if (!(this instanceof EDDSA))
    return new EDDSA(curve);

  curve = curves[curve].curve;
  this.curve = curve;
  this.g = curve.g;
  this.g.precompute(curve.n.bitLength() + 1);

  this.pointClass = curve.point().constructor;
  this.encodingLength = Math.ceil(curve.n.bitLength() / 8);
  this.hash = hash.sha512;
}

module.exports = EDDSA;

/**
* @param {Array|String} message - message bytes
* @param {Array|String|KeyPair} secret - secret bytes or a keypair
* @returns {Signature} - signature
*/
EDDSA.prototype.sign = function sign(message, secret) {
  message = parseBytes(message);
  var key = this.keyFromSecret(secret);
  var r = this.hashInt(key.messagePrefix(), message);
  var R = this.g.mul(r);
  var Rencoded = this.encodePoint(R);
  var s_ = this.hashInt(Rencoded, key.pubBytes(), message)
    .mul(key.priv());
  var S = r.add(s_).umod(this.curve.n);
  return this.makeSignature({ R: R, S: S, Rencoded: Rencoded });
};

/**
* @param {Array} message - message bytes
* @param {Array|String|Signature} sig - sig bytes
* @param {Array|String|Point|KeyPair} pub - public key
* @returns {Boolean} - true if public key matches sig of message
*/
EDDSA.prototype.verify = function verify(message, sig, pub) {
  message = parseBytes(message);
  sig = this.makeSignature(sig);
  var key = this.keyFromPublic(pub);
  var h = this.hashInt(sig.Rencoded(), key.pubBytes(), message);
  var SG = this.g.mul(sig.S());
  var RplusAh = sig.R().add(key.pub().mul(h));
  return RplusAh.eq(SG);
};

EDDSA.prototype.hashInt = function hashInt() {
  var hash = this.hash();
  for (var i = 0; i < arguments.length; i++)
    hash.update(arguments[i]);
  return utils.intFromLE(hash.digest()).umod(this.curve.n);
};

EDDSA.prototype.keyFromPublic = function keyFromPublic(pub) {
  return KeyPair.fromPublic(this, pub);
};

EDDSA.prototype.keyFromSecret = function keyFromSecret(secret) {
  return KeyPair.fromSecret(this, secret);
};

EDDSA.prototype.makeSignature = function makeSignature(sig) {
  if (sig instanceof Signature)
    return sig;
  return new Signature(this, sig);
};

/**
* * https://tools.ietf.org/html/draft-josefsson-eddsa-ed25519-03#section-5.2
*
* EDDSA defines methods for encoding and decoding points and integers. These are
* helper convenience methods, that pass along to utility functions implied
* parameters.
*
*/
EDDSA.prototype.encodePoint = function encodePoint(point) {
  var enc = point.getY().toArray('le', this.encodingLength);
  enc[this.encodingLength - 1] |= point.getX().isOdd() ? 0x80 : 0;
  return enc;
};

EDDSA.prototype.decodePoint = function decodePoint(bytes) {
  bytes = utils.parseBytes(bytes);

  var lastIx = bytes.length - 1;
  var normed = bytes.slice(0, lastIx).concat(bytes[lastIx] & ~0x80);
  var xIsOdd = (bytes[lastIx] & 0x80) !== 0;

  var y = utils.intFromLE(normed);
  return this.curve.pointFromY(y, xIsOdd);
};

EDDSA.prototype.encodeInt = function encodeInt(num) {
  return num.toArray('le', this.encodingLength);
};

EDDSA.prototype.decodeInt = function decodeInt(bytes) {
  return utils.intFromLE(bytes);
};

EDDSA.prototype.isPoint = function isPoint(val) {
  return val instanceof this.pointClass;
};

},{"../curves":107,"../utils":115,"./key":112,"./signature":113,"hash.js":122}],112:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var assert = utils.assert;
var parseBytes = utils.parseBytes;
var cachedProperty = utils.cachedProperty;

/**
* @param {EDDSA} eddsa - instance
* @param {Object} params - public/private key parameters
*
* @param {Array<Byte>} [params.secret] - secret seed bytes
* @param {Point} [params.pub] - public key point (aka `A` in eddsa terms)
* @param {Array<Byte>} [params.pub] - public key point encoded as bytes
*
*/
function KeyPair(eddsa, params) {
  this.eddsa = eddsa;
  this._secret = parseBytes(params.secret);
  if (eddsa.isPoint(params.pub))
    this._pub = params.pub;
  else
    this._pubBytes = parseBytes(params.pub);
}

KeyPair.fromPublic = function fromPublic(eddsa, pub) {
  if (pub instanceof KeyPair)
    return pub;
  return new KeyPair(eddsa, { pub: pub });
};

KeyPair.fromSecret = function fromSecret(eddsa, secret) {
  if (secret instanceof KeyPair)
    return secret;
  return new KeyPair(eddsa, { secret: secret });
};

KeyPair.prototype.secret = function secret() {
  return this._secret;
};

cachedProperty(KeyPair, 'pubBytes', function pubBytes() {
  return this.eddsa.encodePoint(this.pub());
});

cachedProperty(KeyPair, 'pub', function pub() {
  if (this._pubBytes)
    return this.eddsa.decodePoint(this._pubBytes);
  return this.eddsa.g.mul(this.priv());
});

cachedProperty(KeyPair, 'privBytes', function privBytes() {
  var eddsa = this.eddsa;
  var hash = this.hash();
  var lastIx = eddsa.encodingLength - 1;

  var a = hash.slice(0, eddsa.encodingLength);
  a[0] &= 248;
  a[lastIx] &= 127;
  a[lastIx] |= 64;

  return a;
});

cachedProperty(KeyPair, 'priv', function priv() {
  return this.eddsa.decodeInt(this.privBytes());
});

cachedProperty(KeyPair, 'hash', function hash() {
  return this.eddsa.hash().update(this.secret()).digest();
});

cachedProperty(KeyPair, 'messagePrefix', function messagePrefix() {
  return this.hash().slice(this.eddsa.encodingLength);
});

KeyPair.prototype.sign = function sign(message) {
  assert(this._secret, 'KeyPair can only verify');
  return this.eddsa.sign(message, this);
};

KeyPair.prototype.verify = function verify(message, sig) {
  return this.eddsa.verify(message, sig, this);
};

KeyPair.prototype.getSecret = function getSecret(enc) {
  assert(this._secret, 'KeyPair is public only');
  return utils.encode(this.secret(), enc);
};

KeyPair.prototype.getPublic = function getPublic(enc) {
  return utils.encode(this.pubBytes(), enc);
};

module.exports = KeyPair;

},{"../utils":115}],113:[function(require,module,exports){
'use strict';

var BN = require('bn.js');
var utils = require('../utils');
var assert = utils.assert;
var cachedProperty = utils.cachedProperty;
var parseBytes = utils.parseBytes;

/**
* @param {EDDSA} eddsa - eddsa instance
* @param {Array<Bytes>|Object} sig -
* @param {Array<Bytes>|Point} [sig.R] - R point as Point or bytes
* @param {Array<Bytes>|bn} [sig.S] - S scalar as bn or bytes
* @param {Array<Bytes>} [sig.Rencoded] - R point encoded
* @param {Array<Bytes>} [sig.Sencoded] - S scalar encoded
*/
function Signature(eddsa, sig) {
  this.eddsa = eddsa;

  if (typeof sig !== 'object')
    sig = parseBytes(sig);

  if (Array.isArray(sig)) {
    sig = {
      R: sig.slice(0, eddsa.encodingLength),
      S: sig.slice(eddsa.encodingLength),
    };
  }

  assert(sig.R && sig.S, 'Signature without R or S');

  if (eddsa.isPoint(sig.R))
    this._R = sig.R;
  if (sig.S instanceof BN)
    this._S = sig.S;

  this._Rencoded = Array.isArray(sig.R) ? sig.R : sig.Rencoded;
  this._Sencoded = Array.isArray(sig.S) ? sig.S : sig.Sencoded;
}

cachedProperty(Signature, 'S', function S() {
  return this.eddsa.decodeInt(this.Sencoded());
});

cachedProperty(Signature, 'R', function R() {
  return this.eddsa.decodePoint(this.Rencoded());
});

cachedProperty(Signature, 'Rencoded', function Rencoded() {
  return this.eddsa.encodePoint(this.R());
});

cachedProperty(Signature, 'Sencoded', function Sencoded() {
  return this.eddsa.encodeInt(this.S());
});

Signature.prototype.toBytes = function toBytes() {
  return this.Rencoded().concat(this.Sencoded());
};

Signature.prototype.toHex = function toHex() {
  return utils.encode(this.toBytes(), 'hex').toUpperCase();
};

module.exports = Signature;

},{"../utils":115,"bn.js":116}],114:[function(require,module,exports){
module.exports = {
  doubles: {
    step: 4,
    points: [
      [
        'e60fce93b59e9ec53011aabc21c23e97b2a31369b87a5ae9c44ee89e2a6dec0a',
        'f7e3507399e595929db99f34f57937101296891e44d23f0be1f32cce69616821',
      ],
      [
        '8282263212c609d9ea2a6e3e172de238d8c39cabd5ac1ca10646e23fd5f51508',
        '11f8a8098557dfe45e8256e830b60ace62d613ac2f7b17bed31b6eaff6e26caf',
      ],
      [
        '175e159f728b865a72f99cc6c6fc846de0b93833fd2222ed73fce5b551e5b739',
        'd3506e0d9e3c79eba4ef97a51ff71f5eacb5955add24345c6efa6ffee9fed695',
      ],
      [
        '363d90d447b00c9c99ceac05b6262ee053441c7e55552ffe526bad8f83ff4640',
        '4e273adfc732221953b445397f3363145b9a89008199ecb62003c7f3bee9de9',
      ],
      [
        '8b4b5f165df3c2be8c6244b5b745638843e4a781a15bcd1b69f79a55dffdf80c',
        '4aad0a6f68d308b4b3fbd7813ab0da04f9e336546162ee56b3eff0c65fd4fd36',
      ],
      [
        '723cbaa6e5db996d6bf771c00bd548c7b700dbffa6c0e77bcb6115925232fcda',
        '96e867b5595cc498a921137488824d6e2660a0653779494801dc069d9eb39f5f',
      ],
      [
        'eebfa4d493bebf98ba5feec812c2d3b50947961237a919839a533eca0e7dd7fa',
        '5d9a8ca3970ef0f269ee7edaf178089d9ae4cdc3a711f712ddfd4fdae1de8999',
      ],
      [
        '100f44da696e71672791d0a09b7bde459f1215a29b3c03bfefd7835b39a48db0',
        'cdd9e13192a00b772ec8f3300c090666b7ff4a18ff5195ac0fbd5cd62bc65a09',
      ],
      [
        'e1031be262c7ed1b1dc9227a4a04c017a77f8d4464f3b3852c8acde6e534fd2d',
        '9d7061928940405e6bb6a4176597535af292dd419e1ced79a44f18f29456a00d',
      ],
      [
        'feea6cae46d55b530ac2839f143bd7ec5cf8b266a41d6af52d5e688d9094696d',
        'e57c6b6c97dce1bab06e4e12bf3ecd5c981c8957cc41442d3155debf18090088',
      ],
      [
        'da67a91d91049cdcb367be4be6ffca3cfeed657d808583de33fa978bc1ec6cb1',
        '9bacaa35481642bc41f463f7ec9780e5dec7adc508f740a17e9ea8e27a68be1d',
      ],
      [
        '53904faa0b334cdda6e000935ef22151ec08d0f7bb11069f57545ccc1a37b7c0',
        '5bc087d0bc80106d88c9eccac20d3c1c13999981e14434699dcb096b022771c8',
      ],
      [
        '8e7bcd0bd35983a7719cca7764ca906779b53a043a9b8bcaeff959f43ad86047',
        '10b7770b2a3da4b3940310420ca9514579e88e2e47fd68b3ea10047e8460372a',
      ],
      [
        '385eed34c1cdff21e6d0818689b81bde71a7f4f18397e6690a841e1599c43862',
        '283bebc3e8ea23f56701de19e9ebf4576b304eec2086dc8cc0458fe5542e5453',
      ],
      [
        '6f9d9b803ecf191637c73a4413dfa180fddf84a5947fbc9c606ed86c3fac3a7',
        '7c80c68e603059ba69b8e2a30e45c4d47ea4dd2f5c281002d86890603a842160',
      ],
      [
        '3322d401243c4e2582a2147c104d6ecbf774d163db0f5e5313b7e0e742d0e6bd',
        '56e70797e9664ef5bfb019bc4ddaf9b72805f63ea2873af624f3a2e96c28b2a0',
      ],
      [
        '85672c7d2de0b7da2bd1770d89665868741b3f9af7643397721d74d28134ab83',
        '7c481b9b5b43b2eb6374049bfa62c2e5e77f17fcc5298f44c8e3094f790313a6',
      ],
      [
        '948bf809b1988a46b06c9f1919413b10f9226c60f668832ffd959af60c82a0a',
        '53a562856dcb6646dc6b74c5d1c3418c6d4dff08c97cd2bed4cb7f88d8c8e589',
      ],
      [
        '6260ce7f461801c34f067ce0f02873a8f1b0e44dfc69752accecd819f38fd8e8',
        'bc2da82b6fa5b571a7f09049776a1ef7ecd292238051c198c1a84e95b2b4ae17',
      ],
      [
        'e5037de0afc1d8d43d8348414bbf4103043ec8f575bfdc432953cc8d2037fa2d',
        '4571534baa94d3b5f9f98d09fb990bddbd5f5b03ec481f10e0e5dc841d755bda',
      ],
      [
        'e06372b0f4a207adf5ea905e8f1771b4e7e8dbd1c6a6c5b725866a0ae4fce725',
        '7a908974bce18cfe12a27bb2ad5a488cd7484a7787104870b27034f94eee31dd',
      ],
      [
        '213c7a715cd5d45358d0bbf9dc0ce02204b10bdde2a3f58540ad6908d0559754',
        '4b6dad0b5ae462507013ad06245ba190bb4850f5f36a7eeddff2c27534b458f2',
      ],
      [
        '4e7c272a7af4b34e8dbb9352a5419a87e2838c70adc62cddf0cc3a3b08fbd53c',
        '17749c766c9d0b18e16fd09f6def681b530b9614bff7dd33e0b3941817dcaae6',
      ],
      [
        'fea74e3dbe778b1b10f238ad61686aa5c76e3db2be43057632427e2840fb27b6',
        '6e0568db9b0b13297cf674deccb6af93126b596b973f7b77701d3db7f23cb96f',
      ],
      [
        '76e64113f677cf0e10a2570d599968d31544e179b760432952c02a4417bdde39',
        'c90ddf8dee4e95cf577066d70681f0d35e2a33d2b56d2032b4b1752d1901ac01',
      ],
      [
        'c738c56b03b2abe1e8281baa743f8f9a8f7cc643df26cbee3ab150242bcbb891',
        '893fb578951ad2537f718f2eacbfbbbb82314eef7880cfe917e735d9699a84c3',
      ],
      [
        'd895626548b65b81e264c7637c972877d1d72e5f3a925014372e9f6588f6c14b',
        'febfaa38f2bc7eae728ec60818c340eb03428d632bb067e179363ed75d7d991f',
      ],
      [
        'b8da94032a957518eb0f6433571e8761ceffc73693e84edd49150a564f676e03',
        '2804dfa44805a1e4d7c99cc9762808b092cc584d95ff3b511488e4e74efdf6e7',
      ],
      [
        'e80fea14441fb33a7d8adab9475d7fab2019effb5156a792f1a11778e3c0df5d',
        'eed1de7f638e00771e89768ca3ca94472d155e80af322ea9fcb4291b6ac9ec78',
      ],
      [
        'a301697bdfcd704313ba48e51d567543f2a182031efd6915ddc07bbcc4e16070',
        '7370f91cfb67e4f5081809fa25d40f9b1735dbf7c0a11a130c0d1a041e177ea1',
      ],
      [
        '90ad85b389d6b936463f9d0512678de208cc330b11307fffab7ac63e3fb04ed4',
        'e507a3620a38261affdcbd9427222b839aefabe1582894d991d4d48cb6ef150',
      ],
      [
        '8f68b9d2f63b5f339239c1ad981f162ee88c5678723ea3351b7b444c9ec4c0da',
        '662a9f2dba063986de1d90c2b6be215dbbea2cfe95510bfdf23cbf79501fff82',
      ],
      [
        'e4f3fb0176af85d65ff99ff9198c36091f48e86503681e3e6686fd5053231e11',
        '1e63633ad0ef4f1c1661a6d0ea02b7286cc7e74ec951d1c9822c38576feb73bc',
      ],
      [
        '8c00fa9b18ebf331eb961537a45a4266c7034f2f0d4e1d0716fb6eae20eae29e',
        'efa47267fea521a1a9dc343a3736c974c2fadafa81e36c54e7d2a4c66702414b',
      ],
      [
        'e7a26ce69dd4829f3e10cec0a9e98ed3143d084f308b92c0997fddfc60cb3e41',
        '2a758e300fa7984b471b006a1aafbb18d0a6b2c0420e83e20e8a9421cf2cfd51',
      ],
      [
        'b6459e0ee3662ec8d23540c223bcbdc571cbcb967d79424f3cf29eb3de6b80ef',
        '67c876d06f3e06de1dadf16e5661db3c4b3ae6d48e35b2ff30bf0b61a71ba45',
      ],
      [
        'd68a80c8280bb840793234aa118f06231d6f1fc67e73c5a5deda0f5b496943e8',
        'db8ba9fff4b586d00c4b1f9177b0e28b5b0e7b8f7845295a294c84266b133120',
      ],
      [
        '324aed7df65c804252dc0270907a30b09612aeb973449cea4095980fc28d3d5d',
        '648a365774b61f2ff130c0c35aec1f4f19213b0c7e332843967224af96ab7c84',
      ],
      [
        '4df9c14919cde61f6d51dfdbe5fee5dceec4143ba8d1ca888e8bd373fd054c96',
        '35ec51092d8728050974c23a1d85d4b5d506cdc288490192ebac06cad10d5d',
      ],
      [
        '9c3919a84a474870faed8a9c1cc66021523489054d7f0308cbfc99c8ac1f98cd',
        'ddb84f0f4a4ddd57584f044bf260e641905326f76c64c8e6be7e5e03d4fc599d',
      ],
      [
        '6057170b1dd12fdf8de05f281d8e06bb91e1493a8b91d4cc5a21382120a959e5',
        '9a1af0b26a6a4807add9a2daf71df262465152bc3ee24c65e899be932385a2a8',
      ],
      [
        'a576df8e23a08411421439a4518da31880cef0fba7d4df12b1a6973eecb94266',
        '40a6bf20e76640b2c92b97afe58cd82c432e10a7f514d9f3ee8be11ae1b28ec8',
      ],
      [
        '7778a78c28dec3e30a05fe9629de8c38bb30d1f5cf9a3a208f763889be58ad71',
        '34626d9ab5a5b22ff7098e12f2ff580087b38411ff24ac563b513fc1fd9f43ac',
      ],
      [
        '928955ee637a84463729fd30e7afd2ed5f96274e5ad7e5cb09eda9c06d903ac',
        'c25621003d3f42a827b78a13093a95eeac3d26efa8a8d83fc5180e935bcd091f',
      ],
      [
        '85d0fef3ec6db109399064f3a0e3b2855645b4a907ad354527aae75163d82751',
        '1f03648413a38c0be29d496e582cf5663e8751e96877331582c237a24eb1f962',
      ],
      [
        'ff2b0dce97eece97c1c9b6041798b85dfdfb6d8882da20308f5404824526087e',
        '493d13fef524ba188af4c4dc54d07936c7b7ed6fb90e2ceb2c951e01f0c29907',
      ],
      [
        '827fbbe4b1e880ea9ed2b2e6301b212b57f1ee148cd6dd28780e5e2cf856e241',
        'c60f9c923c727b0b71bef2c67d1d12687ff7a63186903166d605b68baec293ec',
      ],
      [
        'eaa649f21f51bdbae7be4ae34ce6e5217a58fdce7f47f9aa7f3b58fa2120e2b3',
        'be3279ed5bbbb03ac69a80f89879aa5a01a6b965f13f7e59d47a5305ba5ad93d',
      ],
      [
        'e4a42d43c5cf169d9391df6decf42ee541b6d8f0c9a137401e23632dda34d24f',
        '4d9f92e716d1c73526fc99ccfb8ad34ce886eedfa8d8e4f13a7f7131deba9414',
      ],
      [
        '1ec80fef360cbdd954160fadab352b6b92b53576a88fea4947173b9d4300bf19',
        'aeefe93756b5340d2f3a4958a7abbf5e0146e77f6295a07b671cdc1cc107cefd',
      ],
      [
        '146a778c04670c2f91b00af4680dfa8bce3490717d58ba889ddb5928366642be',
        'b318e0ec3354028add669827f9d4b2870aaa971d2f7e5ed1d0b297483d83efd0',
      ],
      [
        'fa50c0f61d22e5f07e3acebb1aa07b128d0012209a28b9776d76a8793180eef9',
        '6b84c6922397eba9b72cd2872281a68a5e683293a57a213b38cd8d7d3f4f2811',
      ],
      [
        'da1d61d0ca721a11b1a5bf6b7d88e8421a288ab5d5bba5220e53d32b5f067ec2',
        '8157f55a7c99306c79c0766161c91e2966a73899d279b48a655fba0f1ad836f1',
      ],
      [
        'a8e282ff0c9706907215ff98e8fd416615311de0446f1e062a73b0610d064e13',
        '7f97355b8db81c09abfb7f3c5b2515888b679a3e50dd6bd6cef7c73111f4cc0c',
      ],
      [
        '174a53b9c9a285872d39e56e6913cab15d59b1fa512508c022f382de8319497c',
        'ccc9dc37abfc9c1657b4155f2c47f9e6646b3a1d8cb9854383da13ac079afa73',
      ],
      [
        '959396981943785c3d3e57edf5018cdbe039e730e4918b3d884fdff09475b7ba',
        '2e7e552888c331dd8ba0386a4b9cd6849c653f64c8709385e9b8abf87524f2fd',
      ],
      [
        'd2a63a50ae401e56d645a1153b109a8fcca0a43d561fba2dbb51340c9d82b151',
        'e82d86fb6443fcb7565aee58b2948220a70f750af484ca52d4142174dcf89405',
      ],
      [
        '64587e2335471eb890ee7896d7cfdc866bacbdbd3839317b3436f9b45617e073',
        'd99fcdd5bf6902e2ae96dd6447c299a185b90a39133aeab358299e5e9faf6589',
      ],
      [
        '8481bde0e4e4d885b3a546d3e549de042f0aa6cea250e7fd358d6c86dd45e458',
        '38ee7b8cba5404dd84a25bf39cecb2ca900a79c42b262e556d64b1b59779057e',
      ],
      [
        '13464a57a78102aa62b6979ae817f4637ffcfed3c4b1ce30bcd6303f6caf666b',
        '69be159004614580ef7e433453ccb0ca48f300a81d0942e13f495a907f6ecc27',
      ],
      [
        'bc4a9df5b713fe2e9aef430bcc1dc97a0cd9ccede2f28588cada3a0d2d83f366',
        'd3a81ca6e785c06383937adf4b798caa6e8a9fbfa547b16d758d666581f33c1',
      ],
      [
        '8c28a97bf8298bc0d23d8c749452a32e694b65e30a9472a3954ab30fe5324caa',
        '40a30463a3305193378fedf31f7cc0eb7ae784f0451cb9459e71dc73cbef9482',
      ],
      [
        '8ea9666139527a8c1dd94ce4f071fd23c8b350c5a4bb33748c4ba111faccae0',
        '620efabbc8ee2782e24e7c0cfb95c5d735b783be9cf0f8e955af34a30e62b945',
      ],
      [
        'dd3625faef5ba06074669716bbd3788d89bdde815959968092f76cc4eb9a9787',
        '7a188fa3520e30d461da2501045731ca941461982883395937f68d00c644a573',
      ],
      [
        'f710d79d9eb962297e4f6232b40e8f7feb2bc63814614d692c12de752408221e',
        'ea98e67232d3b3295d3b535532115ccac8612c721851617526ae47a9c77bfc82',
      ],
    ],
  },
  naf: {
    wnd: 7,
    points: [
      [
        'f9308a019258c31049344f85f89d5229b531c845836f99b08601f113bce036f9',
        '388f7b0f632de8140fe337e62a37f3566500a99934c2231b6cb9fd7584b8e672',
      ],
      [
        '2f8bde4d1a07209355b4a7250a5c5128e88b84bddc619ab7cba8d569b240efe4',
        'd8ac222636e5e3d6d4dba9dda6c9c426f788271bab0d6840dca87d3aa6ac62d6',
      ],
      [
        '5cbdf0646e5db4eaa398f365f2ea7a0e3d419b7e0330e39ce92bddedcac4f9bc',
        '6aebca40ba255960a3178d6d861a54dba813d0b813fde7b5a5082628087264da',
      ],
      [
        'acd484e2f0c7f65309ad178a9f559abde09796974c57e714c35f110dfc27ccbe',
        'cc338921b0a7d9fd64380971763b61e9add888a4375f8e0f05cc262ac64f9c37',
      ],
      [
        '774ae7f858a9411e5ef4246b70c65aac5649980be5c17891bbec17895da008cb',
        'd984a032eb6b5e190243dd56d7b7b365372db1e2dff9d6a8301d74c9c953c61b',
      ],
      [
        'f28773c2d975288bc7d1d205c3748651b075fbc6610e58cddeeddf8f19405aa8',
        'ab0902e8d880a89758212eb65cdaf473a1a06da521fa91f29b5cb52db03ed81',
      ],
      [
        'd7924d4f7d43ea965a465ae3095ff41131e5946f3c85f79e44adbcf8e27e080e',
        '581e2872a86c72a683842ec228cc6defea40af2bd896d3a5c504dc9ff6a26b58',
      ],
      [
        'defdea4cdb677750a420fee807eacf21eb9898ae79b9768766e4faa04a2d4a34',
        '4211ab0694635168e997b0ead2a93daeced1f4a04a95c0f6cfb199f69e56eb77',
      ],
      [
        '2b4ea0a797a443d293ef5cff444f4979f06acfebd7e86d277475656138385b6c',
        '85e89bc037945d93b343083b5a1c86131a01f60c50269763b570c854e5c09b7a',
      ],
      [
        '352bbf4a4cdd12564f93fa332ce333301d9ad40271f8107181340aef25be59d5',
        '321eb4075348f534d59c18259dda3e1f4a1b3b2e71b1039c67bd3d8bcf81998c',
      ],
      [
        '2fa2104d6b38d11b0230010559879124e42ab8dfeff5ff29dc9cdadd4ecacc3f',
        '2de1068295dd865b64569335bd5dd80181d70ecfc882648423ba76b532b7d67',
      ],
      [
        '9248279b09b4d68dab21a9b066edda83263c3d84e09572e269ca0cd7f5453714',
        '73016f7bf234aade5d1aa71bdea2b1ff3fc0de2a887912ffe54a32ce97cb3402',
      ],
      [
        'daed4f2be3a8bf278e70132fb0beb7522f570e144bf615c07e996d443dee8729',
        'a69dce4a7d6c98e8d4a1aca87ef8d7003f83c230f3afa726ab40e52290be1c55',
      ],
      [
        'c44d12c7065d812e8acf28d7cbb19f9011ecd9e9fdf281b0e6a3b5e87d22e7db',
        '2119a460ce326cdc76c45926c982fdac0e106e861edf61c5a039063f0e0e6482',
      ],
      [
        '6a245bf6dc698504c89a20cfded60853152b695336c28063b61c65cbd269e6b4',
        'e022cf42c2bd4a708b3f5126f16a24ad8b33ba48d0423b6efd5e6348100d8a82',
      ],
      [
        '1697ffa6fd9de627c077e3d2fe541084ce13300b0bec1146f95ae57f0d0bd6a5',
        'b9c398f186806f5d27561506e4557433a2cf15009e498ae7adee9d63d01b2396',
      ],
      [
        '605bdb019981718b986d0f07e834cb0d9deb8360ffb7f61df982345ef27a7479',
        '2972d2de4f8d20681a78d93ec96fe23c26bfae84fb14db43b01e1e9056b8c49',
      ],
      [
        '62d14dab4150bf497402fdc45a215e10dcb01c354959b10cfe31c7e9d87ff33d',
        '80fc06bd8cc5b01098088a1950eed0db01aa132967ab472235f5642483b25eaf',
      ],
      [
        '80c60ad0040f27dade5b4b06c408e56b2c50e9f56b9b8b425e555c2f86308b6f',
        '1c38303f1cc5c30f26e66bad7fe72f70a65eed4cbe7024eb1aa01f56430bd57a',
      ],
      [
        '7a9375ad6167ad54aa74c6348cc54d344cc5dc9487d847049d5eabb0fa03c8fb',
        'd0e3fa9eca8726909559e0d79269046bdc59ea10c70ce2b02d499ec224dc7f7',
      ],
      [
        'd528ecd9b696b54c907a9ed045447a79bb408ec39b68df504bb51f459bc3ffc9',
        'eecf41253136e5f99966f21881fd656ebc4345405c520dbc063465b521409933',
      ],
      [
        '49370a4b5f43412ea25f514e8ecdad05266115e4a7ecb1387231808f8b45963',
        '758f3f41afd6ed428b3081b0512fd62a54c3f3afbb5b6764b653052a12949c9a',
      ],
      [
        '77f230936ee88cbbd73df930d64702ef881d811e0e1498e2f1c13eb1fc345d74',
        '958ef42a7886b6400a08266e9ba1b37896c95330d97077cbbe8eb3c7671c60d6',
      ],
      [
        'f2dac991cc4ce4b9ea44887e5c7c0bce58c80074ab9d4dbaeb28531b7739f530',
        'e0dedc9b3b2f8dad4da1f32dec2531df9eb5fbeb0598e4fd1a117dba703a3c37',
      ],
      [
        '463b3d9f662621fb1b4be8fbbe2520125a216cdfc9dae3debcba4850c690d45b',
        '5ed430d78c296c3543114306dd8622d7c622e27c970a1de31cb377b01af7307e',
      ],
      [
        'f16f804244e46e2a09232d4aff3b59976b98fac14328a2d1a32496b49998f247',
        'cedabd9b82203f7e13d206fcdf4e33d92a6c53c26e5cce26d6579962c4e31df6',
      ],
      [
        'caf754272dc84563b0352b7a14311af55d245315ace27c65369e15f7151d41d1',
        'cb474660ef35f5f2a41b643fa5e460575f4fa9b7962232a5c32f908318a04476',
      ],
      [
        '2600ca4b282cb986f85d0f1709979d8b44a09c07cb86d7c124497bc86f082120',
        '4119b88753c15bd6a693b03fcddbb45d5ac6be74ab5f0ef44b0be9475a7e4b40',
      ],
      [
        '7635ca72d7e8432c338ec53cd12220bc01c48685e24f7dc8c602a7746998e435',
        '91b649609489d613d1d5e590f78e6d74ecfc061d57048bad9e76f302c5b9c61',
      ],
      [
        '754e3239f325570cdbbf4a87deee8a66b7f2b33479d468fbc1a50743bf56cc18',
        '673fb86e5bda30fb3cd0ed304ea49a023ee33d0197a695d0c5d98093c536683',
      ],
      [
        'e3e6bd1071a1e96aff57859c82d570f0330800661d1c952f9fe2694691d9b9e8',
        '59c9e0bba394e76f40c0aa58379a3cb6a5a2283993e90c4167002af4920e37f5',
      ],
      [
        '186b483d056a033826ae73d88f732985c4ccb1f32ba35f4b4cc47fdcf04aa6eb',
        '3b952d32c67cf77e2e17446e204180ab21fb8090895138b4a4a797f86e80888b',
      ],
      [
        'df9d70a6b9876ce544c98561f4be4f725442e6d2b737d9c91a8321724ce0963f',
        '55eb2dafd84d6ccd5f862b785dc39d4ab157222720ef9da217b8c45cf2ba2417',
      ],
      [
        '5edd5cc23c51e87a497ca815d5dce0f8ab52554f849ed8995de64c5f34ce7143',
        'efae9c8dbc14130661e8cec030c89ad0c13c66c0d17a2905cdc706ab7399a868',
      ],
      [
        '290798c2b6476830da12fe02287e9e777aa3fba1c355b17a722d362f84614fba',
        'e38da76dcd440621988d00bcf79af25d5b29c094db2a23146d003afd41943e7a',
      ],
      [
        'af3c423a95d9f5b3054754efa150ac39cd29552fe360257362dfdecef4053b45',
        'f98a3fd831eb2b749a93b0e6f35cfb40c8cd5aa667a15581bc2feded498fd9c6',
      ],
      [
        '766dbb24d134e745cccaa28c99bf274906bb66b26dcf98df8d2fed50d884249a',
        '744b1152eacbe5e38dcc887980da38b897584a65fa06cedd2c924f97cbac5996',
      ],
      [
        '59dbf46f8c94759ba21277c33784f41645f7b44f6c596a58ce92e666191abe3e',
        'c534ad44175fbc300f4ea6ce648309a042ce739a7919798cd85e216c4a307f6e',
      ],
      [
        'f13ada95103c4537305e691e74e9a4a8dd647e711a95e73cb62dc6018cfd87b8',
        'e13817b44ee14de663bf4bc808341f326949e21a6a75c2570778419bdaf5733d',
      ],
      [
        '7754b4fa0e8aced06d4167a2c59cca4cda1869c06ebadfb6488550015a88522c',
        '30e93e864e669d82224b967c3020b8fa8d1e4e350b6cbcc537a48b57841163a2',
      ],
      [
        '948dcadf5990e048aa3874d46abef9d701858f95de8041d2a6828c99e2262519',
        'e491a42537f6e597d5d28a3224b1bc25df9154efbd2ef1d2cbba2cae5347d57e',
      ],
      [
        '7962414450c76c1689c7b48f8202ec37fb224cf5ac0bfa1570328a8a3d7c77ab',
        '100b610ec4ffb4760d5c1fc133ef6f6b12507a051f04ac5760afa5b29db83437',
      ],
      [
        '3514087834964b54b15b160644d915485a16977225b8847bb0dd085137ec47ca',
        'ef0afbb2056205448e1652c48e8127fc6039e77c15c2378b7e7d15a0de293311',
      ],
      [
        'd3cc30ad6b483e4bc79ce2c9dd8bc54993e947eb8df787b442943d3f7b527eaf',
        '8b378a22d827278d89c5e9be8f9508ae3c2ad46290358630afb34db04eede0a4',
      ],
      [
        '1624d84780732860ce1c78fcbfefe08b2b29823db913f6493975ba0ff4847610',
        '68651cf9b6da903e0914448c6cd9d4ca896878f5282be4c8cc06e2a404078575',
      ],
      [
        '733ce80da955a8a26902c95633e62a985192474b5af207da6df7b4fd5fc61cd4',
        'f5435a2bd2badf7d485a4d8b8db9fcce3e1ef8e0201e4578c54673bc1dc5ea1d',
      ],
      [
        '15d9441254945064cf1a1c33bbd3b49f8966c5092171e699ef258dfab81c045c',
        'd56eb30b69463e7234f5137b73b84177434800bacebfc685fc37bbe9efe4070d',
      ],
      [
        'a1d0fcf2ec9de675b612136e5ce70d271c21417c9d2b8aaaac138599d0717940',
        'edd77f50bcb5a3cab2e90737309667f2641462a54070f3d519212d39c197a629',
      ],
      [
        'e22fbe15c0af8ccc5780c0735f84dbe9a790badee8245c06c7ca37331cb36980',
        'a855babad5cd60c88b430a69f53a1a7a38289154964799be43d06d77d31da06',
      ],
      [
        '311091dd9860e8e20ee13473c1155f5f69635e394704eaa74009452246cfa9b3',
        '66db656f87d1f04fffd1f04788c06830871ec5a64feee685bd80f0b1286d8374',
      ],
      [
        '34c1fd04d301be89b31c0442d3e6ac24883928b45a9340781867d4232ec2dbdf',
        '9414685e97b1b5954bd46f730174136d57f1ceeb487443dc5321857ba73abee',
      ],
      [
        'f219ea5d6b54701c1c14de5b557eb42a8d13f3abbcd08affcc2a5e6b049b8d63',
        '4cb95957e83d40b0f73af4544cccf6b1f4b08d3c07b27fb8d8c2962a400766d1',
      ],
      [
        'd7b8740f74a8fbaab1f683db8f45de26543a5490bca627087236912469a0b448',
        'fa77968128d9c92ee1010f337ad4717eff15db5ed3c049b3411e0315eaa4593b',
      ],
      [
        '32d31c222f8f6f0ef86f7c98d3a3335ead5bcd32abdd94289fe4d3091aa824bf',
        '5f3032f5892156e39ccd3d7915b9e1da2e6dac9e6f26e961118d14b8462e1661',
      ],
      [
        '7461f371914ab32671045a155d9831ea8793d77cd59592c4340f86cbc18347b5',
        '8ec0ba238b96bec0cbdddcae0aa442542eee1ff50c986ea6b39847b3cc092ff6',
      ],
      [
        'ee079adb1df1860074356a25aa38206a6d716b2c3e67453d287698bad7b2b2d6',
        '8dc2412aafe3be5c4c5f37e0ecc5f9f6a446989af04c4e25ebaac479ec1c8c1e',
      ],
      [
        '16ec93e447ec83f0467b18302ee620f7e65de331874c9dc72bfd8616ba9da6b5',
        '5e4631150e62fb40d0e8c2a7ca5804a39d58186a50e497139626778e25b0674d',
      ],
      [
        'eaa5f980c245f6f038978290afa70b6bd8855897f98b6aa485b96065d537bd99',
        'f65f5d3e292c2e0819a528391c994624d784869d7e6ea67fb18041024edc07dc',
      ],
      [
        '78c9407544ac132692ee1910a02439958ae04877151342ea96c4b6b35a49f51',
        'f3e0319169eb9b85d5404795539a5e68fa1fbd583c064d2462b675f194a3ddb4',
      ],
      [
        '494f4be219a1a77016dcd838431aea0001cdc8ae7a6fc688726578d9702857a5',
        '42242a969283a5f339ba7f075e36ba2af925ce30d767ed6e55f4b031880d562c',
      ],
      [
        'a598a8030da6d86c6bc7f2f5144ea549d28211ea58faa70ebf4c1e665c1fe9b5',
        '204b5d6f84822c307e4b4a7140737aec23fc63b65b35f86a10026dbd2d864e6b',
      ],
      [
        'c41916365abb2b5d09192f5f2dbeafec208f020f12570a184dbadc3e58595997',
        '4f14351d0087efa49d245b328984989d5caf9450f34bfc0ed16e96b58fa9913',
      ],
      [
        '841d6063a586fa475a724604da03bc5b92a2e0d2e0a36acfe4c73a5514742881',
        '73867f59c0659e81904f9a1c7543698e62562d6744c169ce7a36de01a8d6154',
      ],
      [
        '5e95bb399a6971d376026947f89bde2f282b33810928be4ded112ac4d70e20d5',
        '39f23f366809085beebfc71181313775a99c9aed7d8ba38b161384c746012865',
      ],
      [
        '36e4641a53948fd476c39f8a99fd974e5ec07564b5315d8bf99471bca0ef2f66',
        'd2424b1b1abe4eb8164227b085c9aa9456ea13493fd563e06fd51cf5694c78fc',
      ],
      [
        '336581ea7bfbbb290c191a2f507a41cf5643842170e914faeab27c2c579f726',
        'ead12168595fe1be99252129b6e56b3391f7ab1410cd1e0ef3dcdcabd2fda224',
      ],
      [
        '8ab89816dadfd6b6a1f2634fcf00ec8403781025ed6890c4849742706bd43ede',
        '6fdcef09f2f6d0a044e654aef624136f503d459c3e89845858a47a9129cdd24e',
      ],
      [
        '1e33f1a746c9c5778133344d9299fcaa20b0938e8acff2544bb40284b8c5fb94',
        '60660257dd11b3aa9c8ed618d24edff2306d320f1d03010e33a7d2057f3b3b6',
      ],
      [
        '85b7c1dcb3cec1b7ee7f30ded79dd20a0ed1f4cc18cbcfcfa410361fd8f08f31',
        '3d98a9cdd026dd43f39048f25a8847f4fcafad1895d7a633c6fed3c35e999511',
      ],
      [
        '29df9fbd8d9e46509275f4b125d6d45d7fbe9a3b878a7af872a2800661ac5f51',
        'b4c4fe99c775a606e2d8862179139ffda61dc861c019e55cd2876eb2a27d84b',
      ],
      [
        'a0b1cae06b0a847a3fea6e671aaf8adfdfe58ca2f768105c8082b2e449fce252',
        'ae434102edde0958ec4b19d917a6a28e6b72da1834aff0e650f049503a296cf2',
      ],
      [
        '4e8ceafb9b3e9a136dc7ff67e840295b499dfb3b2133e4ba113f2e4c0e121e5',
        'cf2174118c8b6d7a4b48f6d534ce5c79422c086a63460502b827ce62a326683c',
      ],
      [
        'd24a44e047e19b6f5afb81c7ca2f69080a5076689a010919f42725c2b789a33b',
        '6fb8d5591b466f8fc63db50f1c0f1c69013f996887b8244d2cdec417afea8fa3',
      ],
      [
        'ea01606a7a6c9cdd249fdfcfacb99584001edd28abbab77b5104e98e8e3b35d4',
        '322af4908c7312b0cfbfe369f7a7b3cdb7d4494bc2823700cfd652188a3ea98d',
      ],
      [
        'af8addbf2b661c8a6c6328655eb96651252007d8c5ea31be4ad196de8ce2131f',
        '6749e67c029b85f52a034eafd096836b2520818680e26ac8f3dfbcdb71749700',
      ],
      [
        'e3ae1974566ca06cc516d47e0fb165a674a3dabcfca15e722f0e3450f45889',
        '2aeabe7e4531510116217f07bf4d07300de97e4874f81f533420a72eeb0bd6a4',
      ],
      [
        '591ee355313d99721cf6993ffed1e3e301993ff3ed258802075ea8ced397e246',
        'b0ea558a113c30bea60fc4775460c7901ff0b053d25ca2bdeee98f1a4be5d196',
      ],
      [
        '11396d55fda54c49f19aa97318d8da61fa8584e47b084945077cf03255b52984',
        '998c74a8cd45ac01289d5833a7beb4744ff536b01b257be4c5767bea93ea57a4',
      ],
      [
        '3c5d2a1ba39c5a1790000738c9e0c40b8dcdfd5468754b6405540157e017aa7a',
        'b2284279995a34e2f9d4de7396fc18b80f9b8b9fdd270f6661f79ca4c81bd257',
      ],
      [
        'cc8704b8a60a0defa3a99a7299f2e9c3fbc395afb04ac078425ef8a1793cc030',
        'bdd46039feed17881d1e0862db347f8cf395b74fc4bcdc4e940b74e3ac1f1b13',
      ],
      [
        'c533e4f7ea8555aacd9777ac5cad29b97dd4defccc53ee7ea204119b2889b197',
        '6f0a256bc5efdf429a2fb6242f1a43a2d9b925bb4a4b3a26bb8e0f45eb596096',
      ],
      [
        'c14f8f2ccb27d6f109f6d08d03cc96a69ba8c34eec07bbcf566d48e33da6593',
        'c359d6923bb398f7fd4473e16fe1c28475b740dd098075e6c0e8649113dc3a38',
      ],
      [
        'a6cbc3046bc6a450bac24789fa17115a4c9739ed75f8f21ce441f72e0b90e6ef',
        '21ae7f4680e889bb130619e2c0f95a360ceb573c70603139862afd617fa9b9f',
      ],
      [
        '347d6d9a02c48927ebfb86c1359b1caf130a3c0267d11ce6344b39f99d43cc38',
        '60ea7f61a353524d1c987f6ecec92f086d565ab687870cb12689ff1e31c74448',
      ],
      [
        'da6545d2181db8d983f7dcb375ef5866d47c67b1bf31c8cf855ef7437b72656a',
        '49b96715ab6878a79e78f07ce5680c5d6673051b4935bd897fea824b77dc208a',
      ],
      [
        'c40747cc9d012cb1a13b8148309c6de7ec25d6945d657146b9d5994b8feb1111',
        '5ca560753be2a12fc6de6caf2cb489565db936156b9514e1bb5e83037e0fa2d4',
      ],
      [
        '4e42c8ec82c99798ccf3a610be870e78338c7f713348bd34c8203ef4037f3502',
        '7571d74ee5e0fb92a7a8b33a07783341a5492144cc54bcc40a94473693606437',
      ],
      [
        '3775ab7089bc6af823aba2e1af70b236d251cadb0c86743287522a1b3b0dedea',
        'be52d107bcfa09d8bcb9736a828cfa7fac8db17bf7a76a2c42ad961409018cf7',
      ],
      [
        'cee31cbf7e34ec379d94fb814d3d775ad954595d1314ba8846959e3e82f74e26',
        '8fd64a14c06b589c26b947ae2bcf6bfa0149ef0be14ed4d80f448a01c43b1c6d',
      ],
      [
        'b4f9eaea09b6917619f6ea6a4eb5464efddb58fd45b1ebefcdc1a01d08b47986',
        '39e5c9925b5a54b07433a4f18c61726f8bb131c012ca542eb24a8ac07200682a',
      ],
      [
        'd4263dfc3d2df923a0179a48966d30ce84e2515afc3dccc1b77907792ebcc60e',
        '62dfaf07a0f78feb30e30d6295853ce189e127760ad6cf7fae164e122a208d54',
      ],
      [
        '48457524820fa65a4f8d35eb6930857c0032acc0a4a2de422233eeda897612c4',
        '25a748ab367979d98733c38a1fa1c2e7dc6cc07db2d60a9ae7a76aaa49bd0f77',
      ],
      [
        'dfeeef1881101f2cb11644f3a2afdfc2045e19919152923f367a1767c11cceda',
        'ecfb7056cf1de042f9420bab396793c0c390bde74b4bbdff16a83ae09a9a7517',
      ],
      [
        '6d7ef6b17543f8373c573f44e1f389835d89bcbc6062ced36c82df83b8fae859',
        'cd450ec335438986dfefa10c57fea9bcc521a0959b2d80bbf74b190dca712d10',
      ],
      [
        'e75605d59102a5a2684500d3b991f2e3f3c88b93225547035af25af66e04541f',
        'f5c54754a8f71ee540b9b48728473e314f729ac5308b06938360990e2bfad125',
      ],
      [
        'eb98660f4c4dfaa06a2be453d5020bc99a0c2e60abe388457dd43fefb1ed620c',
        '6cb9a8876d9cb8520609af3add26cd20a0a7cd8a9411131ce85f44100099223e',
      ],
      [
        '13e87b027d8514d35939f2e6892b19922154596941888336dc3563e3b8dba942',
        'fef5a3c68059a6dec5d624114bf1e91aac2b9da568d6abeb2570d55646b8adf1',
      ],
      [
        'ee163026e9fd6fe017c38f06a5be6fc125424b371ce2708e7bf4491691e5764a',
        '1acb250f255dd61c43d94ccc670d0f58f49ae3fa15b96623e5430da0ad6c62b2',
      ],
      [
        'b268f5ef9ad51e4d78de3a750c2dc89b1e626d43505867999932e5db33af3d80',
        '5f310d4b3c99b9ebb19f77d41c1dee018cf0d34fd4191614003e945a1216e423',
      ],
      [
        'ff07f3118a9df035e9fad85eb6c7bfe42b02f01ca99ceea3bf7ffdba93c4750d',
        '438136d603e858a3a5c440c38eccbaddc1d2942114e2eddd4740d098ced1f0d8',
      ],
      [
        '8d8b9855c7c052a34146fd20ffb658bea4b9f69e0d825ebec16e8c3ce2b526a1',
        'cdb559eedc2d79f926baf44fb84ea4d44bcf50fee51d7ceb30e2e7f463036758',
      ],
      [
        '52db0b5384dfbf05bfa9d472d7ae26dfe4b851ceca91b1eba54263180da32b63',
        'c3b997d050ee5d423ebaf66a6db9f57b3180c902875679de924b69d84a7b375',
      ],
      [
        'e62f9490d3d51da6395efd24e80919cc7d0f29c3f3fa48c6fff543becbd43352',
        '6d89ad7ba4876b0b22c2ca280c682862f342c8591f1daf5170e07bfd9ccafa7d',
      ],
      [
        '7f30ea2476b399b4957509c88f77d0191afa2ff5cb7b14fd6d8e7d65aaab1193',
        'ca5ef7d4b231c94c3b15389a5f6311e9daff7bb67b103e9880ef4bff637acaec',
      ],
      [
        '5098ff1e1d9f14fb46a210fada6c903fef0fb7b4a1dd1d9ac60a0361800b7a00',
        '9731141d81fc8f8084d37c6e7542006b3ee1b40d60dfe5362a5b132fd17ddc0',
      ],
      [
        '32b78c7de9ee512a72895be6b9cbefa6e2f3c4ccce445c96b9f2c81e2778ad58',
        'ee1849f513df71e32efc3896ee28260c73bb80547ae2275ba497237794c8753c',
      ],
      [
        'e2cb74fddc8e9fbcd076eef2a7c72b0ce37d50f08269dfc074b581550547a4f7',
        'd3aa2ed71c9dd2247a62df062736eb0baddea9e36122d2be8641abcb005cc4a4',
      ],
      [
        '8438447566d4d7bedadc299496ab357426009a35f235cb141be0d99cd10ae3a8',
        'c4e1020916980a4da5d01ac5e6ad330734ef0d7906631c4f2390426b2edd791f',
      ],
      [
        '4162d488b89402039b584c6fc6c308870587d9c46f660b878ab65c82c711d67e',
        '67163e903236289f776f22c25fb8a3afc1732f2b84b4e95dbda47ae5a0852649',
      ],
      [
        '3fad3fa84caf0f34f0f89bfd2dcf54fc175d767aec3e50684f3ba4a4bf5f683d',
        'cd1bc7cb6cc407bb2f0ca647c718a730cf71872e7d0d2a53fa20efcdfe61826',
      ],
      [
        '674f2600a3007a00568c1a7ce05d0816c1fb84bf1370798f1c69532faeb1a86b',
        '299d21f9413f33b3edf43b257004580b70db57da0b182259e09eecc69e0d38a5',
      ],
      [
        'd32f4da54ade74abb81b815ad1fb3b263d82d6c692714bcff87d29bd5ee9f08f',
        'f9429e738b8e53b968e99016c059707782e14f4535359d582fc416910b3eea87',
      ],
      [
        '30e4e670435385556e593657135845d36fbb6931f72b08cb1ed954f1e3ce3ff6',
        '462f9bce619898638499350113bbc9b10a878d35da70740dc695a559eb88db7b',
      ],
      [
        'be2062003c51cc3004682904330e4dee7f3dcd10b01e580bf1971b04d4cad297',
        '62188bc49d61e5428573d48a74e1c655b1c61090905682a0d5558ed72dccb9bc',
      ],
      [
        '93144423ace3451ed29e0fb9ac2af211cb6e84a601df5993c419859fff5df04a',
        '7c10dfb164c3425f5c71a3f9d7992038f1065224f72bb9d1d902a6d13037b47c',
      ],
      [
        'b015f8044f5fcbdcf21ca26d6c34fb8197829205c7b7d2a7cb66418c157b112c',
        'ab8c1e086d04e813744a655b2df8d5f83b3cdc6faa3088c1d3aea1454e3a1d5f',
      ],
      [
        'd5e9e1da649d97d89e4868117a465a3a4f8a18de57a140d36b3f2af341a21b52',
        '4cb04437f391ed73111a13cc1d4dd0db1693465c2240480d8955e8592f27447a',
      ],
      [
        'd3ae41047dd7ca065dbf8ed77b992439983005cd72e16d6f996a5316d36966bb',
        'bd1aeb21ad22ebb22a10f0303417c6d964f8cdd7df0aca614b10dc14d125ac46',
      ],
      [
        '463e2763d885f958fc66cdd22800f0a487197d0a82e377b49f80af87c897b065',
        'bfefacdb0e5d0fd7df3a311a94de062b26b80c61fbc97508b79992671ef7ca7f',
      ],
      [
        '7985fdfd127c0567c6f53ec1bb63ec3158e597c40bfe747c83cddfc910641917',
        '603c12daf3d9862ef2b25fe1de289aed24ed291e0ec6708703a5bd567f32ed03',
      ],
      [
        '74a1ad6b5f76e39db2dd249410eac7f99e74c59cb83d2d0ed5ff1543da7703e9',
        'cc6157ef18c9c63cd6193d83631bbea0093e0968942e8c33d5737fd790e0db08',
      ],
      [
        '30682a50703375f602d416664ba19b7fc9bab42c72747463a71d0896b22f6da3',
        '553e04f6b018b4fa6c8f39e7f311d3176290d0e0f19ca73f17714d9977a22ff8',
      ],
      [
        '9e2158f0d7c0d5f26c3791efefa79597654e7a2b2464f52b1ee6c1347769ef57',
        '712fcdd1b9053f09003a3481fa7762e9ffd7c8ef35a38509e2fbf2629008373',
      ],
      [
        '176e26989a43c9cfeba4029c202538c28172e566e3c4fce7322857f3be327d66',
        'ed8cc9d04b29eb877d270b4878dc43c19aefd31f4eee09ee7b47834c1fa4b1c3',
      ],
      [
        '75d46efea3771e6e68abb89a13ad747ecf1892393dfc4f1b7004788c50374da8',
        '9852390a99507679fd0b86fd2b39a868d7efc22151346e1a3ca4726586a6bed8',
      ],
      [
        '809a20c67d64900ffb698c4c825f6d5f2310fb0451c869345b7319f645605721',
        '9e994980d9917e22b76b061927fa04143d096ccc54963e6a5ebfa5f3f8e286c1',
      ],
      [
        '1b38903a43f7f114ed4500b4eac7083fdefece1cf29c63528d563446f972c180',
        '4036edc931a60ae889353f77fd53de4a2708b26b6f5da72ad3394119daf408f9',
      ],
    ],
  },
};

},{}],115:[function(require,module,exports){
'use strict';

var utils = exports;
var BN = require('bn.js');
var minAssert = require('minimalistic-assert');
var minUtils = require('minimalistic-crypto-utils');

utils.assert = minAssert;
utils.toArray = minUtils.toArray;
utils.zero2 = minUtils.zero2;
utils.toHex = minUtils.toHex;
utils.encode = minUtils.encode;

// Represent num in a w-NAF form
function getNAF(num, w, bits) {
  var naf = new Array(Math.max(num.bitLength(), bits) + 1);
  naf.fill(0);

  var ws = 1 << (w + 1);
  var k = num.clone();

  for (var i = 0; i < naf.length; i++) {
    var z;
    var mod = k.andln(ws - 1);
    if (k.isOdd()) {
      if (mod > (ws >> 1) - 1)
        z = (ws >> 1) - mod;
      else
        z = mod;
      k.isubn(z);
    } else {
      z = 0;
    }

    naf[i] = z;
    k.iushrn(1);
  }

  return naf;
}
utils.getNAF = getNAF;

// Represent k1, k2 in a Joint Sparse Form
function getJSF(k1, k2) {
  var jsf = [
    [],
    [],
  ];

  k1 = k1.clone();
  k2 = k2.clone();
  var d1 = 0;
  var d2 = 0;
  var m8;
  while (k1.cmpn(-d1) > 0 || k2.cmpn(-d2) > 0) {
    // First phase
    var m14 = (k1.andln(3) + d1) & 3;
    var m24 = (k2.andln(3) + d2) & 3;
    if (m14 === 3)
      m14 = -1;
    if (m24 === 3)
      m24 = -1;
    var u1;
    if ((m14 & 1) === 0) {
      u1 = 0;
    } else {
      m8 = (k1.andln(7) + d1) & 7;
      if ((m8 === 3 || m8 === 5) && m24 === 2)
        u1 = -m14;
      else
        u1 = m14;
    }
    jsf[0].push(u1);

    var u2;
    if ((m24 & 1) === 0) {
      u2 = 0;
    } else {
      m8 = (k2.andln(7) + d2) & 7;
      if ((m8 === 3 || m8 === 5) && m14 === 2)
        u2 = -m24;
      else
        u2 = m24;
    }
    jsf[1].push(u2);

    // Second phase
    if (2 * d1 === u1 + 1)
      d1 = 1 - d1;
    if (2 * d2 === u2 + 1)
      d2 = 1 - d2;
    k1.iushrn(1);
    k2.iushrn(1);
  }

  return jsf;
}
utils.getJSF = getJSF;

function cachedProperty(obj, name, computer) {
  var key = '_' + name;
  obj.prototype[name] = function cachedProperty() {
    return this[key] !== undefined ? this[key] :
      this[key] = computer.call(this);
  };
}
utils.cachedProperty = cachedProperty;

function parseBytes(bytes) {
  return typeof bytes === 'string' ? utils.toArray(bytes, 'hex') :
    bytes;
}
utils.parseBytes = parseBytes;

function intFromLE(bytes) {
  return new BN(bytes, 'hex', 'le');
}
utils.intFromLE = intFromLE;


},{"bn.js":116,"minimalistic-assert":164,"minimalistic-crypto-utils":165}],116:[function(require,module,exports){
arguments[4][41][0].apply(exports,arguments)
},{"buffer":45,"dup":41}],117:[function(require,module,exports){
module.exports={
  "name": "elliptic",
  "version": "6.5.4",
  "description": "EC cryptography",
  "main": "lib/elliptic.js",
  "files": [
    "lib"
  ],
  "scripts": {
    "lint": "eslint lib test",
    "lint:fix": "npm run lint -- --fix",
    "unit": "istanbul test _mocha --reporter=spec test/index.js",
    "test": "npm run lint && npm run unit",
    "version": "grunt dist && git add dist/"
  },
  "repository": {
    "type": "git",
    "url": "git@github.com:indutny/elliptic"
  },
  "keywords": [
    "EC",
    "Elliptic",
    "curve",
    "Cryptography"
  ],
  "author": "Fedor Indutny <fedor@indutny.com>",
  "license": "MIT",
  "bugs": {
    "url": "https://github.com/indutny/elliptic/issues"
  },
  "homepage": "https://github.com/indutny/elliptic",
  "devDependencies": {
    "brfs": "^2.0.2",
    "coveralls": "^3.1.0",
    "eslint": "^7.6.0",
    "grunt": "^1.2.1",
    "grunt-browserify": "^5.3.0",
    "grunt-cli": "^1.3.2",
    "grunt-contrib-connect": "^3.0.0",
    "grunt-contrib-copy": "^1.0.0",
    "grunt-contrib-uglify": "^5.0.0",
    "grunt-mocha-istanbul": "^5.0.2",
    "grunt-saucelabs": "^9.0.1",
    "istanbul": "^0.4.5",
    "mocha": "^8.0.1"
  },
  "dependencies": {
    "bn.js": "^4.11.9",
    "brorand": "^1.1.0",
    "hash.js": "^1.0.0",
    "hmac-drbg": "^1.0.1",
    "inherits": "^2.0.4",
    "minimalistic-assert": "^1.0.1",
    "minimalistic-crypto-utils": "^1.0.1"
  }
}

},{}],118:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

var R = typeof Reflect === 'object' ? Reflect : null
var ReflectApply = R && typeof R.apply === 'function'
  ? R.apply
  : function ReflectApply(target, receiver, args) {
    return Function.prototype.apply.call(target, receiver, args);
  }

var ReflectOwnKeys
if (R && typeof R.ownKeys === 'function') {
  ReflectOwnKeys = R.ownKeys
} else if (Object.getOwnPropertySymbols) {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target)
      .concat(Object.getOwnPropertySymbols(target));
  };
} else {
  ReflectOwnKeys = function ReflectOwnKeys(target) {
    return Object.getOwnPropertyNames(target);
  };
}

function ProcessEmitWarning(warning) {
  if (console && console.warn) console.warn(warning);
}

var NumberIsNaN = Number.isNaN || function NumberIsNaN(value) {
  return value !== value;
}

function EventEmitter() {
  EventEmitter.init.call(this);
}
module.exports = EventEmitter;
module.exports.once = once;

// Backwards-compat with node 0.10.x
EventEmitter.EventEmitter = EventEmitter;

EventEmitter.prototype._events = undefined;
EventEmitter.prototype._eventsCount = 0;
EventEmitter.prototype._maxListeners = undefined;

// By default EventEmitters will print a warning if more than 10 listeners are
// added to it. This is a useful default which helps finding memory leaks.
var defaultMaxListeners = 10;

function checkListener(listener) {
  if (typeof listener !== 'function') {
    throw new TypeError('The "listener" argument must be of type Function. Received type ' + typeof listener);
  }
}

Object.defineProperty(EventEmitter, 'defaultMaxListeners', {
  enumerable: true,
  get: function() {
    return defaultMaxListeners;
  },
  set: function(arg) {
    if (typeof arg !== 'number' || arg < 0 || NumberIsNaN(arg)) {
      throw new RangeError('The value of "defaultMaxListeners" is out of range. It must be a non-negative number. Received ' + arg + '.');
    }
    defaultMaxListeners = arg;
  }
});

EventEmitter.init = function() {

  if (this._events === undefined ||
      this._events === Object.getPrototypeOf(this)._events) {
    this._events = Object.create(null);
    this._eventsCount = 0;
  }

  this._maxListeners = this._maxListeners || undefined;
};

// Obviously not all Emitters should be limited to 10. This function allows
// that to be increased. Set to zero for unlimited.
EventEmitter.prototype.setMaxListeners = function setMaxListeners(n) {
  if (typeof n !== 'number' || n < 0 || NumberIsNaN(n)) {
    throw new RangeError('The value of "n" is out of range. It must be a non-negative number. Received ' + n + '.');
  }
  this._maxListeners = n;
  return this;
};

function _getMaxListeners(that) {
  if (that._maxListeners === undefined)
    return EventEmitter.defaultMaxListeners;
  return that._maxListeners;
}

EventEmitter.prototype.getMaxListeners = function getMaxListeners() {
  return _getMaxListeners(this);
};

EventEmitter.prototype.emit = function emit(type) {
  var args = [];
  for (var i = 1; i < arguments.length; i++) args.push(arguments[i]);
  var doError = (type === 'error');

  var events = this._events;
  if (events !== undefined)
    doError = (doError && events.error === undefined);
  else if (!doError)
    return false;

  // If there is no 'error' event listener then throw.
  if (doError) {
    var er;
    if (args.length > 0)
      er = args[0];
    if (er instanceof Error) {
      // Note: The comments on the `throw` lines are intentional, they show
      // up in Node's output if this results in an unhandled exception.
      throw er; // Unhandled 'error' event
    }
    // At least give some kind of context to the user
    var err = new Error('Unhandled error.' + (er ? ' (' + er.message + ')' : ''));
    err.context = er;
    throw err; // Unhandled 'error' event
  }

  var handler = events[type];

  if (handler === undefined)
    return false;

  if (typeof handler === 'function') {
    ReflectApply(handler, this, args);
  } else {
    var len = handler.length;
    var listeners = arrayClone(handler, len);
    for (var i = 0; i < len; ++i)
      ReflectApply(listeners[i], this, args);
  }

  return true;
};

function _addListener(target, type, listener, prepend) {
  var m;
  var events;
  var existing;

  checkListener(listener);

  events = target._events;
  if (events === undefined) {
    events = target._events = Object.create(null);
    target._eventsCount = 0;
  } else {
    // To avoid recursion in the case that type === "newListener"! Before
    // adding it to the listeners, first emit "newListener".
    if (events.newListener !== undefined) {
      target.emit('newListener', type,
                  listener.listener ? listener.listener : listener);

      // Re-assign `events` because a newListener handler could have caused the
      // this._events to be assigned to a new object
      events = target._events;
    }
    existing = events[type];
  }

  if (existing === undefined) {
    // Optimize the case of one listener. Don't need the extra array object.
    existing = events[type] = listener;
    ++target._eventsCount;
  } else {
    if (typeof existing === 'function') {
      // Adding the second element, need to change to array.
      existing = events[type] =
        prepend ? [listener, existing] : [existing, listener];
      // If we've already got an array, just append.
    } else if (prepend) {
      existing.unshift(listener);
    } else {
      existing.push(listener);
    }

    // Check for listener leak
    m = _getMaxListeners(target);
    if (m > 0 && existing.length > m && !existing.warned) {
      existing.warned = true;
      // No error code for this since it is a Warning
      // eslint-disable-next-line no-restricted-syntax
      var w = new Error('Possible EventEmitter memory leak detected. ' +
                          existing.length + ' ' + String(type) + ' listeners ' +
                          'added. Use emitter.setMaxListeners() to ' +
                          'increase limit');
      w.name = 'MaxListenersExceededWarning';
      w.emitter = target;
      w.type = type;
      w.count = existing.length;
      ProcessEmitWarning(w);
    }
  }

  return target;
}

EventEmitter.prototype.addListener = function addListener(type, listener) {
  return _addListener(this, type, listener, false);
};

EventEmitter.prototype.on = EventEmitter.prototype.addListener;

EventEmitter.prototype.prependListener =
    function prependListener(type, listener) {
      return _addListener(this, type, listener, true);
    };

function onceWrapper() {
  if (!this.fired) {
    this.target.removeListener(this.type, this.wrapFn);
    this.fired = true;
    if (arguments.length === 0)
      return this.listener.call(this.target);
    return this.listener.apply(this.target, arguments);
  }
}

function _onceWrap(target, type, listener) {
  var state = { fired: false, wrapFn: undefined, target: target, type: type, listener: listener };
  var wrapped = onceWrapper.bind(state);
  wrapped.listener = listener;
  state.wrapFn = wrapped;
  return wrapped;
}

EventEmitter.prototype.once = function once(type, listener) {
  checkListener(listener);
  this.on(type, _onceWrap(this, type, listener));
  return this;
};

EventEmitter.prototype.prependOnceListener =
    function prependOnceListener(type, listener) {
      checkListener(listener);
      this.prependListener(type, _onceWrap(this, type, listener));
      return this;
    };

// Emits a 'removeListener' event if and only if the listener was removed.
EventEmitter.prototype.removeListener =
    function removeListener(type, listener) {
      var list, events, position, i, originalListener;

      checkListener(listener);

      events = this._events;
      if (events === undefined)
        return this;

      list = events[type];
      if (list === undefined)
        return this;

      if (list === listener || list.listener === listener) {
        if (--this._eventsCount === 0)
          this._events = Object.create(null);
        else {
          delete events[type];
          if (events.removeListener)
            this.emit('removeListener', type, list.listener || listener);
        }
      } else if (typeof list !== 'function') {
        position = -1;

        for (i = list.length - 1; i >= 0; i--) {
          if (list[i] === listener || list[i].listener === listener) {
            originalListener = list[i].listener;
            position = i;
            break;
          }
        }

        if (position < 0)
          return this;

        if (position === 0)
          list.shift();
        else {
          spliceOne(list, position);
        }

        if (list.length === 1)
          events[type] = list[0];

        if (events.removeListener !== undefined)
          this.emit('removeListener', type, originalListener || listener);
      }

      return this;
    };

EventEmitter.prototype.off = EventEmitter.prototype.removeListener;

EventEmitter.prototype.removeAllListeners =
    function removeAllListeners(type) {
      var listeners, events, i;

      events = this._events;
      if (events === undefined)
        return this;

      // not listening for removeListener, no need to emit
      if (events.removeListener === undefined) {
        if (arguments.length === 0) {
          this._events = Object.create(null);
          this._eventsCount = 0;
        } else if (events[type] !== undefined) {
          if (--this._eventsCount === 0)
            this._events = Object.create(null);
          else
            delete events[type];
        }
        return this;
      }

      // emit removeListener for all listeners on all events
      if (arguments.length === 0) {
        var keys = Object.keys(events);
        var key;
        for (i = 0; i < keys.length; ++i) {
          key = keys[i];
          if (key === 'removeListener') continue;
          this.removeAllListeners(key);
        }
        this.removeAllListeners('removeListener');
        this._events = Object.create(null);
        this._eventsCount = 0;
        return this;
      }

      listeners = events[type];

      if (typeof listeners === 'function') {
        this.removeListener(type, listeners);
      } else if (listeners !== undefined) {
        // LIFO order
        for (i = listeners.length - 1; i >= 0; i--) {
          this.removeListener(type, listeners[i]);
        }
      }

      return this;
    };

function _listeners(target, type, unwrap) {
  var events = target._events;

  if (events === undefined)
    return [];

  var evlistener = events[type];
  if (evlistener === undefined)
    return [];

  if (typeof evlistener === 'function')
    return unwrap ? [evlistener.listener || evlistener] : [evlistener];

  return unwrap ?
    unwrapListeners(evlistener) : arrayClone(evlistener, evlistener.length);
}

EventEmitter.prototype.listeners = function listeners(type) {
  return _listeners(this, type, true);
};

EventEmitter.prototype.rawListeners = function rawListeners(type) {
  return _listeners(this, type, false);
};

EventEmitter.listenerCount = function(emitter, type) {
  if (typeof emitter.listenerCount === 'function') {
    return emitter.listenerCount(type);
  } else {
    return listenerCount.call(emitter, type);
  }
};

EventEmitter.prototype.listenerCount = listenerCount;
function listenerCount(type) {
  var events = this._events;

  if (events !== undefined) {
    var evlistener = events[type];

    if (typeof evlistener === 'function') {
      return 1;
    } else if (evlistener !== undefined) {
      return evlistener.length;
    }
  }

  return 0;
}

EventEmitter.prototype.eventNames = function eventNames() {
  return this._eventsCount > 0 ? ReflectOwnKeys(this._events) : [];
};

function arrayClone(arr, n) {
  var copy = new Array(n);
  for (var i = 0; i < n; ++i)
    copy[i] = arr[i];
  return copy;
}

function spliceOne(list, index) {
  for (; index + 1 < list.length; index++)
    list[index] = list[index + 1];
  list.pop();
}

function unwrapListeners(arr) {
  var ret = new Array(arr.length);
  for (var i = 0; i < ret.length; ++i) {
    ret[i] = arr[i].listener || arr[i];
  }
  return ret;
}

function once(emitter, name) {
  return new Promise(function (resolve, reject) {
    function errorListener(err) {
      emitter.removeListener(name, resolver);
      reject(err);
    }

    function resolver() {
      if (typeof emitter.removeListener === 'function') {
        emitter.removeListener('error', errorListener);
      }
      resolve([].slice.call(arguments));
    };

    eventTargetAgnosticAddListener(emitter, name, resolver, { once: true });
    if (name !== 'error') {
      addErrorHandlerIfEventEmitter(emitter, errorListener, { once: true });
    }
  });
}

function addErrorHandlerIfEventEmitter(emitter, handler, flags) {
  if (typeof emitter.on === 'function') {
    eventTargetAgnosticAddListener(emitter, 'error', handler, flags);
  }
}

function eventTargetAgnosticAddListener(emitter, name, listener, flags) {
  if (typeof emitter.on === 'function') {
    if (flags.once) {
      emitter.once(name, listener);
    } else {
      emitter.on(name, listener);
    }
  } else if (typeof emitter.addEventListener === 'function') {
    // EventTarget does not have `error` event semantics like Node
    // EventEmitters, we do not listen for `error` events here.
    emitter.addEventListener(name, function wrapListener(arg) {
      // IE does not have builtin `{ once: true }` support so we
      // have to do it manually.
      if (flags.once) {
        emitter.removeEventListener(name, wrapListener);
      }
      listener(arg);
    });
  } else {
    throw new TypeError('The "emitter" argument must be of type EventEmitter. Received type ' + typeof emitter);
  }
}

},{}],119:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer
var MD5 = require('md5.js')

/* eslint-disable camelcase */
function EVP_BytesToKey (password, salt, keyBits, ivLen) {
  if (!Buffer.isBuffer(password)) password = Buffer.from(password, 'binary')
  if (salt) {
    if (!Buffer.isBuffer(salt)) salt = Buffer.from(salt, 'binary')
    if (salt.length !== 8) throw new RangeError('salt should be Buffer with 8 byte length')
  }

  var keyLen = keyBits / 8
  var key = Buffer.alloc(keyLen)
  var iv = Buffer.alloc(ivLen || 0)
  var tmp = Buffer.alloc(0)

  while (keyLen > 0 || ivLen > 0) {
    var hash = new MD5()
    hash.update(tmp)
    hash.update(password)
    if (salt) hash.update(salt)
    tmp = hash.digest()

    var used = 0

    if (keyLen > 0) {
      var keyStart = key.length - keyLen
      used = Math.min(keyLen, tmp.length)
      tmp.copy(key, keyStart, 0, used)
      keyLen -= used
    }

    if (used < tmp.length && ivLen > 0) {
      var ivStart = iv.length - ivLen
      var length = Math.min(ivLen, tmp.length - used)
      tmp.copy(iv, ivStart, used, used + length)
      ivLen -= length
    }
  }

  tmp.fill(0)
  return { key: key, iv: iv }
}

module.exports = EVP_BytesToKey

},{"md5.js":161,"safe-buffer":215}],120:[function(require,module,exports){


/* eslint-disable global-require */

const factory = require('@graphy/core.data.factory');

const memoize = (s_package) => {
	delete graphy[s_package];
	return graphy[s_package] = require('@graphy/'+s_package);
};



// ttl package
const ttl = {

	// read ttl
	get read() {
		// memoize
		delete graphy.content.ttl.read;
		return (graphy.content.ttl.read = require('@graphy/content.ttl.read'));
	},

	// write ttl
	get write() {
		// memoize
		delete graphy.content.ttl.write;
		return (graphy.content.ttl.write = require('@graphy/content.ttl.write'));
	},

	// scribe ttl
	get scribe() {
		// memoize
		delete graphy.content.ttl.scribe;
		return (graphy.content.ttl.scribe = require('@graphy/content.ttl.scribe'));
	},

};	// trig package
const trig = {

	// read trig
	get read() {
		// memoize
		delete graphy.content.trig.read;
		return (graphy.content.trig.read = require('@graphy/content.trig.read'));
	},

	// write trig
	get write() {
		// memoize
		delete graphy.content.trig.write;
		return (graphy.content.trig.write = require('@graphy/content.trig.write'));
	},

	// scribe trig
	get scribe() {
		// memoize
		delete graphy.content.trig.scribe;
		return (graphy.content.trig.scribe = require('@graphy/content.trig.scribe'));
	},

};	// nt package
const nt = {

	// read nt
	get read() {
		// memoize
		delete graphy.content.nt.read;
		return (graphy.content.nt.read = require('@graphy/content.nt.read'));
	},

	// write nt
	get write() {
		// memoize
		delete graphy.content.nt.write;
		return (graphy.content.nt.write = require('@graphy/content.nt.write'));
	},

	// scribe nt
	get scribe() {
		// memoize
		delete graphy.content.nt.scribe;
		return (graphy.content.nt.scribe = require('@graphy/content.nt.scribe'));
	},

	// scan nt
	get scan() {
		// memoize
		delete graphy.content.nt.scan;
		return (graphy.content.nt.scan = require('@graphy/content.nt.scan'));
	},

};	// nq package
const nq = {

	// read nq
	get read() {
		// memoize
		delete graphy.content.nq.read;
		return (graphy.content.nq.read = require('@graphy/content.nq.read'));
	},

	// write nq
	get write() {
		// memoize
		delete graphy.content.nq.write;
		return (graphy.content.nq.write = require('@graphy/content.nq.write'));
	},

	// scribe nq
	get scribe() {
		// memoize
		delete graphy.content.nq.scribe;
		return (graphy.content.nq.scribe = require('@graphy/content.nq.scribe'));
	},

	// scan nq
	get scan() {
		// memoize
		delete graphy.content.nq.scan;
		return (graphy.content.nq.scan = require('@graphy/content.nq.scan'));
	},

};	// xml package
const xml = {

	// scribe xml
	get scribe() {
		// memoize
		delete graphy.content.xml.scribe;
		return (graphy.content.xml.scribe = require('@graphy/content.xml.scribe'));
	},

};



// // SPARQL Results package
// const sparql_results = {
// 	// deserialize sparql_results input
// 	get deserializer() {
// 		// memoize
// 		delete sparql_results.deserializer;
// 		return (sparql_results.deserializer = require('../sparql-results/deserializer.js'));
// 	},
// };


const H_CONTENT_MIMES = {
	'text/turtle': ttl,
	'application/trig': trig,
	'application/n-triples': nt,
	'application/n-quads': nq,
	'application/rdf+xml': xml,
// 'application/sparql-results+json': sparql_results,
};

const H_CONTENT_TAGS = {
	nt,
	ntriples: nt,
	'n-triples': nt,
	nq,
	nquads: nq,
	'n-quads': nq,
	ttl,
	turtle: ttl,
	trig,
	xml,
	'rdf-xml': xml,
	'rdf/xml': xml,
// 'sparql-results': sparql_results,
};



const R_CONTENT_TYPE = /^((?:application|text)\/[^\0-\x20()<>@,;:\\"\/[\]?.=]+)(;.+)*$/i;

const graphy = module.exports = Object.assign({

	VERSION: '4.3.3',

	content: Object.assign((s_query_in) => {
		let s_query = s_query_in.toLowerCase();

		if(s_query in H_CONTENT_TAGS) {
			return H_CONTENT_TAGS[s_query];
		}

		let m_content_type = R_CONTENT_TYPE.exec(s_query);
		if(!m_content_type) throw new Error(`invalid content-type string: "${s_query}"`);
		let [, s_content_type, s_parameters] = m_content_type;
		let s_content_type_normal = s_content_type.toLowerCase();

		if(s_content_type_normal in H_CONTENT_MIMES) {
			return H_CONTENT_MIMES[s_content_type_normal];
		}
		else {
			throw new Error(`no content handlers matched query for "${s_content_type_normal}"`);
		}
	}, {
		ttl,
		trig,
		nt,
		nq,
		xml,

	}),

	core: {
		data: {
			get factory() {
				// memoize
				delete graphy.core.data.factory;
				return (graphy.core.data.factory = require('@graphy/core.data.factory'));
			},
		},
		iso: {
			get stream() {
				// memoize
				delete graphy.core.iso.stream;
				return (graphy.core.iso.stream = require('@graphy/core.iso.stream'));
			},
		},
	},

	get 'core.data.factory'() {
		return memoize('core.data.factory');
	},

	get 'core.iso.stream'() {
		return memoize('core.iso.stream');
	},

	util: {
		dataset: {
			get tree() {
				// memoize
				delete graphy.util.dataset.tree;
				return (graphy.util.dataset.tree = require('@graphy/util.dataset.tree'));
			},
		},
	},

	get 'util.dataset.tree'() {
		return memoize('util.dataset.tree');
	},

	memory: {
		dataset: {
			get fast() {
				// memoize
				delete graphy.memory.dataset.fast;
				return (graphy.memory.dataset.fast = require('@graphy/memory.dataset.fast'));
			},
		},
	},

	get 'memory.dataset.fast'() {
		return memoize('memory.dataset.fast');
	},



	get 'content.ttl.read'() {
		return memoize('content.ttl.read');
	},

	get 'content.ttl.write'() {
		return memoize('content.ttl.write');
	},

	get 'content.ttl.scribe'() {
		return memoize('content.ttl.scribe');
	},

	get 'content.trig.read'() {
		return memoize('content.trig.read');
	},

	get 'content.trig.write'() {
		return memoize('content.trig.write');
	},

	get 'content.trig.scribe'() {
		return memoize('content.trig.scribe');
	},

	get 'content.nt.read'() {
		return memoize('content.nt.read');
	},

	get 'content.nt.write'() {
		return memoize('content.nt.write');
	},

	get 'content.nt.scribe'() {
		return memoize('content.nt.scribe');
	},

	get 'content.nt.scan'() {
		return memoize('content.nt.scan');
	},

	get 'content.nq.read'() {
		return memoize('content.nq.read');
	},

	get 'content.nq.write'() {
		return memoize('content.nq.write');
	},

	get 'content.nq.scribe'() {
		return memoize('content.nq.scribe');
	},

	get 'content.nq.scan'() {
		return memoize('content.nq.scan');
	},

	get 'content.xml.scribe'() {
		return memoize('content.xml.scribe');
	},



}, factory);


// export graphy to window object if in main thread of browser
if('undefined' !== typeof window) window.graphy = graphy;

},{"@graphy/content.nq.read":1,"@graphy/content.nq.scan":2,"@graphy/content.nq.scribe":4,"@graphy/content.nq.write":5,"@graphy/content.nt.read":6,"@graphy/content.nt.scan":7,"@graphy/content.nt.scribe":9,"@graphy/content.nt.write":10,"@graphy/content.trig.read":11,"@graphy/content.trig.scribe":12,"@graphy/content.trig.write":13,"@graphy/content.ttl.read":14,"@graphy/content.ttl.scribe":15,"@graphy/content.ttl.write":16,"@graphy/content.xml.scribe":17,"@graphy/core.data.factory":20,"@graphy/core.iso.stream":21,"@graphy/memory.dataset.fast":25,"@graphy/util.dataset.tree":26}],121:[function(require,module,exports){
'use strict'
var Buffer = require('safe-buffer').Buffer
var Transform = require('readable-stream').Transform
var inherits = require('inherits')

function throwIfNotStringOrBuffer (val, prefix) {
  if (!Buffer.isBuffer(val) && typeof val !== 'string') {
    throw new TypeError(prefix + ' must be a string or a buffer')
  }
}

function HashBase (blockSize) {
  Transform.call(this)

  this._block = Buffer.allocUnsafe(blockSize)
  this._blockSize = blockSize
  this._blockOffset = 0
  this._length = [0, 0, 0, 0]

  this._finalized = false
}

inherits(HashBase, Transform)

HashBase.prototype._transform = function (chunk, encoding, callback) {
  var error = null
  try {
    this.update(chunk, encoding)
  } catch (err) {
    error = err
  }

  callback(error)
}

HashBase.prototype._flush = function (callback) {
  var error = null
  try {
    this.push(this.digest())
  } catch (err) {
    error = err
  }

  callback(error)
}

HashBase.prototype.update = function (data, encoding) {
  throwIfNotStringOrBuffer(data, 'Data')
  if (this._finalized) throw new Error('Digest already called')
  if (!Buffer.isBuffer(data)) data = Buffer.from(data, encoding)

  // consume data
  var block = this._block
  var offset = 0
  while (this._blockOffset + data.length - offset >= this._blockSize) {
    for (var i = this._blockOffset; i < this._blockSize;) block[i++] = data[offset++]
    this._update()
    this._blockOffset = 0
  }
  while (offset < data.length) block[this._blockOffset++] = data[offset++]

  // update length
  for (var j = 0, carry = data.length * 8; carry > 0; ++j) {
    this._length[j] += carry
    carry = (this._length[j] / 0x0100000000) | 0
    if (carry > 0) this._length[j] -= 0x0100000000 * carry
  }

  return this
}

HashBase.prototype._update = function () {
  throw new Error('_update is not implemented')
}

HashBase.prototype.digest = function (encoding) {
  if (this._finalized) throw new Error('Digest already called')
  this._finalized = true

  var digest = this._digest()
  if (encoding !== undefined) digest = digest.toString(encoding)

  // reset state
  this._block.fill(0)
  this._blockOffset = 0
  for (var i = 0; i < 4; ++i) this._length[i] = 0

  return digest
}

HashBase.prototype._digest = function () {
  throw new Error('_digest is not implemented')
}

module.exports = HashBase

},{"inherits":136,"readable-stream":213,"safe-buffer":215}],122:[function(require,module,exports){
var hash = exports;

hash.utils = require('./hash/utils');
hash.common = require('./hash/common');
hash.sha = require('./hash/sha');
hash.ripemd = require('./hash/ripemd');
hash.hmac = require('./hash/hmac');

// Proxy hash functions to the main object
hash.sha1 = hash.sha.sha1;
hash.sha256 = hash.sha.sha256;
hash.sha224 = hash.sha.sha224;
hash.sha384 = hash.sha.sha384;
hash.sha512 = hash.sha.sha512;
hash.ripemd160 = hash.ripemd.ripemd160;

},{"./hash/common":123,"./hash/hmac":124,"./hash/ripemd":125,"./hash/sha":126,"./hash/utils":133}],123:[function(require,module,exports){
'use strict';

var utils = require('./utils');
var assert = require('minimalistic-assert');

function BlockHash() {
  this.pending = null;
  this.pendingTotal = 0;
  this.blockSize = this.constructor.blockSize;
  this.outSize = this.constructor.outSize;
  this.hmacStrength = this.constructor.hmacStrength;
  this.padLength = this.constructor.padLength / 8;
  this.endian = 'big';

  this._delta8 = this.blockSize / 8;
  this._delta32 = this.blockSize / 32;
}
exports.BlockHash = BlockHash;

BlockHash.prototype.update = function update(msg, enc) {
  // Convert message to array, pad it, and join into 32bit blocks
  msg = utils.toArray(msg, enc);
  if (!this.pending)
    this.pending = msg;
  else
    this.pending = this.pending.concat(msg);
  this.pendingTotal += msg.length;

  // Enough data, try updating
  if (this.pending.length >= this._delta8) {
    msg = this.pending;

    // Process pending data in blocks
    var r = msg.length % this._delta8;
    this.pending = msg.slice(msg.length - r, msg.length);
    if (this.pending.length === 0)
      this.pending = null;

    msg = utils.join32(msg, 0, msg.length - r, this.endian);
    for (var i = 0; i < msg.length; i += this._delta32)
      this._update(msg, i, i + this._delta32);
  }

  return this;
};

BlockHash.prototype.digest = function digest(enc) {
  this.update(this._pad());
  assert(this.pending === null);

  return this._digest(enc);
};

BlockHash.prototype._pad = function pad() {
  var len = this.pendingTotal;
  var bytes = this._delta8;
  var k = bytes - ((len + this.padLength) % bytes);
  var res = new Array(k + this.padLength);
  res[0] = 0x80;
  for (var i = 1; i < k; i++)
    res[i] = 0;

  // Append length
  len <<= 3;
  if (this.endian === 'big') {
    for (var t = 8; t < this.padLength; t++)
      res[i++] = 0;

    res[i++] = 0;
    res[i++] = 0;
    res[i++] = 0;
    res[i++] = 0;
    res[i++] = (len >>> 24) & 0xff;
    res[i++] = (len >>> 16) & 0xff;
    res[i++] = (len >>> 8) & 0xff;
    res[i++] = len & 0xff;
  } else {
    res[i++] = len & 0xff;
    res[i++] = (len >>> 8) & 0xff;
    res[i++] = (len >>> 16) & 0xff;
    res[i++] = (len >>> 24) & 0xff;
    res[i++] = 0;
    res[i++] = 0;
    res[i++] = 0;
    res[i++] = 0;

    for (t = 8; t < this.padLength; t++)
      res[i++] = 0;
  }

  return res;
};

},{"./utils":133,"minimalistic-assert":164}],124:[function(require,module,exports){
'use strict';

var utils = require('./utils');
var assert = require('minimalistic-assert');

function Hmac(hash, key, enc) {
  if (!(this instanceof Hmac))
    return new Hmac(hash, key, enc);
  this.Hash = hash;
  this.blockSize = hash.blockSize / 8;
  this.outSize = hash.outSize / 8;
  this.inner = null;
  this.outer = null;

  this._init(utils.toArray(key, enc));
}
module.exports = Hmac;

Hmac.prototype._init = function init(key) {
  // Shorten key, if needed
  if (key.length > this.blockSize)
    key = new this.Hash().update(key).digest();
  assert(key.length <= this.blockSize);

  // Add padding to key
  for (var i = key.length; i < this.blockSize; i++)
    key.push(0);

  for (i = 0; i < key.length; i++)
    key[i] ^= 0x36;
  this.inner = new this.Hash().update(key);

  // 0x36 ^ 0x5c = 0x6a
  for (i = 0; i < key.length; i++)
    key[i] ^= 0x6a;
  this.outer = new this.Hash().update(key);
};

Hmac.prototype.update = function update(msg, enc) {
  this.inner.update(msg, enc);
  return this;
};

Hmac.prototype.digest = function digest(enc) {
  this.outer.update(this.inner.digest());
  return this.outer.digest(enc);
};

},{"./utils":133,"minimalistic-assert":164}],125:[function(require,module,exports){
'use strict';

var utils = require('./utils');
var common = require('./common');

var rotl32 = utils.rotl32;
var sum32 = utils.sum32;
var sum32_3 = utils.sum32_3;
var sum32_4 = utils.sum32_4;
var BlockHash = common.BlockHash;

function RIPEMD160() {
  if (!(this instanceof RIPEMD160))
    return new RIPEMD160();

  BlockHash.call(this);

  this.h = [ 0x67452301, 0xefcdab89, 0x98badcfe, 0x10325476, 0xc3d2e1f0 ];
  this.endian = 'little';
}
utils.inherits(RIPEMD160, BlockHash);
exports.ripemd160 = RIPEMD160;

RIPEMD160.blockSize = 512;
RIPEMD160.outSize = 160;
RIPEMD160.hmacStrength = 192;
RIPEMD160.padLength = 64;

RIPEMD160.prototype._update = function update(msg, start) {
  var A = this.h[0];
  var B = this.h[1];
  var C = this.h[2];
  var D = this.h[3];
  var E = this.h[4];
  var Ah = A;
  var Bh = B;
  var Ch = C;
  var Dh = D;
  var Eh = E;
  for (var j = 0; j < 80; j++) {
    var T = sum32(
      rotl32(
        sum32_4(A, f(j, B, C, D), msg[r[j] + start], K(j)),
        s[j]),
      E);
    A = E;
    E = D;
    D = rotl32(C, 10);
    C = B;
    B = T;
    T = sum32(
      rotl32(
        sum32_4(Ah, f(79 - j, Bh, Ch, Dh), msg[rh[j] + start], Kh(j)),
        sh[j]),
      Eh);
    Ah = Eh;
    Eh = Dh;
    Dh = rotl32(Ch, 10);
    Ch = Bh;
    Bh = T;
  }
  T = sum32_3(this.h[1], C, Dh);
  this.h[1] = sum32_3(this.h[2], D, Eh);
  this.h[2] = sum32_3(this.h[3], E, Ah);
  this.h[3] = sum32_3(this.h[4], A, Bh);
  this.h[4] = sum32_3(this.h[0], B, Ch);
  this.h[0] = T;
};

RIPEMD160.prototype._digest = function digest(enc) {
  if (enc === 'hex')
    return utils.toHex32(this.h, 'little');
  else
    return utils.split32(this.h, 'little');
};

function f(j, x, y, z) {
  if (j <= 15)
    return x ^ y ^ z;
  else if (j <= 31)
    return (x & y) | ((~x) & z);
  else if (j <= 47)
    return (x | (~y)) ^ z;
  else if (j <= 63)
    return (x & z) | (y & (~z));
  else
    return x ^ (y | (~z));
}

function K(j) {
  if (j <= 15)
    return 0x00000000;
  else if (j <= 31)
    return 0x5a827999;
  else if (j <= 47)
    return 0x6ed9eba1;
  else if (j <= 63)
    return 0x8f1bbcdc;
  else
    return 0xa953fd4e;
}

function Kh(j) {
  if (j <= 15)
    return 0x50a28be6;
  else if (j <= 31)
    return 0x5c4dd124;
  else if (j <= 47)
    return 0x6d703ef3;
  else if (j <= 63)
    return 0x7a6d76e9;
  else
    return 0x00000000;
}

var r = [
  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
  7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8,
  3, 10, 14, 4, 9, 15, 8, 1, 2, 7, 0, 6, 13, 11, 5, 12,
  1, 9, 11, 10, 0, 8, 12, 4, 13, 3, 7, 15, 14, 5, 6, 2,
  4, 0, 5, 9, 7, 12, 2, 10, 14, 1, 3, 8, 11, 6, 15, 13
];

var rh = [
  5, 14, 7, 0, 9, 2, 11, 4, 13, 6, 15, 8, 1, 10, 3, 12,
  6, 11, 3, 7, 0, 13, 5, 10, 14, 15, 8, 12, 4, 9, 1, 2,
  15, 5, 1, 3, 7, 14, 6, 9, 11, 8, 12, 2, 10, 0, 4, 13,
  8, 6, 4, 1, 3, 11, 15, 0, 5, 12, 2, 13, 9, 7, 10, 14,
  12, 15, 10, 4, 1, 5, 8, 7, 6, 2, 13, 14, 0, 3, 9, 11
];

var s = [
  11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8,
  7, 6, 8, 13, 11, 9, 7, 15, 7, 12, 15, 9, 11, 7, 13, 12,
  11, 13, 6, 7, 14, 9, 13, 15, 14, 8, 13, 6, 5, 12, 7, 5,
  11, 12, 14, 15, 14, 15, 9, 8, 9, 14, 5, 6, 8, 6, 5, 12,
  9, 15, 5, 11, 6, 8, 13, 12, 5, 12, 13, 14, 11, 8, 5, 6
];

var sh = [
  8, 9, 9, 11, 13, 15, 15, 5, 7, 7, 8, 11, 14, 14, 12, 6,
  9, 13, 15, 7, 12, 8, 9, 11, 7, 7, 12, 7, 6, 15, 13, 11,
  9, 7, 15, 11, 8, 6, 6, 14, 12, 13, 5, 14, 13, 13, 7, 5,
  15, 5, 8, 11, 14, 14, 6, 14, 6, 9, 12, 9, 12, 5, 15, 8,
  8, 5, 12, 9, 12, 5, 14, 6, 8, 13, 6, 5, 15, 13, 11, 11
];

},{"./common":123,"./utils":133}],126:[function(require,module,exports){
'use strict';

exports.sha1 = require('./sha/1');
exports.sha224 = require('./sha/224');
exports.sha256 = require('./sha/256');
exports.sha384 = require('./sha/384');
exports.sha512 = require('./sha/512');

},{"./sha/1":127,"./sha/224":128,"./sha/256":129,"./sha/384":130,"./sha/512":131}],127:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var common = require('../common');
var shaCommon = require('./common');

var rotl32 = utils.rotl32;
var sum32 = utils.sum32;
var sum32_5 = utils.sum32_5;
var ft_1 = shaCommon.ft_1;
var BlockHash = common.BlockHash;

var sha1_K = [
  0x5A827999, 0x6ED9EBA1,
  0x8F1BBCDC, 0xCA62C1D6
];

function SHA1() {
  if (!(this instanceof SHA1))
    return new SHA1();

  BlockHash.call(this);
  this.h = [
    0x67452301, 0xefcdab89, 0x98badcfe,
    0x10325476, 0xc3d2e1f0 ];
  this.W = new Array(80);
}

utils.inherits(SHA1, BlockHash);
module.exports = SHA1;

SHA1.blockSize = 512;
SHA1.outSize = 160;
SHA1.hmacStrength = 80;
SHA1.padLength = 64;

SHA1.prototype._update = function _update(msg, start) {
  var W = this.W;

  for (var i = 0; i < 16; i++)
    W[i] = msg[start + i];

  for(; i < W.length; i++)
    W[i] = rotl32(W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16], 1);

  var a = this.h[0];
  var b = this.h[1];
  var c = this.h[2];
  var d = this.h[3];
  var e = this.h[4];

  for (i = 0; i < W.length; i++) {
    var s = ~~(i / 20);
    var t = sum32_5(rotl32(a, 5), ft_1(s, b, c, d), e, W[i], sha1_K[s]);
    e = d;
    d = c;
    c = rotl32(b, 30);
    b = a;
    a = t;
  }

  this.h[0] = sum32(this.h[0], a);
  this.h[1] = sum32(this.h[1], b);
  this.h[2] = sum32(this.h[2], c);
  this.h[3] = sum32(this.h[3], d);
  this.h[4] = sum32(this.h[4], e);
};

SHA1.prototype._digest = function digest(enc) {
  if (enc === 'hex')
    return utils.toHex32(this.h, 'big');
  else
    return utils.split32(this.h, 'big');
};

},{"../common":123,"../utils":133,"./common":132}],128:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var SHA256 = require('./256');

function SHA224() {
  if (!(this instanceof SHA224))
    return new SHA224();

  SHA256.call(this);
  this.h = [
    0xc1059ed8, 0x367cd507, 0x3070dd17, 0xf70e5939,
    0xffc00b31, 0x68581511, 0x64f98fa7, 0xbefa4fa4 ];
}
utils.inherits(SHA224, SHA256);
module.exports = SHA224;

SHA224.blockSize = 512;
SHA224.outSize = 224;
SHA224.hmacStrength = 192;
SHA224.padLength = 64;

SHA224.prototype._digest = function digest(enc) {
  // Just truncate output
  if (enc === 'hex')
    return utils.toHex32(this.h.slice(0, 7), 'big');
  else
    return utils.split32(this.h.slice(0, 7), 'big');
};


},{"../utils":133,"./256":129}],129:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var common = require('../common');
var shaCommon = require('./common');
var assert = require('minimalistic-assert');

var sum32 = utils.sum32;
var sum32_4 = utils.sum32_4;
var sum32_5 = utils.sum32_5;
var ch32 = shaCommon.ch32;
var maj32 = shaCommon.maj32;
var s0_256 = shaCommon.s0_256;
var s1_256 = shaCommon.s1_256;
var g0_256 = shaCommon.g0_256;
var g1_256 = shaCommon.g1_256;

var BlockHash = common.BlockHash;

var sha256_K = [
  0x428a2f98, 0x71374491, 0xb5c0fbcf, 0xe9b5dba5,
  0x3956c25b, 0x59f111f1, 0x923f82a4, 0xab1c5ed5,
  0xd807aa98, 0x12835b01, 0x243185be, 0x550c7dc3,
  0x72be5d74, 0x80deb1fe, 0x9bdc06a7, 0xc19bf174,
  0xe49b69c1, 0xefbe4786, 0x0fc19dc6, 0x240ca1cc,
  0x2de92c6f, 0x4a7484aa, 0x5cb0a9dc, 0x76f988da,
  0x983e5152, 0xa831c66d, 0xb00327c8, 0xbf597fc7,
  0xc6e00bf3, 0xd5a79147, 0x06ca6351, 0x14292967,
  0x27b70a85, 0x2e1b2138, 0x4d2c6dfc, 0x53380d13,
  0x650a7354, 0x766a0abb, 0x81c2c92e, 0x92722c85,
  0xa2bfe8a1, 0xa81a664b, 0xc24b8b70, 0xc76c51a3,
  0xd192e819, 0xd6990624, 0xf40e3585, 0x106aa070,
  0x19a4c116, 0x1e376c08, 0x2748774c, 0x34b0bcb5,
  0x391c0cb3, 0x4ed8aa4a, 0x5b9cca4f, 0x682e6ff3,
  0x748f82ee, 0x78a5636f, 0x84c87814, 0x8cc70208,
  0x90befffa, 0xa4506ceb, 0xbef9a3f7, 0xc67178f2
];

function SHA256() {
  if (!(this instanceof SHA256))
    return new SHA256();

  BlockHash.call(this);
  this.h = [
    0x6a09e667, 0xbb67ae85, 0x3c6ef372, 0xa54ff53a,
    0x510e527f, 0x9b05688c, 0x1f83d9ab, 0x5be0cd19
  ];
  this.k = sha256_K;
  this.W = new Array(64);
}
utils.inherits(SHA256, BlockHash);
module.exports = SHA256;

SHA256.blockSize = 512;
SHA256.outSize = 256;
SHA256.hmacStrength = 192;
SHA256.padLength = 64;

SHA256.prototype._update = function _update(msg, start) {
  var W = this.W;

  for (var i = 0; i < 16; i++)
    W[i] = msg[start + i];
  for (; i < W.length; i++)
    W[i] = sum32_4(g1_256(W[i - 2]), W[i - 7], g0_256(W[i - 15]), W[i - 16]);

  var a = this.h[0];
  var b = this.h[1];
  var c = this.h[2];
  var d = this.h[3];
  var e = this.h[4];
  var f = this.h[5];
  var g = this.h[6];
  var h = this.h[7];

  assert(this.k.length === W.length);
  for (i = 0; i < W.length; i++) {
    var T1 = sum32_5(h, s1_256(e), ch32(e, f, g), this.k[i], W[i]);
    var T2 = sum32(s0_256(a), maj32(a, b, c));
    h = g;
    g = f;
    f = e;
    e = sum32(d, T1);
    d = c;
    c = b;
    b = a;
    a = sum32(T1, T2);
  }

  this.h[0] = sum32(this.h[0], a);
  this.h[1] = sum32(this.h[1], b);
  this.h[2] = sum32(this.h[2], c);
  this.h[3] = sum32(this.h[3], d);
  this.h[4] = sum32(this.h[4], e);
  this.h[5] = sum32(this.h[5], f);
  this.h[6] = sum32(this.h[6], g);
  this.h[7] = sum32(this.h[7], h);
};

SHA256.prototype._digest = function digest(enc) {
  if (enc === 'hex')
    return utils.toHex32(this.h, 'big');
  else
    return utils.split32(this.h, 'big');
};

},{"../common":123,"../utils":133,"./common":132,"minimalistic-assert":164}],130:[function(require,module,exports){
'use strict';

var utils = require('../utils');

var SHA512 = require('./512');

function SHA384() {
  if (!(this instanceof SHA384))
    return new SHA384();

  SHA512.call(this);
  this.h = [
    0xcbbb9d5d, 0xc1059ed8,
    0x629a292a, 0x367cd507,
    0x9159015a, 0x3070dd17,
    0x152fecd8, 0xf70e5939,
    0x67332667, 0xffc00b31,
    0x8eb44a87, 0x68581511,
    0xdb0c2e0d, 0x64f98fa7,
    0x47b5481d, 0xbefa4fa4 ];
}
utils.inherits(SHA384, SHA512);
module.exports = SHA384;

SHA384.blockSize = 1024;
SHA384.outSize = 384;
SHA384.hmacStrength = 192;
SHA384.padLength = 128;

SHA384.prototype._digest = function digest(enc) {
  if (enc === 'hex')
    return utils.toHex32(this.h.slice(0, 12), 'big');
  else
    return utils.split32(this.h.slice(0, 12), 'big');
};

},{"../utils":133,"./512":131}],131:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var common = require('../common');
var assert = require('minimalistic-assert');

var rotr64_hi = utils.rotr64_hi;
var rotr64_lo = utils.rotr64_lo;
var shr64_hi = utils.shr64_hi;
var shr64_lo = utils.shr64_lo;
var sum64 = utils.sum64;
var sum64_hi = utils.sum64_hi;
var sum64_lo = utils.sum64_lo;
var sum64_4_hi = utils.sum64_4_hi;
var sum64_4_lo = utils.sum64_4_lo;
var sum64_5_hi = utils.sum64_5_hi;
var sum64_5_lo = utils.sum64_5_lo;

var BlockHash = common.BlockHash;

var sha512_K = [
  0x428a2f98, 0xd728ae22, 0x71374491, 0x23ef65cd,
  0xb5c0fbcf, 0xec4d3b2f, 0xe9b5dba5, 0x8189dbbc,
  0x3956c25b, 0xf348b538, 0x59f111f1, 0xb605d019,
  0x923f82a4, 0xaf194f9b, 0xab1c5ed5, 0xda6d8118,
  0xd807aa98, 0xa3030242, 0x12835b01, 0x45706fbe,
  0x243185be, 0x4ee4b28c, 0x550c7dc3, 0xd5ffb4e2,
  0x72be5d74, 0xf27b896f, 0x80deb1fe, 0x3b1696b1,
  0x9bdc06a7, 0x25c71235, 0xc19bf174, 0xcf692694,
  0xe49b69c1, 0x9ef14ad2, 0xefbe4786, 0x384f25e3,
  0x0fc19dc6, 0x8b8cd5b5, 0x240ca1cc, 0x77ac9c65,
  0x2de92c6f, 0x592b0275, 0x4a7484aa, 0x6ea6e483,
  0x5cb0a9dc, 0xbd41fbd4, 0x76f988da, 0x831153b5,
  0x983e5152, 0xee66dfab, 0xa831c66d, 0x2db43210,
  0xb00327c8, 0x98fb213f, 0xbf597fc7, 0xbeef0ee4,
  0xc6e00bf3, 0x3da88fc2, 0xd5a79147, 0x930aa725,
  0x06ca6351, 0xe003826f, 0x14292967, 0x0a0e6e70,
  0x27b70a85, 0x46d22ffc, 0x2e1b2138, 0x5c26c926,
  0x4d2c6dfc, 0x5ac42aed, 0x53380d13, 0x9d95b3df,
  0x650a7354, 0x8baf63de, 0x766a0abb, 0x3c77b2a8,
  0x81c2c92e, 0x47edaee6, 0x92722c85, 0x1482353b,
  0xa2bfe8a1, 0x4cf10364, 0xa81a664b, 0xbc423001,
  0xc24b8b70, 0xd0f89791, 0xc76c51a3, 0x0654be30,
  0xd192e819, 0xd6ef5218, 0xd6990624, 0x5565a910,
  0xf40e3585, 0x5771202a, 0x106aa070, 0x32bbd1b8,
  0x19a4c116, 0xb8d2d0c8, 0x1e376c08, 0x5141ab53,
  0x2748774c, 0xdf8eeb99, 0x34b0bcb5, 0xe19b48a8,
  0x391c0cb3, 0xc5c95a63, 0x4ed8aa4a, 0xe3418acb,
  0x5b9cca4f, 0x7763e373, 0x682e6ff3, 0xd6b2b8a3,
  0x748f82ee, 0x5defb2fc, 0x78a5636f, 0x43172f60,
  0x84c87814, 0xa1f0ab72, 0x8cc70208, 0x1a6439ec,
  0x90befffa, 0x23631e28, 0xa4506ceb, 0xde82bde9,
  0xbef9a3f7, 0xb2c67915, 0xc67178f2, 0xe372532b,
  0xca273ece, 0xea26619c, 0xd186b8c7, 0x21c0c207,
  0xeada7dd6, 0xcde0eb1e, 0xf57d4f7f, 0xee6ed178,
  0x06f067aa, 0x72176fba, 0x0a637dc5, 0xa2c898a6,
  0x113f9804, 0xbef90dae, 0x1b710b35, 0x131c471b,
  0x28db77f5, 0x23047d84, 0x32caab7b, 0x40c72493,
  0x3c9ebe0a, 0x15c9bebc, 0x431d67c4, 0x9c100d4c,
  0x4cc5d4be, 0xcb3e42b6, 0x597f299c, 0xfc657e2a,
  0x5fcb6fab, 0x3ad6faec, 0x6c44198c, 0x4a475817
];

function SHA512() {
  if (!(this instanceof SHA512))
    return new SHA512();

  BlockHash.call(this);
  this.h = [
    0x6a09e667, 0xf3bcc908,
    0xbb67ae85, 0x84caa73b,
    0x3c6ef372, 0xfe94f82b,
    0xa54ff53a, 0x5f1d36f1,
    0x510e527f, 0xade682d1,
    0x9b05688c, 0x2b3e6c1f,
    0x1f83d9ab, 0xfb41bd6b,
    0x5be0cd19, 0x137e2179 ];
  this.k = sha512_K;
  this.W = new Array(160);
}
utils.inherits(SHA512, BlockHash);
module.exports = SHA512;

SHA512.blockSize = 1024;
SHA512.outSize = 512;
SHA512.hmacStrength = 192;
SHA512.padLength = 128;

SHA512.prototype._prepareBlock = function _prepareBlock(msg, start) {
  var W = this.W;

  // 32 x 32bit words
  for (var i = 0; i < 32; i++)
    W[i] = msg[start + i];
  for (; i < W.length; i += 2) {
    var c0_hi = g1_512_hi(W[i - 4], W[i - 3]);  // i - 2
    var c0_lo = g1_512_lo(W[i - 4], W[i - 3]);
    var c1_hi = W[i - 14];  // i - 7
    var c1_lo = W[i - 13];
    var c2_hi = g0_512_hi(W[i - 30], W[i - 29]);  // i - 15
    var c2_lo = g0_512_lo(W[i - 30], W[i - 29]);
    var c3_hi = W[i - 32];  // i - 16
    var c3_lo = W[i - 31];

    W[i] = sum64_4_hi(
      c0_hi, c0_lo,
      c1_hi, c1_lo,
      c2_hi, c2_lo,
      c3_hi, c3_lo);
    W[i + 1] = sum64_4_lo(
      c0_hi, c0_lo,
      c1_hi, c1_lo,
      c2_hi, c2_lo,
      c3_hi, c3_lo);
  }
};

SHA512.prototype._update = function _update(msg, start) {
  this._prepareBlock(msg, start);

  var W = this.W;

  var ah = this.h[0];
  var al = this.h[1];
  var bh = this.h[2];
  var bl = this.h[3];
  var ch = this.h[4];
  var cl = this.h[5];
  var dh = this.h[6];
  var dl = this.h[7];
  var eh = this.h[8];
  var el = this.h[9];
  var fh = this.h[10];
  var fl = this.h[11];
  var gh = this.h[12];
  var gl = this.h[13];
  var hh = this.h[14];
  var hl = this.h[15];

  assert(this.k.length === W.length);
  for (var i = 0; i < W.length; i += 2) {
    var c0_hi = hh;
    var c0_lo = hl;
    var c1_hi = s1_512_hi(eh, el);
    var c1_lo = s1_512_lo(eh, el);
    var c2_hi = ch64_hi(eh, el, fh, fl, gh, gl);
    var c2_lo = ch64_lo(eh, el, fh, fl, gh, gl);
    var c3_hi = this.k[i];
    var c3_lo = this.k[i + 1];
    var c4_hi = W[i];
    var c4_lo = W[i + 1];

    var T1_hi = sum64_5_hi(
      c0_hi, c0_lo,
      c1_hi, c1_lo,
      c2_hi, c2_lo,
      c3_hi, c3_lo,
      c4_hi, c4_lo);
    var T1_lo = sum64_5_lo(
      c0_hi, c0_lo,
      c1_hi, c1_lo,
      c2_hi, c2_lo,
      c3_hi, c3_lo,
      c4_hi, c4_lo);

    c0_hi = s0_512_hi(ah, al);
    c0_lo = s0_512_lo(ah, al);
    c1_hi = maj64_hi(ah, al, bh, bl, ch, cl);
    c1_lo = maj64_lo(ah, al, bh, bl, ch, cl);

    var T2_hi = sum64_hi(c0_hi, c0_lo, c1_hi, c1_lo);
    var T2_lo = sum64_lo(c0_hi, c0_lo, c1_hi, c1_lo);

    hh = gh;
    hl = gl;

    gh = fh;
    gl = fl;

    fh = eh;
    fl = el;

    eh = sum64_hi(dh, dl, T1_hi, T1_lo);
    el = sum64_lo(dl, dl, T1_hi, T1_lo);

    dh = ch;
    dl = cl;

    ch = bh;
    cl = bl;

    bh = ah;
    bl = al;

    ah = sum64_hi(T1_hi, T1_lo, T2_hi, T2_lo);
    al = sum64_lo(T1_hi, T1_lo, T2_hi, T2_lo);
  }

  sum64(this.h, 0, ah, al);
  sum64(this.h, 2, bh, bl);
  sum64(this.h, 4, ch, cl);
  sum64(this.h, 6, dh, dl);
  sum64(this.h, 8, eh, el);
  sum64(this.h, 10, fh, fl);
  sum64(this.h, 12, gh, gl);
  sum64(this.h, 14, hh, hl);
};

SHA512.prototype._digest = function digest(enc) {
  if (enc === 'hex')
    return utils.toHex32(this.h, 'big');
  else
    return utils.split32(this.h, 'big');
};

function ch64_hi(xh, xl, yh, yl, zh) {
  var r = (xh & yh) ^ ((~xh) & zh);
  if (r < 0)
    r += 0x100000000;
  return r;
}

function ch64_lo(xh, xl, yh, yl, zh, zl) {
  var r = (xl & yl) ^ ((~xl) & zl);
  if (r < 0)
    r += 0x100000000;
  return r;
}

function maj64_hi(xh, xl, yh, yl, zh) {
  var r = (xh & yh) ^ (xh & zh) ^ (yh & zh);
  if (r < 0)
    r += 0x100000000;
  return r;
}

function maj64_lo(xh, xl, yh, yl, zh, zl) {
  var r = (xl & yl) ^ (xl & zl) ^ (yl & zl);
  if (r < 0)
    r += 0x100000000;
  return r;
}

function s0_512_hi(xh, xl) {
  var c0_hi = rotr64_hi(xh, xl, 28);
  var c1_hi = rotr64_hi(xl, xh, 2);  // 34
  var c2_hi = rotr64_hi(xl, xh, 7);  // 39

  var r = c0_hi ^ c1_hi ^ c2_hi;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function s0_512_lo(xh, xl) {
  var c0_lo = rotr64_lo(xh, xl, 28);
  var c1_lo = rotr64_lo(xl, xh, 2);  // 34
  var c2_lo = rotr64_lo(xl, xh, 7);  // 39

  var r = c0_lo ^ c1_lo ^ c2_lo;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function s1_512_hi(xh, xl) {
  var c0_hi = rotr64_hi(xh, xl, 14);
  var c1_hi = rotr64_hi(xh, xl, 18);
  var c2_hi = rotr64_hi(xl, xh, 9);  // 41

  var r = c0_hi ^ c1_hi ^ c2_hi;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function s1_512_lo(xh, xl) {
  var c0_lo = rotr64_lo(xh, xl, 14);
  var c1_lo = rotr64_lo(xh, xl, 18);
  var c2_lo = rotr64_lo(xl, xh, 9);  // 41

  var r = c0_lo ^ c1_lo ^ c2_lo;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function g0_512_hi(xh, xl) {
  var c0_hi = rotr64_hi(xh, xl, 1);
  var c1_hi = rotr64_hi(xh, xl, 8);
  var c2_hi = shr64_hi(xh, xl, 7);

  var r = c0_hi ^ c1_hi ^ c2_hi;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function g0_512_lo(xh, xl) {
  var c0_lo = rotr64_lo(xh, xl, 1);
  var c1_lo = rotr64_lo(xh, xl, 8);
  var c2_lo = shr64_lo(xh, xl, 7);

  var r = c0_lo ^ c1_lo ^ c2_lo;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function g1_512_hi(xh, xl) {
  var c0_hi = rotr64_hi(xh, xl, 19);
  var c1_hi = rotr64_hi(xl, xh, 29);  // 61
  var c2_hi = shr64_hi(xh, xl, 6);

  var r = c0_hi ^ c1_hi ^ c2_hi;
  if (r < 0)
    r += 0x100000000;
  return r;
}

function g1_512_lo(xh, xl) {
  var c0_lo = rotr64_lo(xh, xl, 19);
  var c1_lo = rotr64_lo(xl, xh, 29);  // 61
  var c2_lo = shr64_lo(xh, xl, 6);

  var r = c0_lo ^ c1_lo ^ c2_lo;
  if (r < 0)
    r += 0x100000000;
  return r;
}

},{"../common":123,"../utils":133,"minimalistic-assert":164}],132:[function(require,module,exports){
'use strict';

var utils = require('../utils');
var rotr32 = utils.rotr32;

function ft_1(s, x, y, z) {
  if (s === 0)
    return ch32(x, y, z);
  if (s === 1 || s === 3)
    return p32(x, y, z);
  if (s === 2)
    return maj32(x, y, z);
}
exports.ft_1 = ft_1;

function ch32(x, y, z) {
  return (x & y) ^ ((~x) & z);
}
exports.ch32 = ch32;

function maj32(x, y, z) {
  return (x & y) ^ (x & z) ^ (y & z);
}
exports.maj32 = maj32;

function p32(x, y, z) {
  return x ^ y ^ z;
}
exports.p32 = p32;

function s0_256(x) {
  return rotr32(x, 2) ^ rotr32(x, 13) ^ rotr32(x, 22);
}
exports.s0_256 = s0_256;

function s1_256(x) {
  return rotr32(x, 6) ^ rotr32(x, 11) ^ rotr32(x, 25);
}
exports.s1_256 = s1_256;

function g0_256(x) {
  return rotr32(x, 7) ^ rotr32(x, 18) ^ (x >>> 3);
}
exports.g0_256 = g0_256;

function g1_256(x) {
  return rotr32(x, 17) ^ rotr32(x, 19) ^ (x >>> 10);
}
exports.g1_256 = g1_256;

},{"../utils":133}],133:[function(require,module,exports){
'use strict';

var assert = require('minimalistic-assert');
var inherits = require('inherits');

exports.inherits = inherits;

function isSurrogatePair(msg, i) {
  if ((msg.charCodeAt(i) & 0xFC00) !== 0xD800) {
    return false;
  }
  if (i < 0 || i + 1 >= msg.length) {
    return false;
  }
  return (msg.charCodeAt(i + 1) & 0xFC00) === 0xDC00;
}

function toArray(msg, enc) {
  if (Array.isArray(msg))
    return msg.slice();
  if (!msg)
    return [];
  var res = [];
  if (typeof msg === 'string') {
    if (!enc) {
      // Inspired by stringToUtf8ByteArray() in closure-library by Google
      // https://github.com/google/closure-library/blob/8598d87242af59aac233270742c8984e2b2bdbe0/closure/goog/crypt/crypt.js#L117-L143
      // Apache License 2.0
      // https://github.com/google/closure-library/blob/master/LICENSE
      var p = 0;
      for (var i = 0; i < msg.length; i++) {
        var c = msg.charCodeAt(i);
        if (c < 128) {
          res[p++] = c;
        } else if (c < 2048) {
          res[p++] = (c >> 6) | 192;
          res[p++] = (c & 63) | 128;
        } else if (isSurrogatePair(msg, i)) {
          c = 0x10000 + ((c & 0x03FF) << 10) + (msg.charCodeAt(++i) & 0x03FF);
          res[p++] = (c >> 18) | 240;
          res[p++] = ((c >> 12) & 63) | 128;
          res[p++] = ((c >> 6) & 63) | 128;
          res[p++] = (c & 63) | 128;
        } else {
          res[p++] = (c >> 12) | 224;
          res[p++] = ((c >> 6) & 63) | 128;
          res[p++] = (c & 63) | 128;
        }
      }
    } else if (enc === 'hex') {
      msg = msg.replace(/[^a-z0-9]+/ig, '');
      if (msg.length % 2 !== 0)
        msg = '0' + msg;
      for (i = 0; i < msg.length; i += 2)
        res.push(parseInt(msg[i] + msg[i + 1], 16));
    }
  } else {
    for (i = 0; i < msg.length; i++)
      res[i] = msg[i] | 0;
  }
  return res;
}
exports.toArray = toArray;

function toHex(msg) {
  var res = '';
  for (var i = 0; i < msg.length; i++)
    res += zero2(msg[i].toString(16));
  return res;
}
exports.toHex = toHex;

function htonl(w) {
  var res = (w >>> 24) |
            ((w >>> 8) & 0xff00) |
            ((w << 8) & 0xff0000) |
            ((w & 0xff) << 24);
  return res >>> 0;
}
exports.htonl = htonl;

function toHex32(msg, endian) {
  var res = '';
  for (var i = 0; i < msg.length; i++) {
    var w = msg[i];
    if (endian === 'little')
      w = htonl(w);
    res += zero8(w.toString(16));
  }
  return res;
}
exports.toHex32 = toHex32;

function zero2(word) {
  if (word.length === 1)
    return '0' + word;
  else
    return word;
}
exports.zero2 = zero2;

function zero8(word) {
  if (word.length === 7)
    return '0' + word;
  else if (word.length === 6)
    return '00' + word;
  else if (word.length === 5)
    return '000' + word;
  else if (word.length === 4)
    return '0000' + word;
  else if (word.length === 3)
    return '00000' + word;
  else if (word.length === 2)
    return '000000' + word;
  else if (word.length === 1)
    return '0000000' + word;
  else
    return word;
}
exports.zero8 = zero8;

function join32(msg, start, end, endian) {
  var len = end - start;
  assert(len % 4 === 0);
  var res = new Array(len / 4);
  for (var i = 0, k = start; i < res.length; i++, k += 4) {
    var w;
    if (endian === 'big')
      w = (msg[k] << 24) | (msg[k + 1] << 16) | (msg[k + 2] << 8) | msg[k + 3];
    else
      w = (msg[k + 3] << 24) | (msg[k + 2] << 16) | (msg[k + 1] << 8) | msg[k];
    res[i] = w >>> 0;
  }
  return res;
}
exports.join32 = join32;

function split32(msg, endian) {
  var res = new Array(msg.length * 4);
  for (var i = 0, k = 0; i < msg.length; i++, k += 4) {
    var m = msg[i];
    if (endian === 'big') {
      res[k] = m >>> 24;
      res[k + 1] = (m >>> 16) & 0xff;
      res[k + 2] = (m >>> 8) & 0xff;
      res[k + 3] = m & 0xff;
    } else {
      res[k + 3] = m >>> 24;
      res[k + 2] = (m >>> 16) & 0xff;
      res[k + 1] = (m >>> 8) & 0xff;
      res[k] = m & 0xff;
    }
  }
  return res;
}
exports.split32 = split32;

function rotr32(w, b) {
  return (w >>> b) | (w << (32 - b));
}
exports.rotr32 = rotr32;

function rotl32(w, b) {
  return (w << b) | (w >>> (32 - b));
}
exports.rotl32 = rotl32;

function sum32(a, b) {
  return (a + b) >>> 0;
}
exports.sum32 = sum32;

function sum32_3(a, b, c) {
  return (a + b + c) >>> 0;
}
exports.sum32_3 = sum32_3;

function sum32_4(a, b, c, d) {
  return (a + b + c + d) >>> 0;
}
exports.sum32_4 = sum32_4;

function sum32_5(a, b, c, d, e) {
  return (a + b + c + d + e) >>> 0;
}
exports.sum32_5 = sum32_5;

function sum64(buf, pos, ah, al) {
  var bh = buf[pos];
  var bl = buf[pos + 1];

  var lo = (al + bl) >>> 0;
  var hi = (lo < al ? 1 : 0) + ah + bh;
  buf[pos] = hi >>> 0;
  buf[pos + 1] = lo;
}
exports.sum64 = sum64;

function sum64_hi(ah, al, bh, bl) {
  var lo = (al + bl) >>> 0;
  var hi = (lo < al ? 1 : 0) + ah + bh;
  return hi >>> 0;
}
exports.sum64_hi = sum64_hi;

function sum64_lo(ah, al, bh, bl) {
  var lo = al + bl;
  return lo >>> 0;
}
exports.sum64_lo = sum64_lo;

function sum64_4_hi(ah, al, bh, bl, ch, cl, dh, dl) {
  var carry = 0;
  var lo = al;
  lo = (lo + bl) >>> 0;
  carry += lo < al ? 1 : 0;
  lo = (lo + cl) >>> 0;
  carry += lo < cl ? 1 : 0;
  lo = (lo + dl) >>> 0;
  carry += lo < dl ? 1 : 0;

  var hi = ah + bh + ch + dh + carry;
  return hi >>> 0;
}
exports.sum64_4_hi = sum64_4_hi;

function sum64_4_lo(ah, al, bh, bl, ch, cl, dh, dl) {
  var lo = al + bl + cl + dl;
  return lo >>> 0;
}
exports.sum64_4_lo = sum64_4_lo;

function sum64_5_hi(ah, al, bh, bl, ch, cl, dh, dl, eh, el) {
  var carry = 0;
  var lo = al;
  lo = (lo + bl) >>> 0;
  carry += lo < al ? 1 : 0;
  lo = (lo + cl) >>> 0;
  carry += lo < cl ? 1 : 0;
  lo = (lo + dl) >>> 0;
  carry += lo < dl ? 1 : 0;
  lo = (lo + el) >>> 0;
  carry += lo < el ? 1 : 0;

  var hi = ah + bh + ch + dh + eh + carry;
  return hi >>> 0;
}
exports.sum64_5_hi = sum64_5_hi;

function sum64_5_lo(ah, al, bh, bl, ch, cl, dh, dl, eh, el) {
  var lo = al + bl + cl + dl + el;

  return lo >>> 0;
}
exports.sum64_5_lo = sum64_5_lo;

function rotr64_hi(ah, al, num) {
  var r = (al << (32 - num)) | (ah >>> num);
  return r >>> 0;
}
exports.rotr64_hi = rotr64_hi;

function rotr64_lo(ah, al, num) {
  var r = (ah << (32 - num)) | (al >>> num);
  return r >>> 0;
}
exports.rotr64_lo = rotr64_lo;

function shr64_hi(ah, al, num) {
  return ah >>> num;
}
exports.shr64_hi = shr64_hi;

function shr64_lo(ah, al, num) {
  var r = (ah << (32 - num)) | (al >>> num);
  return r >>> 0;
}
exports.shr64_lo = shr64_lo;

},{"inherits":136,"minimalistic-assert":164}],134:[function(require,module,exports){
'use strict';

var hash = require('hash.js');
var utils = require('minimalistic-crypto-utils');
var assert = require('minimalistic-assert');

function HmacDRBG(options) {
  if (!(this instanceof HmacDRBG))
    return new HmacDRBG(options);
  this.hash = options.hash;
  this.predResist = !!options.predResist;

  this.outLen = this.hash.outSize;
  this.minEntropy = options.minEntropy || this.hash.hmacStrength;

  this._reseed = null;
  this.reseedInterval = null;
  this.K = null;
  this.V = null;

  var entropy = utils.toArray(options.entropy, options.entropyEnc || 'hex');
  var nonce = utils.toArray(options.nonce, options.nonceEnc || 'hex');
  var pers = utils.toArray(options.pers, options.persEnc || 'hex');
  assert(entropy.length >= (this.minEntropy / 8),
         'Not enough entropy. Minimum is: ' + this.minEntropy + ' bits');
  this._init(entropy, nonce, pers);
}
module.exports = HmacDRBG;

HmacDRBG.prototype._init = function init(entropy, nonce, pers) {
  var seed = entropy.concat(nonce).concat(pers);

  this.K = new Array(this.outLen / 8);
  this.V = new Array(this.outLen / 8);
  for (var i = 0; i < this.V.length; i++) {
    this.K[i] = 0x00;
    this.V[i] = 0x01;
  }

  this._update(seed);
  this._reseed = 1;
  this.reseedInterval = 0x1000000000000;  // 2^48
};

HmacDRBG.prototype._hmac = function hmac() {
  return new hash.hmac(this.hash, this.K);
};

HmacDRBG.prototype._update = function update(seed) {
  var kmac = this._hmac()
                 .update(this.V)
                 .update([ 0x00 ]);
  if (seed)
    kmac = kmac.update(seed);
  this.K = kmac.digest();
  this.V = this._hmac().update(this.V).digest();
  if (!seed)
    return;

  this.K = this._hmac()
               .update(this.V)
               .update([ 0x01 ])
               .update(seed)
               .digest();
  this.V = this._hmac().update(this.V).digest();
};

HmacDRBG.prototype.reseed = function reseed(entropy, entropyEnc, add, addEnc) {
  // Optional entropy enc
  if (typeof entropyEnc !== 'string') {
    addEnc = add;
    add = entropyEnc;
    entropyEnc = null;
  }

  entropy = utils.toArray(entropy, entropyEnc);
  add = utils.toArray(add, addEnc);

  assert(entropy.length >= (this.minEntropy / 8),
         'Not enough entropy. Minimum is: ' + this.minEntropy + ' bits');

  this._update(entropy.concat(add || []));
  this._reseed = 1;
};

HmacDRBG.prototype.generate = function generate(len, enc, add, addEnc) {
  if (this._reseed > this.reseedInterval)
    throw new Error('Reseed is required');

  // Optional encoding
  if (typeof enc !== 'string') {
    addEnc = add;
    add = enc;
    enc = null;
  }

  // Optional additional data
  if (add) {
    add = utils.toArray(add, addEnc || 'hex');
    this._update(add);
  }

  var temp = [];
  while (temp.length < len) {
    this.V = this._hmac().update(this.V).digest();
    temp = temp.concat(this.V);
  }

  var res = temp.slice(0, len);
  this._update(add);
  this._reseed++;
  return utils.encode(res, enc);
};

},{"hash.js":122,"minimalistic-assert":164,"minimalistic-crypto-utils":165}],135:[function(require,module,exports){
/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */
exports.read = function (buffer, offset, isLE, mLen, nBytes) {
  var e, m
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var nBits = -7
  var i = isLE ? (nBytes - 1) : 0
  var d = isLE ? -1 : 1
  var s = buffer[offset + i]

  i += d

  e = s & ((1 << (-nBits)) - 1)
  s >>= (-nBits)
  nBits += eLen
  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  m = e & ((1 << (-nBits)) - 1)
  e >>= (-nBits)
  nBits += mLen
  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}

  if (e === 0) {
    e = 1 - eBias
  } else if (e === eMax) {
    return m ? NaN : ((s ? -1 : 1) * Infinity)
  } else {
    m = m + Math.pow(2, mLen)
    e = e - eBias
  }
  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)
}

exports.write = function (buffer, value, offset, isLE, mLen, nBytes) {
  var e, m, c
  var eLen = (nBytes * 8) - mLen - 1
  var eMax = (1 << eLen) - 1
  var eBias = eMax >> 1
  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)
  var i = isLE ? 0 : (nBytes - 1)
  var d = isLE ? 1 : -1
  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0

  value = Math.abs(value)

  if (isNaN(value) || value === Infinity) {
    m = isNaN(value) ? 1 : 0
    e = eMax
  } else {
    e = Math.floor(Math.log(value) / Math.LN2)
    if (value * (c = Math.pow(2, -e)) < 1) {
      e--
      c *= 2
    }
    if (e + eBias >= 1) {
      value += rt / c
    } else {
      value += rt * Math.pow(2, 1 - eBias)
    }
    if (value * c >= 2) {
      e++
      c /= 2
    }

    if (e + eBias >= eMax) {
      m = 0
      e = eMax
    } else if (e + eBias >= 1) {
      m = ((value * c) - 1) * Math.pow(2, mLen)
      e = e + eBias
    } else {
      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)
      e = 0
    }
  }

  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}

  e = (e << mLen) | m
  eLen += mLen
  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}

  buffer[offset + i - d] |= s * 128
}

},{}],136:[function(require,module,exports){
if (typeof Object.create === 'function') {
  // implementation from standard node.js 'util' module
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      ctor.prototype = Object.create(superCtor.prototype, {
        constructor: {
          value: ctor,
          enumerable: false,
          writable: true,
          configurable: true
        }
      })
    }
  };
} else {
  // old school shim for old browsers
  module.exports = function inherits(ctor, superCtor) {
    if (superCtor) {
      ctor.super_ = superCtor
      var TempCtor = function () {}
      TempCtor.prototype = superCtor.prototype
      ctor.prototype = new TempCtor()
      ctor.prototype.constructor = ctor
    }
  }
}

},{}],137:[function(require,module,exports){
/*
 * Copyright (c) 2017-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const api = {};
module.exports = api;

/**
 * Converts the given date into W3C datetime format (eg: 2011-03-09T21:55:41Z).
 *
 * @param date the date to convert.
 *
 * @return the date in W3C datetime format.
 */
api.w3cDate = date => {
  if(date === undefined || date === null) {
    date = new Date();
  } else if(typeof date === 'number' || typeof date === 'string') {
    date = new Date(date);
  }
  const str = date.toISOString();
  return str.substr(0, str.length - 5) + 'Z';
};

/**
 * Concatenates two Uint8Arrays.
 *
 * @param b1 {Uint8Array}.
 * @param b2 {Uint8Array}.
 *
 * @return {Uint8Array} the result.
 */
api.concat = (b1, b2) => {
  const rval = new Uint8Array(b1.length + b2.length);
  rval.set(b1, 0);
  rval.set(b2, b1.length);
  return rval;
};

},{}],138:[function(require,module,exports){
/*
 * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {
  isArray: _isArray,
  isObject: _isObject,
  isString: _isString,
} = require('./types');
const {
  asArray: _asArray
} = require('./util');
const {prependBase} = require('./url');
const JsonLdError = require('./JsonLdError');
const ResolvedContext = require('./ResolvedContext');

const MAX_CONTEXT_URLS = 10;

module.exports = class ContextResolver {
  /**
   * Creates a ContextResolver.
   *
   * @param sharedCache a shared LRU cache with `get` and `set` APIs.
   */
  constructor({sharedCache}) {
    this.perOpCache = new Map();
    this.sharedCache = sharedCache;
  }

  async resolve({
    activeCtx, context, documentLoader, base, cycles = new Set()
  }) {
    // process `@context`
    if(context && _isObject(context) && context['@context']) {
      context = context['@context'];
    }

    // context is one or more contexts
    context = _asArray(context);

    // resolve each context in the array
    const allResolved = [];
    for(const ctx of context) {
      if(_isString(ctx)) {
        // see if `ctx` has been resolved before...
        let resolved = this._get(ctx);
        if(!resolved) {
          // not resolved yet, resolve
          resolved = await this._resolveRemoteContext(
            {activeCtx, url: ctx, documentLoader, base, cycles});
        }

        // add to output and continue
        if(_isArray(resolved)) {
          allResolved.push(...resolved);
        } else {
          allResolved.push(resolved);
        }
        continue;
      }
      if(ctx === null) {
        // handle `null` context, nothing to cache
        allResolved.push(new ResolvedContext({document: null}));
        continue;
      }
      if(!_isObject(ctx)) {
        _throwInvalidLocalContext(context);
      }
      // context is an object, get/create `ResolvedContext` for it
      const key = JSON.stringify(ctx);
      let resolved = this._get(key);
      if(!resolved) {
        // create a new static `ResolvedContext` and cache it
        resolved = new ResolvedContext({document: ctx});
        this._cacheResolvedContext({key, resolved, tag: 'static'});
      }
      allResolved.push(resolved);
    }

    return allResolved;
  }

  _get(key) {
    // get key from per operation cache; no `tag` is used with this cache so
    // any retrieved context will always be the same during a single operation
    let resolved = this.perOpCache.get(key);
    if(!resolved) {
      // see if the shared cache has a `static` entry for this URL
      const tagMap = this.sharedCache.get(key);
      if(tagMap) {
        resolved = tagMap.get('static');
        if(resolved) {
          this.perOpCache.set(key, resolved);
        }
      }
    }
    return resolved;
  }

  _cacheResolvedContext({key, resolved, tag}) {
    this.perOpCache.set(key, resolved);
    if(tag !== undefined) {
      let tagMap = this.sharedCache.get(key);
      if(!tagMap) {
        tagMap = new Map();
        this.sharedCache.set(key, tagMap);
      }
      tagMap.set(tag, resolved);
    }
    return resolved;
  }

  async _resolveRemoteContext({activeCtx, url, documentLoader, base, cycles}) {
    // resolve relative URL and fetch context
    url = prependBase(base, url);
    const {context, remoteDoc} = await this._fetchContext(
      {activeCtx, url, documentLoader, cycles});

    // update base according to remote document and resolve any relative URLs
    base = remoteDoc.documentUrl || url;
    _resolveContextUrls({context, base});

    // resolve, cache, and return context
    const resolved = await this.resolve(
      {activeCtx, context, documentLoader, base, cycles});
    this._cacheResolvedContext({key: url, resolved, tag: remoteDoc.tag});
    return resolved;
  }

  async _fetchContext({activeCtx, url, documentLoader, cycles}) {
    // check for max context URLs fetched during a resolve operation
    if(cycles.size > MAX_CONTEXT_URLS) {
      throw new JsonLdError(
        'Maximum number of @context URLs exceeded.',
        'jsonld.ContextUrlError',
        {
          code: activeCtx.processingMode === 'json-ld-1.0' ?
            'loading remote context failed' :
            'context overflow',
          max: MAX_CONTEXT_URLS
        });
    }

    // check for context URL cycle
    // shortcut to avoid extra work that would eventually hit the max above
    if(cycles.has(url)) {
      throw new JsonLdError(
        'Cyclical @context URLs detected.',
        'jsonld.ContextUrlError',
        {
          code: activeCtx.processingMode === 'json-ld-1.0' ?
            'recursive context inclusion' :
            'context overflow',
          url
        });
    }

    // track cycles
    cycles.add(url);

    let context;
    let remoteDoc;

    try {
      remoteDoc = await documentLoader(url);
      context = remoteDoc.document || null;
      // parse string context as JSON
      if(_isString(context)) {
        context = JSON.parse(context);
      }
    } catch(e) {
      throw new JsonLdError(
        'Dereferencing a URL did not result in a valid JSON-LD object. ' +
        'Possible causes are an inaccessible URL perhaps due to ' +
        'a same-origin policy (ensure the server uses CORS if you are ' +
        'using client-side JavaScript), too many redirects, a ' +
        'non-JSON response, or more than one HTTP Link Header was ' +
        'provided for a remote context.',
        'jsonld.InvalidUrl',
        {code: 'loading remote context failed', url, cause: e});
    }

    // ensure ctx is an object
    if(!_isObject(context)) {
      throw new JsonLdError(
        'Dereferencing a URL did not result in a JSON object. The ' +
        'response was valid JSON, but it was not a JSON object.',
        'jsonld.InvalidUrl', {code: 'invalid remote context', url});
    }

    // use empty context if no @context key is present
    if(!('@context' in context)) {
      context = {'@context': {}};
    } else {
      context = {'@context': context['@context']};
    }

    // append @context URL to context if given
    if(remoteDoc.contextUrl) {
      if(!_isArray(context['@context'])) {
        context['@context'] = [context['@context']];
      }
      context['@context'].push(remoteDoc.contextUrl);
    }

    return {context, remoteDoc};
  }
};

function _throwInvalidLocalContext(ctx) {
  throw new JsonLdError(
    'Invalid JSON-LD syntax; @context must be an object.',
    'jsonld.SyntaxError', {
      code: 'invalid local context', context: ctx
    });
}

/**
 * Resolve all relative `@context` URLs in the given context by inline
 * replacing them with absolute URLs.
 *
 * @param context the context.
 * @param base the base IRI to use to resolve relative IRIs.
 */
function _resolveContextUrls({context, base}) {
  if(!context) {
    return;
  }

  const ctx = context['@context'];

  if(_isString(ctx)) {
    context['@context'] = prependBase(base, ctx);
    return;
  }

  if(_isArray(ctx)) {
    for(let i = 0; i < ctx.length; ++i) {
      const element = ctx[i];
      if(_isString(element)) {
        ctx[i] = prependBase(base, element);
        continue;
      }
      if(_isObject(element)) {
        _resolveContextUrls({context: {'@context': element}, base});
      }
    }
    return;
  }

  if(!_isObject(ctx)) {
    // no @context URLs can be found in non-object
    return;
  }

  // ctx is an object, resolve any context URLs in terms
  for(const term in ctx) {
    _resolveContextUrls({context: ctx[term], base});
  }
}

},{"./JsonLdError":139,"./ResolvedContext":143,"./types":157,"./url":158,"./util":159}],139:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

module.exports = class JsonLdError extends Error {
  /**
   * Creates a JSON-LD Error.
   *
   * @param msg the error message.
   * @param type the error type.
   * @param details the error details.
   */
  constructor(
    message = 'An unspecified JSON-LD error occurred.',
    name = 'jsonld.Error',
    details = {}) {
    super(message);
    this.name = name;
    this.message = message;
    this.details = details;
  }
};

},{}],140:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

module.exports = jsonld => {
  class JsonLdProcessor {
    toString() {
      return '[object JsonLdProcessor]';
    }
  }
  Object.defineProperty(JsonLdProcessor, 'prototype', {
    writable: false,
    enumerable: false
  });
  Object.defineProperty(JsonLdProcessor.prototype, 'constructor', {
    writable: true,
    enumerable: false,
    configurable: true,
    value: JsonLdProcessor
  });

  // The Web IDL test harness will check the number of parameters defined in
  // the functions below. The number of parameters must exactly match the
  // required (non-optional) parameters of the JsonLdProcessor interface as
  // defined here:
  // https://www.w3.org/TR/json-ld-api/#the-jsonldprocessor-interface

  JsonLdProcessor.compact = function(input, ctx) {
    if(arguments.length < 2) {
      return Promise.reject(
        new TypeError('Could not compact, too few arguments.'));
    }
    return jsonld.compact(input, ctx);
  };
  JsonLdProcessor.expand = function(input) {
    if(arguments.length < 1) {
      return Promise.reject(
        new TypeError('Could not expand, too few arguments.'));
    }
    return jsonld.expand(input);
  };
  JsonLdProcessor.flatten = function(input) {
    if(arguments.length < 1) {
      return Promise.reject(
        new TypeError('Could not flatten, too few arguments.'));
    }
    return jsonld.flatten(input);
  };

  return JsonLdProcessor;
};

},{}],141:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

// TODO: move `NQuads` to its own package
module.exports = require('rdf-canonize').NQuads;

},{"rdf-canonize":189}],142:[function(require,module,exports){
/*
 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

module.exports = class RequestQueue {
  /**
   * Creates a simple queue for requesting documents.
   */
  constructor() {
    this._requests = {};
  }

  wrapLoader(loader) {
    const self = this;
    self._loader = loader;
    return function(/* url */) {
      return self.add.apply(self, arguments);
    };
  }

  async add(url) {
    let promise = this._requests[url];
    if(promise) {
      // URL already queued, wait for it to load
      return Promise.resolve(promise);
    }

    // queue URL and load it
    promise = this._requests[url] = this._loader(url);

    try {
      return await promise;
    } finally {
      delete this._requests[url];
    }
  }
};

},{}],143:[function(require,module,exports){
/*
 * Copyright (c) 2019 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const LRU = require('lru-cache');

const MAX_ACTIVE_CONTEXTS = 10;

module.exports = class ResolvedContext {
  /**
   * Creates a ResolvedContext.
   *
   * @param document the context document.
   */
  constructor({document}) {
    this.document = document;
    // TODO: enable customization of processed context cache
    // TODO: limit based on size of processed contexts vs. number of them
    this.cache = new LRU({max: MAX_ACTIVE_CONTEXTS});
  }

  getProcessed(activeCtx) {
    return this.cache.get(activeCtx);
  }

  setProcessed(activeCtx, processedCtx) {
    this.cache.set(activeCtx, processedCtx);
  }
};

},{"lru-cache":160}],144:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const JsonLdError = require('./JsonLdError');

const {
  isArray: _isArray,
  isObject: _isObject,
  isString: _isString,
  isUndefined: _isUndefined
} = require('./types');

const {
  isList: _isList,
  isValue: _isValue,
  isGraph: _isGraph,
  isSimpleGraph: _isSimpleGraph,
  isSubjectReference: _isSubjectReference
} = require('./graphTypes');

const {
  expandIri: _expandIri,
  getContextValue: _getContextValue,
  isKeyword: _isKeyword,
  process: _processContext,
  processingMode: _processingMode
} = require('./context');

const {
  removeBase: _removeBase,
  prependBase: _prependBase
} = require('./url');

const {
  addValue: _addValue,
  asArray: _asArray,
  compareShortestLeast: _compareShortestLeast
} = require('./util');

const api = {};
module.exports = api;

/**
 * Recursively compacts an element using the given active context. All values
 * must be in expanded form before this method is called.
 *
 * @param activeCtx the active context to use.
 * @param activeProperty the compacted property associated with the element
 *          to compact, null for none.
 * @param element the element to compact.
 * @param options the compaction options.
 * @param compactionMap the compaction map to use.
 *
 * @return a promise that resolves to the compacted value.
 */
api.compact = async ({
  activeCtx,
  activeProperty = null,
  element,
  options = {},
  compactionMap = () => undefined
}) => {
  // recursively compact array
  if(_isArray(element)) {
    let rval = [];
    for(let i = 0; i < element.length; ++i) {
      // compact, dropping any null values unless custom mapped
      let compacted = await api.compact({
        activeCtx,
        activeProperty,
        element: element[i],
        options,
        compactionMap
      });
      if(compacted === null) {
        compacted = await compactionMap({
          unmappedValue: element[i],
          activeCtx,
          activeProperty,
          parent: element,
          index: i,
          options
        });
        if(compacted === undefined) {
          continue;
        }
      }
      rval.push(compacted);
    }
    if(options.compactArrays && rval.length === 1) {
      // use single element if no container is specified
      const container = _getContextValue(
        activeCtx, activeProperty, '@container') || [];
      if(container.length === 0) {
        rval = rval[0];
      }
    }
    return rval;
  }

  // use any scoped context on activeProperty
  const ctx = _getContextValue(activeCtx, activeProperty, '@context');
  if(!_isUndefined(ctx)) {
    activeCtx = await _processContext({
      activeCtx,
      localCtx: ctx,
      propagate: true,
      overrideProtected: true,
      options
    });
  }

  // recursively compact object
  if(_isObject(element)) {
    if(options.link && '@id' in element &&
      options.link.hasOwnProperty(element['@id'])) {
      // check for a linked element to reuse
      const linked = options.link[element['@id']];
      for(let i = 0; i < linked.length; ++i) {
        if(linked[i].expanded === element) {
          return linked[i].compacted;
        }
      }
    }

    // do value compaction on @values and subject references
    if(_isValue(element) || _isSubjectReference(element)) {
      const rval =
        api.compactValue({activeCtx, activeProperty, value: element, options});
      if(options.link && _isSubjectReference(element)) {
        // store linked element
        if(!(options.link.hasOwnProperty(element['@id']))) {
          options.link[element['@id']] = [];
        }
        options.link[element['@id']].push({expanded: element, compacted: rval});
      }
      return rval;
    }

    // if expanded property is @list and we're contained within a list
    // container, recursively compact this item to an array
    if(_isList(element)) {
      const container = _getContextValue(
        activeCtx, activeProperty, '@container') || [];
      if(container.includes('@list')) {
        return api.compact({
          activeCtx,
          activeProperty,
          element: element['@list'],
          options,
          compactionMap
        });
      }
    }

    // FIXME: avoid misuse of active property as an expanded property?
    const insideReverse = (activeProperty === '@reverse');

    const rval = {};

    // original context before applying property-scoped and local contexts
    const inputCtx = activeCtx;

    // revert to previous context, if there is one,
    // and element is not a value object or a node reference
    if(!_isValue(element) && !_isSubjectReference(element)) {
      activeCtx = activeCtx.revertToPreviousContext();
    }

    // apply property-scoped context after reverting term-scoped context
    const propertyScopedCtx =
      _getContextValue(inputCtx, activeProperty, '@context');
    if(!_isUndefined(propertyScopedCtx)) {
      activeCtx = await _processContext({
        activeCtx,
        localCtx: propertyScopedCtx,
        propagate: true,
        overrideProtected: true,
        options
      });
    }

    if(options.link && '@id' in element) {
      // store linked element
      if(!options.link.hasOwnProperty(element['@id'])) {
        options.link[element['@id']] = [];
      }
      options.link[element['@id']].push({expanded: element, compacted: rval});
    }

    // apply any context defined on an alias of @type
    // if key is @type and any compacted value is a term having a local
    // context, overlay that context
    let types = element['@type'] || [];
    if(types.length > 1) {
      types = Array.from(types).sort();
    }
    // find all type-scoped contexts based on current context, prior to
    // updating it
    const typeContext = activeCtx;
    for(const type of types) {
      const compactedType = api.compactIri(
        {activeCtx: typeContext, iri: type, relativeTo: {vocab: true}});

      // Use any type-scoped context defined on this value
      const ctx = _getContextValue(inputCtx, compactedType, '@context');
      if(!_isUndefined(ctx)) {
        activeCtx = await _processContext({
          activeCtx,
          localCtx: ctx,
          options,
          propagate: false
        });
      }
    }

    // process element keys in order
    const keys = Object.keys(element).sort();
    for(const expandedProperty of keys) {
      const expandedValue = element[expandedProperty];

      // compact @id
      if(expandedProperty === '@id') {
        let compactedValue = _asArray(expandedValue).map(
          expandedIri => api.compactIri({
            activeCtx,
            iri: expandedIri,
            relativeTo: {vocab: false},
            base: options.base
          }));
        if(compactedValue.length === 1) {
          compactedValue = compactedValue[0];
        }

        // use keyword alias and add value
        const alias = api.compactIri(
          {activeCtx, iri: '@id', relativeTo: {vocab: true}});

        rval[alias] = compactedValue;
        continue;
      }

      // compact @type(s)
      if(expandedProperty === '@type') {
        // resolve type values against previous context
        let compactedValue = _asArray(expandedValue).map(
          expandedIri => api.compactIri({
            activeCtx: inputCtx,
            iri: expandedIri,
            relativeTo: {vocab: true}
          }));
        if(compactedValue.length === 1) {
          compactedValue = compactedValue[0];
        }

        // use keyword alias and add value
        const alias = api.compactIri(
          {activeCtx, iri: '@type', relativeTo: {vocab: true}});
        const container = _getContextValue(
          activeCtx, alias, '@container') || [];

        // treat as array for @type if @container includes @set
        const typeAsSet =
          container.includes('@set') &&
          _processingMode(activeCtx, 1.1);
        const isArray =
          typeAsSet || (_isArray(compactedValue) && expandedValue.length === 0);
        _addValue(rval, alias, compactedValue, {propertyIsArray: isArray});
        continue;
      }

      // handle @reverse
      if(expandedProperty === '@reverse') {
        // recursively compact expanded value
        const compactedValue = await api.compact({
          activeCtx,
          activeProperty: '@reverse',
          element: expandedValue,
          options,
          compactionMap
        });

        // handle double-reversed properties
        for(const compactedProperty in compactedValue) {
          if(activeCtx.mappings.has(compactedProperty) &&
            activeCtx.mappings.get(compactedProperty).reverse) {
            const value = compactedValue[compactedProperty];
            const container = _getContextValue(
              activeCtx, compactedProperty, '@container') || [];
            const useArray = (
              container.includes('@set') || !options.compactArrays);
            _addValue(
              rval, compactedProperty, value, {propertyIsArray: useArray});
            delete compactedValue[compactedProperty];
          }
        }

        if(Object.keys(compactedValue).length > 0) {
          // use keyword alias and add value
          const alias = api.compactIri({
            activeCtx,
            iri: expandedProperty,
            relativeTo: {vocab: true}
          });
          _addValue(rval, alias, compactedValue);
        }

        continue;
      }

      if(expandedProperty === '@preserve') {
        // compact using activeProperty
        const compactedValue = await api.compact({
          activeCtx,
          activeProperty,
          element: expandedValue,
          options,
          compactionMap
        });

        if(!(_isArray(compactedValue) && compactedValue.length === 0)) {
          _addValue(rval, expandedProperty, compactedValue);
        }
        continue;
      }

      // handle @index property
      if(expandedProperty === '@index') {
        // drop @index if inside an @index container
        const container = _getContextValue(
          activeCtx, activeProperty, '@container') || [];
        if(container.includes('@index')) {
          continue;
        }

        // use keyword alias and add value
        const alias = api.compactIri({
          activeCtx,
          iri: expandedProperty,
          relativeTo: {vocab: true}
        });
        _addValue(rval, alias, expandedValue);
        continue;
      }

      // skip array processing for keywords that aren't
      // @graph, @list, or @included
      if(expandedProperty !== '@graph' && expandedProperty !== '@list' &&
        expandedProperty !== '@included' &&
        _isKeyword(expandedProperty)) {
        // use keyword alias and add value as is
        const alias = api.compactIri({
          activeCtx,
          iri: expandedProperty,
          relativeTo: {vocab: true}
        });
        _addValue(rval, alias, expandedValue);
        continue;
      }

      // Note: expanded value must be an array due to expansion algorithm.
      if(!_isArray(expandedValue)) {
        throw new JsonLdError(
          'JSON-LD expansion error; expanded value must be an array.',
          'jsonld.SyntaxError');
      }

      // preserve empty arrays
      if(expandedValue.length === 0) {
        const itemActiveProperty = api.compactIri({
          activeCtx,
          iri: expandedProperty,
          value: expandedValue,
          relativeTo: {vocab: true},
          reverse: insideReverse
        });
        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?
          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;
        let nestResult = rval;
        if(nestProperty) {
          _checkNestProperty(activeCtx, nestProperty, options);
          if(!_isObject(rval[nestProperty])) {
            rval[nestProperty] = {};
          }
          nestResult = rval[nestProperty];
        }
        _addValue(
          nestResult, itemActiveProperty, expandedValue, {
            propertyIsArray: true
          });
      }

      // recusively process array values
      for(const expandedItem of expandedValue) {
        // compact property and get container type
        const itemActiveProperty = api.compactIri({
          activeCtx,
          iri: expandedProperty,
          value: expandedItem,
          relativeTo: {vocab: true},
          reverse: insideReverse
        });

        // if itemActiveProperty is a @nest property, add values to nestResult,
        // otherwise rval
        const nestProperty = activeCtx.mappings.has(itemActiveProperty) ?
          activeCtx.mappings.get(itemActiveProperty)['@nest'] : null;
        let nestResult = rval;
        if(nestProperty) {
          _checkNestProperty(activeCtx, nestProperty, options);
          if(!_isObject(rval[nestProperty])) {
            rval[nestProperty] = {};
          }
          nestResult = rval[nestProperty];
        }

        const container = _getContextValue(
          activeCtx, itemActiveProperty, '@container') || [];

        // get simple @graph or @list value if appropriate
        const isGraph = _isGraph(expandedItem);
        const isList = _isList(expandedItem);
        let inner;
        if(isList) {
          inner = expandedItem['@list'];
        } else if(isGraph) {
          inner = expandedItem['@graph'];
        }

        // recursively compact expanded item
        let compactedItem = await api.compact({
          activeCtx,
          activeProperty: itemActiveProperty,
          element: (isList || isGraph) ? inner : expandedItem,
          options,
          compactionMap
        });

        // handle @list
        if(isList) {
          // ensure @list value is an array
          if(!_isArray(compactedItem)) {
            compactedItem = [compactedItem];
          }

          if(!container.includes('@list')) {
            // wrap using @list alias
            compactedItem = {
              [api.compactIri({
                activeCtx,
                iri: '@list',
                relativeTo: {vocab: true}
              })]: compactedItem
            };

            // include @index from expanded @list, if any
            if('@index' in expandedItem) {
              compactedItem[api.compactIri({
                activeCtx,
                iri: '@index',
                relativeTo: {vocab: true}
              })] = expandedItem['@index'];
            }
          } else {
            _addValue(nestResult, itemActiveProperty, compactedItem, {
              valueIsArray: true,
              allowDuplicate: true
            });
            continue;
          }
        }

        // Graph object compaction cases
        if(isGraph) {
          if(container.includes('@graph') && (container.includes('@id') ||
            container.includes('@index') && _isSimpleGraph(expandedItem))) {
            // get or create the map object
            let mapObject;
            if(nestResult.hasOwnProperty(itemActiveProperty)) {
              mapObject = nestResult[itemActiveProperty];
            } else {
              nestResult[itemActiveProperty] = mapObject = {};
            }

            // index on @id or @index or alias of @none
            const key = (container.includes('@id') ?
              expandedItem['@id'] : expandedItem['@index']) ||
              api.compactIri({activeCtx, iri: '@none',
                relativeTo: {vocab: true}});
            // add compactedItem to map, using value of `@id` or a new blank
            // node identifier

            _addValue(
              mapObject, key, compactedItem, {
                propertyIsArray:
                  (!options.compactArrays || container.includes('@set'))
              });
          } else if(container.includes('@graph') &&
            _isSimpleGraph(expandedItem)) {
            // container includes @graph but not @id or @index and value is a
            // simple graph object add compact value
            // if compactedItem contains multiple values, it is wrapped in
            // `@included`
            if(_isArray(compactedItem) && compactedItem.length > 1) {
              compactedItem = {'@included': compactedItem};
            }
            _addValue(
              nestResult, itemActiveProperty, compactedItem, {
                propertyIsArray:
                  (!options.compactArrays || container.includes('@set'))
              });
          } else {
            // wrap using @graph alias, remove array if only one item and
            // compactArrays not set
            if(_isArray(compactedItem) && compactedItem.length === 1 &&
              options.compactArrays) {
              compactedItem = compactedItem[0];
            }
            compactedItem = {
              [api.compactIri({
                activeCtx,
                iri: '@graph',
                relativeTo: {vocab: true}
              })]: compactedItem
            };

            // include @id from expanded graph, if any
            if('@id' in expandedItem) {
              compactedItem[api.compactIri({
                activeCtx,
                iri: '@id',
                relativeTo: {vocab: true}
              })] = expandedItem['@id'];
            }

            // include @index from expanded graph, if any
            if('@index' in expandedItem) {
              compactedItem[api.compactIri({
                activeCtx,
                iri: '@index',
                relativeTo: {vocab: true}
              })] = expandedItem['@index'];
            }
            _addValue(
              nestResult, itemActiveProperty, compactedItem, {
                propertyIsArray:
                  (!options.compactArrays || container.includes('@set'))
              });
          }
        } else if(container.includes('@language') ||
          container.includes('@index') || container.includes('@id') ||
          container.includes('@type')) {
          // handle language and index maps
          // get or create the map object
          let mapObject;
          if(nestResult.hasOwnProperty(itemActiveProperty)) {
            mapObject = nestResult[itemActiveProperty];
          } else {
            nestResult[itemActiveProperty] = mapObject = {};
          }

          let key;
          if(container.includes('@language')) {
          // if container is a language map, simplify compacted value to
          // a simple string
            if(_isValue(compactedItem)) {
              compactedItem = compactedItem['@value'];
            }
            key = expandedItem['@language'];
          } else if(container.includes('@index')) {
            const indexKey = _getContextValue(
              activeCtx, itemActiveProperty, '@index') || '@index';
            const containerKey = api.compactIri(
              {activeCtx, iri: indexKey, relativeTo: {vocab: true}});
            if(indexKey === '@index') {
              key = expandedItem['@index'];
              delete compactedItem[containerKey];
            } else {
              let others;
              [key, ...others] = _asArray(compactedItem[indexKey] || []);
              if(!_isString(key)) {
                // Will use @none if it isn't a string.
                key = null;
              } else {
                switch(others.length) {
                  case 0:
                    delete compactedItem[indexKey];
                    break;
                  case 1:
                    compactedItem[indexKey] = others[0];
                    break;
                  default:
                    compactedItem[indexKey] = others;
                    break;
                }
              }
            }
          } else if(container.includes('@id')) {
            const idKey = api.compactIri({activeCtx, iri: '@id',
              relativeTo: {vocab: true}});
            key = compactedItem[idKey];
            delete compactedItem[idKey];
          } else if(container.includes('@type')) {
            const typeKey = api.compactIri({
              activeCtx,
              iri: '@type',
              relativeTo: {vocab: true}
            });
            let types;
            [key, ...types] = _asArray(compactedItem[typeKey] || []);
            switch(types.length) {
              case 0:
                delete compactedItem[typeKey];
                break;
              case 1:
                compactedItem[typeKey] = types[0];
                break;
              default:
                compactedItem[typeKey] = types;
                break;
            }

            // If compactedItem contains a single entry
            // whose key maps to @id, recompact without @type
            if(Object.keys(compactedItem).length === 1 &&
              '@id' in expandedItem) {
              compactedItem = await api.compact({
                activeCtx,
                activeProperty: itemActiveProperty,
                element: {'@id': expandedItem['@id']},
                options,
                compactionMap
              });
            }
          }

          // if compacting this value which has no key, index on @none
          if(!key) {
            key = api.compactIri({activeCtx, iri: '@none',
              relativeTo: {vocab: true}});
          }
          // add compact value to map object using key from expanded value
          // based on the container type
          _addValue(
            mapObject, key, compactedItem, {
              propertyIsArray: container.includes('@set')
            });
        } else {
          // use an array if: compactArrays flag is false,
          // @container is @set or @list , value is an empty
          // array, or key is @graph
          const isArray = (!options.compactArrays ||
            container.includes('@set') || container.includes('@list') ||
            (_isArray(compactedItem) && compactedItem.length === 0) ||
            expandedProperty === '@list' || expandedProperty === '@graph');

          // add compact value
          _addValue(
            nestResult, itemActiveProperty, compactedItem,
            {propertyIsArray: isArray});
        }
      }
    }

    return rval;
  }

  // only primitives remain which are already compact
  return element;
};

/**
 * Compacts an IRI or keyword into a term or prefix if it can be. If the
 * IRI has an associated value it may be passed.
 *
 * @param activeCtx the active context to use.
 * @param iri the IRI to compact.
 * @param value the value to check or null.
 * @param relativeTo options for how to compact IRIs:
 *          vocab: true to split after @vocab, false not to.
 * @param reverse true if a reverse property is being compacted, false if not.
 * @param base the absolute URL to use for compacting document-relative IRIs.
 *
 * @return the compacted term, prefix, keyword alias, or the original IRI.
 */
api.compactIri = ({
  activeCtx,
  iri,
  value = null,
  relativeTo = {vocab: false},
  reverse = false,
  base = null
}) => {
  // can't compact null
  if(iri === null) {
    return iri;
  }

  // if context is from a property term scoped context composed with a
  // type-scoped context, then use the previous context instead
  if(activeCtx.isPropertyTermScoped && activeCtx.previousContext) {
    activeCtx = activeCtx.previousContext;
  }

  const inverseCtx = activeCtx.getInverse();

  // if term is a keyword, it may be compacted to a simple alias
  if(_isKeyword(iri) &&
    iri in inverseCtx &&
    '@none' in inverseCtx[iri] &&
    '@type' in inverseCtx[iri]['@none'] &&
    '@none' in inverseCtx[iri]['@none']['@type']) {
    return inverseCtx[iri]['@none']['@type']['@none'];
  }

  // use inverse context to pick a term if iri is relative to vocab
  if(relativeTo.vocab && iri in inverseCtx) {
    const defaultLanguage = activeCtx['@language'] || '@none';

    // prefer @index if available in value
    const containers = [];
    if(_isObject(value) && '@index' in value && !('@graph' in value)) {
      containers.push('@index', '@index@set');
    }

    // if value is a preserve object, use its value
    if(_isObject(value) && '@preserve' in value) {
      value = value['@preserve'][0];
    }

    // prefer most specific container including @graph, prefering @set
    // variations
    if(_isGraph(value)) {
      // favor indexmap if the graph is indexed
      if('@index' in value) {
        containers.push(
          '@graph@index', '@graph@index@set', '@index', '@index@set');
      }
      // favor idmap if the graph is has an @id
      if('@id' in value) {
        containers.push(
          '@graph@id', '@graph@id@set');
      }
      containers.push('@graph', '@graph@set', '@set');
      // allow indexmap if the graph is not indexed
      if(!('@index' in value)) {
        containers.push(
          '@graph@index', '@graph@index@set', '@index', '@index@set');
      }
      // allow idmap if the graph does not have an @id
      if(!('@id' in value)) {
        containers.push('@graph@id', '@graph@id@set');
      }
    } else if(_isObject(value) && !_isValue(value)) {
      containers.push('@id', '@id@set', '@type', '@set@type');
    }

    // defaults for term selection based on type/language
    let typeOrLanguage = '@language';
    let typeOrLanguageValue = '@null';

    if(reverse) {
      typeOrLanguage = '@type';
      typeOrLanguageValue = '@reverse';
      containers.push('@set');
    } else if(_isList(value)) {
      // choose the most specific term that works for all elements in @list
      // only select @list containers if @index is NOT in value
      if(!('@index' in value)) {
        containers.push('@list');
      }
      const list = value['@list'];
      if(list.length === 0) {
        // any empty list can be matched against any term that uses the
        // @list container regardless of @type or @language
        typeOrLanguage = '@any';
        typeOrLanguageValue = '@none';
      } else {
        let commonLanguage = (list.length === 0) ? defaultLanguage : null;
        let commonType = null;
        for(let i = 0; i < list.length; ++i) {
          const item = list[i];
          let itemLanguage = '@none';
          let itemType = '@none';
          if(_isValue(item)) {
            if('@direction' in item) {
              const lang = (item['@language'] || '').toLowerCase();
              const dir = item['@direction'];
              itemLanguage = `${lang}_${dir}`;
            } else if('@language' in item) {
              itemLanguage = item['@language'].toLowerCase();
            } else if('@type' in item) {
              itemType = item['@type'];
            } else {
              // plain literal
              itemLanguage = '@null';
            }
          } else {
            itemType = '@id';
          }
          if(commonLanguage === null) {
            commonLanguage = itemLanguage;
          } else if(itemLanguage !== commonLanguage && _isValue(item)) {
            commonLanguage = '@none';
          }
          if(commonType === null) {
            commonType = itemType;
          } else if(itemType !== commonType) {
            commonType = '@none';
          }
          // there are different languages and types in the list, so choose
          // the most generic term, no need to keep iterating the list
          if(commonLanguage === '@none' && commonType === '@none') {
            break;
          }
        }
        commonLanguage = commonLanguage || '@none';
        commonType = commonType || '@none';
        if(commonType !== '@none') {
          typeOrLanguage = '@type';
          typeOrLanguageValue = commonType;
        } else {
          typeOrLanguageValue = commonLanguage;
        }
      }
    } else {
      if(_isValue(value)) {
        if('@language' in value && !('@index' in value)) {
          containers.push('@language', '@language@set');
          typeOrLanguageValue = value['@language'];
          const dir = value['@direction'];
          if(dir) {
            typeOrLanguageValue = `${typeOrLanguageValue}_${dir}`;
          }
        } else if('@direction' in value && !('@index' in value)) {
          typeOrLanguageValue = `_${value['@direction']}`;
        } else if('@type' in value) {
          typeOrLanguage = '@type';
          typeOrLanguageValue = value['@type'];
        }
      } else {
        typeOrLanguage = '@type';
        typeOrLanguageValue = '@id';
      }
      containers.push('@set');
    }

    // do term selection
    containers.push('@none');

    // an index map can be used to index values using @none, so add as a low
    // priority
    if(_isObject(value) && !('@index' in value)) {
      // allow indexing even if no @index present
      containers.push('@index', '@index@set');
    }

    // values without type or language can use @language map
    if(_isValue(value) && Object.keys(value).length === 1) {
      // allow indexing even if no @index present
      containers.push('@language', '@language@set');
    }

    const term = _selectTerm(
      activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue);
    if(term !== null) {
      return term;
    }
  }

  // no term match, use @vocab if available
  if(relativeTo.vocab) {
    if('@vocab' in activeCtx) {
      // determine if vocab is a prefix of the iri
      const vocab = activeCtx['@vocab'];
      if(iri.indexOf(vocab) === 0 && iri !== vocab) {
        // use suffix as relative iri if it is not a term in the active context
        const suffix = iri.substr(vocab.length);
        if(!activeCtx.mappings.has(suffix)) {
          return suffix;
        }
      }
    }
  }

  // no term or @vocab match, check for possible CURIEs
  let choice = null;
  // TODO: make FastCurieMap a class with a method to do this lookup
  const partialMatches = [];
  let iriMap = activeCtx.fastCurieMap;
  // check for partial matches of against `iri`, which means look until
  // iri.length - 1, not full length
  const maxPartialLength = iri.length - 1;
  for(let i = 0; i < maxPartialLength && iri[i] in iriMap; ++i) {
    iriMap = iriMap[iri[i]];
    if('' in iriMap) {
      partialMatches.push(iriMap[''][0]);
    }
  }
  // check partial matches in reverse order to prefer longest ones first
  for(let i = partialMatches.length - 1; i >= 0; --i) {
    const entry = partialMatches[i];
    const terms = entry.terms;
    for(const term of terms) {
      // a CURIE is usable if:
      // 1. it has no mapping, OR
      // 2. value is null, which means we're not compacting an @value, AND
      //   the mapping matches the IRI
      const curie = term + ':' + iri.substr(entry.iri.length);
      const isUsableCurie = (activeCtx.mappings.get(term)._prefix &&
        (!activeCtx.mappings.has(curie) ||
        (value === null && activeCtx.mappings.get(curie)['@id'] === iri)));

      // select curie if it is shorter or the same length but lexicographically
      // less than the current choice
      if(isUsableCurie && (choice === null ||
        _compareShortestLeast(curie, choice) < 0)) {
        choice = curie;
      }
    }
  }

  // return chosen curie
  if(choice !== null) {
    return choice;
  }

  // If iri could be confused with a compact IRI using a term in this context,
  // signal an error
  for(const [term, td] of activeCtx.mappings) {
    if(td && td._prefix && iri.startsWith(term + ':')) {
      throw new JsonLdError(
        `Absolute IRI "${iri}" confused with prefix "${term}".`,
        'jsonld.SyntaxError',
        {code: 'IRI confused with prefix', context: activeCtx});
    }
  }

  // compact IRI relative to base
  if(!relativeTo.vocab) {
    if('@base' in activeCtx) {
      if(!activeCtx['@base']) {
        // The None case preserves rval as potentially relative
        return iri;
      } else {
        return _removeBase(_prependBase(base, activeCtx['@base']), iri);
      }
    } else {
      return _removeBase(base, iri);
    }
  }

  // return IRI as is
  return iri;
};

/**
 * Performs value compaction on an object with '@value' or '@id' as the only
 * property.
 *
 * @param activeCtx the active context.
 * @param activeProperty the active property that points to the value.
 * @param value the value to compact.
 * @param {Object} [options] - processing options.
 *
 * @return the compaction result.
 */
api.compactValue = ({activeCtx, activeProperty, value, options}) => {
  // value is a @value
  if(_isValue(value)) {
    // get context rules
    const type = _getContextValue(activeCtx, activeProperty, '@type');
    const language = _getContextValue(activeCtx, activeProperty, '@language');
    const direction = _getContextValue(activeCtx, activeProperty, '@direction');
    const container =
      _getContextValue(activeCtx, activeProperty, '@container') || [];

    // whether or not the value has an @index that must be preserved
    const preserveIndex = '@index' in value && !container.includes('@index');

    // if there's no @index to preserve ...
    if(!preserveIndex && type !== '@none') {
      // matching @type or @language specified in context, compact value
      if(value['@type'] === type) {
        return value['@value'];
      }
      if('@language' in value && value['@language'] === language &&
         '@direction' in value && value['@direction'] === direction) {
        return value['@value'];
      }
      if('@language' in value && value['@language'] === language) {
        return value['@value'];
      }
      if('@direction' in value && value['@direction'] === direction) {
        return value['@value'];
      }
    }

    // return just the value of @value if all are true:
    // 1. @value is the only key or @index isn't being preserved
    // 2. there is no default language or @value is not a string or
    //   the key has a mapping with a null @language
    const keyCount = Object.keys(value).length;
    const isValueOnlyKey = (keyCount === 1 ||
      (keyCount === 2 && '@index' in value && !preserveIndex));
    const hasDefaultLanguage = ('@language' in activeCtx);
    const isValueString = _isString(value['@value']);
    const hasNullMapping = (activeCtx.mappings.has(activeProperty) &&
      activeCtx.mappings.get(activeProperty)['@language'] === null);
    if(isValueOnlyKey &&
      type !== '@none' &&
      (!hasDefaultLanguage || !isValueString || hasNullMapping)) {
      return value['@value'];
    }

    const rval = {};

    // preserve @index
    if(preserveIndex) {
      rval[api.compactIri({
        activeCtx,
        iri: '@index',
        relativeTo: {vocab: true}
      })] = value['@index'];
    }

    if('@type' in value) {
      // compact @type IRI
      rval[api.compactIri({
        activeCtx,
        iri: '@type',
        relativeTo: {vocab: true}
      })] = api.compactIri(
        {activeCtx, iri: value['@type'], relativeTo: {vocab: true}});
    } else if('@language' in value) {
      // alias @language
      rval[api.compactIri({
        activeCtx,
        iri: '@language',
        relativeTo: {vocab: true}
      })] = value['@language'];
    }

    if('@direction' in value) {
      // alias @direction
      rval[api.compactIri({
        activeCtx,
        iri: '@direction',
        relativeTo: {vocab: true}
      })] = value['@direction'];
    }

    // alias @value
    rval[api.compactIri({
      activeCtx,
      iri: '@value',
      relativeTo: {vocab: true}
    })] = value['@value'];

    return rval;
  }

  // value is a subject reference
  const expandedProperty = _expandIri(activeCtx, activeProperty, {vocab: true},
    options);
  const type = _getContextValue(activeCtx, activeProperty, '@type');
  const compacted = api.compactIri({
    activeCtx,
    iri: value['@id'],
    relativeTo: {vocab: type === '@vocab'},
    base: options.base});

  // compact to scalar
  if(type === '@id' || type === '@vocab' || expandedProperty === '@graph') {
    return compacted;
  }

  return {
    [api.compactIri({
      activeCtx,
      iri: '@id',
      relativeTo: {vocab: true}
    })]: compacted
  };
};

/**
 * Picks the preferred compaction term from the given inverse context entry.
 *
 * @param activeCtx the active context.
 * @param iri the IRI to pick the term for.
 * @param value the value to pick the term for.
 * @param containers the preferred containers.
 * @param typeOrLanguage either '@type' or '@language'.
 * @param typeOrLanguageValue the preferred value for '@type' or '@language'.
 *
 * @return the preferred term.
 */
function _selectTerm(
  activeCtx, iri, value, containers, typeOrLanguage, typeOrLanguageValue) {
  if(typeOrLanguageValue === null) {
    typeOrLanguageValue = '@null';
  }

  // preferences for the value of @type or @language
  const prefs = [];

  // determine prefs for @id based on whether or not value compacts to a term
  if((typeOrLanguageValue === '@id' || typeOrLanguageValue === '@reverse') &&
    _isObject(value) && '@id' in value) {
    // prefer @reverse first
    if(typeOrLanguageValue === '@reverse') {
      prefs.push('@reverse');
    }
    // try to compact value to a term
    const term = api.compactIri(
      {activeCtx, iri: value['@id'], relativeTo: {vocab: true}});
    if(activeCtx.mappings.has(term) &&
      activeCtx.mappings.get(term) &&
      activeCtx.mappings.get(term)['@id'] === value['@id']) {
      // prefer @vocab
      prefs.push.apply(prefs, ['@vocab', '@id']);
    } else {
      // prefer @id
      prefs.push.apply(prefs, ['@id', '@vocab']);
    }
  } else {
    prefs.push(typeOrLanguageValue);

    // consider direction only
    const langDir = prefs.find(el => el.includes('_'));
    if(langDir) {
      // consider _dir portion
      prefs.push(langDir.replace(/^[^_]+_/, '_'));
    }
  }
  prefs.push('@none');

  const containerMap = activeCtx.inverse[iri];
  for(const container of containers) {
    // if container not available in the map, continue
    if(!(container in containerMap)) {
      continue;
    }

    const typeOrLanguageValueMap = containerMap[container][typeOrLanguage];
    for(const pref of prefs) {
      // if type/language option not available in the map, continue
      if(!(pref in typeOrLanguageValueMap)) {
        continue;
      }

      // select term
      return typeOrLanguageValueMap[pref];
    }
  }

  return null;
}

/**
 * The value of `@nest` in the term definition must either be `@nest`, or a term
 * which resolves to `@nest`.
 *
 * @param activeCtx the active context.
 * @param nestProperty a term in the active context or `@nest`.
 * @param {Object} [options] - processing options.
 */
function _checkNestProperty(activeCtx, nestProperty, options) {
  if(_expandIri(activeCtx, nestProperty, {vocab: true}, options) !== '@nest') {
    throw new JsonLdError(
      'JSON-LD compact error; nested property must have an @nest value ' +
      'resolving to @nest.',
      'jsonld.SyntaxError', {code: 'invalid @nest value'});
  }
}

},{"./JsonLdError":139,"./context":146,"./graphTypes":152,"./types":157,"./url":158,"./util":159}],145:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';
const XSD = 'http://www.w3.org/2001/XMLSchema#';

module.exports = {
  // TODO: Deprecated and will be removed later. Use LINK_HEADER_CONTEXT.
  LINK_HEADER_REL: 'http://www.w3.org/ns/json-ld#context',

  LINK_HEADER_CONTEXT: 'http://www.w3.org/ns/json-ld#context',

  RDF,
  RDF_LIST: RDF + 'List',
  RDF_FIRST: RDF + 'first',
  RDF_REST: RDF + 'rest',
  RDF_NIL: RDF + 'nil',
  RDF_TYPE: RDF + 'type',
  RDF_PLAIN_LITERAL: RDF + 'PlainLiteral',
  RDF_XML_LITERAL: RDF + 'XMLLiteral',
  RDF_JSON_LITERAL: RDF + 'JSON',
  RDF_OBJECT: RDF + 'object',
  RDF_LANGSTRING: RDF + 'langString',

  XSD,
  XSD_BOOLEAN: XSD + 'boolean',
  XSD_DOUBLE: XSD + 'double',
  XSD_INTEGER: XSD + 'integer',
  XSD_STRING: XSD + 'string',
};

},{}],146:[function(require,module,exports){
/*
 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const util = require('./util');
const JsonLdError = require('./JsonLdError');

const {
  isArray: _isArray,
  isObject: _isObject,
  isString: _isString,
  isUndefined: _isUndefined
} = require('./types');

const {
  isAbsolute: _isAbsoluteIri,
  isRelative: _isRelativeIri,
  prependBase
} = require('./url');

const {
  asArray: _asArray,
  compareShortestLeast: _compareShortestLeast
} = require('./util');

const INITIAL_CONTEXT_CACHE = new Map();
const INITIAL_CONTEXT_CACHE_MAX_SIZE = 10000;
const KEYWORD_PATTERN = /^@[a-zA-Z]+$/;

const api = {};
module.exports = api;

/**
 * Processes a local context and returns a new active context.
 *
 * @param activeCtx the current active context.
 * @param localCtx the local context to process.
 * @param options the context processing options.
 * @param propagate `true` if `false`, retains any previously defined term,
 *   which can be rolled back when the descending into a new node object.
 * @param overrideProtected `false` allows protected terms to be modified.
 *
 * @return a Promise that resolves to the new active context.
 */
api.process = async ({
  activeCtx, localCtx, options,
  propagate = true,
  overrideProtected = false,
  cycles = new Set()
}) => {
  // normalize local context to an array of @context objects
  if(_isObject(localCtx) && '@context' in localCtx &&
    _isArray(localCtx['@context'])) {
    localCtx = localCtx['@context'];
  }
  const ctxs = _asArray(localCtx);

  // no contexts in array, return current active context w/o changes
  if(ctxs.length === 0) {
    return activeCtx;
  }

  // resolve contexts
  const resolved = await options.contextResolver.resolve({
    activeCtx,
    context: localCtx,
    documentLoader: options.documentLoader,
    base: options.base
  });

  // override propagate if first resolved context has `@propagate`
  if(_isObject(resolved[0].document) &&
    typeof resolved[0].document['@propagate'] === 'boolean') {
    // retrieve early, error checking done later
    propagate = resolved[0].document['@propagate'];
  }

  // process each context in order, update active context
  // on each iteration to ensure proper caching
  let rval = activeCtx;

  // track the previous context
  // if not propagating, make sure rval has a previous context
  if(!propagate && !rval.previousContext) {
    // clone `rval` context before updating
    rval = rval.clone();
    rval.previousContext = activeCtx;
  }

  for(const resolvedContext of resolved) {
    let {document: ctx} = resolvedContext;

    // update active context to one computed from last iteration
    activeCtx = rval;

    // reset to initial context
    if(ctx === null) {
      // We can't nullify if there are protected terms and we're
      // not allowing overrides (e.g. processing a property term scoped context)
      if(!overrideProtected &&
        Object.keys(activeCtx.protected).length !== 0) {
        const protectedMode = (options && options.protectedMode) || 'error';
        if(protectedMode === 'error') {
          throw new JsonLdError(
            'Tried to nullify a context with protected terms outside of ' +
            'a term definition.',
            'jsonld.SyntaxError',
            {code: 'invalid context nullification'});
        } else if(protectedMode === 'warn') {
          // FIXME: remove logging and use a handler
          console.warn('WARNING: invalid context nullification');

          // get processed context from cache if available
          const processed = resolvedContext.getProcessed(activeCtx);
          if(processed) {
            rval = activeCtx = processed;
            continue;
          }

          const oldActiveCtx = activeCtx;
          // copy all protected term definitions to fresh initial context
          rval = activeCtx = api.getInitialContext(options).clone();
          for(const [term, _protected] of
            Object.entries(oldActiveCtx.protected)) {
            if(_protected) {
              activeCtx.mappings[term] =
                util.clone(oldActiveCtx.mappings[term]);
            }
          }
          activeCtx.protected = util.clone(oldActiveCtx.protected);

          // cache processed result
          resolvedContext.setProcessed(oldActiveCtx, rval);
          continue;
        }
        throw new JsonLdError(
          'Invalid protectedMode.',
          'jsonld.SyntaxError',
          {code: 'invalid protected mode', context: localCtx, protectedMode});
      }
      rval = activeCtx = api.getInitialContext(options).clone();
      continue;
    }

    // get processed context from cache if available
    const processed = resolvedContext.getProcessed(activeCtx);
    if(processed) {
      rval = activeCtx = processed;
      continue;
    }

    // dereference @context key if present
    if(_isObject(ctx) && '@context' in ctx) {
      ctx = ctx['@context'];
    }

    // context must be an object by now, all URLs retrieved before this call
    if(!_isObject(ctx)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context must be an object.',
        'jsonld.SyntaxError', {code: 'invalid local context', context: ctx});
    }

    // TODO: there is likely a `previousContext` cloning optimization that
    // could be applied here (no need to copy it under certain conditions)

    // clone context before updating it
    rval = rval.clone();

    // define context mappings for keys in local context
    const defined = new Map();

    // handle @version
    if('@version' in ctx) {
      if(ctx['@version'] !== 1.1) {
        throw new JsonLdError(
          'Unsupported JSON-LD version: ' + ctx['@version'],
          'jsonld.UnsupportedVersion',
          {code: 'invalid @version value', context: ctx});
      }
      if(activeCtx.processingMode &&
        activeCtx.processingMode === 'json-ld-1.0') {
        throw new JsonLdError(
          '@version: ' + ctx['@version'] + ' not compatible with ' +
          activeCtx.processingMode,
          'jsonld.ProcessingModeConflict',
          {code: 'processing mode conflict', context: ctx});
      }
      rval.processingMode = 'json-ld-1.1';
      rval['@version'] = ctx['@version'];
      defined.set('@version', true);
    }

    // if not set explicitly, set processingMode to "json-ld-1.1"
    rval.processingMode =
      rval.processingMode || activeCtx.processingMode;

    // handle @base
    if('@base' in ctx) {
      let base = ctx['@base'];

      if(base === null || _isAbsoluteIri(base)) {
        // no action
      } else if(_isRelativeIri(base)) {
        base = prependBase(rval['@base'], base);
      } else {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; the value of "@base" in a ' +
          '@context must be an absolute IRI, a relative IRI, or null.',
          'jsonld.SyntaxError', {code: 'invalid base IRI', context: ctx});
      }

      rval['@base'] = base;
      defined.set('@base', true);
    }

    // handle @vocab
    if('@vocab' in ctx) {
      const value = ctx['@vocab'];
      if(value === null) {
        delete rval['@vocab'];
      } else if(!_isString(value)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; the value of "@vocab" in a ' +
          '@context must be a string or null.',
          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});
      } else if(!_isAbsoluteIri(value) && api.processingMode(rval, 1.0)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; the value of "@vocab" in a ' +
          '@context must be an absolute IRI.',
          'jsonld.SyntaxError', {code: 'invalid vocab mapping', context: ctx});
      } else {
        rval['@vocab'] = _expandIri(rval, value, {vocab: true, base: true},
          undefined, undefined, options);
      }
      defined.set('@vocab', true);
    }

    // handle @language
    if('@language' in ctx) {
      const value = ctx['@language'];
      if(value === null) {
        delete rval['@language'];
      } else if(!_isString(value)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; the value of "@language" in a ' +
          '@context must be a string or null.',
          'jsonld.SyntaxError',
          {code: 'invalid default language', context: ctx});
      } else {
        rval['@language'] = value.toLowerCase();
      }
      defined.set('@language', true);
    }

    // handle @direction
    if('@direction' in ctx) {
      const value = ctx['@direction'];
      if(activeCtx.processingMode === 'json-ld-1.0') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @direction not compatible with ' +
          activeCtx.processingMode,
          'jsonld.SyntaxError',
          {code: 'invalid context member', context: ctx});
      }
      if(value === null) {
        delete rval['@direction'];
      } else if(value !== 'ltr' && value !== 'rtl') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; the value of "@direction" in a ' +
          '@context must be null, "ltr", or "rtl".',
          'jsonld.SyntaxError',
          {code: 'invalid base direction', context: ctx});
      } else {
        rval['@direction'] = value;
      }
      defined.set('@direction', true);
    }

    // handle @propagate
    // note: we've already extracted it, here we just do error checking
    if('@propagate' in ctx) {
      const value = ctx['@propagate'];
      if(activeCtx.processingMode === 'json-ld-1.0') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @propagate not compatible with ' +
          activeCtx.processingMode,
          'jsonld.SyntaxError',
          {code: 'invalid context entry', context: ctx});
      }
      if(typeof value !== 'boolean') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @propagate value must be a boolean.',
          'jsonld.SyntaxError',
          {code: 'invalid @propagate value', context: localCtx});
      }
      defined.set('@propagate', true);
    }

    // handle @import
    if('@import' in ctx) {
      const value = ctx['@import'];
      if(activeCtx.processingMode === 'json-ld-1.0') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @import not compatible with ' +
          activeCtx.processingMode,
          'jsonld.SyntaxError',
          {code: 'invalid context entry', context: ctx});
      }
      if(!_isString(value)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @import must be a string.',
          'jsonld.SyntaxError',
          {code: 'invalid @import value', context: localCtx});
      }

      // resolve contexts
      const resolvedImport = await options.contextResolver.resolve({
        activeCtx,
        context: value,
        documentLoader: options.documentLoader,
        base: options.base
      });
      if(resolvedImport.length !== 1) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @import must reference a single context.',
          'jsonld.SyntaxError',
          {code: 'invalid remote context', context: localCtx});
      }
      const processedImport = resolvedImport[0].getProcessed(activeCtx);
      if(processedImport) {
        // Note: if the same context were used in this active context
        // as a reference context, then processed_input might not
        // be a dict.
        ctx = processedImport;
      } else {
        const importCtx = resolvedImport[0].document;
        if('@import' in importCtx) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax: ' +
            'imported context must not include @import.',
            'jsonld.SyntaxError',
            {code: 'invalid context entry', context: localCtx});
        }

        // merge ctx into importCtx and replace rval with the result
        for(const key in importCtx) {
          if(!ctx.hasOwnProperty(key)) {
            ctx[key] = importCtx[key];
          }
        }

        // Note: this could potenially conflict if the import
        // were used in the same active context as a referenced
        // context and an import. In this case, we
        // could override the cached result, but seems unlikely.
        resolvedImport[0].setProcessed(activeCtx, ctx);
      }

      defined.set('@import', true);
    }

    // handle @protected; determine whether this sub-context is declaring
    // all its terms to be "protected" (exceptions can be made on a
    // per-definition basis)
    defined.set('@protected', ctx['@protected'] || false);

    // process all other keys
    for(const key in ctx) {
      api.createTermDefinition({
        activeCtx: rval,
        localCtx: ctx,
        term: key,
        defined,
        options,
        overrideProtected
      });

      if(_isObject(ctx[key]) && '@context' in ctx[key]) {
        const keyCtx = ctx[key]['@context'];
        let process = true;
        if(_isString(keyCtx)) {
          const url = prependBase(options.base, keyCtx);
          // track processed contexts to avoid scoped context recursion
          if(cycles.has(url)) {
            process = false;
          } else {
            cycles.add(url);
          }
        }
        // parse context to validate
        if(process) {
          try {
            await api.process({
              activeCtx: rval.clone(),
              localCtx: ctx[key]['@context'],
              overrideProtected: true,
              options,
              cycles
            });
          } catch(e) {
            throw new JsonLdError(
              'Invalid JSON-LD syntax; invalid scoped context.',
              'jsonld.SyntaxError',
              {
                code: 'invalid scoped context',
                context: ctx[key]['@context'],
                term: key
              });
          }
        }
      }
    }

    // cache processed result
    resolvedContext.setProcessed(activeCtx, rval);
  }

  return rval;
};

/**
 * Creates a term definition during context processing.
 *
 * @param activeCtx the current active context.
 * @param localCtx the local context being processed.
 * @param term the term in the local context to define the mapping for.
 * @param defined a map of defining/defined keys to detect cycles and prevent
 *          double definitions.
 * @param {Object} [options] - creation options.
 * @param {string} [options.protectedMode="error"] - "error" to throw error
 *   on `@protected` constraint violation, "warn" to allow violations and
 *   signal a warning.
 * @param overrideProtected `false` allows protected terms to be modified.
 */
api.createTermDefinition = ({
  activeCtx,
  localCtx,
  term,
  defined,
  options,
  overrideProtected = false,
}) => {
  if(defined.has(term)) {
    // term already defined
    if(defined.get(term)) {
      return;
    }
    // cycle detected
    throw new JsonLdError(
      'Cyclical context definition detected.',
      'jsonld.CyclicalContext',
      {code: 'cyclic IRI mapping', context: localCtx, term});
  }

  // now defining term
  defined.set(term, false);

  // get context term value
  let value;
  if(localCtx.hasOwnProperty(term)) {
    value = localCtx[term];
  }

  if(term === '@type' &&
     _isObject(value) &&
     (value['@container'] || '@set') === '@set' &&
     api.processingMode(activeCtx, 1.1)) {

    const validKeys = ['@container', '@id', '@protected'];
    const keys = Object.keys(value);
    if(keys.length === 0 || keys.some(k => !validKeys.includes(k))) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; keywords cannot be overridden.',
        'jsonld.SyntaxError',
        {code: 'keyword redefinition', context: localCtx, term});
    }
  } else if(api.isKeyword(term)) {
    throw new JsonLdError(
      'Invalid JSON-LD syntax; keywords cannot be overridden.',
      'jsonld.SyntaxError',
      {code: 'keyword redefinition', context: localCtx, term});
  } else if(term.match(KEYWORD_PATTERN)) {
    // FIXME: remove logging and use a handler
    console.warn('WARNING: terms beginning with "@" are reserved' +
      ' for future use and ignored', {term});
    return;
  } else if(term === '') {
    throw new JsonLdError(
      'Invalid JSON-LD syntax; a term cannot be an empty string.',
      'jsonld.SyntaxError',
      {code: 'invalid term definition', context: localCtx});
  }

  // keep reference to previous mapping for potential `@protected` check
  const previousMapping = activeCtx.mappings.get(term);

  // remove old mapping
  if(activeCtx.mappings.has(term)) {
    activeCtx.mappings.delete(term);
  }

  // convert short-hand value to object w/@id
  let simpleTerm = false;
  if(_isString(value) || value === null) {
    simpleTerm = true;
    value = {'@id': value};
  }

  if(!_isObject(value)) {
    throw new JsonLdError(
      'Invalid JSON-LD syntax; @context term values must be ' +
      'strings or objects.',
      'jsonld.SyntaxError',
      {code: 'invalid term definition', context: localCtx});
  }

  // create new mapping
  const mapping = {};
  activeCtx.mappings.set(term, mapping);
  mapping.reverse = false;

  // make sure term definition only has expected keywords
  const validKeys = ['@container', '@id', '@language', '@reverse', '@type'];

  // JSON-LD 1.1 support
  if(api.processingMode(activeCtx, 1.1)) {
    validKeys.push(
      '@context', '@direction', '@index', '@nest', '@prefix', '@protected');
  }

  for(const kw in value) {
    if(!validKeys.includes(kw)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a term definition must not contain ' + kw,
        'jsonld.SyntaxError',
        {code: 'invalid term definition', context: localCtx});
    }
  }

  // always compute whether term has a colon as an optimization for
  // _compactIri
  const colon = term.indexOf(':');
  mapping._termHasColon = (colon > 0);

  if('@reverse' in value) {
    if('@id' in value) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a @reverse term definition must not ' +
        'contain @id.', 'jsonld.SyntaxError',
        {code: 'invalid reverse property', context: localCtx});
    }
    if('@nest' in value) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a @reverse term definition must not ' +
        'contain @nest.', 'jsonld.SyntaxError',
        {code: 'invalid reverse property', context: localCtx});
    }
    const reverse = value['@reverse'];
    if(!_isString(reverse)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a @context @reverse value must be a string.',
        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
    }

    if(!api.isKeyword(reverse) && reverse.match(KEYWORD_PATTERN)) {
      // FIXME: remove logging and use a handler
      console.warn('WARNING: values beginning with "@" are reserved' +
        ' for future use and ignored', {reverse});
      if(previousMapping) {
        activeCtx.mappings.set(term, previousMapping);
      } else {
        activeCtx.mappings.delete(term);
      }
      return;
    }

    // expand and add @id mapping
    const id = _expandIri(
      activeCtx, reverse, {vocab: true, base: false}, localCtx, defined,
      options);
    if(!_isAbsoluteIri(id)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a @context @reverse value must be an ' +
        'absolute IRI or a blank node identifier.',
        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
    }

    mapping['@id'] = id;
    mapping.reverse = true;
  } else if('@id' in value) {
    let id = value['@id'];
    if(id && !_isString(id)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; a @context @id value must be an array ' +
        'of strings or a string.',
        'jsonld.SyntaxError', {code: 'invalid IRI mapping', context: localCtx});
    }
    if(id === null) {
      // reserve a null term, which may be protected
      mapping['@id'] = null;
    } else if(!api.isKeyword(id) && id.match(KEYWORD_PATTERN)) {
      // FIXME: remove logging and use a handler
      console.warn('WARNING: values beginning with "@" are reserved' +
        ' for future use and ignored', {id});
      if(previousMapping) {
        activeCtx.mappings.set(term, previousMapping);
      } else {
        activeCtx.mappings.delete(term);
      }
      return;
    } else if(id !== term) {
      // expand and add @id mapping
      id = _expandIri(
        activeCtx, id, {vocab: true, base: false}, localCtx, defined, options);
      if(!_isAbsoluteIri(id) && !api.isKeyword(id)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; a @context @id value must be an ' +
          'absolute IRI, a blank node identifier, or a keyword.',
          'jsonld.SyntaxError',
          {code: 'invalid IRI mapping', context: localCtx});
      }

      // if term has the form of an IRI it must map the same
      if(term.match(/(?::[^:])|\//)) {
        const termDefined = new Map(defined).set(term, true);
        const termIri = _expandIri(
          activeCtx, term, {vocab: true, base: false},
          localCtx, termDefined, options);
        if(termIri !== id) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; term in form of IRI must ' +
            'expand to definition.',
            'jsonld.SyntaxError',
            {code: 'invalid IRI mapping', context: localCtx});
        }
      }

      mapping['@id'] = id;
      // indicate if this term may be used as a compact IRI prefix
      mapping._prefix = (simpleTerm &&
        !mapping._termHasColon &&
        id.match(/[:\/\?#\[\]@]$/));
    }
  }

  if(!('@id' in mapping)) {
    // see if the term has a prefix
    if(mapping._termHasColon) {
      const prefix = term.substr(0, colon);
      if(localCtx.hasOwnProperty(prefix)) {
        // define parent prefix
        api.createTermDefinition({
          activeCtx, localCtx, term: prefix, defined, options
        });
      }

      if(activeCtx.mappings.has(prefix)) {
        // set @id based on prefix parent
        const suffix = term.substr(colon + 1);
        mapping['@id'] = activeCtx.mappings.get(prefix)['@id'] + suffix;
      } else {
        // term is an absolute IRI
        mapping['@id'] = term;
      }
    } else if(term === '@type') {
      // Special case, were we've previously determined that container is @set
      mapping['@id'] = term;
    } else {
      // non-IRIs *must* define @ids if @vocab is not available
      if(!('@vocab' in activeCtx)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; @context terms must define an @id.',
          'jsonld.SyntaxError',
          {code: 'invalid IRI mapping', context: localCtx, term});
      }
      // prepend vocab to term
      mapping['@id'] = activeCtx['@vocab'] + term;
    }
  }

  // Handle term protection
  if(value['@protected'] === true ||
    (defined.get('@protected') === true && value['@protected'] !== false)) {
    activeCtx.protected[term] = true;
    mapping.protected = true;
  }

  // IRI mapping now defined
  defined.set(term, true);

  if('@type' in value) {
    let type = value['@type'];
    if(!_isString(type)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; an @context @type value must be a string.',
        'jsonld.SyntaxError',
        {code: 'invalid type mapping', context: localCtx});
    }

    if((type === '@json' || type === '@none')) {
      if(api.processingMode(activeCtx, 1.0)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; an @context @type value must not be ' +
          `"${type}" in JSON-LD 1.0 mode.`,
          'jsonld.SyntaxError',
          {code: 'invalid type mapping', context: localCtx});
      }
    } else if(type !== '@id' && type !== '@vocab') {
      // expand @type to full IRI
      type = _expandIri(
        activeCtx, type, {vocab: true, base: false}, localCtx, defined,
        options);
      if(!_isAbsoluteIri(type)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; an @context @type value must be an ' +
          'absolute IRI.',
          'jsonld.SyntaxError',
          {code: 'invalid type mapping', context: localCtx});
      }
      if(type.indexOf('_:') === 0) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; an @context @type value must be an IRI, ' +
          'not a blank node identifier.',
          'jsonld.SyntaxError',
          {code: 'invalid type mapping', context: localCtx});
      }
    }

    // add @type to mapping
    mapping['@type'] = type;
  }

  if('@container' in value) {
    // normalize container to an array form
    const container = _isString(value['@container']) ?
      [value['@container']] : (value['@container'] || []);
    const validContainers = ['@list', '@set', '@index', '@language'];
    let isValid = true;
    const hasSet = container.includes('@set');

    // JSON-LD 1.1 support
    if(api.processingMode(activeCtx, 1.1)) {
      validContainers.push('@graph', '@id', '@type');

      // check container length
      if(container.includes('@list')) {
        if(container.length !== 1) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; @context @container with @list must ' +
            'have no other values',
            'jsonld.SyntaxError',
            {code: 'invalid container mapping', context: localCtx});
        }
      } else if(container.includes('@graph')) {
        if(container.some(key =>
          key !== '@graph' && key !== '@id' && key !== '@index' &&
          key !== '@set')) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; @context @container with @graph must ' +
            'have no other values other than @id, @index, and @set',
            'jsonld.SyntaxError',
            {code: 'invalid container mapping', context: localCtx});
        }
      } else {
        // otherwise, container may also include @set
        isValid &= container.length <= (hasSet ? 2 : 1);
      }

      if(container.includes('@type')) {
        // If mapping does not have an @type,
        // set it to @id
        mapping['@type'] = mapping['@type'] || '@id';

        // type mapping must be either @id or @vocab
        if(!['@id', '@vocab'].includes(mapping['@type'])) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; container: @type requires @type to be ' +
            '@id or @vocab.',
            'jsonld.SyntaxError',
            {code: 'invalid type mapping', context: localCtx});
        }
      }
    } else {
      // in JSON-LD 1.0, container must not be an array (it must be a string,
      // which is one of the validContainers)
      isValid &= !_isArray(value['@container']);

      // check container length
      isValid &= container.length <= 1;
    }

    // check against valid containers
    isValid &= container.every(c => validContainers.includes(c));

    // @set not allowed with @list
    isValid &= !(hasSet && container.includes('@list'));

    if(!isValid) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context @container value must be ' +
        'one of the following: ' + validContainers.join(', '),
        'jsonld.SyntaxError',
        {code: 'invalid container mapping', context: localCtx});
    }

    if(mapping.reverse &&
      !container.every(c => ['@index', '@set'].includes(c))) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context @container value for a @reverse ' +
        'type definition must be @index or @set.', 'jsonld.SyntaxError',
        {code: 'invalid reverse property', context: localCtx});
    }

    // add @container to mapping
    mapping['@container'] = container;
  }

  // property indexing
  if('@index' in value) {
    if(!('@container' in value) || !mapping['@container'].includes('@index')) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @index without @index in @container: ' +
        `"${value['@index']}" on term "${term}".`, 'jsonld.SyntaxError',
        {code: 'invalid term definition', context: localCtx});
    }
    if(!_isString(value['@index']) || value['@index'].indexOf('@') === 0) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @index must expand to an IRI: ' +
        `"${value['@index']}" on term "${term}".`, 'jsonld.SyntaxError',
        {code: 'invalid term definition', context: localCtx});
    }
    mapping['@index'] = value['@index'];
  }

  // scoped contexts
  if('@context' in value) {
    mapping['@context'] = value['@context'];
  }

  if('@language' in value && !('@type' in value)) {
    let language = value['@language'];
    if(language !== null && !_isString(language)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context @language value must be ' +
        'a string or null.', 'jsonld.SyntaxError',
        {code: 'invalid language mapping', context: localCtx});
    }

    // add @language to mapping
    if(language !== null) {
      language = language.toLowerCase();
    }
    mapping['@language'] = language;
  }

  // term may be used as a prefix
  if('@prefix' in value) {
    if(term.match(/:|\//)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context @prefix used on a compact IRI term',
        'jsonld.SyntaxError',
        {code: 'invalid term definition', context: localCtx});
    }
    if(api.isKeyword(mapping['@id'])) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; keywords may not be used as prefixes',
        'jsonld.SyntaxError',
        {code: 'invalid term definition', context: localCtx});
    }
    if(typeof value['@prefix'] === 'boolean') {
      mapping._prefix = value['@prefix'] === true;
    } else {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context value for @prefix must be boolean',
        'jsonld.SyntaxError',
        {code: 'invalid @prefix value', context: localCtx});
    }
  }

  if('@direction' in value) {
    const direction = value['@direction'];
    if(direction !== null && direction !== 'ltr' && direction !== 'rtl') {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @direction value must be ' +
        'null, "ltr", or "rtl".',
        'jsonld.SyntaxError',
        {code: 'invalid base direction', context: localCtx});
    }
    mapping['@direction'] = direction;
  }

  if('@nest' in value) {
    const nest = value['@nest'];
    if(!_isString(nest) || (nest !== '@nest' && nest.indexOf('@') === 0)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; @context @nest value must be ' +
        'a string which is not a keyword other than @nest.',
        'jsonld.SyntaxError',
        {code: 'invalid @nest value', context: localCtx});
    }
    mapping['@nest'] = nest;
  }

  // disallow aliasing @context and @preserve
  const id = mapping['@id'];
  if(id === '@context' || id === '@preserve') {
    throw new JsonLdError(
      'Invalid JSON-LD syntax; @context and @preserve cannot be aliased.',
      'jsonld.SyntaxError', {code: 'invalid keyword alias', context: localCtx});
  }

  // Check for overriding protected terms
  if(previousMapping && previousMapping.protected && !overrideProtected) {
    // force new term to continue to be protected and see if the mappings would
    // be equal
    activeCtx.protected[term] = true;
    mapping.protected = true;
    if(!_deepCompare(previousMapping, mapping)) {
      const protectedMode = (options && options.protectedMode) || 'error';
      if(protectedMode === 'error') {
        throw new JsonLdError(
          `Invalid JSON-LD syntax; tried to redefine "${term}" which is a ` +
          'protected term.',
          'jsonld.SyntaxError',
          {code: 'protected term redefinition', context: localCtx, term});
      } else if(protectedMode === 'warn') {
        // FIXME: remove logging and use a handler
        console.warn('WARNING: protected term redefinition', {term});
        return;
      }
      throw new JsonLdError(
        'Invalid protectedMode.',
        'jsonld.SyntaxError',
        {code: 'invalid protected mode', context: localCtx, term,
          protectedMode});
    }
  }
};

/**
 * Expands a string to a full IRI. The string may be a term, a prefix, a
 * relative IRI, or an absolute IRI. The associated absolute IRI will be
 * returned.
 *
 * @param activeCtx the current active context.
 * @param value the string to expand.
 * @param relativeTo options for how to resolve relative IRIs:
 *          base: true to resolve against the base IRI, false not to.
 *          vocab: true to concatenate after @vocab, false not to.
 * @param {Object} [options] - processing options.
 *
 * @return the expanded value.
 */
api.expandIri = (activeCtx, value, relativeTo, options) => {
  return _expandIri(activeCtx, value, relativeTo, undefined, undefined,
    options);
};

/**
 * Expands a string to a full IRI. The string may be a term, a prefix, a
 * relative IRI, or an absolute IRI. The associated absolute IRI will be
 * returned.
 *
 * @param activeCtx the current active context.
 * @param value the string to expand.
 * @param relativeTo options for how to resolve relative IRIs:
 *          base: true to resolve against the base IRI, false not to.
 *          vocab: true to concatenate after @vocab, false not to.
 * @param localCtx the local context being processed (only given if called
 *          during context processing).
 * @param defined a map for tracking cycles in context definitions (only given
 *          if called during context processing).
 * @param {Object} [options] - processing options.
 *
 * @return the expanded value.
 */
function _expandIri(activeCtx, value, relativeTo, localCtx, defined, options) {
  // already expanded
  if(value === null || !_isString(value) || api.isKeyword(value)) {
    return value;
  }

  // ignore non-keyword things that look like a keyword
  if(value.match(KEYWORD_PATTERN)) {
    return null;
  }

  // define term dependency if not defined
  if(localCtx && localCtx.hasOwnProperty(value) &&
    defined.get(value) !== true) {
    api.createTermDefinition({
      activeCtx, localCtx, term: value, defined, options
    });
  }

  relativeTo = relativeTo || {};
  if(relativeTo.vocab) {
    const mapping = activeCtx.mappings.get(value);

    // value is explicitly ignored with a null mapping
    if(mapping === null) {
      return null;
    }

    if(_isObject(mapping) && '@id' in mapping) {
      // value is a term
      return mapping['@id'];
    }
  }

  // split value into prefix:suffix
  const colon = value.indexOf(':');
  if(colon > 0) {
    const prefix = value.substr(0, colon);
    const suffix = value.substr(colon + 1);

    // do not expand blank nodes (prefix of '_') or already-absolute
    // IRIs (suffix of '//')
    if(prefix === '_' || suffix.indexOf('//') === 0) {
      return value;
    }

    // prefix dependency not defined, define it
    if(localCtx && localCtx.hasOwnProperty(prefix)) {
      api.createTermDefinition({
        activeCtx, localCtx, term: prefix, defined, options
      });
    }

    // use mapping if prefix is defined
    const mapping = activeCtx.mappings.get(prefix);
    if(mapping && mapping._prefix) {
      return mapping['@id'] + suffix;
    }

    // already absolute IRI
    if(_isAbsoluteIri(value)) {
      return value;
    }
  }

  // prepend vocab
  if(relativeTo.vocab && '@vocab' in activeCtx) {
    return activeCtx['@vocab'] + value;
  }

  // prepend base
  if(relativeTo.base && '@base' in activeCtx) {
    if(activeCtx['@base']) {
      // The null case preserves value as potentially relative
      return prependBase(prependBase(options.base, activeCtx['@base']), value);
    }
  } else if(relativeTo.base) {
    return prependBase(options.base, value);
  }

  return value;
}

/**
 * Gets the initial context.
 *
 * @param options the options to use:
 *          [base] the document base IRI.
 *
 * @return the initial context.
 */
api.getInitialContext = options => {
  const key = JSON.stringify({processingMode: options.processingMode});
  const cached = INITIAL_CONTEXT_CACHE.get(key);
  if(cached) {
    return cached;
  }

  const initialContext = {
    processingMode: options.processingMode,
    mappings: new Map(),
    inverse: null,
    getInverse: _createInverseContext,
    clone: _cloneActiveContext,
    revertToPreviousContext: _revertToPreviousContext,
    protected: {}
  };
  // TODO: consider using LRU cache instead
  if(INITIAL_CONTEXT_CACHE.size === INITIAL_CONTEXT_CACHE_MAX_SIZE) {
    // clear whole cache -- assumes scenario where the cache fills means
    // the cache isn't being used very efficiently anyway
    INITIAL_CONTEXT_CACHE.clear();
  }
  INITIAL_CONTEXT_CACHE.set(key, initialContext);
  return initialContext;

  /**
   * Generates an inverse context for use in the compaction algorithm, if
   * not already generated for the given active context.
   *
   * @return the inverse context.
   */
  function _createInverseContext() {
    const activeCtx = this;

    // lazily create inverse
    if(activeCtx.inverse) {
      return activeCtx.inverse;
    }
    const inverse = activeCtx.inverse = {};

    // variables for building fast CURIE map
    const fastCurieMap = activeCtx.fastCurieMap = {};
    const irisToTerms = {};

    // handle default language
    const defaultLanguage = (activeCtx['@language'] || '@none').toLowerCase();

    // handle default direction
    const defaultDirection = activeCtx['@direction'];

    // create term selections for each mapping in the context, ordered by
    // shortest and then lexicographically least
    const mappings = activeCtx.mappings;
    const terms = [...mappings.keys()].sort(_compareShortestLeast);
    for(const term of terms) {
      const mapping = mappings.get(term);
      if(mapping === null) {
        continue;
      }

      let container = mapping['@container'] || '@none';
      container = [].concat(container).sort().join('');

      if(mapping['@id'] === null) {
        continue;
      }
      // iterate over every IRI in the mapping
      const ids = _asArray(mapping['@id']);
      for(const iri of ids) {
        let entry = inverse[iri];
        const isKeyword = api.isKeyword(iri);

        if(!entry) {
          // initialize entry
          inverse[iri] = entry = {};

          if(!isKeyword && !mapping._termHasColon) {
            // init IRI to term map and fast CURIE prefixes
            irisToTerms[iri] = [term];
            const fastCurieEntry = {iri, terms: irisToTerms[iri]};
            if(iri[0] in fastCurieMap) {
              fastCurieMap[iri[0]].push(fastCurieEntry);
            } else {
              fastCurieMap[iri[0]] = [fastCurieEntry];
            }
          }
        } else if(!isKeyword && !mapping._termHasColon) {
          // add IRI to term match
          irisToTerms[iri].push(term);
        }

        // add new entry
        if(!entry[container]) {
          entry[container] = {
            '@language': {},
            '@type': {},
            '@any': {}
          };
        }
        entry = entry[container];
        _addPreferredTerm(term, entry['@any'], '@none');

        if(mapping.reverse) {
          // term is preferred for values using @reverse
          _addPreferredTerm(term, entry['@type'], '@reverse');
        } else if(mapping['@type'] === '@none') {
          _addPreferredTerm(term, entry['@any'], '@none');
          _addPreferredTerm(term, entry['@language'], '@none');
          _addPreferredTerm(term, entry['@type'], '@none');
        } else if('@type' in mapping) {
          // term is preferred for values using specific type
          _addPreferredTerm(term, entry['@type'], mapping['@type']);
        } else if('@language' in mapping && '@direction' in mapping) {
          // term is preferred for values using specific language and direction
          const language = mapping['@language'];
          const direction = mapping['@direction'];
          if(language && direction) {
            _addPreferredTerm(term, entry['@language'],
              `${language}_${direction}`.toLowerCase());
          } else if(language) {
            _addPreferredTerm(term, entry['@language'], language.toLowerCase());
          } else if(direction) {
            _addPreferredTerm(term, entry['@language'], `_${direction}`);
          } else {
            _addPreferredTerm(term, entry['@language'], '@null');
          }
        } else if('@language' in mapping) {
          _addPreferredTerm(term, entry['@language'],
            (mapping['@language'] || '@null').toLowerCase());
        } else if('@direction' in mapping) {
          if(mapping['@direction']) {
            _addPreferredTerm(term, entry['@language'],
              `_${mapping['@direction']}`);
          } else {
            _addPreferredTerm(term, entry['@language'], '@none');
          }
        } else if(defaultDirection) {
          _addPreferredTerm(term, entry['@language'], `_${defaultDirection}`);
          _addPreferredTerm(term, entry['@language'], '@none');
          _addPreferredTerm(term, entry['@type'], '@none');
        } else {
          // add entries for no type and no language
          _addPreferredTerm(term, entry['@language'], defaultLanguage);
          _addPreferredTerm(term, entry['@language'], '@none');
          _addPreferredTerm(term, entry['@type'], '@none');
        }
      }
    }

    // build fast CURIE map
    for(const key in fastCurieMap) {
      _buildIriMap(fastCurieMap, key, 1);
    }

    return inverse;
  }

  /**
   * Runs a recursive algorithm to build a lookup map for quickly finding
   * potential CURIEs.
   *
   * @param iriMap the map to build.
   * @param key the current key in the map to work on.
   * @param idx the index into the IRI to compare.
   */
  function _buildIriMap(iriMap, key, idx) {
    const entries = iriMap[key];
    const next = iriMap[key] = {};

    let iri;
    let letter;
    for(const entry of entries) {
      iri = entry.iri;
      if(idx >= iri.length) {
        letter = '';
      } else {
        letter = iri[idx];
      }
      if(letter in next) {
        next[letter].push(entry);
      } else {
        next[letter] = [entry];
      }
    }

    for(const key in next) {
      if(key === '') {
        continue;
      }
      _buildIriMap(next, key, idx + 1);
    }
  }

  /**
   * Adds the term for the given entry if not already added.
   *
   * @param term the term to add.
   * @param entry the inverse context typeOrLanguage entry to add to.
   * @param typeOrLanguageValue the key in the entry to add to.
   */
  function _addPreferredTerm(term, entry, typeOrLanguageValue) {
    if(!entry.hasOwnProperty(typeOrLanguageValue)) {
      entry[typeOrLanguageValue] = term;
    }
  }

  /**
   * Clones an active context, creating a child active context.
   *
   * @return a clone (child) of the active context.
   */
  function _cloneActiveContext() {
    const child = {};
    child.mappings = util.clone(this.mappings);
    child.clone = this.clone;
    child.inverse = null;
    child.getInverse = this.getInverse;
    child.protected = util.clone(this.protected);
    if(this.previousContext) {
      child.previousContext = this.previousContext.clone();
    }
    child.revertToPreviousContext = this.revertToPreviousContext;
    if('@base' in this) {
      child['@base'] = this['@base'];
    }
    if('@language' in this) {
      child['@language'] = this['@language'];
    }
    if('@vocab' in this) {
      child['@vocab'] = this['@vocab'];
    }
    return child;
  }

  /**
   * Reverts any type-scoped context in this active context to the previous
   * context.
   */
  function _revertToPreviousContext() {
    if(!this.previousContext) {
      return this;
    }
    return this.previousContext.clone();
  }
};

/**
 * Gets the value for the given active context key and type, null if none is
 * set or undefined if none is set and type is '@context'.
 *
 * @param ctx the active context.
 * @param key the context key.
 * @param [type] the type of value to get (eg: '@id', '@type'), if not
 *          specified gets the entire entry for a key, null if not found.
 *
 * @return the value, null, or undefined.
 */
api.getContextValue = (ctx, key, type) => {
  // invalid key
  if(key === null) {
    if(type === '@context') {
      return undefined;
    }
    return null;
  }

  // get specific entry information
  if(ctx.mappings.has(key)) {
    const entry = ctx.mappings.get(key);

    if(_isUndefined(type)) {
      // return whole entry
      return entry;
    }
    if(entry.hasOwnProperty(type)) {
      // return entry value for type
      return entry[type];
    }
  }

  // get default language
  if(type === '@language' && type in ctx) {
    return ctx[type];
  }

  // get default direction
  if(type === '@direction' && type in ctx) {
    return ctx[type];
  }

  if(type === '@context') {
    return undefined;
  }
  return null;
};

/**
 * Processing Mode check.
 *
 * @param activeCtx the current active context.
 * @param version the string or numeric version to check.
 *
 * @return boolean.
 */
api.processingMode = (activeCtx, version) => {
  if(version.toString() >= '1.1') {
    return !activeCtx.processingMode ||
      activeCtx.processingMode >= 'json-ld-' + version.toString();
  } else {
    return activeCtx.processingMode === 'json-ld-1.0';
  }
};

/**
 * Returns whether or not the given value is a keyword.
 *
 * @param v the value to check.
 *
 * @return true if the value is a keyword, false if not.
 */
api.isKeyword = v => {
  if(!_isString(v) || v[0] !== '@') {
    return false;
  }
  switch(v) {
    case '@base':
    case '@container':
    case '@context':
    case '@default':
    case '@direction':
    case '@embed':
    case '@explicit':
    case '@graph':
    case '@id':
    case '@included':
    case '@index':
    case '@json':
    case '@language':
    case '@list':
    case '@nest':
    case '@none':
    case '@omitDefault':
    case '@prefix':
    case '@preserve':
    case '@protected':
    case '@requireAll':
    case '@reverse':
    case '@set':
    case '@type':
    case '@value':
    case '@version':
    case '@vocab':
      return true;
  }
  return false;
};

function _deepCompare(x1, x2) {
  // compare `null` or primitive types directly
  if((!(x1 && typeof x1 === 'object')) ||
     (!(x2 && typeof x2 === 'object'))) {
    return x1 === x2;
  }
  // x1 and x2 are objects (also potentially arrays)
  const x1Array = Array.isArray(x1);
  if(x1Array !== Array.isArray(x2)) {
    return false;
  }
  if(x1Array) {
    if(x1.length !== x2.length) {
      return false;
    }
    for(let i = 0; i < x1.length; ++i) {
      if(!_deepCompare(x1[i], x2[i])) {
        return false;
      }
    }
    return true;
  }
  // x1 and x2 are non-array objects
  const k1s = Object.keys(x1);
  const k2s = Object.keys(x2);
  if(k1s.length !== k2s.length) {
    return false;
  }
  for(const k1 in x1) {
    let v1 = x1[k1];
    let v2 = x2[k1];
    // special case: `@container` can be in any order
    if(k1 === '@container') {
      if(Array.isArray(v1) && Array.isArray(v2)) {
        v1 = v1.slice().sort();
        v2 = v2.slice().sort();
      }
    }
    if(!_deepCompare(v1, v2)) {
      return false;
    }
  }
  return true;
}

},{"./JsonLdError":139,"./types":157,"./url":158,"./util":159}],147:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {parseLinkHeader, buildHeaders} = require('../util');
const {LINK_HEADER_CONTEXT} = require('../constants');
const JsonLdError = require('../JsonLdError');
const RequestQueue = require('../RequestQueue');
const {prependBase} = require('../url');

const REGEX_LINK_HEADER = /(^|(\r\n))link:/i;

/**
 * Creates a built-in XMLHttpRequest document loader.
 *
 * @param options the options to use:
 *          secure: require all URLs to use HTTPS.
 *          headers: an object (map) of headers which will be passed as request
 *            headers for the requested document. Accept is not allowed.
 *          [xhr]: the XMLHttpRequest API to use.
 *
 * @return the XMLHttpRequest document loader.
 */
module.exports = ({
  secure,
  headers = {},
  xhr
} = {headers: {}}) => {
  headers = buildHeaders(headers);
  const queue = new RequestQueue();
  return queue.wrapLoader(loader);

  async function loader(url) {
    if(url.indexOf('http:') !== 0 && url.indexOf('https:') !== 0) {
      throw new JsonLdError(
        'URL could not be dereferenced; only "http" and "https" URLs are ' +
        'supported.',
        'jsonld.InvalidUrl', {code: 'loading document failed', url});
    }
    if(secure && url.indexOf('https') !== 0) {
      throw new JsonLdError(
        'URL could not be dereferenced; secure mode is enabled and ' +
        'the URL\'s scheme is not "https".',
        'jsonld.InvalidUrl', {code: 'loading document failed', url});
    }

    let req;
    try {
      req = await _get(xhr, url, headers);
    } catch(e) {
      throw new JsonLdError(
        'URL could not be dereferenced, an error occurred.',
        'jsonld.LoadDocumentError',
        {code: 'loading document failed', url, cause: e});
    }

    if(req.status >= 400) {
      throw new JsonLdError(
        'URL could not be dereferenced: ' + req.statusText,
        'jsonld.LoadDocumentError', {
          code: 'loading document failed',
          url,
          httpStatusCode: req.status
        });
    }

    let doc = {contextUrl: null, documentUrl: url, document: req.response};
    let alternate = null;

    // handle Link Header (avoid unsafe header warning by existence testing)
    const contentType = req.getResponseHeader('Content-Type');
    let linkHeader;
    if(REGEX_LINK_HEADER.test(req.getAllResponseHeaders())) {
      linkHeader = req.getResponseHeader('Link');
    }
    if(linkHeader && contentType !== 'application/ld+json') {
      // only 1 related link header permitted
      const linkHeaders = parseLinkHeader(linkHeader);
      const linkedContext = linkHeaders[LINK_HEADER_CONTEXT];
      if(Array.isArray(linkedContext)) {
        throw new JsonLdError(
          'URL could not be dereferenced, it has more than one ' +
          'associated HTTP Link Header.',
          'jsonld.InvalidUrl',
          {code: 'multiple context link headers', url});
      }
      if(linkedContext) {
        doc.contextUrl = linkedContext.target;
      }

      // "alternate" link header is a redirect
      alternate = linkHeaders['alternate'];
      if(alternate &&
        alternate.type == 'application/ld+json' &&
        !(contentType || '').match(/^application\/(\w*\+)?json$/)) {
        doc = await loader(prependBase(url, alternate.target));
      }
    }

    return doc;
  }
};

function _get(xhr, url, headers) {
  xhr = xhr || XMLHttpRequest;
  const req = new xhr();
  return new Promise((resolve, reject) => {
    req.onload = () => resolve(req);
    req.onerror = err => reject(err);
    req.open('GET', url, true);
    for(const k in headers) {
      req.setRequestHeader(k, headers[k]);
    }
    req.send();
  });
}

},{"../JsonLdError":139,"../RequestQueue":142,"../constants":145,"../url":158,"../util":159}],148:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const JsonLdError = require('./JsonLdError');

const {
  isArray: _isArray,
  isObject: _isObject,
  isEmptyObject: _isEmptyObject,
  isString: _isString,
  isUndefined: _isUndefined
} = require('./types');

const {
  isList: _isList,
  isValue: _isValue,
  isGraph: _isGraph,
  isSubject: _isSubject
} = require('./graphTypes');

const {
  expandIri: _expandIri,
  getContextValue: _getContextValue,
  isKeyword: _isKeyword,
  process: _processContext,
  processingMode: _processingMode
} = require('./context');

const {
  isAbsolute: _isAbsoluteIri
} = require('./url');

const {
  addValue: _addValue,
  asArray: _asArray,
  getValues: _getValues,
  validateTypeValue: _validateTypeValue
} = require('./util');

const api = {};
module.exports = api;
const REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;

/**
 * Recursively expands an element using the given context. Any context in
 * the element will be removed. All context URLs must have been retrieved
 * before calling this method.
 *
 * @param activeCtx the context to use.
 * @param activeProperty the property for the element, null for none.
 * @param element the element to expand.
 * @param options the expansion options.
 * @param insideList true if the element is a list, false if not.
 * @param insideIndex true if the element is inside an index container,
 *          false if not.
 * @param typeScopedContext an optional type-scoped active context for
 *          expanding values of nodes that were expressed according to
 *          a type-scoped context.
 * @param expansionMap(info) a function that can be used to custom map
 *          unmappable values (or to throw an error when they are detected);
 *          if this function returns `undefined` then the default behavior
 *          will be used.
 *
 * @return a Promise that resolves to the expanded value.
 */
api.expand = async ({
  activeCtx,
  activeProperty = null,
  element,
  options = {},
  insideList = false,
  insideIndex = false,
  typeScopedContext = null,
  expansionMap = () => undefined
}) => {
  // nothing to expand
  if(element === null || element === undefined) {
    return null;
  }

  // disable framing if activeProperty is @default
  if(activeProperty === '@default') {
    options = Object.assign({}, options, {isFrame: false});
  }

  if(!_isArray(element) && !_isObject(element)) {
    // drop free-floating scalars that are not in lists unless custom mapped
    if(!insideList && (activeProperty === null ||
      _expandIri(activeCtx, activeProperty, {vocab: true},
        options) === '@graph')) {
      const mapped = await expansionMap({
        unmappedValue: element,
        activeCtx,
        activeProperty,
        options,
        insideList
      });
      if(mapped === undefined) {
        return null;
      }
      return mapped;
    }

    // expand element according to value expansion rules
    return _expandValue({activeCtx, activeProperty, value: element, options});
  }

  // recursively expand array
  if(_isArray(element)) {
    let rval = [];
    const container = _getContextValue(
      activeCtx, activeProperty, '@container') || [];
    insideList = insideList || container.includes('@list');
    for(let i = 0; i < element.length; ++i) {
      // expand element
      let e = await api.expand({
        activeCtx,
        activeProperty,
        element: element[i],
        options,
        expansionMap,
        insideIndex,
        typeScopedContext
      });
      if(insideList && _isArray(e)) {
        e = {'@list': e};
      }

      if(e === null) {
        e = await expansionMap({
          unmappedValue: element[i],
          activeCtx,
          activeProperty,
          parent: element,
          index: i,
          options,
          expandedParent: rval,
          insideList
        });
        if(e === undefined) {
          continue;
        }
      }

      if(_isArray(e)) {
        rval = rval.concat(e);
      } else {
        rval.push(e);
      }
    }
    return rval;
  }

  // recursively expand object:

  // first, expand the active property
  const expandedActiveProperty = _expandIri(
    activeCtx, activeProperty, {vocab: true}, options);

  // Get any property-scoped context for activeProperty
  const propertyScopedCtx =
    _getContextValue(activeCtx, activeProperty, '@context');

  // second, determine if any type-scoped context should be reverted; it
  // should only be reverted when the following are all true:
  // 1. `element` is not a value or subject reference
  // 2. `insideIndex` is false
  typeScopedContext = typeScopedContext ||
    (activeCtx.previousContext ? activeCtx : null);
  let keys = Object.keys(element).sort();
  let mustRevert = !insideIndex;
  if(mustRevert && typeScopedContext && keys.length <= 2 &&
    !keys.includes('@context')) {
    for(const key of keys) {
      const expandedProperty = _expandIri(
        typeScopedContext, key, {vocab: true}, options);
      if(expandedProperty === '@value') {
        // value found, ensure type-scoped context is used to expand it
        mustRevert = false;
        activeCtx = typeScopedContext;
        break;
      }
      if(expandedProperty === '@id' && keys.length === 1) {
        // subject reference found, do not revert
        mustRevert = false;
        break;
      }
    }
  }

  if(mustRevert) {
    // revert type scoped context
    activeCtx = activeCtx.revertToPreviousContext();
  }

  // apply property-scoped context after reverting term-scoped context
  if(!_isUndefined(propertyScopedCtx)) {
    activeCtx = await _processContext({
      activeCtx,
      localCtx: propertyScopedCtx,
      propagate: true,
      overrideProtected: true,
      options
    });
  }

  // if element has a context, process it
  if('@context' in element) {
    activeCtx = await _processContext(
      {activeCtx, localCtx: element['@context'], options});
  }

  // set the type-scoped context to the context on input, for use later
  typeScopedContext = activeCtx;

  // Remember the first key found expanding to @type
  let typeKey = null;

  // look for scoped contexts on `@type`
  for(const key of keys) {
    const expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);
    if(expandedProperty === '@type') {
      // set scoped contexts from @type
      // avoid sorting if possible
      typeKey = typeKey || key;
      const value = element[key];
      const types =
        Array.isArray(value) ?
          (value.length > 1 ? value.slice().sort() : value) : [value];
      for(const type of types) {
        const ctx = _getContextValue(typeScopedContext, type, '@context');
        if(!_isUndefined(ctx)) {
          activeCtx = await _processContext({
            activeCtx,
            localCtx: ctx,
            options,
            propagate: false
          });
        }
      }
    }
  }

  // process each key and value in element, ignoring @nest content
  let rval = {};
  await _expandObject({
    activeCtx,
    activeProperty,
    expandedActiveProperty,
    element,
    expandedParent: rval,
    options,
    insideList,
    typeKey,
    typeScopedContext,
    expansionMap});

  // get property count on expanded output
  keys = Object.keys(rval);
  let count = keys.length;

  if('@value' in rval) {
    // @value must only have @language or @type
    if('@type' in rval && ('@language' in rval || '@direction' in rval)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; an element containing "@value" may not ' +
        'contain both "@type" and either "@language" or "@direction".',
        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});
    }
    let validCount = count - 1;
    if('@type' in rval) {
      validCount -= 1;
    }
    if('@index' in rval) {
      validCount -= 1;
    }
    if('@language' in rval) {
      validCount -= 1;
    }
    if('@direction' in rval) {
      validCount -= 1;
    }
    if(validCount !== 0) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; an element containing "@value" may only ' +
        'have an "@index" property and either "@type" ' +
        'or either or both "@language" or "@direction".',
        'jsonld.SyntaxError', {code: 'invalid value object', element: rval});
    }
    const values = rval['@value'] === null ? [] : _asArray(rval['@value']);
    const types = _getValues(rval, '@type');

    // drop null @values unless custom mapped
    if(_processingMode(activeCtx, 1.1) && types.includes('@json') &&
      types.length === 1) {
      // Any value of @value is okay if @type: @json
    } else if(values.length === 0) {
      const mapped = await expansionMap({
        unmappedValue: rval,
        activeCtx,
        activeProperty,
        element,
        options,
        insideList
      });
      if(mapped !== undefined) {
        rval = mapped;
      } else {
        rval = null;
      }
    } else if(!values.every(v => (_isString(v) || _isEmptyObject(v))) &&
      '@language' in rval) {
      // if @language is present, @value must be a string
      throw new JsonLdError(
        'Invalid JSON-LD syntax; only strings may be language-tagged.',
        'jsonld.SyntaxError',
        {code: 'invalid language-tagged value', element: rval});
    } else if(!types.every(t =>
      (_isAbsoluteIri(t) && !(_isString(t) && t.indexOf('_:') === 0) ||
      _isEmptyObject(t)))) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; an element containing "@value" and "@type" ' +
        'must have an absolute IRI for the value of "@type".',
        'jsonld.SyntaxError', {code: 'invalid typed value', element: rval});
    }
  } else if('@type' in rval && !_isArray(rval['@type'])) {
    // convert @type to an array
    rval['@type'] = [rval['@type']];
  } else if('@set' in rval || '@list' in rval) {
    // handle @set and @list
    if(count > 1 && !(count === 2 && '@index' in rval)) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; if an element has the property "@set" ' +
        'or "@list", then it can have at most one other property that is ' +
        '"@index".', 'jsonld.SyntaxError',
        {code: 'invalid set or list object', element: rval});
    }
    // optimize away @set
    if('@set' in rval) {
      rval = rval['@set'];
      keys = Object.keys(rval);
      count = keys.length;
    }
  } else if(count === 1 && '@language' in rval) {
    // drop objects with only @language unless custom mapped
    const mapped = await expansionMap(rval, {
      unmappedValue: rval,
      activeCtx,
      activeProperty,
      element,
      options,
      insideList
    });
    if(mapped !== undefined) {
      rval = mapped;
    } else {
      rval = null;
    }
  }

  // drop certain top-level objects that do not occur in lists, unless custom
  // mapped
  if(_isObject(rval) &&
    !options.keepFreeFloatingNodes && !insideList &&
    (activeProperty === null || expandedActiveProperty === '@graph')) {
    // drop empty object, top-level @value/@list, or object with only @id
    if(count === 0 || '@value' in rval || '@list' in rval ||
      (count === 1 && '@id' in rval)) {
      const mapped = await expansionMap({
        unmappedValue: rval,
        activeCtx,
        activeProperty,
        element,
        options,
        insideList
      });
      if(mapped !== undefined) {
        rval = mapped;
      } else {
        rval = null;
      }
    }
  }

  return rval;
};

/**
 * Expand each key and value of element adding to result
 *
 * @param activeCtx the context to use.
 * @param activeProperty the property for the element.
 * @param expandedActiveProperty the expansion of activeProperty
 * @param element the element to expand.
 * @param expandedParent the expanded result into which to add values.
 * @param options the expansion options.
 * @param insideList true if the element is a list, false if not.
 * @param typeKey first key found expanding to @type.
 * @param typeScopedContext the context before reverting.
 * @param expansionMap(info) a function that can be used to custom map
 *          unmappable values (or to throw an error when they are detected);
 *          if this function returns `undefined` then the default behavior
 *          will be used.
 */
async function _expandObject({
  activeCtx,
  activeProperty,
  expandedActiveProperty,
  element,
  expandedParent,
  options = {},
  insideList,
  typeKey,
  typeScopedContext,
  expansionMap
}) {
  const keys = Object.keys(element).sort();
  const nests = [];
  let unexpandedValue;

  // Figure out if this is the type for a JSON literal
  const isJsonType = element[typeKey] &&
    _expandIri(activeCtx,
      (_isArray(element[typeKey]) ? element[typeKey][0] : element[typeKey]),
      {vocab: true}, options) === '@json';

  for(const key of keys) {
    let value = element[key];
    let expandedValue;

    // skip @context
    if(key === '@context') {
      continue;
    }

    // expand property
    let expandedProperty = _expandIri(activeCtx, key, {vocab: true}, options);

    // drop non-absolute IRI keys that aren't keywords unless custom mapped
    if(expandedProperty === null ||
      !(_isAbsoluteIri(expandedProperty) || _isKeyword(expandedProperty))) {
      // TODO: use `await` to support async
      expandedProperty = expansionMap({
        unmappedProperty: key,
        activeCtx,
        activeProperty,
        parent: element,
        options,
        insideList,
        value,
        expandedParent
      });
      if(expandedProperty === undefined) {
        continue;
      }
    }

    if(_isKeyword(expandedProperty)) {
      if(expandedActiveProperty === '@reverse') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; a keyword cannot be used as a @reverse ' +
          'property.', 'jsonld.SyntaxError',
          {code: 'invalid reverse property map', value});
      }
      if(expandedProperty in expandedParent &&
         expandedProperty !== '@included' &&
         expandedProperty !== '@type') {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; colliding keywords detected.',
          'jsonld.SyntaxError',
          {code: 'colliding keywords', keyword: expandedProperty});
      }
    }

    // syntax error if @id is not a string
    if(expandedProperty === '@id') {
      if(!_isString(value)) {
        if(!options.isFrame) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; "@id" value must a string.',
            'jsonld.SyntaxError', {code: 'invalid @id value', value});
        }
        if(_isObject(value)) {
          // empty object is a wildcard
          if(!_isEmptyObject(value)) {
            throw new JsonLdError(
              'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
              'of strings, if framing',
              'jsonld.SyntaxError', {code: 'invalid @id value', value});
          }
        } else if(_isArray(value)) {
          if(!value.every(v => _isString(v))) {
            throw new JsonLdError(
              'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
              'of strings, if framing',
              'jsonld.SyntaxError', {code: 'invalid @id value', value});
          }
        } else {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; "@id" value an empty object or array ' +
            'of strings, if framing',
            'jsonld.SyntaxError', {code: 'invalid @id value', value});
        }
      }

      _addValue(
        expandedParent, '@id',
        _asArray(value).map(v =>
          _isString(v) ? _expandIri(activeCtx, v, {base: true}, options) : v),
        {propertyIsArray: options.isFrame});
      continue;
    }

    if(expandedProperty === '@type') {
      // if framing, can be a default object, but need to expand
      // key to determine that
      if(_isObject(value)) {
        value = Object.fromEntries(Object.entries(value).map(([k, v]) => [
          _expandIri(typeScopedContext, k, {vocab: true}),
          _asArray(v).map(vv =>
            _expandIri(typeScopedContext, vv, {base: true, vocab: true})
          )
        ]));
      }
      _validateTypeValue(value, options.isFrame);
      _addValue(
        expandedParent, '@type',
        _asArray(value).map(v =>
          _isString(v) ?
            _expandIri(typeScopedContext, v,
              {base: true, vocab: true}, options) : v),
        {propertyIsArray: options.isFrame});
      continue;
    }

    // Included blocks are treated as an array of separate object nodes sharing
    // the same referencing active_property.
    // For 1.0, it is skipped as are other unknown keywords
    if(expandedProperty === '@included' && _processingMode(activeCtx, 1.1)) {
      const includedResult = _asArray(await api.expand({
        activeCtx,
        activeProperty,
        element: value,
        options,
        expansionMap
      }));

      // Expanded values must be node objects
      if(!includedResult.every(v => _isSubject(v))) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; ' +
          'values of @included must expand to node objects.',
          'jsonld.SyntaxError', {code: 'invalid @included value', value});
      }

      _addValue(
        expandedParent, '@included', includedResult, {propertyIsArray: true});
      continue;
    }

    // @graph must be an array or an object
    if(expandedProperty === '@graph' &&
      !(_isObject(value) || _isArray(value))) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; "@graph" value must not be an ' +
        'object or an array.',
        'jsonld.SyntaxError', {code: 'invalid @graph value', value});
    }

    if(expandedProperty === '@value') {
      // capture value for later
      // "colliding keywords" check prevents this from being set twice
      unexpandedValue = value;
      if(isJsonType && _processingMode(activeCtx, 1.1)) {
        // no coercion to array, and retain all values
        expandedParent['@value'] = value;
      } else {
        _addValue(
          expandedParent, '@value', value, {propertyIsArray: options.isFrame});
      }
      continue;
    }

    // @language must be a string
    // it should match BCP47
    if(expandedProperty === '@language') {
      if(value === null) {
        // drop null @language values, they expand as if they didn't exist
        continue;
      }
      if(!_isString(value) && !options.isFrame) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; "@language" value must be a string.',
          'jsonld.SyntaxError',
          {code: 'invalid language-tagged string', value});
      }
      // ensure language value is lowercase
      value = _asArray(value).map(v => _isString(v) ? v.toLowerCase() : v);

      // ensure language tag matches BCP47
      for(const lang of value) {
        if(_isString(lang) && !lang.match(REGEX_BCP47)) {
          console.warn(`@language must be valid BCP47: ${lang}`);
        }
      }

      _addValue(
        expandedParent, '@language', value, {propertyIsArray: options.isFrame});
      continue;
    }

    // @direction must be "ltr" or "rtl"
    if(expandedProperty === '@direction') {
      if(!_isString(value) && !options.isFrame) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; "@direction" value must be a string.',
          'jsonld.SyntaxError',
          {code: 'invalid base direction', value});
      }

      value = _asArray(value);

      // ensure direction is "ltr" or "rtl"
      for(const dir of value) {
        if(_isString(dir) && dir !== 'ltr' && dir !== 'rtl') {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; "@direction" must be "ltr" or "rtl".',
            'jsonld.SyntaxError',
            {code: 'invalid base direction', value});
        }
      }

      _addValue(
        expandedParent, '@direction', value,
        {propertyIsArray: options.isFrame});
      continue;
    }

    // @index must be a string
    if(expandedProperty === '@index') {
      if(!_isString(value)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; "@index" value must be a string.',
          'jsonld.SyntaxError',
          {code: 'invalid @index value', value});
      }
      _addValue(expandedParent, '@index', value);
      continue;
    }

    // @reverse must be an object
    if(expandedProperty === '@reverse') {
      if(!_isObject(value)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; "@reverse" value must be an object.',
          'jsonld.SyntaxError', {code: 'invalid @reverse value', value});
      }

      expandedValue = await api.expand({
        activeCtx,
        activeProperty:
        '@reverse',
        element: value,
        options,
        expansionMap
      });
      // properties double-reversed
      if('@reverse' in expandedValue) {
        for(const property in expandedValue['@reverse']) {
          _addValue(
            expandedParent, property, expandedValue['@reverse'][property],
            {propertyIsArray: true});
        }
      }

      // FIXME: can this be merged with code below to simplify?
      // merge in all reversed properties
      let reverseMap = expandedParent['@reverse'] || null;
      for(const property in expandedValue) {
        if(property === '@reverse') {
          continue;
        }
        if(reverseMap === null) {
          reverseMap = expandedParent['@reverse'] = {};
        }
        _addValue(reverseMap, property, [], {propertyIsArray: true});
        const items = expandedValue[property];
        for(let ii = 0; ii < items.length; ++ii) {
          const item = items[ii];
          if(_isValue(item) || _isList(item)) {
            throw new JsonLdError(
              'Invalid JSON-LD syntax; "@reverse" value must not be a ' +
              '@value or an @list.', 'jsonld.SyntaxError',
              {code: 'invalid reverse property value', value: expandedValue});
          }
          _addValue(reverseMap, property, item, {propertyIsArray: true});
        }
      }

      continue;
    }

    // nested keys
    if(expandedProperty === '@nest') {
      nests.push(key);
      continue;
    }

    // use potential scoped context for key
    let termCtx = activeCtx;
    const ctx = _getContextValue(activeCtx, key, '@context');
    if(!_isUndefined(ctx)) {
      termCtx = await _processContext({
        activeCtx,
        localCtx: ctx,
        propagate: true,
        overrideProtected: true,
        options
      });
    }

    const container = _getContextValue(termCtx, key, '@container') || [];

    if(container.includes('@language') && _isObject(value)) {
      const direction = _getContextValue(termCtx, key, '@direction');
      // handle language map container (skip if value is not an object)
      expandedValue = _expandLanguageMap(termCtx, value, direction, options);
    } else if(container.includes('@index') && _isObject(value)) {
      // handle index container (skip if value is not an object)
      const asGraph = container.includes('@graph');
      const indexKey = _getContextValue(termCtx, key, '@index') || '@index';
      const propertyIndex = indexKey !== '@index' &&
        _expandIri(activeCtx, indexKey, {vocab: true}, options);

      expandedValue = await _expandIndexMap({
        activeCtx: termCtx,
        options,
        activeProperty: key,
        value,
        expansionMap,
        asGraph,
        indexKey,
        propertyIndex
      });
    } else if(container.includes('@id') && _isObject(value)) {
      // handle id container (skip if value is not an object)
      const asGraph = container.includes('@graph');
      expandedValue = await _expandIndexMap({
        activeCtx: termCtx,
        options,
        activeProperty: key,
        value,
        expansionMap,
        asGraph,
        indexKey: '@id'
      });
    } else if(container.includes('@type') && _isObject(value)) {
      // handle type container (skip if value is not an object)
      expandedValue = await _expandIndexMap({
        // since container is `@type`, revert type scoped context when expanding
        activeCtx: termCtx.revertToPreviousContext(),
        options,
        activeProperty: key,
        value,
        expansionMap,
        asGraph: false,
        indexKey: '@type'
      });
    } else {
      // recurse into @list or @set
      const isList = (expandedProperty === '@list');
      if(isList || expandedProperty === '@set') {
        let nextActiveProperty = activeProperty;
        if(isList && expandedActiveProperty === '@graph') {
          nextActiveProperty = null;
        }
        expandedValue = await api.expand({
          activeCtx: termCtx,
          activeProperty: nextActiveProperty,
          element: value,
          options,
          insideList: isList,
          expansionMap
        });
      } else if(
        _getContextValue(activeCtx, key, '@type') === '@json') {
        expandedValue = {
          '@type': '@json',
          '@value': value
        };
      } else {
        // recursively expand value with key as new active property
        expandedValue = await api.expand({
          activeCtx: termCtx,
          activeProperty: key,
          element: value,
          options,
          insideList: false,
          expansionMap
        });
      }
    }

    // drop null values if property is not @value
    if(expandedValue === null && expandedProperty !== '@value') {
      // TODO: use `await` to support async
      expandedValue = expansionMap({
        unmappedValue: value,
        expandedProperty,
        activeCtx: termCtx,
        activeProperty,
        parent: element,
        options,
        insideList,
        key,
        expandedParent
      });
      if(expandedValue === undefined) {
        continue;
      }
    }

    // convert expanded value to @list if container specifies it
    if(expandedProperty !== '@list' && !_isList(expandedValue) &&
      container.includes('@list')) {
      // ensure expanded value in @list is an array
      expandedValue = {'@list': _asArray(expandedValue)};
    }

    // convert expanded value to @graph if container specifies it
    // and value is not, itself, a graph
    // index cases handled above
    if(container.includes('@graph') &&
      !container.some(key => key === '@id' || key === '@index')) {
      // ensure expanded values are arrays
      expandedValue = _asArray(expandedValue)
        .map(v => ({'@graph': _asArray(v)}));
    }

    // FIXME: can this be merged with code above to simplify?
    // merge in reverse properties
    if(termCtx.mappings.has(key) && termCtx.mappings.get(key).reverse) {
      const reverseMap =
        expandedParent['@reverse'] = expandedParent['@reverse'] || {};
      expandedValue = _asArray(expandedValue);
      for(let ii = 0; ii < expandedValue.length; ++ii) {
        const item = expandedValue[ii];
        if(_isValue(item) || _isList(item)) {
          throw new JsonLdError(
            'Invalid JSON-LD syntax; "@reverse" value must not be a ' +
            '@value or an @list.', 'jsonld.SyntaxError',
            {code: 'invalid reverse property value', value: expandedValue});
        }
        _addValue(reverseMap, expandedProperty, item, {propertyIsArray: true});
      }
      continue;
    }

    // add value for property
    // special keywords handled above
    _addValue(expandedParent, expandedProperty, expandedValue, {
      propertyIsArray: true
    });
  }

  // @value must not be an object or an array (unless framing) or if @type is
  // @json
  if('@value' in expandedParent) {
    if(expandedParent['@type'] === '@json' && _processingMode(activeCtx, 1.1)) {
      // allow any value, to be verified when the object is fully expanded and
      // the @type is @json.
    } else if((_isObject(unexpandedValue) || _isArray(unexpandedValue)) &&
      !options.isFrame) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; "@value" value must not be an ' +
        'object or an array.',
        'jsonld.SyntaxError',
        {code: 'invalid value object value', value: unexpandedValue});
    }
  }

  // expand each nested key
  for(const key of nests) {
    const nestedValues = _isArray(element[key]) ? element[key] : [element[key]];
    for(const nv of nestedValues) {
      if(!_isObject(nv) || Object.keys(nv).some(k =>
        _expandIri(activeCtx, k, {vocab: true}, options) === '@value')) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; nested value must be a node object.',
          'jsonld.SyntaxError',
          {code: 'invalid @nest value', value: nv});
      }
      await _expandObject({
        activeCtx,
        activeProperty,
        expandedActiveProperty,
        element: nv,
        expandedParent,
        options,
        insideList,
        typeScopedContext,
        typeKey,
        expansionMap});
    }
  }
}

/**
 * Expands the given value by using the coercion and keyword rules in the
 * given context.
 *
 * @param activeCtx the active context to use.
 * @param activeProperty the active property the value is associated with.
 * @param value the value to expand.
 * @param {Object} [options] - processing options.
 *
 * @return the expanded value.
 */
function _expandValue({activeCtx, activeProperty, value, options}) {
  // nothing to expand
  if(value === null || value === undefined) {
    return null;
  }

  // special-case expand @id and @type (skips '@id' expansion)
  const expandedProperty = _expandIri(
    activeCtx, activeProperty, {vocab: true}, options);
  if(expandedProperty === '@id') {
    return _expandIri(activeCtx, value, {base: true}, options);
  } else if(expandedProperty === '@type') {
    return _expandIri(activeCtx, value, {vocab: true, base: true}, options);
  }

  // get type definition from context
  const type = _getContextValue(activeCtx, activeProperty, '@type');

  // do @id expansion (automatic for @graph)
  if((type === '@id' || expandedProperty === '@graph') && _isString(value)) {
    return {'@id': _expandIri(activeCtx, value, {base: true}, options)};
  }
  // do @id expansion w/vocab
  if(type === '@vocab' && _isString(value)) {
    return {
      '@id': _expandIri(activeCtx, value, {vocab: true, base: true}, options)
    };
  }

  // do not expand keyword values
  if(_isKeyword(expandedProperty)) {
    return value;
  }

  const rval = {};

  if(type && !['@id', '@vocab', '@none'].includes(type)) {
    // other type
    rval['@type'] = type;
  } else if(_isString(value)) {
    // check for language tagging for strings
    const language = _getContextValue(activeCtx, activeProperty, '@language');
    if(language !== null) {
      rval['@language'] = language;
    }
    const direction = _getContextValue(activeCtx, activeProperty, '@direction');
    if(direction !== null) {
      rval['@direction'] = direction;
    }
  }
  // do conversion of values that aren't basic JSON types to strings
  if(!['boolean', 'number', 'string'].includes(typeof value)) {
    value = value.toString();
  }
  rval['@value'] = value;

  return rval;
}

/**
 * Expands a language map.
 *
 * @param activeCtx the active context to use.
 * @param languageMap the language map to expand.
 * @param direction the direction to apply to values.
 * @param {Object} [options] - processing options.
 *
 * @return the expanded language map.
 */
function _expandLanguageMap(activeCtx, languageMap, direction, options) {
  const rval = [];
  const keys = Object.keys(languageMap).sort();
  for(const key of keys) {
    const expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);
    let val = languageMap[key];
    if(!_isArray(val)) {
      val = [val];
    }
    for(const item of val) {
      if(item === null) {
        // null values are allowed (8.5) but ignored (3.1)
        continue;
      }
      if(!_isString(item)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; language map values must be strings.',
          'jsonld.SyntaxError',
          {code: 'invalid language map value', languageMap});
      }
      const val = {'@value': item};
      if(expandedKey !== '@none') {
        val['@language'] = key.toLowerCase();
      }
      if(direction) {
        val['@direction'] = direction;
      }
      rval.push(val);
    }
  }
  return rval;
}

async function _expandIndexMap(
  {activeCtx, options, activeProperty, value, expansionMap, asGraph,
    indexKey, propertyIndex}) {
  const rval = [];
  const keys = Object.keys(value).sort();
  const isTypeIndex = indexKey === '@type';
  for(let key of keys) {
    // if indexKey is @type, there may be a context defined for it
    if(isTypeIndex) {
      const ctx = _getContextValue(activeCtx, key, '@context');
      if(!_isUndefined(ctx)) {
        activeCtx = await _processContext({
          activeCtx,
          localCtx: ctx,
          propagate: false,
          options
        });
      }
    }

    let val = value[key];
    if(!_isArray(val)) {
      val = [val];
    }

    val = await api.expand({
      activeCtx,
      activeProperty,
      element: val,
      options,
      insideList: false,
      insideIndex: true,
      expansionMap
    });

    // expand for @type, but also for @none
    let expandedKey;
    if(propertyIndex) {
      if(key === '@none') {
        expandedKey = '@none';
      } else {
        expandedKey = _expandValue(
          {activeCtx, activeProperty: indexKey, value: key, options});
      }
    } else {
      expandedKey = _expandIri(activeCtx, key, {vocab: true}, options);
    }

    if(indexKey === '@id') {
      // expand document relative
      key = _expandIri(activeCtx, key, {base: true}, options);
    } else if(isTypeIndex) {
      key = expandedKey;
    }

    for(let item of val) {
      // If this is also a @graph container, turn items into graphs
      if(asGraph && !_isGraph(item)) {
        item = {'@graph': [item]};
      }
      if(indexKey === '@type') {
        if(expandedKey === '@none') {
          // ignore @none
        } else if(item['@type']) {
          item['@type'] = [key].concat(item['@type']);
        } else {
          item['@type'] = [key];
        }
      } else if(_isValue(item) &&
        !['@language', '@type', '@index'].includes(indexKey)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; Attempt to add illegal key to value ' +
          `object: "${indexKey}".`,
          'jsonld.SyntaxError',
          {code: 'invalid value object', value: item});
      } else if(propertyIndex) {
        // index is a property to be expanded, and values interpreted for that
        // property
        if(expandedKey !== '@none') {
          // expand key as a value
          _addValue(item, propertyIndex, expandedKey, {
            propertyIsArray: true,
            prependValue: true
          });
        }
      } else if(expandedKey !== '@none' && !(indexKey in item)) {
        item[indexKey] = key;
      }
      rval.push(item);
    }
  }
  return rval;
}

},{"./JsonLdError":139,"./context":146,"./graphTypes":152,"./types":157,"./url":158,"./util":159}],149:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {
  isSubjectReference: _isSubjectReference
} = require('./graphTypes');

const {
  createMergedNodeMap: _createMergedNodeMap
} = require('./nodeMap');

const api = {};
module.exports = api;

/**
 * Performs JSON-LD flattening.
 *
 * @param input the expanded JSON-LD to flatten.
 *
 * @return the flattened output.
 */
api.flatten = input => {
  const defaultGraph = _createMergedNodeMap(input);

  // produce flattened output
  const flattened = [];
  const keys = Object.keys(defaultGraph).sort();
  for(let ki = 0; ki < keys.length; ++ki) {
    const node = defaultGraph[keys[ki]];
    // only add full subjects to top-level
    if(!_isSubjectReference(node)) {
      flattened.push(node);
    }
  }
  return flattened;
};

},{"./graphTypes":152,"./nodeMap":154}],150:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {isKeyword} = require('./context');
const graphTypes = require('./graphTypes');
const types = require('./types');
const util = require('./util');
const url = require('./url');
const JsonLdError = require('./JsonLdError');
const {
  createNodeMap: _createNodeMap,
  mergeNodeMapGraphs: _mergeNodeMapGraphs
} = require('./nodeMap');

const api = {};
module.exports = api;

/**
 * Performs JSON-LD `merged` framing.
 *
 * @param input the expanded JSON-LD to frame.
 * @param frame the expanded JSON-LD frame to use.
 * @param options the framing options.
 *
 * @return the framed output.
 */
api.frameMergedOrDefault = (input, frame, options) => {
  // create framing state
  const state = {
    options,
    embedded: false,
    graph: '@default',
    graphMap: {'@default': {}},
    subjectStack: [],
    link: {},
    bnodeMap: {}
  };

  // produce a map of all graphs and name each bnode
  // FIXME: currently uses subjects from @merged graph only
  const issuer = new util.IdentifierIssuer('_:b');
  _createNodeMap(input, state.graphMap, '@default', issuer);
  if(options.merged) {
    state.graphMap['@merged'] = _mergeNodeMapGraphs(state.graphMap);
    state.graph = '@merged';
  }
  state.subjects = state.graphMap[state.graph];

  // frame the subjects
  const framed = [];
  api.frame(state, Object.keys(state.subjects).sort(), frame, framed);

  // If pruning blank nodes, find those to prune
  if(options.pruneBlankNodeIdentifiers) {
    // remove all blank nodes appearing only once, done in compaction
    options.bnodesToClear =
      Object.keys(state.bnodeMap).filter(id => state.bnodeMap[id].length === 1);
  }

  // remove @preserve from results
  options.link = {};
  return _cleanupPreserve(framed, options);
};

/**
 * Frames subjects according to the given frame.
 *
 * @param state the current framing state.
 * @param subjects the subjects to filter.
 * @param frame the frame.
 * @param parent the parent subject or top-level array.
 * @param property the parent property, initialized to null.
 */
api.frame = (state, subjects, frame, parent, property = null) => {
  // validate the frame
  _validateFrame(frame);
  frame = frame[0];

  // get flags for current frame
  const options = state.options;
  const flags = {
    embed: _getFrameFlag(frame, options, 'embed'),
    explicit: _getFrameFlag(frame, options, 'explicit'),
    requireAll: _getFrameFlag(frame, options, 'requireAll')
  };

  // get link for current graph
  if(!state.link.hasOwnProperty(state.graph)) {
    state.link[state.graph] = {};
  }
  const link = state.link[state.graph];

  // filter out subjects that match the frame
  const matches = _filterSubjects(state, subjects, frame, flags);

  // add matches to output
  const ids = Object.keys(matches).sort();
  for(const id of ids) {
    const subject = matches[id];

    /* Note: In order to treat each top-level match as a compartmentalized
    result, clear the unique embedded subjects map when the property is null,
    which only occurs at the top-level. */
    if(property === null) {
      state.uniqueEmbeds = {[state.graph]: {}};
    } else {
      state.uniqueEmbeds[state.graph] = state.uniqueEmbeds[state.graph] || {};
    }

    if(flags.embed === '@link' && id in link) {
      // TODO: may want to also match an existing linked subject against
      // the current frame ... so different frames could produce different
      // subjects that are only shared in-memory when the frames are the same

      // add existing linked subject
      _addFrameOutput(parent, property, link[id]);
      continue;
    }

    // start output for subject
    const output = {'@id': id};
    if(id.indexOf('_:') === 0) {
      util.addValue(state.bnodeMap, id, output, {propertyIsArray: true});
    }
    link[id] = output;

    // validate @embed
    if((flags.embed === '@first' || flags.embed === '@last') && state.is11) {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; invalid value of @embed.',
        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});
    }

    if(!state.embedded && state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {
      // skip adding this node object to the top level, as it was
      // already included in another node object
      continue;
    }

    // if embed is @never or if a circular reference would be created by an
    // embed, the subject cannot be embedded, just add the reference;
    // note that a circular reference won't occur when the embed flag is
    // `@link` as the above check will short-circuit before reaching this point
    if(state.embedded &&
      (flags.embed === '@never' ||
      _createsCircularReference(subject, state.graph, state.subjectStack))) {
      _addFrameOutput(parent, property, output);
      continue;
    }

    // if only the first (or once) should be embedded
    if(state.embedded &&
       (flags.embed == '@first' || flags.embed == '@once') &&
       state.uniqueEmbeds[state.graph].hasOwnProperty(id)) {
      _addFrameOutput(parent, property, output);
      continue;
    }

    // if only the last match should be embedded
    if(flags.embed === '@last') {
      // remove any existing embed
      if(id in state.uniqueEmbeds[state.graph]) {
        _removeEmbed(state, id);
      }
    }

    state.uniqueEmbeds[state.graph][id] = {parent, property};

    // push matching subject onto stack to enable circular embed checks
    state.subjectStack.push({subject, graph: state.graph});

    // subject is also the name of a graph
    if(id in state.graphMap) {
      let recurse = false;
      let subframe = null;
      if(!('@graph' in frame)) {
        recurse = state.graph !== '@merged';
        subframe = {};
      } else {
        subframe = frame['@graph'][0];
        recurse = !(id === '@merged' || id === '@default');
        if(!types.isObject(subframe)) {
          subframe = {};
        }
      }

      if(recurse) {
        // recurse into graph
        api.frame(
          {...state, graph: id, embedded: false},
          Object.keys(state.graphMap[id]).sort(), [subframe], output, '@graph');
      }
    }

    // if frame has @included, recurse over its sub-frame
    if('@included' in frame) {
      api.frame(
        {...state, embedded: false},
        subjects, frame['@included'], output, '@included');
    }

    // iterate over subject properties
    for(const prop of Object.keys(subject).sort()) {
      // copy keywords to output
      if(isKeyword(prop)) {
        output[prop] = util.clone(subject[prop]);

        if(prop === '@type') {
          // count bnode values of @type
          for(const type of subject['@type']) {
            if(type.indexOf('_:') === 0) {
              util.addValue(
                state.bnodeMap, type, output, {propertyIsArray: true});
            }
          }
        }
        continue;
      }

      // explicit is on and property isn't in the frame, skip processing
      if(flags.explicit && !(prop in frame)) {
        continue;
      }

      // add objects
      for(const o of subject[prop]) {
        const subframe = (prop in frame ?
          frame[prop] : _createImplicitFrame(flags));

        // recurse into list
        if(graphTypes.isList(o)) {
          const subframe =
            (frame[prop] && frame[prop][0] && frame[prop][0]['@list']) ?
              frame[prop][0]['@list'] :
              _createImplicitFrame(flags);

          // add empty list
          const list = {'@list': []};
          _addFrameOutput(output, prop, list);

          // add list objects
          const src = o['@list'];
          for(const oo of src) {
            if(graphTypes.isSubjectReference(oo)) {
              // recurse into subject reference
              api.frame(
                {...state, embedded: true},
                [oo['@id']], subframe, list, '@list');
            } else {
              // include other values automatically
              _addFrameOutput(list, '@list', util.clone(oo));
            }
          }
        } else if(graphTypes.isSubjectReference(o)) {
          // recurse into subject reference
          api.frame(
            {...state, embedded: true},
            [o['@id']], subframe, output, prop);
        } else if(_valueMatch(subframe[0], o)) {
          // include other values, if they match
          _addFrameOutput(output, prop, util.clone(o));
        }
      }
    }

    // handle defaults
    for(const prop of Object.keys(frame).sort()) {
      // skip keywords
      if(prop === '@type') {
        if(!types.isObject(frame[prop][0]) ||
           !('@default' in frame[prop][0])) {
          continue;
        }
        // allow through default types
      } else if(isKeyword(prop)) {
        continue;
      }

      // if omit default is off, then include default values for properties
      // that appear in the next frame but are not in the matching subject
      const next = frame[prop][0] || {};
      const omitDefaultOn = _getFrameFlag(next, options, 'omitDefault');
      if(!omitDefaultOn && !(prop in output)) {
        let preserve = '@null';
        if('@default' in next) {
          preserve = util.clone(next['@default']);
        }
        if(!types.isArray(preserve)) {
          preserve = [preserve];
        }
        output[prop] = [{'@preserve': preserve}];
      }
    }

    // if embed reverse values by finding nodes having this subject as a value
    // of the associated property
    for(const reverseProp of Object.keys(frame['@reverse'] || {}).sort()) {
      const subframe = frame['@reverse'][reverseProp];
      for(const subject of Object.keys(state.subjects)) {
        const nodeValues =
          util.getValues(state.subjects[subject], reverseProp);
        if(nodeValues.some(v => v['@id'] === id)) {
          // node has property referencing this subject, recurse
          output['@reverse'] = output['@reverse'] || {};
          util.addValue(
            output['@reverse'], reverseProp, [], {propertyIsArray: true});
          api.frame(
            {...state, embedded: true},
            [subject], subframe, output['@reverse'][reverseProp],
            property);
        }
      }
    }

    // add output to parent
    _addFrameOutput(parent, property, output);

    // pop matching subject from circular ref-checking stack
    state.subjectStack.pop();
  }
};

/**
 * Replace `@null` with `null`, removing it from arrays.
 *
 * @param input the framed, compacted output.
 * @param options the framing options used.
 *
 * @return the resulting output.
 */
api.cleanupNull = (input, options) => {
  // recurse through arrays
  if(types.isArray(input)) {
    const noNulls = input.map(v => api.cleanupNull(v, options));
    return noNulls.filter(v => v); // removes nulls from array
  }

  if(input === '@null') {
    return null;
  }

  if(types.isObject(input)) {
    // handle in-memory linked nodes
    if('@id' in input) {
      const id = input['@id'];
      if(options.link.hasOwnProperty(id)) {
        const idx = options.link[id].indexOf(input);
        if(idx !== -1) {
          // already visited
          return options.link[id][idx];
        }
        // prevent circular visitation
        options.link[id].push(input);
      } else {
        // prevent circular visitation
        options.link[id] = [input];
      }
    }

    for(const key in input) {
      input[key] = api.cleanupNull(input[key], options);
    }
  }
  return input;
};

/**
 * Creates an implicit frame when recursing through subject matches. If
 * a frame doesn't have an explicit frame for a particular property, then
 * a wildcard child frame will be created that uses the same flags that the
 * parent frame used.
 *
 * @param flags the current framing flags.
 *
 * @return the implicit frame.
 */
function _createImplicitFrame(flags) {
  const frame = {};
  for(const key in flags) {
    if(flags[key] !== undefined) {
      frame['@' + key] = [flags[key]];
    }
  }
  return [frame];
}

/**
 * Checks the current subject stack to see if embedding the given subject
 * would cause a circular reference.
 *
 * @param subjectToEmbed the subject to embed.
 * @param graph the graph the subject to embed is in.
 * @param subjectStack the current stack of subjects.
 *
 * @return true if a circular reference would be created, false if not.
 */
function _createsCircularReference(subjectToEmbed, graph, subjectStack) {
  for(let i = subjectStack.length - 1; i >= 0; --i) {
    const subject = subjectStack[i];
    if(subject.graph === graph &&
      subject.subject['@id'] === subjectToEmbed['@id']) {
      return true;
    }
  }
  return false;
}

/**
 * Gets the frame flag value for the given flag name.
 *
 * @param frame the frame.
 * @param options the framing options.
 * @param name the flag name.
 *
 * @return the flag value.
 */
function _getFrameFlag(frame, options, name) {
  const flag = '@' + name;
  let rval = (flag in frame ? frame[flag][0] : options[name]);
  if(name === 'embed') {
    // default is "@last"
    // backwards-compatibility support for "embed" maps:
    // true => "@last"
    // false => "@never"
    if(rval === true) {
      rval = '@once';
    } else if(rval === false) {
      rval = '@never';
    } else if(rval !== '@always' && rval !== '@never' && rval !== '@link' &&
      rval !== '@first' && rval !== '@last' && rval !== '@once') {
      throw new JsonLdError(
        'Invalid JSON-LD syntax; invalid value of @embed.',
        'jsonld.SyntaxError', {code: 'invalid @embed value', frame});
    }
  }
  return rval;
}

/**
 * Validates a JSON-LD frame, throwing an exception if the frame is invalid.
 *
 * @param frame the frame to validate.
 */
function _validateFrame(frame) {
  if(!types.isArray(frame) || frame.length !== 1 || !types.isObject(frame[0])) {
    throw new JsonLdError(
      'Invalid JSON-LD syntax; a JSON-LD frame must be a single object.',
      'jsonld.SyntaxError', {frame});
  }

  if('@id' in frame[0]) {
    for(const id of util.asArray(frame[0]['@id'])) {
      // @id must be wildcard or an IRI
      if(!(types.isObject(id) || url.isAbsolute(id)) ||
        (types.isString(id) && id.indexOf('_:') === 0)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; invalid @id in frame.',
          'jsonld.SyntaxError', {code: 'invalid frame', frame});
      }
    }
  }

  if('@type' in frame[0]) {
    for(const type of util.asArray(frame[0]['@type'])) {
      // @id must be wildcard or an IRI
      if(!(types.isObject(type) || url.isAbsolute(type)) ||
        (types.isString(type) && type.indexOf('_:') === 0)) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; invalid @type in frame.',
          'jsonld.SyntaxError', {code: 'invalid frame', frame});
      }
    }
  }
}

/**
 * Returns a map of all of the subjects that match a parsed frame.
 *
 * @param state the current framing state.
 * @param subjects the set of subjects to filter.
 * @param frame the parsed frame.
 * @param flags the frame flags.
 *
 * @return all of the matched subjects.
 */
function _filterSubjects(state, subjects, frame, flags) {
  // filter subjects in @id order
  const rval = {};
  for(const id of subjects) {
    const subject = state.graphMap[state.graph][id];
    if(_filterSubject(state, subject, frame, flags)) {
      rval[id] = subject;
    }
  }
  return rval;
}

/**
 * Returns true if the given subject matches the given frame.
 *
 * Matches either based on explicit type inclusion where the node has any
 * type listed in the frame. If the frame has empty types defined matches
 * nodes not having a @type. If the frame has a type of {} defined matches
 * nodes having any type defined.
 *
 * Otherwise, does duck typing, where the node must have all of the
 * properties defined in the frame.
 *
 * @param state the current framing state.
 * @param subject the subject to check.
 * @param frame the frame to check.
 * @param flags the frame flags.
 *
 * @return true if the subject matches, false if not.
 */
function _filterSubject(state, subject, frame, flags) {
  // check ducktype
  let wildcard = true;
  let matchesSome = false;

  for(const key in frame) {
    let matchThis = false;
    const nodeValues = util.getValues(subject, key);
    const isEmpty = util.getValues(frame, key).length === 0;

    if(key === '@id') {
      // match on no @id or any matching @id, including wildcard
      if(types.isEmptyObject(frame['@id'][0] || {})) {
        matchThis = true;
      } else if(frame['@id'].length >= 0) {
        matchThis = frame['@id'].includes(nodeValues[0]);
      }
      if(!flags.requireAll) {
        return matchThis;
      }
    } else if(key === '@type') {
      // check @type (object value means 'any' type,
      // fall through to ducktyping)
      wildcard = false;
      if(isEmpty) {
        if(nodeValues.length > 0) {
          // don't match on no @type
          return false;
        }
        matchThis = true;
      } else if(frame['@type'].length === 1 &&
        types.isEmptyObject(frame['@type'][0])) {
        // match on wildcard @type if there is a type
        matchThis = nodeValues.length > 0;
      } else {
        // match on a specific @type
        for(const type of frame['@type']) {
          if(types.isObject(type) && '@default' in type) {
            // match on default object
            matchThis = true;
          } else {
            matchThis = matchThis || nodeValues.some(tt => tt === type);
          }
        }
      }
      if(!flags.requireAll) {
        return matchThis;
      }
    } else if(isKeyword(key)) {
      continue;
    } else {
      // Force a copy of this frame entry so it can be manipulated
      const thisFrame = util.getValues(frame, key)[0];
      let hasDefault = false;
      if(thisFrame) {
        _validateFrame([thisFrame]);
        hasDefault = '@default' in thisFrame;
      }

      // no longer a wildcard pattern if frame has any non-keyword properties
      wildcard = false;

      // skip, but allow match if node has no value for property, and frame has
      // a default value
      if(nodeValues.length === 0 && hasDefault) {
        continue;
      }

      // if frame value is empty, don't match if subject has any value
      if(nodeValues.length > 0 && isEmpty) {
        return false;
      }

      if(thisFrame === undefined) {
        // node does not match if values is not empty and the value of property
        // in frame is match none.
        if(nodeValues.length > 0) {
          return false;
        }
        matchThis = true;
      } else {
        if(graphTypes.isList(thisFrame)) {
          const listValue = thisFrame['@list'][0];
          if(graphTypes.isList(nodeValues[0])) {
            const nodeListValues = nodeValues[0]['@list'];

            if(graphTypes.isValue(listValue)) {
              // match on any matching value
              matchThis = nodeListValues.some(lv => _valueMatch(listValue, lv));
            } else if(graphTypes.isSubject(listValue) ||
              graphTypes.isSubjectReference(listValue)) {
              matchThis = nodeListValues.some(lv => _nodeMatch(
                state, listValue, lv, flags));
            }
          }
        } else if(graphTypes.isValue(thisFrame)) {
          matchThis = nodeValues.some(nv => _valueMatch(thisFrame, nv));
        } else if(graphTypes.isSubjectReference(thisFrame)) {
          matchThis =
            nodeValues.some(nv => _nodeMatch(state, thisFrame, nv, flags));
        } else if(types.isObject(thisFrame)) {
          matchThis = nodeValues.length > 0;
        } else {
          matchThis = false;
        }
      }
    }

    // all non-defaulted values must match if requireAll is set
    if(!matchThis && flags.requireAll) {
      return false;
    }

    matchesSome = matchesSome || matchThis;
  }

  // return true if wildcard or subject matches some properties
  return wildcard || matchesSome;
}

/**
 * Removes an existing embed.
 *
 * @param state the current framing state.
 * @param id the @id of the embed to remove.
 */
function _removeEmbed(state, id) {
  // get existing embed
  const embeds = state.uniqueEmbeds[state.graph];
  const embed = embeds[id];
  const parent = embed.parent;
  const property = embed.property;

  // create reference to replace embed
  const subject = {'@id': id};

  // remove existing embed
  if(types.isArray(parent)) {
    // replace subject with reference
    for(let i = 0; i < parent.length; ++i) {
      if(util.compareValues(parent[i], subject)) {
        parent[i] = subject;
        break;
      }
    }
  } else {
    // replace subject with reference
    const useArray = types.isArray(parent[property]);
    util.removeValue(parent, property, subject, {propertyIsArray: useArray});
    util.addValue(parent, property, subject, {propertyIsArray: useArray});
  }

  // recursively remove dependent dangling embeds
  const removeDependents = id => {
    // get embed keys as a separate array to enable deleting keys in map
    const ids = Object.keys(embeds);
    for(const next of ids) {
      if(next in embeds && types.isObject(embeds[next].parent) &&
        embeds[next].parent['@id'] === id) {
        delete embeds[next];
        removeDependents(next);
      }
    }
  };
  removeDependents(id);
}

/**
 * Removes the @preserve keywords from expanded result of framing.
 *
 * @param input the framed, framed output.
 * @param options the framing options used.
 *
 * @return the resulting output.
 */
function _cleanupPreserve(input, options) {
  // recurse through arrays
  if(types.isArray(input)) {
    return input.map(value => _cleanupPreserve(value, options));
  }

  if(types.isObject(input)) {
    // remove @preserve
    if('@preserve' in input) {
      return input['@preserve'][0];
    }

    // skip @values
    if(graphTypes.isValue(input)) {
      return input;
    }

    // recurse through @lists
    if(graphTypes.isList(input)) {
      input['@list'] = _cleanupPreserve(input['@list'], options);
      return input;
    }

    // handle in-memory linked nodes
    if('@id' in input) {
      const id = input['@id'];
      if(options.link.hasOwnProperty(id)) {
        const idx = options.link[id].indexOf(input);
        if(idx !== -1) {
          // already visited
          return options.link[id][idx];
        }
        // prevent circular visitation
        options.link[id].push(input);
      } else {
        // prevent circular visitation
        options.link[id] = [input];
      }
    }

    // recurse through properties
    for(const prop in input) {
      // potentially remove the id, if it is an unreference bnode
      if(prop === '@id' && options.bnodesToClear.includes(input[prop])) {
        delete input['@id'];
        continue;
      }

      input[prop] = _cleanupPreserve(input[prop], options);
    }
  }
  return input;
}

/**
 * Adds framing output to the given parent.
 *
 * @param parent the parent to add to.
 * @param property the parent property.
 * @param output the output to add.
 */
function _addFrameOutput(parent, property, output) {
  if(types.isObject(parent)) {
    util.addValue(parent, property, output, {propertyIsArray: true});
  } else {
    parent.push(output);
  }
}

/**
 * Node matches if it is a node, and matches the pattern as a frame.
 *
 * @param state the current framing state.
 * @param pattern used to match value
 * @param value to check
 * @param flags the frame flags.
 */
function _nodeMatch(state, pattern, value, flags) {
  if(!('@id' in value)) {
    return false;
  }
  const nodeObject = state.subjects[value['@id']];
  return nodeObject && _filterSubject(state, nodeObject, pattern, flags);
}

/**
 * Value matches if it is a value and matches the value pattern
 *
 * * `pattern` is empty
 * * @values are the same, or `pattern[@value]` is a wildcard, and
 * * @types are the same or `value[@type]` is not null
 *   and `pattern[@type]` is `{}`, or `value[@type]` is null
 *   and `pattern[@type]` is null or `[]`, and
 * * @languages are the same or `value[@language]` is not null
 *   and `pattern[@language]` is `{}`, or `value[@language]` is null
 *   and `pattern[@language]` is null or `[]`.
 *
 * @param pattern used to match value
 * @param value to check
 */
function _valueMatch(pattern, value) {
  const v1 = value['@value'];
  const t1 = value['@type'];
  const l1 = value['@language'];
  const v2 = pattern['@value'] ?
    (types.isArray(pattern['@value']) ?
      pattern['@value'] : [pattern['@value']]) :
    [];
  const t2 = pattern['@type'] ?
    (types.isArray(pattern['@type']) ?
      pattern['@type'] : [pattern['@type']]) :
    [];
  const l2 = pattern['@language'] ?
    (types.isArray(pattern['@language']) ?
      pattern['@language'] : [pattern['@language']]) :
    [];

  if(v2.length === 0 && t2.length === 0 && l2.length === 0) {
    return true;
  }
  if(!(v2.includes(v1) || types.isEmptyObject(v2[0]))) {
    return false;
  }
  if(!(!t1 && t2.length === 0 || t2.includes(t1) || t1 &&
    types.isEmptyObject(t2[0]))) {
    return false;
  }
  if(!(!l1 && l2.length === 0 || l2.includes(l1) || l1 &&
    types.isEmptyObject(l2[0]))) {
    return false;
  }
  return true;
}

},{"./JsonLdError":139,"./context":146,"./graphTypes":152,"./nodeMap":154,"./types":157,"./url":158,"./util":159}],151:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const JsonLdError = require('./JsonLdError');
const graphTypes = require('./graphTypes');
const types = require('./types');
const util = require('./util');

// constants
const {
  // RDF,
  RDF_LIST,
  RDF_FIRST,
  RDF_REST,
  RDF_NIL,
  RDF_TYPE,
  // RDF_PLAIN_LITERAL,
  // RDF_XML_LITERAL,
  RDF_JSON_LITERAL,
  // RDF_OBJECT,
  // RDF_LANGSTRING,

  // XSD,
  XSD_BOOLEAN,
  XSD_DOUBLE,
  XSD_INTEGER,
  XSD_STRING,
} = require('./constants');

const REGEX_BCP47 = /^[a-zA-Z]{1,8}(-[a-zA-Z0-9]{1,8})*$/;

const api = {};
module.exports = api;

/**
 * Converts an RDF dataset to JSON-LD.
 *
 * @param dataset the RDF dataset.
 * @param options the RDF serialization options.
 *
 * @return a Promise that resolves to the JSON-LD output.
 */
api.fromRDF = async (
  dataset,
  {
    useRdfType = false,
    useNativeTypes = false,
    rdfDirection = null
  }
) => {
  const defaultGraph = {};
  const graphMap = {'@default': defaultGraph};
  const referencedOnce = {};

  for(const quad of dataset) {
    // TODO: change 'name' to 'graph'
    const name = (quad.graph.termType === 'DefaultGraph') ?
      '@default' : quad.graph.value;
    if(!(name in graphMap)) {
      graphMap[name] = {};
    }
    if(name !== '@default' && !(name in defaultGraph)) {
      defaultGraph[name] = {'@id': name};
    }

    const nodeMap = graphMap[name];

    // get subject, predicate, object
    const s = quad.subject.value;
    const p = quad.predicate.value;
    const o = quad.object;

    if(!(s in nodeMap)) {
      nodeMap[s] = {'@id': s};
    }
    const node = nodeMap[s];

    const objectIsNode = o.termType.endsWith('Node');
    if(objectIsNode && !(o.value in nodeMap)) {
      nodeMap[o.value] = {'@id': o.value};
    }

    if(p === RDF_TYPE && !useRdfType && objectIsNode) {
      util.addValue(node, '@type', o.value, {propertyIsArray: true});
      continue;
    }

    const value = _RDFToObject(o, useNativeTypes, rdfDirection);
    util.addValue(node, p, value, {propertyIsArray: true});

    // object may be an RDF list/partial list node but we can't know easily
    // until all triples are read
    if(objectIsNode) {
      if(o.value === RDF_NIL) {
        // track rdf:nil uniquely per graph
        const object = nodeMap[o.value];
        if(!('usages' in object)) {
          object.usages = [];
        }
        object.usages.push({
          node,
          property: p,
          value
        });
      } else if(o.value in referencedOnce) {
        // object referenced more than once
        referencedOnce[o.value] = false;
      } else {
        // keep track of single reference
        referencedOnce[o.value] = {
          node,
          property: p,
          value
        };
      }
    }
  }

  /*
  for(let name in dataset) {
    const graph = dataset[name];
    if(!(name in graphMap)) {
      graphMap[name] = {};
    }
    if(name !== '@default' && !(name in defaultGraph)) {
      defaultGraph[name] = {'@id': name};
    }
    const nodeMap = graphMap[name];
    for(let ti = 0; ti < graph.length; ++ti) {
      const triple = graph[ti];

      // get subject, predicate, object
      const s = triple.subject.value;
      const p = triple.predicate.value;
      const o = triple.object;

      if(!(s in nodeMap)) {
        nodeMap[s] = {'@id': s};
      }
      const node = nodeMap[s];

      const objectIsId = (o.type === 'IRI' || o.type === 'blank node');
      if(objectIsId && !(o.value in nodeMap)) {
        nodeMap[o.value] = {'@id': o.value};
      }

      if(p === RDF_TYPE && !useRdfType && objectIsId) {
        util.addValue(node, '@type', o.value, {propertyIsArray: true});
        continue;
      }

      const value = _RDFToObject(o, useNativeTypes);
      util.addValue(node, p, value, {propertyIsArray: true});

      // object may be an RDF list/partial list node but we can't know easily
      // until all triples are read
      if(objectIsId) {
        if(o.value === RDF_NIL) {
          // track rdf:nil uniquely per graph
          const object = nodeMap[o.value];
          if(!('usages' in object)) {
            object.usages = [];
          }
          object.usages.push({
            node: node,
            property: p,
            value: value
          });
        } else if(o.value in referencedOnce) {
          // object referenced more than once
          referencedOnce[o.value] = false;
        } else {
          // keep track of single reference
          referencedOnce[o.value] = {
            node: node,
            property: p,
            value: value
          };
        }
      }
    }
  }*/

  // convert linked lists to @list arrays
  for(const name in graphMap) {
    const graphObject = graphMap[name];

    // no @lists to be converted, continue
    if(!(RDF_NIL in graphObject)) {
      continue;
    }

    // iterate backwards through each RDF list
    const nil = graphObject[RDF_NIL];
    if(!nil.usages) {
      continue;
    }
    for(let usage of nil.usages) {
      let node = usage.node;
      let property = usage.property;
      let head = usage.value;
      const list = [];
      const listNodes = [];

      // ensure node is a well-formed list node; it must:
      // 1. Be referenced only once.
      // 2. Have an array for rdf:first that has 1 item.
      // 3. Have an array for rdf:rest that has 1 item.
      // 4. Have no keys other than: @id, rdf:first, rdf:rest, and,
      //   optionally, @type where the value is rdf:List.
      let nodeKeyCount = Object.keys(node).length;
      while(property === RDF_REST &&
        types.isObject(referencedOnce[node['@id']]) &&
        types.isArray(node[RDF_FIRST]) && node[RDF_FIRST].length === 1 &&
        types.isArray(node[RDF_REST]) && node[RDF_REST].length === 1 &&
        (nodeKeyCount === 3 ||
          (nodeKeyCount === 4 && types.isArray(node['@type']) &&
          node['@type'].length === 1 && node['@type'][0] === RDF_LIST))) {
        list.push(node[RDF_FIRST][0]);
        listNodes.push(node['@id']);

        // get next node, moving backwards through list
        usage = referencedOnce[node['@id']];
        node = usage.node;
        property = usage.property;
        head = usage.value;
        nodeKeyCount = Object.keys(node).length;

        // if node is not a blank node, then list head found
        if(!graphTypes.isBlankNode(node)) {
          break;
        }
      }

      // transform list into @list object
      delete head['@id'];
      head['@list'] = list.reverse();
      for(const listNode of listNodes) {
        delete graphObject[listNode];
      }
    }

    delete nil.usages;
  }

  const result = [];
  const subjects = Object.keys(defaultGraph).sort();
  for(const subject of subjects) {
    const node = defaultGraph[subject];
    if(subject in graphMap) {
      const graph = node['@graph'] = [];
      const graphObject = graphMap[subject];
      const graphSubjects = Object.keys(graphObject).sort();
      for(const graphSubject of graphSubjects) {
        const node = graphObject[graphSubject];
        // only add full subjects to top-level
        if(!graphTypes.isSubjectReference(node)) {
          graph.push(node);
        }
      }
    }
    // only add full subjects to top-level
    if(!graphTypes.isSubjectReference(node)) {
      result.push(node);
    }
  }

  return result;
};

/**
 * Converts an RDF triple object to a JSON-LD object.
 *
 * @param o the RDF triple object to convert.
 * @param useNativeTypes true to output native types, false not to.
 *
 * @return the JSON-LD object.
 */
function _RDFToObject(o, useNativeTypes, rdfDirection) {
  // convert NamedNode/BlankNode object to JSON-LD
  if(o.termType.endsWith('Node')) {
    return {'@id': o.value};
  }

  // convert literal to JSON-LD
  const rval = {'@value': o.value};

  // add language
  if(o.language) {
    rval['@language'] = o.language;
  } else {
    let type = o.datatype.value;
    if(!type) {
      type = XSD_STRING;
    }
    if(type === RDF_JSON_LITERAL) {
      type = '@json';
      try {
        rval['@value'] = JSON.parse(rval['@value']);
      } catch(e) {
        throw new JsonLdError(
          'JSON literal could not be parsed.',
          'jsonld.InvalidJsonLiteral',
          {code: 'invalid JSON literal', value: rval['@value'], cause: e});
      }
    }
    // use native types for certain xsd types
    if(useNativeTypes) {
      if(type === XSD_BOOLEAN) {
        if(rval['@value'] === 'true') {
          rval['@value'] = true;
        } else if(rval['@value'] === 'false') {
          rval['@value'] = false;
        }
      } else if(types.isNumeric(rval['@value'])) {
        if(type === XSD_INTEGER) {
          const i = parseInt(rval['@value'], 10);
          if(i.toFixed(0) === rval['@value']) {
            rval['@value'] = i;
          }
        } else if(type === XSD_DOUBLE) {
          rval['@value'] = parseFloat(rval['@value']);
        }
      }
      // do not add native type
      if(![XSD_BOOLEAN, XSD_INTEGER, XSD_DOUBLE, XSD_STRING].includes(type)) {
        rval['@type'] = type;
      }
    } else if(rdfDirection === 'i18n-datatype' &&
      type.startsWith('https://www.w3.org/ns/i18n#')) {
      const [, language, direction] = type.split(/[#_]/);
      if(language.length > 0) {
        rval['@language'] = language;
        if(!language.match(REGEX_BCP47)) {
          console.warn(`@language must be valid BCP47: ${language}`);
        }
      }
      rval['@direction'] = direction;
    } else if(type !== XSD_STRING) {
      rval['@type'] = type;
    }
  }

  return rval;
}

},{"./JsonLdError":139,"./constants":145,"./graphTypes":152,"./types":157,"./util":159}],152:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const types = require('./types');

const api = {};
module.exports = api;

/**
 * Returns true if the given value is a subject with properties.
 *
 * @param v the value to check.
 *
 * @return true if the value is a subject with properties, false if not.
 */
api.isSubject = v => {
  // Note: A value is a subject if all of these hold true:
  // 1. It is an Object.
  // 2. It is not a @value, @set, or @list.
  // 3. It has more than 1 key OR any existing key is not @id.
  if(types.isObject(v) &&
    !(('@value' in v) || ('@set' in v) || ('@list' in v))) {
    const keyCount = Object.keys(v).length;
    return (keyCount > 1 || !('@id' in v));
  }
  return false;
};

/**
 * Returns true if the given value is a subject reference.
 *
 * @param v the value to check.
 *
 * @return true if the value is a subject reference, false if not.
 */
api.isSubjectReference = v =>
  // Note: A value is a subject reference if all of these hold true:
  // 1. It is an Object.
  // 2. It has a single key: @id.
  (types.isObject(v) && Object.keys(v).length === 1 && ('@id' in v));

/**
 * Returns true if the given value is a @value.
 *
 * @param v the value to check.
 *
 * @return true if the value is a @value, false if not.
 */
api.isValue = v =>
  // Note: A value is a @value if all of these hold true:
  // 1. It is an Object.
  // 2. It has the @value property.
  types.isObject(v) && ('@value' in v);

/**
 * Returns true if the given value is a @list.
 *
 * @param v the value to check.
 *
 * @return true if the value is a @list, false if not.
 */
api.isList = v =>
  // Note: A value is a @list if all of these hold true:
  // 1. It is an Object.
  // 2. It has the @list property.
  types.isObject(v) && ('@list' in v);

/**
 * Returns true if the given value is a @graph.
 *
 * @return true if the value is a @graph, false if not.
 */
api.isGraph = v => {
  // Note: A value is a graph if all of these hold true:
  // 1. It is an object.
  // 2. It has an `@graph` key.
  // 3. It may have '@id' or '@index'
  return types.isObject(v) &&
    '@graph' in v &&
    Object.keys(v)
      .filter(key => key !== '@id' && key !== '@index').length === 1;
};

/**
 * Returns true if the given value is a simple @graph.
 *
 * @return true if the value is a simple @graph, false if not.
 */
api.isSimpleGraph = v => {
  // Note: A value is a simple graph if all of these hold true:
  // 1. It is an object.
  // 2. It has an `@graph` key.
  // 3. It has only 1 key or 2 keys where one of them is `@index`.
  return api.isGraph(v) && !('@id' in v);
};

/**
 * Returns true if the given value is a blank node.
 *
 * @param v the value to check.
 *
 * @return true if the value is a blank node, false if not.
 */
api.isBlankNode = v => {
  // Note: A value is a blank node if all of these hold true:
  // 1. It is an Object.
  // 2. If it has an @id key its value begins with '_:'.
  // 3. It has no keys OR is not a @value, @set, or @list.
  if(types.isObject(v)) {
    if('@id' in v) {
      return (v['@id'].indexOf('_:') === 0);
    }
    return (Object.keys(v).length === 0 ||
      !(('@value' in v) || ('@set' in v) || ('@list' in v)));
  }
  return false;
};

},{"./types":157}],153:[function(require,module,exports){
/**
 * A JavaScript implementation of the JSON-LD API.
 *
 * @author Dave Longley
 *
 * @license BSD 3-Clause License
 * Copyright (c) 2011-2019 Digital Bazaar, Inc.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 * Redistributions of source code must retain the above copyright notice,
 * this list of conditions and the following disclaimer.
 *
 * Redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution.
 *
 * Neither the name of the Digital Bazaar, Inc. nor the names of its
 * contributors may be used to endorse or promote products derived from
 * this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
const canonize = require('rdf-canonize');
const platform = require('./platform');
const util = require('./util');
const ContextResolver = require('./ContextResolver');
const IdentifierIssuer = util.IdentifierIssuer;
const JsonLdError = require('./JsonLdError');
const LRU = require('lru-cache');
const NQuads = require('./NQuads');

const {expand: _expand} = require('./expand');
const {flatten: _flatten} = require('./flatten');
const {fromRDF: _fromRDF} = require('./fromRdf');
const {toRDF: _toRDF} = require('./toRdf');

const {
  frameMergedOrDefault: _frameMergedOrDefault,
  cleanupNull: _cleanupNull
} = require('./frame');

const {
  isArray: _isArray,
  isObject: _isObject,
  isString: _isString
} = require('./types');

const {
  isSubjectReference: _isSubjectReference,
} = require('./graphTypes');

const {
  expandIri: _expandIri,
  getInitialContext: _getInitialContext,
  process: _processContext,
  processingMode: _processingMode
} = require('./context');

const {
  compact: _compact,
  compactIri: _compactIri
} = require('./compact');

const {
  createNodeMap: _createNodeMap,
  createMergedNodeMap: _createMergedNodeMap,
  mergeNodeMaps: _mergeNodeMaps
} = require('./nodeMap');

/* eslint-disable indent */
// attaches jsonld API to the given object
const wrapper = function(jsonld) {

/** Registered RDF dataset parsers hashed by content-type. */
const _rdfParsers = {};

// resolved context cache
// TODO: consider basing max on context size rather than number
const RESOLVED_CONTEXT_CACHE_MAX_SIZE = 100;
const _resolvedContextCache = new LRU({max: RESOLVED_CONTEXT_CACHE_MAX_SIZE});

/* Core API */

/**
 * Performs JSON-LD compaction.
 *
 * @param input the JSON-LD input to compact.
 * @param ctx the context to compact with.
 * @param [options] options to use:
 *          [base] the base IRI to use.
 *          [compactArrays] true to compact arrays to single values when
 *            appropriate, false not to (default: true).
 *          [compactToRelative] true to compact IRIs to be relative to document
 *            base, false to keep absolute (default: true)
 *          [graph] true to always output a top-level graph (default: false).
 *          [expandContext] a context to expand with.
 *          [skipExpansion] true to assume the input is expanded and skip
 *            expansion, false not to, defaults to false.
 *          [documentLoader(url, options)] the document loader.
 *          [expansionMap(info)] a function that can be used to custom map
 *            unmappable values (or to throw an error when they are detected);
 *            if this function returns `undefined` then the default behavior
 *            will be used.
 *          [framing] true if compaction is occuring during a framing operation.
 *          [compactionMap(info)] a function that can be used to custom map
 *            unmappable values (or to throw an error when they are detected);
 *            if this function returns `undefined` then the default behavior
 *            will be used.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the compacted output.
 */
jsonld.compact = async function(input, ctx, options) {
  if(arguments.length < 2) {
    throw new TypeError('Could not compact, too few arguments.');
  }

  if(ctx === null) {
    throw new JsonLdError(
      'The compaction context must not be null.',
      'jsonld.CompactError', {code: 'invalid local context'});
  }

  // nothing to compact
  if(input === null) {
    return null;
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    compactArrays: true,
    compactToRelative: true,
    graph: false,
    skipExpansion: false,
    link: false,
    issuer: new IdentifierIssuer('_:b'),
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });
  if(options.link) {
    // force skip expansion when linking, "link" is not part of the public
    // API, it should only be called from framing
    options.skipExpansion = true;
  }
  if(!options.compactToRelative) {
    delete options.base;
  }

  // expand input
  let expanded;
  if(options.skipExpansion) {
    expanded = input;
  } else {
    expanded = await jsonld.expand(input, options);
  }

  // process context
  const activeCtx = await jsonld.processContext(
    _getInitialContext(options), ctx, options);

  // do compaction
  let compacted = await _compact({
    activeCtx,
    element: expanded,
    options,
    compactionMap: options.compactionMap
  });

  // perform clean up
  if(options.compactArrays && !options.graph && _isArray(compacted)) {
    if(compacted.length === 1) {
      // simplify to a single item
      compacted = compacted[0];
    } else if(compacted.length === 0) {
      // simplify to an empty object
      compacted = {};
    }
  } else if(options.graph && _isObject(compacted)) {
    // always use array if graph option is on
    compacted = [compacted];
  }

  // follow @context key
  if(_isObject(ctx) && '@context' in ctx) {
    ctx = ctx['@context'];
  }

  // build output context
  ctx = util.clone(ctx);
  if(!_isArray(ctx)) {
    ctx = [ctx];
  }
  // remove empty contexts
  const tmp = ctx;
  ctx = [];
  for(let i = 0; i < tmp.length; ++i) {
    if(!_isObject(tmp[i]) || Object.keys(tmp[i]).length > 0) {
      ctx.push(tmp[i]);
    }
  }

  // remove array if only one context
  const hasContext = (ctx.length > 0);
  if(ctx.length === 1) {
    ctx = ctx[0];
  }

  // add context and/or @graph
  if(_isArray(compacted)) {
    // use '@graph' keyword
    const graphAlias = _compactIri({
      activeCtx, iri: '@graph', relativeTo: {vocab: true}
    });
    const graph = compacted;
    compacted = {};
    if(hasContext) {
      compacted['@context'] = ctx;
    }
    compacted[graphAlias] = graph;
  } else if(_isObject(compacted) && hasContext) {
    // reorder keys so @context is first
    const graph = compacted;
    compacted = {'@context': ctx};
    for(const key in graph) {
      compacted[key] = graph[key];
    }
  }

  return compacted;
};

/**
 * Performs JSON-LD expansion.
 *
 * @param input the JSON-LD input to expand.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [keepFreeFloatingNodes] true to keep free-floating nodes,
 *            false not to, defaults to false.
 *          [documentLoader(url, options)] the document loader.
 *          [expansionMap(info)] a function that can be used to custom map
 *            unmappable values (or to throw an error when they are detected);
 *            if this function returns `undefined` then the default behavior
 *            will be used.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the expanded output.
 */
jsonld.expand = async function(input, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not expand, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    keepFreeFloatingNodes: false,
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });
  if(options.expansionMap === false) {
    options.expansionMap = undefined;
  }

  // build set of objects that may have @contexts to resolve
  const toResolve = {};

  // build set of contexts to process prior to expansion
  const contextsToProcess = [];

  // if an `expandContext` has been given ensure it gets resolved
  if('expandContext' in options) {
    const expandContext = util.clone(options.expandContext);
    if(_isObject(expandContext) && '@context' in expandContext) {
      toResolve.expandContext = expandContext;
    } else {
      toResolve.expandContext = {'@context': expandContext};
    }
    contextsToProcess.push(toResolve.expandContext);
  }

  // if input is a string, attempt to dereference remote document
  let defaultBase;
  if(!_isString(input)) {
    // input is not a URL, do not need to retrieve it first
    toResolve.input = util.clone(input);
  } else {
    // load remote doc
    const remoteDoc = await jsonld.get(input, options);
    defaultBase = remoteDoc.documentUrl;
    toResolve.input = remoteDoc.document;
    if(remoteDoc.contextUrl) {
      // context included in HTTP link header and must be resolved
      toResolve.remoteContext = {'@context': remoteDoc.contextUrl};
      contextsToProcess.push(toResolve.remoteContext);
    }
  }

  // set default base
  if(!('base' in options)) {
    options.base = defaultBase || '';
  }

  // process any additional contexts
  let activeCtx = _getInitialContext(options);
  for(const localCtx of contextsToProcess) {
    activeCtx = await _processContext({activeCtx, localCtx, options});
  }

  // expand resolved input
  let expanded = await _expand({
    activeCtx,
    element: toResolve.input,
    options,
    expansionMap: options.expansionMap
  });

  // optimize away @graph with no other properties
  if(_isObject(expanded) && ('@graph' in expanded) &&
    Object.keys(expanded).length === 1) {
    expanded = expanded['@graph'];
  } else if(expanded === null) {
    expanded = [];
  }

  // normalize to an array
  if(!_isArray(expanded)) {
    expanded = [expanded];
  }

  return expanded;
};

/**
 * Performs JSON-LD flattening.
 *
 * @param input the JSON-LD to flatten.
 * @param ctx the context to use to compact the flattened output, or null.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the flattened output.
 */
jsonld.flatten = async function(input, ctx, options) {
  if(arguments.length < 1) {
    return new TypeError('Could not flatten, too few arguments.');
  }

  if(typeof ctx === 'function') {
    ctx = null;
  } else {
    ctx = ctx || null;
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // expand input
  const expanded = await jsonld.expand(input, options);

  // do flattening
  const flattened = _flatten(expanded);

  if(ctx === null) {
    // no compaction required
    return flattened;
  }

  // compact result (force @graph option to true, skip expansion)
  options.graph = true;
  options.skipExpansion = true;
  const compacted = await jsonld.compact(flattened, ctx, options);

  return compacted;
};

/**
 * Performs JSON-LD framing.
 *
 * @param input the JSON-LD input to frame.
 * @param frame the JSON-LD frame to use.
 * @param [options] the framing options.
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [embed] default @embed flag: '@last', '@always', '@never', '@link'
 *            (default: '@last').
 *          [explicit] default @explicit flag (default: false).
 *          [requireAll] default @requireAll flag (default: true).
 *          [omitDefault] default @omitDefault flag (default: false).
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the framed output.
 */
jsonld.frame = async function(input, frame, options) {
  if(arguments.length < 2) {
    throw new TypeError('Could not frame, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    embed: '@once',
    explicit: false,
    requireAll: false,
    omitDefault: false,
    bnodesToClear: [],
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // if frame is a string, attempt to dereference remote document
  if(_isString(frame)) {
    // load remote doc
    const remoteDoc = await jsonld.get(frame, options);
    frame = remoteDoc.document;

    if(remoteDoc.contextUrl) {
      // inject link header @context into frame
      let ctx = frame['@context'];
      if(!ctx) {
        ctx = remoteDoc.contextUrl;
      } else if(_isArray(ctx)) {
        ctx.push(remoteDoc.contextUrl);
      } else {
        ctx = [ctx, remoteDoc.contextUrl];
      }
      frame['@context'] = ctx;
    }
  }

  const frameContext = frame ? frame['@context'] || {} : {};

  // process context
  const activeCtx = await jsonld.processContext(
    _getInitialContext(options), frameContext, options);

  // mode specific defaults
  if(!options.hasOwnProperty('omitGraph')) {
    options.omitGraph = _processingMode(activeCtx, 1.1);
  }
  if(!options.hasOwnProperty('pruneBlankNodeIdentifiers')) {
    options.pruneBlankNodeIdentifiers = _processingMode(activeCtx, 1.1);
  }

  // expand input
  const expanded = await jsonld.expand(input, options);

  // expand frame
  const opts = {...options};
  opts.isFrame = true;
  opts.keepFreeFloatingNodes = true;
  const expandedFrame = await jsonld.expand(frame, opts);

  // if the unexpanded frame includes a key expanding to @graph, frame the
  // default graph, otherwise, the merged graph
  const frameKeys = Object.keys(frame)
    .map(key => _expandIri(activeCtx, key, {vocab: true}));
  opts.merged = !frameKeys.includes('@graph');
  opts.is11 = _processingMode(activeCtx, 1.1);

  // do framing
  const framed = _frameMergedOrDefault(expanded, expandedFrame, opts);

  opts.graph = !options.omitGraph;
  opts.skipExpansion = true;
  opts.link = {};
  opts.framing = true;
  let compacted = await jsonld.compact(framed, frameContext, opts);

  // replace @null with null, compacting arrays
  opts.link = {};
  compacted = _cleanupNull(compacted, opts);

  return compacted;
};

/**
 * **Experimental**
 *
 * Links a JSON-LD document's nodes in memory.
 *
 * @param input the JSON-LD document to link.
 * @param [ctx] the JSON-LD context to apply.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the linked output.
 */
jsonld.link = async function(input, ctx, options) {
  // API matches running frame with a wildcard frame and embed: '@link'
  // get arguments
  const frame = {};
  if(ctx) {
    frame['@context'] = ctx;
  }
  frame['@embed'] = '@link';
  return jsonld.frame(input, frame, options);
};

/**
 * Performs RDF dataset normalization on the given input. The input is JSON-LD
 * unless the 'inputFormat' option is used. The output is an RDF dataset
 * unless the 'format' option is used.
 *
 * @param input the input to normalize as JSON-LD or as a format specified by
 *          the 'inputFormat' option.
 * @param [options] the options to use:
 *          [algorithm] the normalization algorithm to use, `URDNA2015` or
 *            `URGNA2012` (default: `URDNA2015`).
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [skipExpansion] true to assume the input is expanded and skip
 *            expansion, false not to, defaults to false.
 *          [inputFormat] the format if input is not JSON-LD:
 *            'application/n-quads' for N-Quads.
 *          [format] the format if output is a string:
 *            'application/n-quads' for N-Quads.
 *          [documentLoader(url, options)] the document loader.
 *          [useNative] true to use a native canonize algorithm
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the normalized output.
 */
jsonld.normalize = jsonld.canonize = async function(input, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not canonize, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    algorithm: 'URDNA2015',
    skipExpansion: false,
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });
  if('inputFormat' in options) {
    if(options.inputFormat !== 'application/n-quads' &&
      options.inputFormat !== 'application/nquads') {
      throw new JsonLdError(
        'Unknown canonicalization input format.',
        'jsonld.CanonizeError');
    }
    // TODO: `await` for async parsers
    const parsedInput = NQuads.parse(input);

    // do canonicalization
    return canonize.canonize(parsedInput, options);
  }

  // convert to RDF dataset then do normalization
  const opts = {...options};
  delete opts.format;
  opts.produceGeneralizedRdf = false;
  const dataset = await jsonld.toRDF(input, opts);

  // do canonicalization
  return canonize.canonize(dataset, options);
};

/**
 * Converts an RDF dataset to JSON-LD.
 *
 * @param dataset a serialized string of RDF in a format specified by the
 *          format option or an RDF dataset to convert.
 * @param [options] the options to use:
 *          [format] the format if dataset param must first be parsed:
 *            'application/n-quads' for N-Quads (default).
 *          [rdfParser] a custom RDF-parser to use to parse the dataset.
 *          [useRdfType] true to use rdf:type, false to use @type
 *            (default: false).
 *          [useNativeTypes] true to convert XSD types into native types
 *            (boolean, integer, double), false not to (default: false).
 *
 * @return a Promise that resolves to the JSON-LD document.
 */
jsonld.fromRDF = async function(dataset, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not convert from RDF, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    format: _isString(dataset) ? 'application/n-quads' : undefined
  });

  const {format} = options;
  let {rdfParser} = options;

  // handle special format
  if(format) {
    // check supported formats
    rdfParser = rdfParser || _rdfParsers[format];
    if(!rdfParser) {
      throw new JsonLdError(
        'Unknown input format.',
        'jsonld.UnknownFormat', {format});
    }
  } else {
    // no-op parser, assume dataset already parsed
    rdfParser = () => dataset;
  }

  // rdfParser must be synchronous or return a promise, no callback support
  const parsedDataset = await rdfParser(dataset);
  return _fromRDF(parsedDataset, options);
};

/**
 * Outputs the RDF dataset found in the given JSON-LD object.
 *
 * @param input the JSON-LD input.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [skipExpansion] true to assume the input is expanded and skip
 *            expansion, false not to, defaults to false.
 *          [format] the format to use to output a string:
 *            'application/n-quads' for N-Quads.
 *          [produceGeneralizedRdf] true to output generalized RDF, false
 *            to produce only standard RDF (default: false).
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the RDF dataset.
 */
jsonld.toRDF = async function(input, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not convert to RDF, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    skipExpansion: false,
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // TODO: support toRDF custom map?
  let expanded;
  if(options.skipExpansion) {
    expanded = input;
  } else {
    // expand input
    expanded = await jsonld.expand(input, options);
  }

  // output RDF dataset
  const dataset = _toRDF(expanded, options);
  if(options.format) {
    if(options.format === 'application/n-quads' ||
      options.format === 'application/nquads') {
      return NQuads.serialize(dataset);
    }
    throw new JsonLdError(
      'Unknown output format.',
      'jsonld.UnknownFormat', {format: options.format});
  }

  return dataset;
};

/**
 * **Experimental**
 *
 * Recursively flattens the nodes in the given JSON-LD input into a merged
 * map of node ID => node. All graphs will be merged into the default graph.
 *
 * @param input the JSON-LD input.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the merged node map.
 */
jsonld.createNodeMap = async function(input, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not create node map, too few arguments.');
  }

  // set default options
  options = _setDefaults(options, {
    base: _isString(input) ? input : '',
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // expand input
  const expanded = await jsonld.expand(input, options);

  return _createMergedNodeMap(expanded, options);
};

/**
 * **Experimental**
 *
 * Merges two or more JSON-LD documents into a single flattened document.
 *
 * @param docs the JSON-LD documents to merge together.
 * @param ctx the context to use to compact the merged result, or null.
 * @param [options] the options to use:
 *          [base] the base IRI to use.
 *          [expandContext] a context to expand with.
 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
 *          [mergeNodes] true to merge properties for nodes with the same ID,
 *            false to ignore new properties for nodes with the same ID once
 *            the ID has been defined; note that this may not prevent merging
 *            new properties where a node is in the `object` position
 *            (default: true).
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the merged output.
 */
jsonld.merge = async function(docs, ctx, options) {
  if(arguments.length < 1) {
    throw new TypeError('Could not merge, too few arguments.');
  }
  if(!_isArray(docs)) {
    throw new TypeError('Could not merge, "docs" must be an array.');
  }

  if(typeof ctx === 'function') {
    ctx = null;
  } else {
    ctx = ctx || null;
  }

  // set default options
  options = _setDefaults(options, {
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // expand all documents
  const expanded = await Promise.all(docs.map(doc => {
    const opts = {...options};
    return jsonld.expand(doc, opts);
  }));

  let mergeNodes = true;
  if('mergeNodes' in options) {
    mergeNodes = options.mergeNodes;
  }

  const issuer = options.issuer || new IdentifierIssuer('_:b');
  const graphs = {'@default': {}};

  for(let i = 0; i < expanded.length; ++i) {
    // uniquely relabel blank nodes
    const doc = util.relabelBlankNodes(expanded[i], {
      issuer: new IdentifierIssuer('_:b' + i + '-')
    });

    // add nodes to the shared node map graphs if merging nodes, to a
    // separate graph set if not
    const _graphs = (mergeNodes || i === 0) ? graphs : {'@default': {}};
    _createNodeMap(doc, _graphs, '@default', issuer);

    if(_graphs !== graphs) {
      // merge document graphs but don't merge existing nodes
      for(const graphName in _graphs) {
        const _nodeMap = _graphs[graphName];
        if(!(graphName in graphs)) {
          graphs[graphName] = _nodeMap;
          continue;
        }
        const nodeMap = graphs[graphName];
        for(const key in _nodeMap) {
          if(!(key in nodeMap)) {
            nodeMap[key] = _nodeMap[key];
          }
        }
      }
    }
  }

  // add all non-default graphs to default graph
  const defaultGraph = _mergeNodeMaps(graphs);

  // produce flattened output
  const flattened = [];
  const keys = Object.keys(defaultGraph).sort();
  for(let ki = 0; ki < keys.length; ++ki) {
    const node = defaultGraph[keys[ki]];
    // only add full subjects to top-level
    if(!_isSubjectReference(node)) {
      flattened.push(node);
    }
  }

  if(ctx === null) {
    return flattened;
  }

  // compact result (force @graph option to true, skip expansion)
  options.graph = true;
  options.skipExpansion = true;
  const compacted = await jsonld.compact(flattened, ctx, options);

  return compacted;
};

/**
 * The default document loader for external documents.
 *
 * @param url the URL to load.
 *
 * @return a promise that resolves to the remote document.
 */
Object.defineProperty(jsonld, 'documentLoader', {
  get: () => jsonld._documentLoader,
  set: v => jsonld._documentLoader = v
});
// default document loader not implemented
jsonld.documentLoader = async url => {
  throw new JsonLdError(
    'Could not retrieve a JSON-LD document from the URL. URL ' +
    'dereferencing not implemented.', 'jsonld.LoadDocumentError',
    {code: 'loading document failed', url});
};

/**
 * Gets a remote JSON-LD document using the default document loader or
 * one given in the passed options.
 *
 * @param url the URL to fetch.
 * @param [options] the options to use:
 *          [documentLoader] the document loader to use.
 *
 * @return a Promise that resolves to the retrieved remote document.
 */
jsonld.get = async function(url, options) {
  let load;
  if(typeof options.documentLoader === 'function') {
    load = options.documentLoader;
  } else {
    load = jsonld.documentLoader;
  }

  const remoteDoc = await load(url);

  try {
    if(!remoteDoc.document) {
      throw new JsonLdError(
        'No remote document found at the given URL.',
        'jsonld.NullRemoteDocument');
    }
    if(_isString(remoteDoc.document)) {
      remoteDoc.document = JSON.parse(remoteDoc.document);
    }
  } catch(e) {
    throw new JsonLdError(
      'Could not retrieve a JSON-LD document from the URL.',
      'jsonld.LoadDocumentError', {
        code: 'loading document failed',
        cause: e,
        remoteDoc
      });
  }

  return remoteDoc;
};

/**
 * Processes a local context, resolving any URLs as necessary, and returns a
 * new active context.
 *
 * @param activeCtx the current active context.
 * @param localCtx the local context to process.
 * @param [options] the options to use:
 *          [documentLoader(url, options)] the document loader.
 *          [contextResolver] internal use only.
 *
 * @return a Promise that resolves to the new active context.
 */
jsonld.processContext = async function(
  activeCtx, localCtx, options) {
  // set default options
  options = _setDefaults(options, {
    base: '',
    contextResolver: new ContextResolver(
      {sharedCache: _resolvedContextCache})
  });

  // return initial context early for null context
  if(localCtx === null) {
    return _getInitialContext(options);
  }

  // get URLs in localCtx
  localCtx = util.clone(localCtx);
  if(!(_isObject(localCtx) && '@context' in localCtx)) {
    localCtx = {'@context': localCtx};
  }

  return _processContext({activeCtx, localCtx, options});
};

// backwards compatibility
jsonld.getContextValue = require('./context').getContextValue;

/**
 * Document loaders.
 */
jsonld.documentLoaders = {};

/**
 * Assigns the default document loader for external document URLs to a built-in
 * default. Supported types currently include: 'xhr' and 'node'.
 *
 * @param type the type to set.
 * @param [params] the parameters required to use the document loader.
 */
jsonld.useDocumentLoader = function(type) {
  if(!(type in jsonld.documentLoaders)) {
    throw new JsonLdError(
      'Unknown document loader type: "' + type + '"',
      'jsonld.UnknownDocumentLoader',
      {type});
  }

  // set document loader
  jsonld.documentLoader = jsonld.documentLoaders[type].apply(
    jsonld, Array.prototype.slice.call(arguments, 1));
};

/**
 * Registers an RDF dataset parser by content-type, for use with
 * jsonld.fromRDF. An RDF dataset parser will always be given one parameter,
 * a string of input. An RDF dataset parser can be synchronous or
 * asynchronous (by returning a promise).
 *
 * @param contentType the content-type for the parser.
 * @param parser(input) the parser function (takes a string as a parameter
 *          and either returns an RDF dataset or a Promise that resolves to one.
 */
jsonld.registerRDFParser = function(contentType, parser) {
  _rdfParsers[contentType] = parser;
};

/**
 * Unregisters an RDF dataset parser by content-type.
 *
 * @param contentType the content-type for the parser.
 */
jsonld.unregisterRDFParser = function(contentType) {
  delete _rdfParsers[contentType];
};

// register the N-Quads RDF parser
jsonld.registerRDFParser('application/n-quads', NQuads.parse);
jsonld.registerRDFParser('application/nquads', NQuads.parse);

/* URL API */
jsonld.url = require('./url');

/* Utility API */
jsonld.util = util;
// backwards compatibility
Object.assign(jsonld, util);

// reexpose API as jsonld.promises for backwards compatability
jsonld.promises = jsonld;

// backwards compatibility
jsonld.RequestQueue = require('./RequestQueue');

/* WebIDL API */
jsonld.JsonLdProcessor = require('./JsonLdProcessor')(jsonld);

platform.setupGlobals(jsonld);
platform.setupDocumentLoaders(jsonld);

function _setDefaults(options, {
  documentLoader = jsonld.documentLoader,
  ...defaults
}) {
  return Object.assign({}, {documentLoader}, defaults, options);
}

// end of jsonld API `wrapper` factory
return jsonld;
};

// external APIs:

// used to generate a new jsonld API instance
const factory = function() {
  return wrapper(function() {
    return factory();
  });
};

// wrap the main jsonld API instance
wrapper(factory);
// export API
module.exports = factory;

},{"./ContextResolver":138,"./JsonLdError":139,"./JsonLdProcessor":140,"./NQuads":141,"./RequestQueue":142,"./compact":144,"./context":146,"./expand":148,"./flatten":149,"./frame":150,"./fromRdf":151,"./graphTypes":152,"./nodeMap":154,"./platform":155,"./toRdf":156,"./types":157,"./url":158,"./util":159,"lru-cache":160,"rdf-canonize":189}],154:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {isKeyword} = require('./context');
const graphTypes = require('./graphTypes');
const types = require('./types');
const util = require('./util');
const JsonLdError = require('./JsonLdError');

const api = {};
module.exports = api;

/**
 * Creates a merged JSON-LD node map (node ID => node).
 *
 * @param input the expanded JSON-LD to create a node map of.
 * @param [options] the options to use:
 *          [issuer] a jsonld.IdentifierIssuer to use to label blank nodes.
 *
 * @return the node map.
 */
api.createMergedNodeMap = (input, options) => {
  options = options || {};

  // produce a map of all subjects and name each bnode
  const issuer = options.issuer || new util.IdentifierIssuer('_:b');
  const graphs = {'@default': {}};
  api.createNodeMap(input, graphs, '@default', issuer);

  // add all non-default graphs to default graph
  return api.mergeNodeMaps(graphs);
};

/**
 * Recursively flattens the subjects in the given JSON-LD expanded input
 * into a node map.
 *
 * @param input the JSON-LD expanded input.
 * @param graphs a map of graph name to subject map.
 * @param graph the name of the current graph.
 * @param issuer the blank node identifier issuer.
 * @param name the name assigned to the current input if it is a bnode.
 * @param list the list to append to, null for none.
 */
api.createNodeMap = (input, graphs, graph, issuer, name, list) => {
  // recurse through array
  if(types.isArray(input)) {
    for(const node of input) {
      api.createNodeMap(node, graphs, graph, issuer, undefined, list);
    }
    return;
  }

  // add non-object to list
  if(!types.isObject(input)) {
    if(list) {
      list.push(input);
    }
    return;
  }

  // add values to list
  if(graphTypes.isValue(input)) {
    if('@type' in input) {
      let type = input['@type'];
      // rename @type blank node
      if(type.indexOf('_:') === 0) {
        input['@type'] = type = issuer.getId(type);
      }
    }
    if(list) {
      list.push(input);
    }
    return;
  } else if(list && graphTypes.isList(input)) {
    const _list = [];
    api.createNodeMap(input['@list'], graphs, graph, issuer, name, _list);
    list.push({'@list': _list});
    return;
  }

  // Note: At this point, input must be a subject.

  // spec requires @type to be named first, so assign names early
  if('@type' in input) {
    const types = input['@type'];
    for(const type of types) {
      if(type.indexOf('_:') === 0) {
        issuer.getId(type);
      }
    }
  }

  // get name for subject
  if(types.isUndefined(name)) {
    name = graphTypes.isBlankNode(input) ?
      issuer.getId(input['@id']) : input['@id'];
  }

  // add subject reference to list
  if(list) {
    list.push({'@id': name});
  }

  // create new subject or merge into existing one
  const subjects = graphs[graph];
  const subject = subjects[name] = subjects[name] || {};
  subject['@id'] = name;
  const properties = Object.keys(input).sort();
  for(let property of properties) {
    // skip @id
    if(property === '@id') {
      continue;
    }

    // handle reverse properties
    if(property === '@reverse') {
      const referencedNode = {'@id': name};
      const reverseMap = input['@reverse'];
      for(const reverseProperty in reverseMap) {
        const items = reverseMap[reverseProperty];
        for(const item of items) {
          let itemName = item['@id'];
          if(graphTypes.isBlankNode(item)) {
            itemName = issuer.getId(itemName);
          }
          api.createNodeMap(item, graphs, graph, issuer, itemName);
          util.addValue(
            subjects[itemName], reverseProperty, referencedNode,
            {propertyIsArray: true, allowDuplicate: false});
        }
      }
      continue;
    }

    // recurse into graph
    if(property === '@graph') {
      // add graph subjects map entry
      if(!(name in graphs)) {
        graphs[name] = {};
      }
      api.createNodeMap(input[property], graphs, name, issuer);
      continue;
    }

    // recurse into included
    if(property === '@included') {
      api.createNodeMap(input[property], graphs, graph, issuer);
      continue;
    }

    // copy non-@type keywords
    if(property !== '@type' && isKeyword(property)) {
      if(property === '@index' && property in subject &&
        (input[property] !== subject[property] ||
        input[property]['@id'] !== subject[property]['@id'])) {
        throw new JsonLdError(
          'Invalid JSON-LD syntax; conflicting @index property detected.',
          'jsonld.SyntaxError',
          {code: 'conflicting indexes', subject});
      }
      subject[property] = input[property];
      continue;
    }

    // iterate over objects
    const objects = input[property];

    // if property is a bnode, assign it a new id
    if(property.indexOf('_:') === 0) {
      property = issuer.getId(property);
    }

    // ensure property is added for empty arrays
    if(objects.length === 0) {
      util.addValue(subject, property, [], {propertyIsArray: true});
      continue;
    }
    for(let o of objects) {
      if(property === '@type') {
        // rename @type blank nodes
        o = (o.indexOf('_:') === 0) ? issuer.getId(o) : o;
      }

      // handle embedded subject or subject reference
      if(graphTypes.isSubject(o) || graphTypes.isSubjectReference(o)) {
        // skip null @id
        if('@id' in o && !o['@id']) {
          continue;
        }

        // relabel blank node @id
        const id = graphTypes.isBlankNode(o) ?
          issuer.getId(o['@id']) : o['@id'];

        // add reference and recurse
        util.addValue(
          subject, property, {'@id': id},
          {propertyIsArray: true, allowDuplicate: false});
        api.createNodeMap(o, graphs, graph, issuer, id);
      } else if(graphTypes.isValue(o)) {
        util.addValue(
          subject, property, o,
          {propertyIsArray: true, allowDuplicate: false});
      } else if(graphTypes.isList(o)) {
        // handle @list
        const _list = [];
        api.createNodeMap(o['@list'], graphs, graph, issuer, name, _list);
        o = {'@list': _list};
        util.addValue(
          subject, property, o,
          {propertyIsArray: true, allowDuplicate: false});
      } else {
        // handle @value
        api.createNodeMap(o, graphs, graph, issuer, name);
        util.addValue(
          subject, property, o, {propertyIsArray: true, allowDuplicate: false});
      }
    }
  }
};

/**
 * Merge separate named graphs into a single merged graph including
 * all nodes from the default graph and named graphs.
 *
 * @param graphs a map of graph name to subject map.
 *
 * @return the merged graph map.
 */
api.mergeNodeMapGraphs = graphs => {
  const merged = {};
  for(const name of Object.keys(graphs).sort()) {
    for(const id of Object.keys(graphs[name]).sort()) {
      const node = graphs[name][id];
      if(!(id in merged)) {
        merged[id] = {'@id': id};
      }
      const mergedNode = merged[id];

      for(const property of Object.keys(node).sort()) {
        if(isKeyword(property) && property !== '@type') {
          // copy keywords
          mergedNode[property] = util.clone(node[property]);
        } else {
          // merge objects
          for(const value of node[property]) {
            util.addValue(
              mergedNode, property, util.clone(value),
              {propertyIsArray: true, allowDuplicate: false});
          }
        }
      }
    }
  }

  return merged;
};

api.mergeNodeMaps = graphs => {
  // add all non-default graphs to default graph
  const defaultGraph = graphs['@default'];
  const graphNames = Object.keys(graphs).sort();
  for(const graphName of graphNames) {
    if(graphName === '@default') {
      continue;
    }
    const nodeMap = graphs[graphName];
    let subject = defaultGraph[graphName];
    if(!subject) {
      defaultGraph[graphName] = subject = {
        '@id': graphName,
        '@graph': []
      };
    } else if(!('@graph' in subject)) {
      subject['@graph'] = [];
    }
    const graph = subject['@graph'];
    for(const id of Object.keys(nodeMap).sort()) {
      const node = nodeMap[id];
      // only add full subjects
      if(!graphTypes.isSubjectReference(node)) {
        graph.push(node);
      }
    }
  }
  return defaultGraph;
};

},{"./JsonLdError":139,"./context":146,"./graphTypes":152,"./types":157,"./util":159}],155:[function(require,module,exports){
/*
 * Copyright (c) 2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const xhrLoader = require('./documentLoaders/xhr');

const api = {};
module.exports = api;

/**
 * Setup browser document loaders.
 *
 * @param jsonld the jsonld api.
 */
api.setupDocumentLoaders = function(jsonld) {
  if(typeof XMLHttpRequest !== 'undefined') {
    jsonld.documentLoaders.xhr = xhrLoader;
    // use xhr document loader by default
    jsonld.useDocumentLoader('xhr');
  }
};

/**
 * Setup browser globals.
 *
 * @param jsonld the jsonld api.
 */
api.setupGlobals = function(jsonld) {
  // setup browser global JsonLdProcessor
  if(typeof globalThis.JsonLdProcessor === 'undefined') {
    Object.defineProperty(globalThis, 'JsonLdProcessor', {
      writable: true,
      enumerable: false,
      configurable: true,
      value: jsonld.JsonLdProcessor
    });
  }
};

},{"./documentLoaders/xhr":147}],156:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const {createNodeMap} = require('./nodeMap');
const {isKeyword} = require('./context');
const graphTypes = require('./graphTypes');
const jsonCanonicalize = require('canonicalize');
const types = require('./types');
const util = require('./util');

const {
  // RDF,
  // RDF_LIST,
  RDF_FIRST,
  RDF_REST,
  RDF_NIL,
  RDF_TYPE,
  // RDF_PLAIN_LITERAL,
  // RDF_XML_LITERAL,
  RDF_JSON_LITERAL,
  // RDF_OBJECT,
  RDF_LANGSTRING,

  // XSD,
  XSD_BOOLEAN,
  XSD_DOUBLE,
  XSD_INTEGER,
  XSD_STRING,
} = require('./constants');

const {
  isAbsolute: _isAbsoluteIri
} = require('./url');

const api = {};
module.exports = api;

/**
 * Outputs an RDF dataset for the expanded JSON-LD input.
 *
 * @param input the expanded JSON-LD input.
 * @param options the RDF serialization options.
 *
 * @return the RDF dataset.
 */
api.toRDF = (input, options) => {
  // create node map for default graph (and any named graphs)
  const issuer = new util.IdentifierIssuer('_:b');
  const nodeMap = {'@default': {}};
  createNodeMap(input, nodeMap, '@default', issuer);

  const dataset = [];
  const graphNames = Object.keys(nodeMap).sort();
  for(const graphName of graphNames) {
    let graphTerm;
    if(graphName === '@default') {
      graphTerm = {termType: 'DefaultGraph', value: ''};
    } else if(_isAbsoluteIri(graphName)) {
      if(graphName.startsWith('_:')) {
        graphTerm = {termType: 'BlankNode'};
      } else {
        graphTerm = {termType: 'NamedNode'};
      }
      graphTerm.value = graphName;
    } else {
      // skip relative IRIs (not valid RDF)
      continue;
    }
    _graphToRDF(dataset, nodeMap[graphName], graphTerm, issuer, options);
  }

  return dataset;
};

/**
 * Adds RDF quads for a particular graph to the given dataset.
 *
 * @param dataset the dataset to append RDF quads to.
 * @param graph the graph to create RDF quads for.
 * @param graphTerm the graph term for each quad.
 * @param issuer a IdentifierIssuer for assigning blank node names.
 * @param options the RDF serialization options.
 *
 * @return the array of RDF triples for the given graph.
 */
function _graphToRDF(dataset, graph, graphTerm, issuer, options) {
  const ids = Object.keys(graph).sort();
  for(const id of ids) {
    const node = graph[id];
    const properties = Object.keys(node).sort();
    for(let property of properties) {
      const items = node[property];
      if(property === '@type') {
        property = RDF_TYPE;
      } else if(isKeyword(property)) {
        continue;
      }

      for(const item of items) {
        // RDF subject
        const subject = {
          termType: id.startsWith('_:') ? 'BlankNode' : 'NamedNode',
          value: id
        };

        // skip relative IRI subjects (not valid RDF)
        if(!_isAbsoluteIri(id)) {
          continue;
        }

        // RDF predicate
        const predicate = {
          termType: property.startsWith('_:') ? 'BlankNode' : 'NamedNode',
          value: property
        };

        // skip relative IRI predicates (not valid RDF)
        if(!_isAbsoluteIri(property)) {
          continue;
        }

        // skip blank node predicates unless producing generalized RDF
        if(predicate.termType === 'BlankNode' &&
          !options.produceGeneralizedRdf) {
          continue;
        }

        // convert list, value or node object to triple
        const object =
          _objectToRDF(item, issuer, dataset, graphTerm, options.rdfDirection);
        // skip null objects (they are relative IRIs)
        if(object) {
          dataset.push({
            subject,
            predicate,
            object,
            graph: graphTerm
          });
        }
      }
    }
  }
}

/**
 * Converts a @list value into linked list of blank node RDF quads
 * (an RDF collection).
 *
 * @param list the @list value.
 * @param issuer a IdentifierIssuer for assigning blank node names.
 * @param dataset the array of quads to append to.
 * @param graphTerm the graph term for each quad.
 *
 * @return the head of the list.
 */
function _listToRDF(list, issuer, dataset, graphTerm, rdfDirection) {
  const first = {termType: 'NamedNode', value: RDF_FIRST};
  const rest = {termType: 'NamedNode', value: RDF_REST};
  const nil = {termType: 'NamedNode', value: RDF_NIL};

  const last = list.pop();
  // Result is the head of the list
  const result = last ? {termType: 'BlankNode', value: issuer.getId()} : nil;
  let subject = result;

  for(const item of list) {
    const object = _objectToRDF(item, issuer, dataset, graphTerm, rdfDirection);
    const next = {termType: 'BlankNode', value: issuer.getId()};
    dataset.push({
      subject,
      predicate: first,
      object,
      graph: graphTerm
    });
    dataset.push({
      subject,
      predicate: rest,
      object: next,
      graph: graphTerm
    });
    subject = next;
  }

  // Tail of list
  if(last) {
    const object = _objectToRDF(last, issuer, dataset, graphTerm, rdfDirection);
    dataset.push({
      subject,
      predicate: first,
      object,
      graph: graphTerm
    });
    dataset.push({
      subject,
      predicate: rest,
      object: nil,
      graph: graphTerm
    });
  }

  return result;
}

/**
 * Converts a JSON-LD value object to an RDF literal or a JSON-LD string,
 * node object to an RDF resource, or adds a list.
 *
 * @param item the JSON-LD value or node object.
 * @param issuer a IdentifierIssuer for assigning blank node names.
 * @param dataset the dataset to append RDF quads to.
 * @param graphTerm the graph term for each quad.
 *
 * @return the RDF literal or RDF resource.
 */
function _objectToRDF(item, issuer, dataset, graphTerm, rdfDirection) {
  const object = {};

  // convert value object to RDF
  if(graphTypes.isValue(item)) {
    object.termType = 'Literal';
    object.value = undefined;
    object.datatype = {
      termType: 'NamedNode'
    };
    let value = item['@value'];
    const datatype = item['@type'] || null;

    // convert to XSD/JSON datatypes as appropriate
    if(datatype === '@json') {
      object.value = jsonCanonicalize(value);
      object.datatype.value = RDF_JSON_LITERAL;
    } else if(types.isBoolean(value)) {
      object.value = value.toString();
      object.datatype.value = datatype || XSD_BOOLEAN;
    } else if(types.isDouble(value) || datatype === XSD_DOUBLE) {
      if(!types.isDouble(value)) {
        value = parseFloat(value);
      }
      // canonical double representation
      object.value = value.toExponential(15).replace(/(\d)0*e\+?/, '$1E');
      object.datatype.value = datatype || XSD_DOUBLE;
    } else if(types.isNumber(value)) {
      object.value = value.toFixed(0);
      object.datatype.value = datatype || XSD_INTEGER;
    } else if(rdfDirection === 'i18n-datatype' &&
      '@direction' in item) {
      const datatype = 'https://www.w3.org/ns/i18n#' +
        (item['@language'] || '') +
        `_${item['@direction']}`;
      object.datatype.value = datatype;
      object.value = value;
    } else if('@language' in item) {
      object.value = value;
      object.datatype.value = datatype || RDF_LANGSTRING;
      object.language = item['@language'];
    } else {
      object.value = value;
      object.datatype.value = datatype || XSD_STRING;
    }
  } else if(graphTypes.isList(item)) {
    const _list =
      _listToRDF(item['@list'], issuer, dataset, graphTerm, rdfDirection);
    object.termType = _list.termType;
    object.value = _list.value;
  } else {
    // convert string/node object to RDF
    const id = types.isObject(item) ? item['@id'] : item;
    object.termType = id.startsWith('_:') ? 'BlankNode' : 'NamedNode';
    object.value = id;
  }

  // skip relative IRIs, not valid RDF
  if(object.termType === 'NamedNode' && !_isAbsoluteIri(object.value)) {
    return null;
  }

  return object;
}

},{"./constants":145,"./context":146,"./graphTypes":152,"./nodeMap":154,"./types":157,"./url":158,"./util":159,"canonicalize":78}],157:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const api = {};
module.exports = api;

/**
 * Returns true if the given value is an Array.
 *
 * @param v the value to check.
 *
 * @return true if the value is an Array, false if not.
 */
api.isArray = Array.isArray;

/**
 * Returns true if the given value is a Boolean.
 *
 * @param v the value to check.
 *
 * @return true if the value is a Boolean, false if not.
 */
api.isBoolean = v => (typeof v === 'boolean' ||
  Object.prototype.toString.call(v) === '[object Boolean]');

/**
 * Returns true if the given value is a double.
 *
 * @param v the value to check.
 *
 * @return true if the value is a double, false if not.
 */
api.isDouble = v => api.isNumber(v) &&
  (String(v).indexOf('.') !== -1 || Math.abs(v) >= 1e21);

/**
 * Returns true if the given value is an empty Object.
 *
 * @param v the value to check.
 *
 * @return true if the value is an empty Object, false if not.
 */
api.isEmptyObject = v => api.isObject(v) && Object.keys(v).length === 0;

/**
 * Returns true if the given value is a Number.
 *
 * @param v the value to check.
 *
 * @return true if the value is a Number, false if not.
 */
api.isNumber = v => (typeof v === 'number' ||
  Object.prototype.toString.call(v) === '[object Number]');

/**
 * Returns true if the given value is numeric.
 *
 * @param v the value to check.
 *
 * @return true if the value is numeric, false if not.
 */
api.isNumeric = v => !isNaN(parseFloat(v)) && isFinite(v);

/**
 * Returns true if the given value is an Object.
 *
 * @param v the value to check.
 *
 * @return true if the value is an Object, false if not.
 */
api.isObject = v => Object.prototype.toString.call(v) === '[object Object]';

/**
 * Returns true if the given value is a String.
 *
 * @param v the value to check.
 *
 * @return true if the value is a String, false if not.
 */
api.isString = v => (typeof v === 'string' ||
  Object.prototype.toString.call(v) === '[object String]');

/**
 * Returns true if the given value is undefined.
 *
 * @param v the value to check.
 *
 * @return true if the value is undefined, false if not.
 */
api.isUndefined = v => typeof v === 'undefined';

},{}],158:[function(require,module,exports){
/*
 * Copyright (c) 2017 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const types = require('./types');

const api = {};
module.exports = api;

// define URL parser
// parseUri 1.2.2
// (c) Steven Levithan <stevenlevithan.com>
// MIT License
// with local jsonld.js modifications
api.parsers = {
  simple: {
    // RFC 3986 basic parts
    keys: [
      'href', 'scheme', 'authority', 'path', 'query', 'fragment'
    ],
    /* eslint-disable-next-line max-len */
    regex: /^(?:([^:\/?#]+):)?(?:\/\/([^\/?#]*))?([^?#]*)(?:\?([^#]*))?(?:#(.*))?/
  },
  full: {
    keys: [
      'href', 'protocol', 'scheme', 'authority', 'auth', 'user', 'password',
      'hostname', 'port', 'path', 'directory', 'file', 'query', 'fragment'
    ],
    /* eslint-disable-next-line max-len */
    regex: /^(([^:\/?#]+):)?(?:\/\/((?:(([^:@]*)(?::([^:@]*))?)?@)?([^:\/?#]*)(?::(\d*))?))?(?:(((?:[^?#\/]*\/)*)([^?#]*))(?:\?([^#]*))?(?:#(.*))?)/
  }
};
api.parse = (str, parser) => {
  const parsed = {};
  const o = api.parsers[parser || 'full'];
  const m = o.regex.exec(str);
  let i = o.keys.length;
  while(i--) {
    parsed[o.keys[i]] = (m[i] === undefined) ? null : m[i];
  }

  // remove default ports in found in URLs
  if((parsed.scheme === 'https' && parsed.port === '443') ||
    (parsed.scheme === 'http' && parsed.port === '80')) {
    parsed.href = parsed.href.replace(':' + parsed.port, '');
    parsed.authority = parsed.authority.replace(':' + parsed.port, '');
    parsed.port = null;
  }

  parsed.normalizedPath = api.removeDotSegments(parsed.path);
  return parsed;
};

/**
 * Prepends a base IRI to the given relative IRI.
 *
 * @param base the base IRI.
 * @param iri the relative IRI.
 *
 * @return the absolute IRI.
 */
api.prependBase = (base, iri) => {
  // skip IRI processing
  if(base === null) {
    return iri;
  }
  // already an absolute IRI
  if(api.isAbsolute(iri)) {
    return iri;
  }

  // parse base if it is a string
  if(!base || types.isString(base)) {
    base = api.parse(base || '');
  }

  // parse given IRI
  const rel = api.parse(iri);

  // per RFC3986 5.2.2
  const transform = {
    protocol: base.protocol || ''
  };

  if(rel.authority !== null) {
    transform.authority = rel.authority;
    transform.path = rel.path;
    transform.query = rel.query;
  } else {
    transform.authority = base.authority;

    if(rel.path === '') {
      transform.path = base.path;
      if(rel.query !== null) {
        transform.query = rel.query;
      } else {
        transform.query = base.query;
      }
    } else {
      if(rel.path.indexOf('/') === 0) {
        // IRI represents an absolute path
        transform.path = rel.path;
      } else {
        // merge paths
        let path = base.path;

        // append relative path to the end of the last directory from base
        path = path.substr(0, path.lastIndexOf('/') + 1);
        if((path.length > 0 || base.authority) && path.substr(-1) !== '/') {
          path += '/';
        }
        path += rel.path;

        transform.path = path;
      }
      transform.query = rel.query;
    }
  }

  if(rel.path !== '') {
    // remove slashes and dots in path
    transform.path = api.removeDotSegments(transform.path);
  }

  // construct URL
  let rval = transform.protocol;
  if(transform.authority !== null) {
    rval += '//' + transform.authority;
  }
  rval += transform.path;
  if(transform.query !== null) {
    rval += '?' + transform.query;
  }
  if(rel.fragment !== null) {
    rval += '#' + rel.fragment;
  }

  // handle empty base
  if(rval === '') {
    rval = './';
  }

  return rval;
};

/**
 * Removes a base IRI from the given absolute IRI.
 *
 * @param base the base IRI.
 * @param iri the absolute IRI.
 *
 * @return the relative IRI if relative to base, otherwise the absolute IRI.
 */
api.removeBase = (base, iri) => {
  // skip IRI processing
  if(base === null) {
    return iri;
  }

  if(!base || types.isString(base)) {
    base = api.parse(base || '');
  }

  // establish base root
  let root = '';
  if(base.href !== '') {
    root += (base.protocol || '') + '//' + (base.authority || '');
  } else if(iri.indexOf('//')) {
    // support network-path reference with empty base
    root += '//';
  }

  // IRI not relative to base
  if(iri.indexOf(root) !== 0) {
    return iri;
  }

  // remove root from IRI and parse remainder
  const rel = api.parse(iri.substr(root.length));

  // remove path segments that match (do not remove last segment unless there
  // is a hash or query)
  const baseSegments = base.normalizedPath.split('/');
  const iriSegments = rel.normalizedPath.split('/');
  const last = (rel.fragment || rel.query) ? 0 : 1;
  while(baseSegments.length > 0 && iriSegments.length > last) {
    if(baseSegments[0] !== iriSegments[0]) {
      break;
    }
    baseSegments.shift();
    iriSegments.shift();
  }

  // use '../' for each non-matching base segment
  let rval = '';
  if(baseSegments.length > 0) {
    // don't count the last segment (if it ends with '/' last path doesn't
    // count and if it doesn't end with '/' it isn't a path)
    baseSegments.pop();
    for(let i = 0; i < baseSegments.length; ++i) {
      rval += '../';
    }
  }

  // prepend remaining segments
  rval += iriSegments.join('/');

  // add query and hash
  if(rel.query !== null) {
    rval += '?' + rel.query;
  }
  if(rel.fragment !== null) {
    rval += '#' + rel.fragment;
  }

  // handle empty base
  if(rval === '') {
    rval = './';
  }

  return rval;
};

/**
 * Removes dot segments from a URL path.
 *
 * @param path the path to remove dot segments from.
 */
api.removeDotSegments = path => {
  // RFC 3986 5.2.4 (reworked)

  // empty path shortcut
  if(path.length === 0) {
    return '';
  }

  const input = path.split('/');
  const output = [];

  while(input.length > 0) {
    const next = input.shift();
    const done = input.length === 0;

    if(next === '.') {
      if(done) {
        // ensure output has trailing /
        output.push('');
      }
      continue;
    }

    if(next === '..') {
      output.pop();
      if(done) {
        // ensure output has trailing /
        output.push('');
      }
      continue;
    }

    output.push(next);
  }

  // if path was absolute, ensure output has leading /
  if(path[0] === '/' && output.length > 0 && output[0] !== '') {
    output.unshift('');
  }
  if(output.length === 1 && output[0] === '') {
    return '/';
  }

  return output.join('/');
};

// TODO: time better isAbsolute/isRelative checks using full regexes:
// http://jmrware.com/articles/2009/uri_regexp/URI_regex.html

// regex to check for absolute IRI (starting scheme and ':') or blank node IRI
const isAbsoluteRegex = /^([A-Za-z][A-Za-z0-9+-.]*|_):[^\s]*$/;

/**
 * Returns true if the given value is an absolute IRI or blank node IRI, false
 * if not.
 * Note: This weak check only checks for a correct starting scheme.
 *
 * @param v the value to check.
 *
 * @return true if the value is an absolute IRI, false if not.
 */
api.isAbsolute = v => types.isString(v) && isAbsoluteRegex.test(v);

/**
 * Returns true if the given value is a relative IRI, false if not.
 * Note: this is a weak check.
 *
 * @param v the value to check.
 *
 * @return true if the value is a relative IRI, false if not.
 */
api.isRelative = v => types.isString(v);

},{"./types":157}],159:[function(require,module,exports){
/*
 * Copyright (c) 2017-2019 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const graphTypes = require('./graphTypes');
const types = require('./types');
// TODO: move `IdentifierIssuer` to its own package
const IdentifierIssuer = require('rdf-canonize').IdentifierIssuer;
const JsonLdError = require('./JsonLdError');

// constants
const REGEX_LINK_HEADERS = /(?:<[^>]*?>|"[^"]*?"|[^,])+/g;
const REGEX_LINK_HEADER = /\s*<([^>]*?)>\s*(?:;\s*(.*))?/;
const REGEX_LINK_HEADER_PARAMS =
  /(.*?)=(?:(?:"([^"]*?)")|([^"]*?))\s*(?:(?:;\s*)|$)/g;

const DEFAULTS = {
  headers: {
    accept: 'application/ld+json, application/json'
  }
};

const api = {};
module.exports = api;
api.IdentifierIssuer = IdentifierIssuer;

/**
 * Clones an object, array, Map, Set, or string/number. If a typed JavaScript
 * object is given, such as a Date, it will be converted to a string.
 *
 * @param value the value to clone.
 *
 * @return the cloned value.
 */
api.clone = function(value) {
  if(value && typeof value === 'object') {
    let rval;
    if(types.isArray(value)) {
      rval = [];
      for(let i = 0; i < value.length; ++i) {
        rval[i] = api.clone(value[i]);
      }
    } else if(value instanceof Map) {
      rval = new Map();
      for(const [k, v] of value) {
        rval.set(k, api.clone(v));
      }
    } else if(value instanceof Set) {
      rval = new Set();
      for(const v of value) {
        rval.add(api.clone(v));
      }
    } else if(types.isObject(value)) {
      rval = {};
      for(const key in value) {
        rval[key] = api.clone(value[key]);
      }
    } else {
      rval = value.toString();
    }
    return rval;
  }
  return value;
};

/**
 * Ensure a value is an array. If the value is an array, it is returned.
 * Otherwise, it is wrapped in an array.
 *
 * @param value the value to return as an array.
 *
 * @return the value as an array.
 */
api.asArray = function(value) {
  return Array.isArray(value) ? value : [value];
};

/**
 * Builds an HTTP headers object for making a JSON-LD request from custom
 * headers and asserts the `accept` header isn't overridden.
 *
 * @param headers an object of headers with keys as header names and values
 *          as header values.
 *
 * @return an object of headers with a valid `accept` header.
 */
api.buildHeaders = (headers = {}) => {
  const hasAccept = Object.keys(headers).some(
    h => h.toLowerCase() === 'accept');

  if(hasAccept) {
    throw new RangeError(
      'Accept header may not be specified; only "' +
      DEFAULTS.headers.accept + '" is supported.');
  }

  return Object.assign({Accept: DEFAULTS.headers.accept}, headers);
};

/**
 * Parses a link header. The results will be key'd by the value of "rel".
 *
 * Link: <http://json-ld.org/contexts/person.jsonld>;
 * rel="http://www.w3.org/ns/json-ld#context"; type="application/ld+json"
 *
 * Parses as: {
 *   'http://www.w3.org/ns/json-ld#context': {
 *     target: http://json-ld.org/contexts/person.jsonld,
 *     type: 'application/ld+json'
 *   }
 * }
 *
 * If there is more than one "rel" with the same IRI, then entries in the
 * resulting map for that "rel" will be arrays.
 *
 * @param header the link header to parse.
 */
api.parseLinkHeader = header => {
  const rval = {};
  // split on unbracketed/unquoted commas
  const entries = header.match(REGEX_LINK_HEADERS);
  for(let i = 0; i < entries.length; ++i) {
    let match = entries[i].match(REGEX_LINK_HEADER);
    if(!match) {
      continue;
    }
    const result = {target: match[1]};
    const params = match[2];
    while((match = REGEX_LINK_HEADER_PARAMS.exec(params))) {
      result[match[1]] = (match[2] === undefined) ? match[3] : match[2];
    }
    const rel = result['rel'] || '';
    if(Array.isArray(rval[rel])) {
      rval[rel].push(result);
    } else if(rval.hasOwnProperty(rel)) {
      rval[rel] = [rval[rel], result];
    } else {
      rval[rel] = result;
    }
  }
  return rval;
};

/**
 * Throws an exception if the given value is not a valid @type value.
 *
 * @param v the value to check.
 */
api.validateTypeValue = (v, isFrame) => {
  if(types.isString(v)) {
    return;
  }

  if(types.isArray(v) && v.every(vv => types.isString(vv))) {
    return;
  }
  if(isFrame && types.isObject(v)) {
    switch(Object.keys(v).length) {
      case 0:
        // empty object is wildcard
        return;
      case 1:
        // default entry is all strings
        if('@default' in v &&
          api.asArray(v['@default']).every(vv => types.isString(vv))) {
          return;
        }
    }
  }

  throw new JsonLdError(
    'Invalid JSON-LD syntax; "@type" value must a string, an array of ' +
    'strings, an empty object, ' +
    'or a default object.', 'jsonld.SyntaxError',
    {code: 'invalid type value', value: v});
};

/**
 * Returns true if the given subject has the given property.
 *
 * @param subject the subject to check.
 * @param property the property to look for.
 *
 * @return true if the subject has the given property, false if not.
 */
api.hasProperty = (subject, property) => {
  if(subject.hasOwnProperty(property)) {
    const value = subject[property];
    return (!types.isArray(value) || value.length > 0);
  }
  return false;
};

/**
 * Determines if the given value is a property of the given subject.
 *
 * @param subject the subject to check.
 * @param property the property to check.
 * @param value the value to check.
 *
 * @return true if the value exists, false if not.
 */
api.hasValue = (subject, property, value) => {
  if(api.hasProperty(subject, property)) {
    let val = subject[property];
    const isList = graphTypes.isList(val);
    if(types.isArray(val) || isList) {
      if(isList) {
        val = val['@list'];
      }
      for(let i = 0; i < val.length; ++i) {
        if(api.compareValues(value, val[i])) {
          return true;
        }
      }
    } else if(!types.isArray(value)) {
      // avoid matching the set of values with an array value parameter
      return api.compareValues(value, val);
    }
  }
  return false;
};

/**
 * Adds a value to a subject. If the value is an array, all values in the
 * array will be added.
 *
 * @param subject the subject to add the value to.
 * @param property the property that relates the value to the subject.
 * @param value the value to add.
 * @param [options] the options to use:
 *        [propertyIsArray] true if the property is always an array, false
 *          if not (default: false).
 *        [valueIsArray] true if the value to be added should be preserved as
 *          an array (lists) (default: false).
 *        [allowDuplicate] true to allow duplicates, false not to (uses a
 *          simple shallow comparison of subject ID or value) (default: true).
 *        [prependValue] false to prepend value to any existing values.
 *          (default: false)
 */
api.addValue = (subject, property, value, options) => {
  options = options || {};
  if(!('propertyIsArray' in options)) {
    options.propertyIsArray = false;
  }
  if(!('valueIsArray' in options)) {
    options.valueIsArray = false;
  }
  if(!('allowDuplicate' in options)) {
    options.allowDuplicate = true;
  }
  if(!('prependValue' in options)) {
    options.prependValue = false;
  }

  if(options.valueIsArray) {
    subject[property] = value;
  } else if(types.isArray(value)) {
    if(value.length === 0 && options.propertyIsArray &&
      !subject.hasOwnProperty(property)) {
      subject[property] = [];
    }
    if(options.prependValue) {
      value = value.concat(subject[property]);
      subject[property] = [];
    }
    for(let i = 0; i < value.length; ++i) {
      api.addValue(subject, property, value[i], options);
    }
  } else if(subject.hasOwnProperty(property)) {
    // check if subject already has value if duplicates not allowed
    const hasValue = (!options.allowDuplicate &&
      api.hasValue(subject, property, value));

    // make property an array if value not present or always an array
    if(!types.isArray(subject[property]) &&
      (!hasValue || options.propertyIsArray)) {
      subject[property] = [subject[property]];
    }

    // add new value
    if(!hasValue) {
      if(options.prependValue) {
        subject[property].unshift(value);
      } else {
        subject[property].push(value);
      }
    }
  } else {
    // add new value as set or single value
    subject[property] = options.propertyIsArray ? [value] : value;
  }
};

/**
 * Gets all of the values for a subject's property as an array.
 *
 * @param subject the subject.
 * @param property the property.
 *
 * @return all of the values for a subject's property as an array.
 */
api.getValues = (subject, property) => [].concat(subject[property] || []);

/**
 * Removes a property from a subject.
 *
 * @param subject the subject.
 * @param property the property.
 */
api.removeProperty = (subject, property) => {
  delete subject[property];
};

/**
 * Removes a value from a subject.
 *
 * @param subject the subject.
 * @param property the property that relates the value to the subject.
 * @param value the value to remove.
 * @param [options] the options to use:
 *          [propertyIsArray] true if the property is always an array, false
 *            if not (default: false).
 */
api.removeValue = (subject, property, value, options) => {
  options = options || {};
  if(!('propertyIsArray' in options)) {
    options.propertyIsArray = false;
  }

  // filter out value
  const values = api.getValues(subject, property).filter(
    e => !api.compareValues(e, value));

  if(values.length === 0) {
    api.removeProperty(subject, property);
  } else if(values.length === 1 && !options.propertyIsArray) {
    subject[property] = values[0];
  } else {
    subject[property] = values;
  }
};

/**
 * Relabels all blank nodes in the given JSON-LD input.
 *
 * @param input the JSON-LD input.
 * @param [options] the options to use:
 *          [issuer] an IdentifierIssuer to use to label blank nodes.
 */
api.relabelBlankNodes = (input, options) => {
  options = options || {};
  const issuer = options.issuer || new IdentifierIssuer('_:b');
  return _labelBlankNodes(issuer, input);
};

/**
 * Compares two JSON-LD values for equality. Two JSON-LD values will be
 * considered equal if:
 *
 * 1. They are both primitives of the same type and value.
 * 2. They are both @values with the same @value, @type, @language,
 *   and @index, OR
 * 3. They both have @ids they are the same.
 *
 * @param v1 the first value.
 * @param v2 the second value.
 *
 * @return true if v1 and v2 are considered equal, false if not.
 */
api.compareValues = (v1, v2) => {
  // 1. equal primitives
  if(v1 === v2) {
    return true;
  }

  // 2. equal @values
  if(graphTypes.isValue(v1) && graphTypes.isValue(v2) &&
    v1['@value'] === v2['@value'] &&
    v1['@type'] === v2['@type'] &&
    v1['@language'] === v2['@language'] &&
    v1['@index'] === v2['@index']) {
    return true;
  }

  // 3. equal @ids
  if(types.isObject(v1) &&
    ('@id' in v1) &&
    types.isObject(v2) &&
    ('@id' in v2)) {
    return v1['@id'] === v2['@id'];
  }

  return false;
};

/**
 * Compares two strings first based on length and then lexicographically.
 *
 * @param a the first string.
 * @param b the second string.
 *
 * @return -1 if a < b, 1 if a > b, 0 if a === b.
 */
api.compareShortestLeast = (a, b) => {
  if(a.length < b.length) {
    return -1;
  }
  if(b.length < a.length) {
    return 1;
  }
  if(a === b) {
    return 0;
  }
  return (a < b) ? -1 : 1;
};

/**
 * Labels the blank nodes in the given value using the given IdentifierIssuer.
 *
 * @param issuer the IdentifierIssuer to use.
 * @param element the element with blank nodes to rename.
 *
 * @return the element.
 */
function _labelBlankNodes(issuer, element) {
  if(types.isArray(element)) {
    for(let i = 0; i < element.length; ++i) {
      element[i] = _labelBlankNodes(issuer, element[i]);
    }
  } else if(graphTypes.isList(element)) {
    element['@list'] = _labelBlankNodes(issuer, element['@list']);
  } else if(types.isObject(element)) {
    // relabel blank node
    if(graphTypes.isBlankNode(element)) {
      element['@id'] = issuer.getId(element['@id']);
    }

    // recursively apply to all keys
    const keys = Object.keys(element).sort();
    for(let ki = 0; ki < keys.length; ++ki) {
      const key = keys[ki];
      if(key !== '@id') {
        element[key] = _labelBlankNodes(issuer, element[key]);
      }
    }
  }

  return element;
}

},{"./JsonLdError":139,"./graphTypes":152,"./types":157,"rdf-canonize":189}],160:[function(require,module,exports){
'use strict'

// A linked list to keep track of recently-used-ness
const Yallist = require('yallist')

const MAX = Symbol('max')
const LENGTH = Symbol('length')
const LENGTH_CALCULATOR = Symbol('lengthCalculator')
const ALLOW_STALE = Symbol('allowStale')
const MAX_AGE = Symbol('maxAge')
const DISPOSE = Symbol('dispose')
const NO_DISPOSE_ON_SET = Symbol('noDisposeOnSet')
const LRU_LIST = Symbol('lruList')
const CACHE = Symbol('cache')
const UPDATE_AGE_ON_GET = Symbol('updateAgeOnGet')

const naiveLength = () => 1

// lruList is a yallist where the head is the youngest
// item, and the tail is the oldest.  the list contains the Hit
// objects as the entries.
// Each Hit object has a reference to its Yallist.Node.  This
// never changes.
//
// cache is a Map (or PseudoMap) that matches the keys to
// the Yallist.Node object.
class LRUCache {
  constructor (options) {
    if (typeof options === 'number')
      options = { max: options }

    if (!options)
      options = {}

    if (options.max && (typeof options.max !== 'number' || options.max < 0))
      throw new TypeError('max must be a non-negative number')
    // Kind of weird to have a default max of Infinity, but oh well.
    const max = this[MAX] = options.max || Infinity

    const lc = options.length || naiveLength
    this[LENGTH_CALCULATOR] = (typeof lc !== 'function') ? naiveLength : lc
    this[ALLOW_STALE] = options.stale || false
    if (options.maxAge && typeof options.maxAge !== 'number')
      throw new TypeError('maxAge must be a number')
    this[MAX_AGE] = options.maxAge || 0
    this[DISPOSE] = options.dispose
    this[NO_DISPOSE_ON_SET] = options.noDisposeOnSet || false
    this[UPDATE_AGE_ON_GET] = options.updateAgeOnGet || false
    this.reset()
  }

  // resize the cache when the max changes.
  set max (mL) {
    if (typeof mL !== 'number' || mL < 0)
      throw new TypeError('max must be a non-negative number')

    this[MAX] = mL || Infinity
    trim(this)
  }
  get max () {
    return this[MAX]
  }

  set allowStale (allowStale) {
    this[ALLOW_STALE] = !!allowStale
  }
  get allowStale () {
    return this[ALLOW_STALE]
  }

  set maxAge (mA) {
    if (typeof mA !== 'number')
      throw new TypeError('maxAge must be a non-negative number')

    this[MAX_AGE] = mA
    trim(this)
  }
  get maxAge () {
    return this[MAX_AGE]
  }

  // resize the cache when the lengthCalculator changes.
  set lengthCalculator (lC) {
    if (typeof lC !== 'function')
      lC = naiveLength

    if (lC !== this[LENGTH_CALCULATOR]) {
      this[LENGTH_CALCULATOR] = lC
      this[LENGTH] = 0
      this[LRU_LIST].forEach(hit => {
        hit.length = this[LENGTH_CALCULATOR](hit.value, hit.key)
        this[LENGTH] += hit.length
      })
    }
    trim(this)
  }
  get lengthCalculator () { return this[LENGTH_CALCULATOR] }

  get length () { return this[LENGTH] }
  get itemCount () { return this[LRU_LIST].length }

  rforEach (fn, thisp) {
    thisp = thisp || this
    for (let walker = this[LRU_LIST].tail; walker !== null;) {
      const prev = walker.prev
      forEachStep(this, fn, walker, thisp)
      walker = prev
    }
  }

  forEach (fn, thisp) {
    thisp = thisp || this
    for (let walker = this[LRU_LIST].head; walker !== null;) {
      const next = walker.next
      forEachStep(this, fn, walker, thisp)
      walker = next
    }
  }

  keys () {
    return this[LRU_LIST].toArray().map(k => k.key)
  }

  values () {
    return this[LRU_LIST].toArray().map(k => k.value)
  }

  reset () {
    if (this[DISPOSE] &&
        this[LRU_LIST] &&
        this[LRU_LIST].length) {
      this[LRU_LIST].forEach(hit => this[DISPOSE](hit.key, hit.value))
    }

    this[CACHE] = new Map() // hash of items by key
    this[LRU_LIST] = new Yallist() // list of items in order of use recency
    this[LENGTH] = 0 // length of items in the list
  }

  dump () {
    return this[LRU_LIST].map(hit =>
      isStale(this, hit) ? false : {
        k: hit.key,
        v: hit.value,
        e: hit.now + (hit.maxAge || 0)
      }).toArray().filter(h => h)
  }

  dumpLru () {
    return this[LRU_LIST]
  }

  set (key, value, maxAge) {
    maxAge = maxAge || this[MAX_AGE]

    if (maxAge && typeof maxAge !== 'number')
      throw new TypeError('maxAge must be a number')

    const now = maxAge ? Date.now() : 0
    const len = this[LENGTH_CALCULATOR](value, key)

    if (this[CACHE].has(key)) {
      if (len > this[MAX]) {
        del(this, this[CACHE].get(key))
        return false
      }

      const node = this[CACHE].get(key)
      const item = node.value

      // dispose of the old one before overwriting
      // split out into 2 ifs for better coverage tracking
      if (this[DISPOSE]) {
        if (!this[NO_DISPOSE_ON_SET])
          this[DISPOSE](key, item.value)
      }

      item.now = now
      item.maxAge = maxAge
      item.value = value
      this[LENGTH] += len - item.length
      item.length = len
      this.get(key)
      trim(this)
      return true
    }

    const hit = new Entry(key, value, len, now, maxAge)

    // oversized objects fall out of cache automatically.
    if (hit.length > this[MAX]) {
      if (this[DISPOSE])
        this[DISPOSE](key, value)

      return false
    }

    this[LENGTH] += hit.length
    this[LRU_LIST].unshift(hit)
    this[CACHE].set(key, this[LRU_LIST].head)
    trim(this)
    return true
  }

  has (key) {
    if (!this[CACHE].has(key)) return false
    const hit = this[CACHE].get(key).value
    return !isStale(this, hit)
  }

  get (key) {
    return get(this, key, true)
  }

  peek (key) {
    return get(this, key, false)
  }

  pop () {
    const node = this[LRU_LIST].tail
    if (!node)
      return null

    del(this, node)
    return node.value
  }

  del (key) {
    del(this, this[CACHE].get(key))
  }

  load (arr) {
    // reset the cache
    this.reset()

    const now = Date.now()
    // A previous serialized cache has the most recent items first
    for (let l = arr.length - 1; l >= 0; l--) {
      const hit = arr[l]
      const expiresAt = hit.e || 0
      if (expiresAt === 0)
        // the item was created without expiration in a non aged cache
        this.set(hit.k, hit.v)
      else {
        const maxAge = expiresAt - now
        // dont add already expired items
        if (maxAge > 0) {
          this.set(hit.k, hit.v, maxAge)
        }
      }
    }
  }

  prune () {
    this[CACHE].forEach((value, key) => get(this, key, false))
  }
}

const get = (self, key, doUse) => {
  const node = self[CACHE].get(key)
  if (node) {
    const hit = node.value
    if (isStale(self, hit)) {
      del(self, node)
      if (!self[ALLOW_STALE])
        return undefined
    } else {
      if (doUse) {
        if (self[UPDATE_AGE_ON_GET])
          node.value.now = Date.now()
        self[LRU_LIST].unshiftNode(node)
      }
    }
    return hit.value
  }
}

const isStale = (self, hit) => {
  if (!hit || (!hit.maxAge && !self[MAX_AGE]))
    return false

  const diff = Date.now() - hit.now
  return hit.maxAge ? diff > hit.maxAge
    : self[MAX_AGE] && (diff > self[MAX_AGE])
}

const trim = self => {
  if (self[LENGTH] > self[MAX]) {
    for (let walker = self[LRU_LIST].tail;
      self[LENGTH] > self[MAX] && walker !== null;) {
      // We know that we're about to delete this one, and also
      // what the next least recently used key will be, so just
      // go ahead and set it now.
      const prev = walker.prev
      del(self, walker)
      walker = prev
    }
  }
}

const del = (self, node) => {
  if (node) {
    const hit = node.value
    if (self[DISPOSE])
      self[DISPOSE](hit.key, hit.value)

    self[LENGTH] -= hit.length
    self[CACHE].delete(hit.key)
    self[LRU_LIST].removeNode(node)
  }
}

class Entry {
  constructor (key, value, length, now, maxAge) {
    this.key = key
    this.value = value
    this.length = length
    this.now = now
    this.maxAge = maxAge || 0
  }
}

const forEachStep = (self, fn, node, thisp) => {
  let hit = node.value
  if (isStale(self, hit)) {
    del(self, node)
    if (!self[ALLOW_STALE])
      hit = undefined
  }
  if (hit)
    fn.call(thisp, hit.value, hit.key, self)
}

module.exports = LRUCache

},{"yallist":232}],161:[function(require,module,exports){
'use strict'
var inherits = require('inherits')
var HashBase = require('hash-base')
var Buffer = require('safe-buffer').Buffer

var ARRAY16 = new Array(16)

function MD5 () {
  HashBase.call(this, 64)

  // state
  this._a = 0x67452301
  this._b = 0xefcdab89
  this._c = 0x98badcfe
  this._d = 0x10325476
}

inherits(MD5, HashBase)

MD5.prototype._update = function () {
  var M = ARRAY16
  for (var i = 0; i < 16; ++i) M[i] = this._block.readInt32LE(i * 4)

  var a = this._a
  var b = this._b
  var c = this._c
  var d = this._d

  a = fnF(a, b, c, d, M[0], 0xd76aa478, 7)
  d = fnF(d, a, b, c, M[1], 0xe8c7b756, 12)
  c = fnF(c, d, a, b, M[2], 0x242070db, 17)
  b = fnF(b, c, d, a, M[3], 0xc1bdceee, 22)
  a = fnF(a, b, c, d, M[4], 0xf57c0faf, 7)
  d = fnF(d, a, b, c, M[5], 0x4787c62a, 12)
  c = fnF(c, d, a, b, M[6], 0xa8304613, 17)
  b = fnF(b, c, d, a, M[7], 0xfd469501, 22)
  a = fnF(a, b, c, d, M[8], 0x698098d8, 7)
  d = fnF(d, a, b, c, M[9], 0x8b44f7af, 12)
  c = fnF(c, d, a, b, M[10], 0xffff5bb1, 17)
  b = fnF(b, c, d, a, M[11], 0x895cd7be, 22)
  a = fnF(a, b, c, d, M[12], 0x6b901122, 7)
  d = fnF(d, a, b, c, M[13], 0xfd987193, 12)
  c = fnF(c, d, a, b, M[14], 0xa679438e, 17)
  b = fnF(b, c, d, a, M[15], 0x49b40821, 22)

  a = fnG(a, b, c, d, M[1], 0xf61e2562, 5)
  d = fnG(d, a, b, c, M[6], 0xc040b340, 9)
  c = fnG(c, d, a, b, M[11], 0x265e5a51, 14)
  b = fnG(b, c, d, a, M[0], 0xe9b6c7aa, 20)
  a = fnG(a, b, c, d, M[5], 0xd62f105d, 5)
  d = fnG(d, a, b, c, M[10], 0x02441453, 9)
  c = fnG(c, d, a, b, M[15], 0xd8a1e681, 14)
  b = fnG(b, c, d, a, M[4], 0xe7d3fbc8, 20)
  a = fnG(a, b, c, d, M[9], 0x21e1cde6, 5)
  d = fnG(d, a, b, c, M[14], 0xc33707d6, 9)
  c = fnG(c, d, a, b, M[3], 0xf4d50d87, 14)
  b = fnG(b, c, d, a, M[8], 0x455a14ed, 20)
  a = fnG(a, b, c, d, M[13], 0xa9e3e905, 5)
  d = fnG(d, a, b, c, M[2], 0xfcefa3f8, 9)
  c = fnG(c, d, a, b, M[7], 0x676f02d9, 14)
  b = fnG(b, c, d, a, M[12], 0x8d2a4c8a, 20)

  a = fnH(a, b, c, d, M[5], 0xfffa3942, 4)
  d = fnH(d, a, b, c, M[8], 0x8771f681, 11)
  c = fnH(c, d, a, b, M[11], 0x6d9d6122, 16)
  b = fnH(b, c, d, a, M[14], 0xfde5380c, 23)
  a = fnH(a, b, c, d, M[1], 0xa4beea44, 4)
  d = fnH(d, a, b, c, M[4], 0x4bdecfa9, 11)
  c = fnH(c, d, a, b, M[7], 0xf6bb4b60, 16)
  b = fnH(b, c, d, a, M[10], 0xbebfbc70, 23)
  a = fnH(a, b, c, d, M[13], 0x289b7ec6, 4)
  d = fnH(d, a, b, c, M[0], 0xeaa127fa, 11)
  c = fnH(c, d, a, b, M[3], 0xd4ef3085, 16)
  b = fnH(b, c, d, a, M[6], 0x04881d05, 23)
  a = fnH(a, b, c, d, M[9], 0xd9d4d039, 4)
  d = fnH(d, a, b, c, M[12], 0xe6db99e5, 11)
  c = fnH(c, d, a, b, M[15], 0x1fa27cf8, 16)
  b = fnH(b, c, d, a, M[2], 0xc4ac5665, 23)

  a = fnI(a, b, c, d, M[0], 0xf4292244, 6)
  d = fnI(d, a, b, c, M[7], 0x432aff97, 10)
  c = fnI(c, d, a, b, M[14], 0xab9423a7, 15)
  b = fnI(b, c, d, a, M[5], 0xfc93a039, 21)
  a = fnI(a, b, c, d, M[12], 0x655b59c3, 6)
  d = fnI(d, a, b, c, M[3], 0x8f0ccc92, 10)
  c = fnI(c, d, a, b, M[10], 0xffeff47d, 15)
  b = fnI(b, c, d, a, M[1], 0x85845dd1, 21)
  a = fnI(a, b, c, d, M[8], 0x6fa87e4f, 6)
  d = fnI(d, a, b, c, M[15], 0xfe2ce6e0, 10)
  c = fnI(c, d, a, b, M[6], 0xa3014314, 15)
  b = fnI(b, c, d, a, M[13], 0x4e0811a1, 21)
  a = fnI(a, b, c, d, M[4], 0xf7537e82, 6)
  d = fnI(d, a, b, c, M[11], 0xbd3af235, 10)
  c = fnI(c, d, a, b, M[2], 0x2ad7d2bb, 15)
  b = fnI(b, c, d, a, M[9], 0xeb86d391, 21)

  this._a = (this._a + a) | 0
  this._b = (this._b + b) | 0
  this._c = (this._c + c) | 0
  this._d = (this._d + d) | 0
}

MD5.prototype._digest = function () {
  // create padding and handle blocks
  this._block[this._blockOffset++] = 0x80
  if (this._blockOffset > 56) {
    this._block.fill(0, this._blockOffset, 64)
    this._update()
    this._blockOffset = 0
  }

  this._block.fill(0, this._blockOffset, 56)
  this._block.writeUInt32LE(this._length[0], 56)
  this._block.writeUInt32LE(this._length[1], 60)
  this._update()

  // produce result
  var buffer = Buffer.allocUnsafe(16)
  buffer.writeInt32LE(this._a, 0)
  buffer.writeInt32LE(this._b, 4)
  buffer.writeInt32LE(this._c, 8)
  buffer.writeInt32LE(this._d, 12)
  return buffer
}

function rotl (x, n) {
  return (x << n) | (x >>> (32 - n))
}

function fnF (a, b, c, d, m, k, s) {
  return (rotl((a + ((b & c) | ((~b) & d)) + m + k) | 0, s) + b) | 0
}

function fnG (a, b, c, d, m, k, s) {
  return (rotl((a + ((b & d) | (c & (~d))) + m + k) | 0, s) + b) | 0
}

function fnH (a, b, c, d, m, k, s) {
  return (rotl((a + (b ^ c ^ d) + m + k) | 0, s) + b) | 0
}

function fnI (a, b, c, d, m, k, s) {
  return (rotl((a + ((c ^ (b | (~d)))) + m + k) | 0, s) + b) | 0
}

module.exports = MD5

},{"hash-base":121,"inherits":136,"safe-buffer":215}],162:[function(require,module,exports){
var bn = require('bn.js');
var brorand = require('brorand');

function MillerRabin(rand) {
  this.rand = rand || new brorand.Rand();
}
module.exports = MillerRabin;

MillerRabin.create = function create(rand) {
  return new MillerRabin(rand);
};

MillerRabin.prototype._randbelow = function _randbelow(n) {
  var len = n.bitLength();
  var min_bytes = Math.ceil(len / 8);

  // Generage random bytes until a number less than n is found.
  // This ensures that 0..n-1 have an equal probability of being selected.
  do
    var a = new bn(this.rand.generate(min_bytes));
  while (a.cmp(n) >= 0);

  return a;
};

MillerRabin.prototype._randrange = function _randrange(start, stop) {
  // Generate a random number greater than or equal to start and less than stop.
  var size = stop.sub(start);
  return start.add(this._randbelow(size));
};

MillerRabin.prototype.test = function test(n, k, cb) {
  var len = n.bitLength();
  var red = bn.mont(n);
  var rone = new bn(1).toRed(red);

  if (!k)
    k = Math.max(1, (len / 48) | 0);

  // Find d and s, (n - 1) = (2 ^ s) * d;
  var n1 = n.subn(1);
  for (var s = 0; !n1.testn(s); s++) {}
  var d = n.shrn(s);

  var rn1 = n1.toRed(red);

  var prime = true;
  for (; k > 0; k--) {
    var a = this._randrange(new bn(2), n1);
    if (cb)
      cb(a);

    var x = a.toRed(red).redPow(d);
    if (x.cmp(rone) === 0 || x.cmp(rn1) === 0)
      continue;

    for (var i = 1; i < s; i++) {
      x = x.redSqr();

      if (x.cmp(rone) === 0)
        return false;
      if (x.cmp(rn1) === 0)
        break;
    }

    if (i === s)
      return false;
  }

  return prime;
};

MillerRabin.prototype.getDivisor = function getDivisor(n, k) {
  var len = n.bitLength();
  var red = bn.mont(n);
  var rone = new bn(1).toRed(red);

  if (!k)
    k = Math.max(1, (len / 48) | 0);

  // Find d and s, (n - 1) = (2 ^ s) * d;
  var n1 = n.subn(1);
  for (var s = 0; !n1.testn(s); s++) {}
  var d = n.shrn(s);

  var rn1 = n1.toRed(red);

  for (; k > 0; k--) {
    var a = this._randrange(new bn(2), n1);

    var g = n.gcd(a);
    if (g.cmpn(1) !== 0)
      return g;

    var x = a.toRed(red).redPow(d);
    if (x.cmp(rone) === 0 || x.cmp(rn1) === 0)
      continue;

    for (var i = 1; i < s; i++) {
      x = x.redSqr();

      if (x.cmp(rone) === 0)
        return x.fromRed().subn(1).gcd(n);
      if (x.cmp(rn1) === 0)
        break;
    }

    if (i === s) {
      x = x.redSqr();
      return x.fromRed().subn(1).gcd(n);
    }
  }

  return false;
};

},{"bn.js":163,"brorand":44}],163:[function(require,module,exports){
arguments[4][41][0].apply(exports,arguments)
},{"buffer":45,"dup":41}],164:[function(require,module,exports){
module.exports = assert;

function assert(val, msg) {
  if (!val)
    throw new Error(msg || 'Assertion failed');
}

assert.equal = function assertEqual(l, r, msg) {
  if (l != r)
    throw new Error(msg || ('Assertion failed: ' + l + ' != ' + r));
};

},{}],165:[function(require,module,exports){
'use strict';

var utils = exports;

function toArray(msg, enc) {
  if (Array.isArray(msg))
    return msg.slice();
  if (!msg)
    return [];
  var res = [];
  if (typeof msg !== 'string') {
    for (var i = 0; i < msg.length; i++)
      res[i] = msg[i] | 0;
    return res;
  }
  if (enc === 'hex') {
    msg = msg.replace(/[^a-z0-9]+/ig, '');
    if (msg.length % 2 !== 0)
      msg = '0' + msg;
    for (var i = 0; i < msg.length; i += 2)
      res.push(parseInt(msg[i] + msg[i + 1], 16));
  } else {
    for (var i = 0; i < msg.length; i++) {
      var c = msg.charCodeAt(i);
      var hi = c >> 8;
      var lo = c & 0xff;
      if (hi)
        res.push(hi, lo);
      else
        res.push(lo);
    }
  }
  return res;
}
utils.toArray = toArray;

function zero2(word) {
  if (word.length === 1)
    return '0' + word;
  else
    return word;
}
utils.zero2 = zero2;

function toHex(msg) {
  var res = '';
  for (var i = 0; i < msg.length; i++)
    res += zero2(msg[i].toString(16));
  return res;
}
utils.toHex = toHex;

utils.encode = function encode(arr, enc) {
  if (enc === 'hex')
    return toHex(arr);
  else
    return arr;
};

},{}],166:[function(require,module,exports){
exports.endianness = function () { return 'LE' };

exports.hostname = function () {
    if (typeof location !== 'undefined') {
        return location.hostname
    }
    else return '';
};

exports.loadavg = function () { return [] };

exports.uptime = function () { return 0 };

exports.freemem = function () {
    return Number.MAX_VALUE;
};

exports.totalmem = function () {
    return Number.MAX_VALUE;
};

exports.cpus = function () { return [] };

exports.type = function () { return 'Browser' };

exports.release = function () {
    if (typeof navigator !== 'undefined') {
        return navigator.appVersion;
    }
    return '';
};

exports.networkInterfaces
= exports.getNetworkInterfaces
= function () { return {} };

exports.arch = function () { return 'javascript' };

exports.platform = function () { return 'browser' };

exports.tmpdir = exports.tmpDir = function () {
    return '/tmp';
};

exports.EOL = '\n';

exports.homedir = function () {
	return '/'
};

},{}],167:[function(require,module,exports){
module.exports={"2.16.840.1.101.3.4.1.1": "aes-128-ecb",
"2.16.840.1.101.3.4.1.2": "aes-128-cbc",
"2.16.840.1.101.3.4.1.3": "aes-128-ofb",
"2.16.840.1.101.3.4.1.4": "aes-128-cfb",
"2.16.840.1.101.3.4.1.21": "aes-192-ecb",
"2.16.840.1.101.3.4.1.22": "aes-192-cbc",
"2.16.840.1.101.3.4.1.23": "aes-192-ofb",
"2.16.840.1.101.3.4.1.24": "aes-192-cfb",
"2.16.840.1.101.3.4.1.41": "aes-256-ecb",
"2.16.840.1.101.3.4.1.42": "aes-256-cbc",
"2.16.840.1.101.3.4.1.43": "aes-256-ofb",
"2.16.840.1.101.3.4.1.44": "aes-256-cfb"
}
},{}],168:[function(require,module,exports){
// from https://github.com/indutny/self-signed/blob/gh-pages/lib/asn1.js
// Fedor, you are amazing.
'use strict'

var asn1 = require('asn1.js')

exports.certificate = require('./certificate')

var RSAPrivateKey = asn1.define('RSAPrivateKey', function () {
  this.seq().obj(
    this.key('version').int(),
    this.key('modulus').int(),
    this.key('publicExponent').int(),
    this.key('privateExponent').int(),
    this.key('prime1').int(),
    this.key('prime2').int(),
    this.key('exponent1').int(),
    this.key('exponent2').int(),
    this.key('coefficient').int()
  )
})
exports.RSAPrivateKey = RSAPrivateKey

var RSAPublicKey = asn1.define('RSAPublicKey', function () {
  this.seq().obj(
    this.key('modulus').int(),
    this.key('publicExponent').int()
  )
})
exports.RSAPublicKey = RSAPublicKey

var PublicKey = asn1.define('SubjectPublicKeyInfo', function () {
  this.seq().obj(
    this.key('algorithm').use(AlgorithmIdentifier),
    this.key('subjectPublicKey').bitstr()
  )
})
exports.PublicKey = PublicKey

var AlgorithmIdentifier = asn1.define('AlgorithmIdentifier', function () {
  this.seq().obj(
    this.key('algorithm').objid(),
    this.key('none').null_().optional(),
    this.key('curve').objid().optional(),
    this.key('params').seq().obj(
      this.key('p').int(),
      this.key('q').int(),
      this.key('g').int()
    ).optional()
  )
})

var PrivateKeyInfo = asn1.define('PrivateKeyInfo', function () {
  this.seq().obj(
    this.key('version').int(),
    this.key('algorithm').use(AlgorithmIdentifier),
    this.key('subjectPrivateKey').octstr()
  )
})
exports.PrivateKey = PrivateKeyInfo
var EncryptedPrivateKeyInfo = asn1.define('EncryptedPrivateKeyInfo', function () {
  this.seq().obj(
    this.key('algorithm').seq().obj(
      this.key('id').objid(),
      this.key('decrypt').seq().obj(
        this.key('kde').seq().obj(
          this.key('id').objid(),
          this.key('kdeparams').seq().obj(
            this.key('salt').octstr(),
            this.key('iters').int()
          )
        ),
        this.key('cipher').seq().obj(
          this.key('algo').objid(),
          this.key('iv').octstr()
        )
      )
    ),
    this.key('subjectPrivateKey').octstr()
  )
})

exports.EncryptedPrivateKey = EncryptedPrivateKeyInfo

var DSAPrivateKey = asn1.define('DSAPrivateKey', function () {
  this.seq().obj(
    this.key('version').int(),
    this.key('p').int(),
    this.key('q').int(),
    this.key('g').int(),
    this.key('pub_key').int(),
    this.key('priv_key').int()
  )
})
exports.DSAPrivateKey = DSAPrivateKey

exports.DSAparam = asn1.define('DSAparam', function () {
  this.int()
})

var ECPrivateKey = asn1.define('ECPrivateKey', function () {
  this.seq().obj(
    this.key('version').int(),
    this.key('privateKey').octstr(),
    this.key('parameters').optional().explicit(0).use(ECParameters),
    this.key('publicKey').optional().explicit(1).bitstr()
  )
})
exports.ECPrivateKey = ECPrivateKey

var ECParameters = asn1.define('ECParameters', function () {
  this.choice({
    namedCurve: this.objid()
  })
})

exports.signature = asn1.define('signature', function () {
  this.seq().obj(
    this.key('r').int(),
    this.key('s').int()
  )
})

},{"./certificate":169,"asn1.js":27}],169:[function(require,module,exports){
// from https://github.com/Rantanen/node-dtls/blob/25a7dc861bda38cfeac93a723500eea4f0ac2e86/Certificate.js
// thanks to @Rantanen

'use strict'

var asn = require('asn1.js')

var Time = asn.define('Time', function () {
  this.choice({
    utcTime: this.utctime(),
    generalTime: this.gentime()
  })
})

var AttributeTypeValue = asn.define('AttributeTypeValue', function () {
  this.seq().obj(
    this.key('type').objid(),
    this.key('value').any()
  )
})

var AlgorithmIdentifier = asn.define('AlgorithmIdentifier', function () {
  this.seq().obj(
    this.key('algorithm').objid(),
    this.key('parameters').optional(),
    this.key('curve').objid().optional()
  )
})

var SubjectPublicKeyInfo = asn.define('SubjectPublicKeyInfo', function () {
  this.seq().obj(
    this.key('algorithm').use(AlgorithmIdentifier),
    this.key('subjectPublicKey').bitstr()
  )
})

var RelativeDistinguishedName = asn.define('RelativeDistinguishedName', function () {
  this.setof(AttributeTypeValue)
})

var RDNSequence = asn.define('RDNSequence', function () {
  this.seqof(RelativeDistinguishedName)
})

var Name = asn.define('Name', function () {
  this.choice({
    rdnSequence: this.use(RDNSequence)
  })
})

var Validity = asn.define('Validity', function () {
  this.seq().obj(
    this.key('notBefore').use(Time),
    this.key('notAfter').use(Time)
  )
})

var Extension = asn.define('Extension', function () {
  this.seq().obj(
    this.key('extnID').objid(),
    this.key('critical').bool().def(false),
    this.key('extnValue').octstr()
  )
})

var TBSCertificate = asn.define('TBSCertificate', function () {
  this.seq().obj(
    this.key('version').explicit(0).int().optional(),
    this.key('serialNumber').int(),
    this.key('signature').use(AlgorithmIdentifier),
    this.key('issuer').use(Name),
    this.key('validity').use(Validity),
    this.key('subject').use(Name),
    this.key('subjectPublicKeyInfo').use(SubjectPublicKeyInfo),
    this.key('issuerUniqueID').implicit(1).bitstr().optional(),
    this.key('subjectUniqueID').implicit(2).bitstr().optional(),
    this.key('extensions').explicit(3).seqof(Extension).optional()
  )
})

var X509Certificate = asn.define('X509Certificate', function () {
  this.seq().obj(
    this.key('tbsCertificate').use(TBSCertificate),
    this.key('signatureAlgorithm').use(AlgorithmIdentifier),
    this.key('signatureValue').bitstr()
  )
})

module.exports = X509Certificate

},{"asn1.js":27}],170:[function(require,module,exports){
// adapted from https://github.com/apatil/pemstrip
var findProc = /Proc-Type: 4,ENCRYPTED[\n\r]+DEK-Info: AES-((?:128)|(?:192)|(?:256))-CBC,([0-9A-H]+)[\n\r]+([0-9A-z\n\r+/=]+)[\n\r]+/m
var startRegex = /^-----BEGIN ((?:.*? KEY)|CERTIFICATE)-----/m
var fullRegex = /^-----BEGIN ((?:.*? KEY)|CERTIFICATE)-----([0-9A-z\n\r+/=]+)-----END \1-----$/m
var evp = require('evp_bytestokey')
var ciphers = require('browserify-aes')
var Buffer = require('safe-buffer').Buffer
module.exports = function (okey, password) {
  var key = okey.toString()
  var match = key.match(findProc)
  var decrypted
  if (!match) {
    var match2 = key.match(fullRegex)
    decrypted = Buffer.from(match2[2].replace(/[\r\n]/g, ''), 'base64')
  } else {
    var suite = 'aes' + match[1]
    var iv = Buffer.from(match[2], 'hex')
    var cipherText = Buffer.from(match[3].replace(/[\r\n]/g, ''), 'base64')
    var cipherKey = evp(password, iv.slice(0, 8), parseInt(match[1], 10)).key
    var out = []
    var cipher = ciphers.createDecipheriv(suite, cipherKey, iv)
    out.push(cipher.update(cipherText))
    out.push(cipher.final())
    decrypted = Buffer.concat(out)
  }
  var tag = key.match(startRegex)[1]
  return {
    tag: tag,
    data: decrypted
  }
}

},{"browserify-aes":48,"evp_bytestokey":119,"safe-buffer":215}],171:[function(require,module,exports){
var asn1 = require('./asn1')
var aesid = require('./aesid.json')
var fixProc = require('./fixProc')
var ciphers = require('browserify-aes')
var compat = require('pbkdf2')
var Buffer = require('safe-buffer').Buffer
module.exports = parseKeys

function parseKeys (buffer) {
  var password
  if (typeof buffer === 'object' && !Buffer.isBuffer(buffer)) {
    password = buffer.passphrase
    buffer = buffer.key
  }
  if (typeof buffer === 'string') {
    buffer = Buffer.from(buffer)
  }

  var stripped = fixProc(buffer, password)

  var type = stripped.tag
  var data = stripped.data
  var subtype, ndata
  switch (type) {
    case 'CERTIFICATE':
      ndata = asn1.certificate.decode(data, 'der').tbsCertificate.subjectPublicKeyInfo
      // falls through
    case 'PUBLIC KEY':
      if (!ndata) {
        ndata = asn1.PublicKey.decode(data, 'der')
      }
      subtype = ndata.algorithm.algorithm.join('.')
      switch (subtype) {
        case '1.2.840.113549.1.1.1':
          return asn1.RSAPublicKey.decode(ndata.subjectPublicKey.data, 'der')
        case '1.2.840.10045.2.1':
          ndata.subjectPrivateKey = ndata.subjectPublicKey
          return {
            type: 'ec',
            data: ndata
          }
        case '1.2.840.10040.4.1':
          ndata.algorithm.params.pub_key = asn1.DSAparam.decode(ndata.subjectPublicKey.data, 'der')
          return {
            type: 'dsa',
            data: ndata.algorithm.params
          }
        default: throw new Error('unknown key id ' + subtype)
      }
      // throw new Error('unknown key type ' + type)
    case 'ENCRYPTED PRIVATE KEY':
      data = asn1.EncryptedPrivateKey.decode(data, 'der')
      data = decrypt(data, password)
      // falls through
    case 'PRIVATE KEY':
      ndata = asn1.PrivateKey.decode(data, 'der')
      subtype = ndata.algorithm.algorithm.join('.')
      switch (subtype) {
        case '1.2.840.113549.1.1.1':
          return asn1.RSAPrivateKey.decode(ndata.subjectPrivateKey, 'der')
        case '1.2.840.10045.2.1':
          return {
            curve: ndata.algorithm.curve,
            privateKey: asn1.ECPrivateKey.decode(ndata.subjectPrivateKey, 'der').privateKey
          }
        case '1.2.840.10040.4.1':
          ndata.algorithm.params.priv_key = asn1.DSAparam.decode(ndata.subjectPrivateKey, 'der')
          return {
            type: 'dsa',
            params: ndata.algorithm.params
          }
        default: throw new Error('unknown key id ' + subtype)
      }
      // throw new Error('unknown key type ' + type)
    case 'RSA PUBLIC KEY':
      return asn1.RSAPublicKey.decode(data, 'der')
    case 'RSA PRIVATE KEY':
      return asn1.RSAPrivateKey.decode(data, 'der')
    case 'DSA PRIVATE KEY':
      return {
        type: 'dsa',
        params: asn1.DSAPrivateKey.decode(data, 'der')
      }
    case 'EC PRIVATE KEY':
      data = asn1.ECPrivateKey.decode(data, 'der')
      return {
        curve: data.parameters.value,
        privateKey: data.privateKey
      }
    default: throw new Error('unknown key type ' + type)
  }
}
parseKeys.signature = asn1.signature
function decrypt (data, password) {
  var salt = data.algorithm.decrypt.kde.kdeparams.salt
  var iters = parseInt(data.algorithm.decrypt.kde.kdeparams.iters.toString(), 10)
  var algo = aesid[data.algorithm.decrypt.cipher.algo.join('.')]
  var iv = data.algorithm.decrypt.cipher.iv
  var cipherText = data.subjectPrivateKey
  var keylen = parseInt(algo.split('-')[1], 10) / 8
  var key = compat.pbkdf2Sync(password, salt, iters, keylen, 'sha1')
  var cipher = ciphers.createDecipheriv(algo, key, iv)
  var out = []
  out.push(cipher.update(cipherText))
  out.push(cipher.final())
  return Buffer.concat(out)
}

},{"./aesid.json":167,"./asn1":168,"./fixProc":170,"browserify-aes":48,"pbkdf2":173,"safe-buffer":215}],172:[function(require,module,exports){
(function (process){(function (){
// 'path' module extracted from Node.js v8.11.1 (only the posix part)
// transplited with Babel

// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

'use strict';

function assertPath(path) {
  if (typeof path !== 'string') {
    throw new TypeError('Path must be a string. Received ' + JSON.stringify(path));
  }
}

// Resolves . and .. elements in a path with directory names
function normalizeStringPosix(path, allowAboveRoot) {
  var res = '';
  var lastSegmentLength = 0;
  var lastSlash = -1;
  var dots = 0;
  var code;
  for (var i = 0; i <= path.length; ++i) {
    if (i < path.length)
      code = path.charCodeAt(i);
    else if (code === 47 /*/*/)
      break;
    else
      code = 47 /*/*/;
    if (code === 47 /*/*/) {
      if (lastSlash === i - 1 || dots === 1) {
        // NOOP
      } else if (lastSlash !== i - 1 && dots === 2) {
        if (res.length < 2 || lastSegmentLength !== 2 || res.charCodeAt(res.length - 1) !== 46 /*.*/ || res.charCodeAt(res.length - 2) !== 46 /*.*/) {
          if (res.length > 2) {
            var lastSlashIndex = res.lastIndexOf('/');
            if (lastSlashIndex !== res.length - 1) {
              if (lastSlashIndex === -1) {
                res = '';
                lastSegmentLength = 0;
              } else {
                res = res.slice(0, lastSlashIndex);
                lastSegmentLength = res.length - 1 - res.lastIndexOf('/');
              }
              lastSlash = i;
              dots = 0;
              continue;
            }
          } else if (res.length === 2 || res.length === 1) {
            res = '';
            lastSegmentLength = 0;
            lastSlash = i;
            dots = 0;
            continue;
          }
        }
        if (allowAboveRoot) {
          if (res.length > 0)
            res += '/..';
          else
            res = '..';
          lastSegmentLength = 2;
        }
      } else {
        if (res.length > 0)
          res += '/' + path.slice(lastSlash + 1, i);
        else
          res = path.slice(lastSlash + 1, i);
        lastSegmentLength = i - lastSlash - 1;
      }
      lastSlash = i;
      dots = 0;
    } else if (code === 46 /*.*/ && dots !== -1) {
      ++dots;
    } else {
      dots = -1;
    }
  }
  return res;
}

function _format(sep, pathObject) {
  var dir = pathObject.dir || pathObject.root;
  var base = pathObject.base || (pathObject.name || '') + (pathObject.ext || '');
  if (!dir) {
    return base;
  }
  if (dir === pathObject.root) {
    return dir + base;
  }
  return dir + sep + base;
}

var posix = {
  // path.resolve([from ...], to)
  resolve: function resolve() {
    var resolvedPath = '';
    var resolvedAbsolute = false;
    var cwd;

    for (var i = arguments.length - 1; i >= -1 && !resolvedAbsolute; i--) {
      var path;
      if (i >= 0)
        path = arguments[i];
      else {
        if (cwd === undefined)
          cwd = process.cwd();
        path = cwd;
      }

      assertPath(path);

      // Skip empty entries
      if (path.length === 0) {
        continue;
      }

      resolvedPath = path + '/' + resolvedPath;
      resolvedAbsolute = path.charCodeAt(0) === 47 /*/*/;
    }

    // At this point the path should be resolved to a full absolute path, but
    // handle relative paths to be safe (might happen when process.cwd() fails)

    // Normalize the path
    resolvedPath = normalizeStringPosix(resolvedPath, !resolvedAbsolute);

    if (resolvedAbsolute) {
      if (resolvedPath.length > 0)
        return '/' + resolvedPath;
      else
        return '/';
    } else if (resolvedPath.length > 0) {
      return resolvedPath;
    } else {
      return '.';
    }
  },

  normalize: function normalize(path) {
    assertPath(path);

    if (path.length === 0) return '.';

    var isAbsolute = path.charCodeAt(0) === 47 /*/*/;
    var trailingSeparator = path.charCodeAt(path.length - 1) === 47 /*/*/;

    // Normalize the path
    path = normalizeStringPosix(path, !isAbsolute);

    if (path.length === 0 && !isAbsolute) path = '.';
    if (path.length > 0 && trailingSeparator) path += '/';

    if (isAbsolute) return '/' + path;
    return path;
  },

  isAbsolute: function isAbsolute(path) {
    assertPath(path);
    return path.length > 0 && path.charCodeAt(0) === 47 /*/*/;
  },

  join: function join() {
    if (arguments.length === 0)
      return '.';
    var joined;
    for (var i = 0; i < arguments.length; ++i) {
      var arg = arguments[i];
      assertPath(arg);
      if (arg.length > 0) {
        if (joined === undefined)
          joined = arg;
        else
          joined += '/' + arg;
      }
    }
    if (joined === undefined)
      return '.';
    return posix.normalize(joined);
  },

  relative: function relative(from, to) {
    assertPath(from);
    assertPath(to);

    if (from === to) return '';

    from = posix.resolve(from);
    to = posix.resolve(to);

    if (from === to) return '';

    // Trim any leading backslashes
    var fromStart = 1;
    for (; fromStart < from.length; ++fromStart) {
      if (from.charCodeAt(fromStart) !== 47 /*/*/)
        break;
    }
    var fromEnd = from.length;
    var fromLen = fromEnd - fromStart;

    // Trim any leading backslashes
    var toStart = 1;
    for (; toStart < to.length; ++toStart) {
      if (to.charCodeAt(toStart) !== 47 /*/*/)
        break;
    }
    var toEnd = to.length;
    var toLen = toEnd - toStart;

    // Compare paths to find the longest common path from root
    var length = fromLen < toLen ? fromLen : toLen;
    var lastCommonSep = -1;
    var i = 0;
    for (; i <= length; ++i) {
      if (i === length) {
        if (toLen > length) {
          if (to.charCodeAt(toStart + i) === 47 /*/*/) {
            // We get here if `from` is the exact base path for `to`.
            // For example: from='/foo/bar'; to='/foo/bar/baz'
            return to.slice(toStart + i + 1);
          } else if (i === 0) {
            // We get here if `from` is the root
            // For example: from='/'; to='/foo'
            return to.slice(toStart + i);
          }
        } else if (fromLen > length) {
          if (from.charCodeAt(fromStart + i) === 47 /*/*/) {
            // We get here if `to` is the exact base path for `from`.
            // For example: from='/foo/bar/baz'; to='/foo/bar'
            lastCommonSep = i;
          } else if (i === 0) {
            // We get here if `to` is the root.
            // For example: from='/foo'; to='/'
            lastCommonSep = 0;
          }
        }
        break;
      }
      var fromCode = from.charCodeAt(fromStart + i);
      var toCode = to.charCodeAt(toStart + i);
      if (fromCode !== toCode)
        break;
      else if (fromCode === 47 /*/*/)
        lastCommonSep = i;
    }

    var out = '';
    // Generate the relative path based on the path difference between `to`
    // and `from`
    for (i = fromStart + lastCommonSep + 1; i <= fromEnd; ++i) {
      if (i === fromEnd || from.charCodeAt(i) === 47 /*/*/) {
        if (out.length === 0)
          out += '..';
        else
          out += '/..';
      }
    }

    // Lastly, append the rest of the destination (`to`) path that comes after
    // the common path parts
    if (out.length > 0)
      return out + to.slice(toStart + lastCommonSep);
    else {
      toStart += lastCommonSep;
      if (to.charCodeAt(toStart) === 47 /*/*/)
        ++toStart;
      return to.slice(toStart);
    }
  },

  _makeLong: function _makeLong(path) {
    return path;
  },

  dirname: function dirname(path) {
    assertPath(path);
    if (path.length === 0) return '.';
    var code = path.charCodeAt(0);
    var hasRoot = code === 47 /*/*/;
    var end = -1;
    var matchedSlash = true;
    for (var i = path.length - 1; i >= 1; --i) {
      code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          if (!matchedSlash) {
            end = i;
            break;
          }
        } else {
        // We saw the first non-path separator
        matchedSlash = false;
      }
    }

    if (end === -1) return hasRoot ? '/' : '.';
    if (hasRoot && end === 1) return '//';
    return path.slice(0, end);
  },

  basename: function basename(path, ext) {
    if (ext !== undefined && typeof ext !== 'string') throw new TypeError('"ext" argument must be a string');
    assertPath(path);

    var start = 0;
    var end = -1;
    var matchedSlash = true;
    var i;

    if (ext !== undefined && ext.length > 0 && ext.length <= path.length) {
      if (ext.length === path.length && ext === path) return '';
      var extIdx = ext.length - 1;
      var firstNonSlashEnd = -1;
      for (i = path.length - 1; i >= 0; --i) {
        var code = path.charCodeAt(i);
        if (code === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1;
              break;
            }
          } else {
          if (firstNonSlashEnd === -1) {
            // We saw the first non-path separator, remember this index in case
            // we need it if the extension ends up not matching
            matchedSlash = false;
            firstNonSlashEnd = i + 1;
          }
          if (extIdx >= 0) {
            // Try to match the explicit extension
            if (code === ext.charCodeAt(extIdx)) {
              if (--extIdx === -1) {
                // We matched the extension, so mark this as the end of our path
                // component
                end = i;
              }
            } else {
              // Extension does not match, so our result is the entire path
              // component
              extIdx = -1;
              end = firstNonSlashEnd;
            }
          }
        }
      }

      if (start === end) end = firstNonSlashEnd;else if (end === -1) end = path.length;
      return path.slice(start, end);
    } else {
      for (i = path.length - 1; i >= 0; --i) {
        if (path.charCodeAt(i) === 47 /*/*/) {
            // If we reached a path separator that was not part of a set of path
            // separators at the end of the string, stop now
            if (!matchedSlash) {
              start = i + 1;
              break;
            }
          } else if (end === -1) {
          // We saw the first non-path separator, mark this as the end of our
          // path component
          matchedSlash = false;
          end = i + 1;
        }
      }

      if (end === -1) return '';
      return path.slice(start, end);
    }
  },

  extname: function extname(path) {
    assertPath(path);
    var startDot = -1;
    var startPart = 0;
    var end = -1;
    var matchedSlash = true;
    // Track the state of characters (if any) we see before our first dot and
    // after any path separator we find
    var preDotState = 0;
    for (var i = path.length - 1; i >= 0; --i) {
      var code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1;
            break;
          }
          continue;
        }
      if (end === -1) {
        // We saw the first non-path separator, mark this as the end of our
        // extension
        matchedSlash = false;
        end = i + 1;
      }
      if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1)
            startDot = i;
          else if (preDotState !== 1)
            preDotState = 1;
      } else if (startDot !== -1) {
        // We saw a non-dot and non-path separator before our dot, so we should
        // have a good chance at having a non-empty extension
        preDotState = -1;
      }
    }

    if (startDot === -1 || end === -1 ||
        // We saw a non-dot character immediately before the dot
        preDotState === 0 ||
        // The (right-most) trimmed path component is exactly '..'
        preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {
      return '';
    }
    return path.slice(startDot, end);
  },

  format: function format(pathObject) {
    if (pathObject === null || typeof pathObject !== 'object') {
      throw new TypeError('The "pathObject" argument must be of type Object. Received type ' + typeof pathObject);
    }
    return _format('/', pathObject);
  },

  parse: function parse(path) {
    assertPath(path);

    var ret = { root: '', dir: '', base: '', ext: '', name: '' };
    if (path.length === 0) return ret;
    var code = path.charCodeAt(0);
    var isAbsolute = code === 47 /*/*/;
    var start;
    if (isAbsolute) {
      ret.root = '/';
      start = 1;
    } else {
      start = 0;
    }
    var startDot = -1;
    var startPart = 0;
    var end = -1;
    var matchedSlash = true;
    var i = path.length - 1;

    // Track the state of characters (if any) we see before our first dot and
    // after any path separator we find
    var preDotState = 0;

    // Get non-dir info
    for (; i >= start; --i) {
      code = path.charCodeAt(i);
      if (code === 47 /*/*/) {
          // If we reached a path separator that was not part of a set of path
          // separators at the end of the string, stop now
          if (!matchedSlash) {
            startPart = i + 1;
            break;
          }
          continue;
        }
      if (end === -1) {
        // We saw the first non-path separator, mark this as the end of our
        // extension
        matchedSlash = false;
        end = i + 1;
      }
      if (code === 46 /*.*/) {
          // If this is our first dot, mark it as the start of our extension
          if (startDot === -1) startDot = i;else if (preDotState !== 1) preDotState = 1;
        } else if (startDot !== -1) {
        // We saw a non-dot and non-path separator before our dot, so we should
        // have a good chance at having a non-empty extension
        preDotState = -1;
      }
    }

    if (startDot === -1 || end === -1 ||
    // We saw a non-dot character immediately before the dot
    preDotState === 0 ||
    // The (right-most) trimmed path component is exactly '..'
    preDotState === 1 && startDot === end - 1 && startDot === startPart + 1) {
      if (end !== -1) {
        if (startPart === 0 && isAbsolute) ret.base = ret.name = path.slice(1, end);else ret.base = ret.name = path.slice(startPart, end);
      }
    } else {
      if (startPart === 0 && isAbsolute) {
        ret.name = path.slice(1, startDot);
        ret.base = path.slice(1, end);
      } else {
        ret.name = path.slice(startPart, startDot);
        ret.base = path.slice(startPart, end);
      }
      ret.ext = path.slice(startDot, end);
    }

    if (startPart > 0) ret.dir = path.slice(0, startPart - 1);else if (isAbsolute) ret.dir = '/';

    return ret;
  },

  sep: '/',
  delimiter: ':',
  win32: null,
  posix: null
};

posix.posix = posix;

module.exports = posix;

}).call(this)}).call(this,require('_process'))
},{"_process":179}],173:[function(require,module,exports){
exports.pbkdf2 = require('./lib/async')
exports.pbkdf2Sync = require('./lib/sync')

},{"./lib/async":174,"./lib/sync":177}],174:[function(require,module,exports){
(function (global){(function (){
var Buffer = require('safe-buffer').Buffer

var checkParameters = require('./precondition')
var defaultEncoding = require('./default-encoding')
var sync = require('./sync')
var toBuffer = require('./to-buffer')

var ZERO_BUF
var subtle = global.crypto && global.crypto.subtle
var toBrowser = {
  sha: 'SHA-1',
  'sha-1': 'SHA-1',
  sha1: 'SHA-1',
  sha256: 'SHA-256',
  'sha-256': 'SHA-256',
  sha384: 'SHA-384',
  'sha-384': 'SHA-384',
  'sha-512': 'SHA-512',
  sha512: 'SHA-512'
}
var checks = []
function checkNative (algo) {
  if (global.process && !global.process.browser) {
    return Promise.resolve(false)
  }
  if (!subtle || !subtle.importKey || !subtle.deriveBits) {
    return Promise.resolve(false)
  }
  if (checks[algo] !== undefined) {
    return checks[algo]
  }
  ZERO_BUF = ZERO_BUF || Buffer.alloc(8)
  var prom = browserPbkdf2(ZERO_BUF, ZERO_BUF, 10, 128, algo)
    .then(function () {
      return true
    }).catch(function () {
      return false
    })
  checks[algo] = prom
  return prom
}
var nextTick
function getNextTick () {
  if (nextTick) {
    return nextTick
  }
  if (global.process && global.process.nextTick) {
    nextTick = global.process.nextTick
  } else if (global.queueMicrotask) {
    nextTick = global.queueMicrotask
  } else if (global.setImmediate) {
    nextTick = global.setImmediate
  } else {
    nextTick = global.setTimeout
  }
  return nextTick
}
function browserPbkdf2 (password, salt, iterations, length, algo) {
  return subtle.importKey(
    'raw', password, { name: 'PBKDF2' }, false, ['deriveBits']
  ).then(function (key) {
    return subtle.deriveBits({
      name: 'PBKDF2',
      salt: salt,
      iterations: iterations,
      hash: {
        name: algo
      }
    }, key, length << 3)
  }).then(function (res) {
    return Buffer.from(res)
  })
}

function resolvePromise (promise, callback) {
  promise.then(function (out) {
    getNextTick()(function () {
      callback(null, out)
    })
  }, function (e) {
    getNextTick()(function () {
      callback(e)
    })
  })
}
module.exports = function (password, salt, iterations, keylen, digest, callback) {
  if (typeof digest === 'function') {
    callback = digest
    digest = undefined
  }

  digest = digest || 'sha1'
  var algo = toBrowser[digest.toLowerCase()]

  if (!algo || typeof global.Promise !== 'function') {
    getNextTick()(function () {
      var out
      try {
        out = sync(password, salt, iterations, keylen, digest)
      } catch (e) {
        return callback(e)
      }
      callback(null, out)
    })
    return
  }

  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')
  if (typeof callback !== 'function') throw new Error('No callback provided to pbkdf2')

  resolvePromise(checkNative(algo).then(function (resp) {
    if (resp) return browserPbkdf2(password, salt, iterations, keylen, algo)

    return sync(password, salt, iterations, keylen, digest)
  }), callback)
}

}).call(this)}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"./default-encoding":175,"./precondition":176,"./sync":177,"./to-buffer":178,"safe-buffer":215}],175:[function(require,module,exports){
(function (process,global){(function (){
var defaultEncoding
/* istanbul ignore next */
if (global.process && global.process.browser) {
  defaultEncoding = 'utf-8'
} else if (global.process && global.process.version) {
  var pVersionMajor = parseInt(process.version.split('.')[0].slice(1), 10)

  defaultEncoding = pVersionMajor >= 6 ? 'utf-8' : 'binary'
} else {
  defaultEncoding = 'utf-8'
}
module.exports = defaultEncoding

}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":179}],176:[function(require,module,exports){
var MAX_ALLOC = Math.pow(2, 30) - 1 // default in iojs

module.exports = function (iterations, keylen) {
  if (typeof iterations !== 'number') {
    throw new TypeError('Iterations not a number')
  }

  if (iterations < 0) {
    throw new TypeError('Bad iterations')
  }

  if (typeof keylen !== 'number') {
    throw new TypeError('Key length not a number')
  }

  if (keylen < 0 || keylen > MAX_ALLOC || keylen !== keylen) { /* eslint no-self-compare: 0 */
    throw new TypeError('Bad key length')
  }
}

},{}],177:[function(require,module,exports){
var md5 = require('create-hash/md5')
var RIPEMD160 = require('ripemd160')
var sha = require('sha.js')
var Buffer = require('safe-buffer').Buffer

var checkParameters = require('./precondition')
var defaultEncoding = require('./default-encoding')
var toBuffer = require('./to-buffer')

var ZEROS = Buffer.alloc(128)
var sizes = {
  md5: 16,
  sha1: 20,
  sha224: 28,
  sha256: 32,
  sha384: 48,
  sha512: 64,
  rmd160: 20,
  ripemd160: 20
}

function Hmac (alg, key, saltLen) {
  var hash = getDigest(alg)
  var blocksize = (alg === 'sha512' || alg === 'sha384') ? 128 : 64

  if (key.length > blocksize) {
    key = hash(key)
  } else if (key.length < blocksize) {
    key = Buffer.concat([key, ZEROS], blocksize)
  }

  var ipad = Buffer.allocUnsafe(blocksize + sizes[alg])
  var opad = Buffer.allocUnsafe(blocksize + sizes[alg])
  for (var i = 0; i < blocksize; i++) {
    ipad[i] = key[i] ^ 0x36
    opad[i] = key[i] ^ 0x5C
  }

  var ipad1 = Buffer.allocUnsafe(blocksize + saltLen + 4)
  ipad.copy(ipad1, 0, 0, blocksize)
  this.ipad1 = ipad1
  this.ipad2 = ipad
  this.opad = opad
  this.alg = alg
  this.blocksize = blocksize
  this.hash = hash
  this.size = sizes[alg]
}

Hmac.prototype.run = function (data, ipad) {
  data.copy(ipad, this.blocksize)
  var h = this.hash(ipad)
  h.copy(this.opad, this.blocksize)
  return this.hash(this.opad)
}

function getDigest (alg) {
  function shaFunc (data) {
    return sha(alg).update(data).digest()
  }
  function rmd160Func (data) {
    return new RIPEMD160().update(data).digest()
  }

  if (alg === 'rmd160' || alg === 'ripemd160') return rmd160Func
  if (alg === 'md5') return md5
  return shaFunc
}

function pbkdf2 (password, salt, iterations, keylen, digest) {
  checkParameters(iterations, keylen)
  password = toBuffer(password, defaultEncoding, 'Password')
  salt = toBuffer(salt, defaultEncoding, 'Salt')

  digest = digest || 'sha1'

  var hmac = new Hmac(digest, password, salt.length)

  var DK = Buffer.allocUnsafe(keylen)
  var block1 = Buffer.allocUnsafe(salt.length + 4)
  salt.copy(block1, 0, 0, salt.length)

  var destPos = 0
  var hLen = sizes[digest]
  var l = Math.ceil(keylen / hLen)

  for (var i = 1; i <= l; i++) {
    block1.writeUInt32BE(i, salt.length)

    var T = hmac.run(block1, hmac.ipad1)
    var U = T

    for (var j = 1; j < iterations; j++) {
      U = hmac.run(U, hmac.ipad2)
      for (var k = 0; k < hLen; k++) T[k] ^= U[k]
    }

    T.copy(DK, destPos)
    destPos += hLen
  }

  return DK
}

module.exports = pbkdf2

},{"./default-encoding":175,"./precondition":176,"./to-buffer":178,"create-hash/md5":83,"ripemd160":214,"safe-buffer":215,"sha.js":219}],178:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer

module.exports = function (thing, encoding, name) {
  if (Buffer.isBuffer(thing)) {
    return thing
  } else if (typeof thing === 'string') {
    return Buffer.from(thing, encoding)
  } else if (ArrayBuffer.isView(thing)) {
    return Buffer.from(thing.buffer)
  } else {
    throw new TypeError(name + ' must be a string, a Buffer, a typed array or a DataView')
  }
}

},{"safe-buffer":215}],179:[function(require,module,exports){
// shim for using process in browser
var process = module.exports = {};

// cached from whatever global is present so that test runners that stub it
// don't break things.  But we need to wrap it in a try catch in case it is
// wrapped in strict mode code which doesn't define any globals.  It's inside a
// function because try/catches deoptimize in certain engines.

var cachedSetTimeout;
var cachedClearTimeout;

function defaultSetTimout() {
    throw new Error('setTimeout has not been defined');
}
function defaultClearTimeout () {
    throw new Error('clearTimeout has not been defined');
}
(function () {
    try {
        if (typeof setTimeout === 'function') {
            cachedSetTimeout = setTimeout;
        } else {
            cachedSetTimeout = defaultSetTimout;
        }
    } catch (e) {
        cachedSetTimeout = defaultSetTimout;
    }
    try {
        if (typeof clearTimeout === 'function') {
            cachedClearTimeout = clearTimeout;
        } else {
            cachedClearTimeout = defaultClearTimeout;
        }
    } catch (e) {
        cachedClearTimeout = defaultClearTimeout;
    }
} ())
function runTimeout(fun) {
    if (cachedSetTimeout === setTimeout) {
        //normal enviroments in sane situations
        return setTimeout(fun, 0);
    }
    // if setTimeout wasn't available but was latter defined
    if ((cachedSetTimeout === defaultSetTimout || !cachedSetTimeout) && setTimeout) {
        cachedSetTimeout = setTimeout;
        return setTimeout(fun, 0);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedSetTimeout(fun, 0);
    } catch(e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't trust the global object when called normally
            return cachedSetTimeout.call(null, fun, 0);
        } catch(e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error
            return cachedSetTimeout.call(this, fun, 0);
        }
    }


}
function runClearTimeout(marker) {
    if (cachedClearTimeout === clearTimeout) {
        //normal enviroments in sane situations
        return clearTimeout(marker);
    }
    // if clearTimeout wasn't available but was latter defined
    if ((cachedClearTimeout === defaultClearTimeout || !cachedClearTimeout) && clearTimeout) {
        cachedClearTimeout = clearTimeout;
        return clearTimeout(marker);
    }
    try {
        // when when somebody has screwed with setTimeout but no I.E. maddness
        return cachedClearTimeout(marker);
    } catch (e){
        try {
            // When we are in I.E. but the script has been evaled so I.E. doesn't  trust the global object when called normally
            return cachedClearTimeout.call(null, marker);
        } catch (e){
            // same as above but when it's a version of I.E. that must have the global object for 'this', hopfully our context correct otherwise it will throw a global error.
            // Some versions of I.E. have different rules for clearTimeout vs setTimeout
            return cachedClearTimeout.call(this, marker);
        }
    }



}
var queue = [];
var draining = false;
var currentQueue;
var queueIndex = -1;

function cleanUpNextTick() {
    if (!draining || !currentQueue) {
        return;
    }
    draining = false;
    if (currentQueue.length) {
        queue = currentQueue.concat(queue);
    } else {
        queueIndex = -1;
    }
    if (queue.length) {
        drainQueue();
    }
}

function drainQueue() {
    if (draining) {
        return;
    }
    var timeout = runTimeout(cleanUpNextTick);
    draining = true;

    var len = queue.length;
    while(len) {
        currentQueue = queue;
        queue = [];
        while (++queueIndex < len) {
            if (currentQueue) {
                currentQueue[queueIndex].run();
            }
        }
        queueIndex = -1;
        len = queue.length;
    }
    currentQueue = null;
    draining = false;
    runClearTimeout(timeout);
}

process.nextTick = function (fun) {
    var args = new Array(arguments.length - 1);
    if (arguments.length > 1) {
        for (var i = 1; i < arguments.length; i++) {
            args[i - 1] = arguments[i];
        }
    }
    queue.push(new Item(fun, args));
    if (queue.length === 1 && !draining) {
        runTimeout(drainQueue);
    }
};

// v8 likes predictible objects
function Item(fun, array) {
    this.fun = fun;
    this.array = array;
}
Item.prototype.run = function () {
    this.fun.apply(null, this.array);
};
process.title = 'browser';
process.browser = true;
process.env = {};
process.argv = [];
process.version = ''; // empty string to avoid regexp issues
process.versions = {};

function noop() {}

process.on = noop;
process.addListener = noop;
process.once = noop;
process.off = noop;
process.removeListener = noop;
process.removeAllListeners = noop;
process.emit = noop;
process.prependListener = noop;
process.prependOnceListener = noop;

process.listeners = function (name) { return [] }

process.binding = function (name) {
    throw new Error('process.binding is not supported');
};

process.cwd = function () { return '/' };
process.chdir = function (dir) {
    throw new Error('process.chdir is not supported');
};
process.umask = function() { return 0; };

},{}],180:[function(require,module,exports){
exports.publicEncrypt = require('./publicEncrypt')
exports.privateDecrypt = require('./privateDecrypt')

exports.privateEncrypt = function privateEncrypt (key, buf) {
  return exports.publicEncrypt(key, buf, true)
}

exports.publicDecrypt = function publicDecrypt (key, buf) {
  return exports.privateDecrypt(key, buf, true)
}

},{"./privateDecrypt":183,"./publicEncrypt":184}],181:[function(require,module,exports){
var createHash = require('create-hash')
var Buffer = require('safe-buffer').Buffer

module.exports = function (seed, len) {
  var t = Buffer.alloc(0)
  var i = 0
  var c
  while (t.length < len) {
    c = i2ops(i++)
    t = Buffer.concat([t, createHash('sha1').update(seed).update(c).digest()])
  }
  return t.slice(0, len)
}

function i2ops (c) {
  var out = Buffer.allocUnsafe(4)
  out.writeUInt32BE(c, 0)
  return out
}

},{"create-hash":82,"safe-buffer":215}],182:[function(require,module,exports){
arguments[4][41][0].apply(exports,arguments)
},{"buffer":45,"dup":41}],183:[function(require,module,exports){
var parseKeys = require('parse-asn1')
var mgf = require('./mgf')
var xor = require('./xor')
var BN = require('bn.js')
var crt = require('browserify-rsa')
var createHash = require('create-hash')
var withPublic = require('./withPublic')
var Buffer = require('safe-buffer').Buffer

module.exports = function privateDecrypt (privateKey, enc, reverse) {
  var padding
  if (privateKey.padding) {
    padding = privateKey.padding
  } else if (reverse) {
    padding = 1
  } else {
    padding = 4
  }

  var key = parseKeys(privateKey)
  var k = key.modulus.byteLength()
  if (enc.length > k || new BN(enc).cmp(key.modulus) >= 0) {
    throw new Error('decryption error')
  }
  var msg
  if (reverse) {
    msg = withPublic(new BN(enc), key)
  } else {
    msg = crt(enc, key)
  }
  var zBuffer = Buffer.alloc(k - msg.length)
  msg = Buffer.concat([zBuffer, msg], k)
  if (padding === 4) {
    return oaep(key, msg)
  } else if (padding === 1) {
    return pkcs1(key, msg, reverse)
  } else if (padding === 3) {
    return msg
  } else {
    throw new Error('unknown padding')
  }
}

function oaep (key, msg) {
  var k = key.modulus.byteLength()
  var iHash = createHash('sha1').update(Buffer.alloc(0)).digest()
  var hLen = iHash.length
  if (msg[0] !== 0) {
    throw new Error('decryption error')
  }
  var maskedSeed = msg.slice(1, hLen + 1)
  var maskedDb = msg.slice(hLen + 1)
  var seed = xor(maskedSeed, mgf(maskedDb, hLen))
  var db = xor(maskedDb, mgf(seed, k - hLen - 1))
  if (compare(iHash, db.slice(0, hLen))) {
    throw new Error('decryption error')
  }
  var i = hLen
  while (db[i] === 0) {
    i++
  }
  if (db[i++] !== 1) {
    throw new Error('decryption error')
  }
  return db.slice(i)
}

function pkcs1 (key, msg, reverse) {
  var p1 = msg.slice(0, 2)
  var i = 2
  var status = 0
  while (msg[i++] !== 0) {
    if (i >= msg.length) {
      status++
      break
    }
  }
  var ps = msg.slice(2, i - 1)

  if ((p1.toString('hex') !== '0002' && !reverse) || (p1.toString('hex') !== '0001' && reverse)) {
    status++
  }
  if (ps.length < 8) {
    status++
  }
  if (status) {
    throw new Error('decryption error')
  }
  return msg.slice(i)
}
function compare (a, b) {
  a = Buffer.from(a)
  b = Buffer.from(b)
  var dif = 0
  var len = a.length
  if (a.length !== b.length) {
    dif++
    len = Math.min(a.length, b.length)
  }
  var i = -1
  while (++i < len) {
    dif += (a[i] ^ b[i])
  }
  return dif
}

},{"./mgf":181,"./withPublic":185,"./xor":186,"bn.js":182,"browserify-rsa":66,"create-hash":82,"parse-asn1":171,"safe-buffer":215}],184:[function(require,module,exports){
var parseKeys = require('parse-asn1')
var randomBytes = require('randombytes')
var createHash = require('create-hash')
var mgf = require('./mgf')
var xor = require('./xor')
var BN = require('bn.js')
var withPublic = require('./withPublic')
var crt = require('browserify-rsa')
var Buffer = require('safe-buffer').Buffer

module.exports = function publicEncrypt (publicKey, msg, reverse) {
  var padding
  if (publicKey.padding) {
    padding = publicKey.padding
  } else if (reverse) {
    padding = 1
  } else {
    padding = 4
  }
  var key = parseKeys(publicKey)
  var paddedMsg
  if (padding === 4) {
    paddedMsg = oaep(key, msg)
  } else if (padding === 1) {
    paddedMsg = pkcs1(key, msg, reverse)
  } else if (padding === 3) {
    paddedMsg = new BN(msg)
    if (paddedMsg.cmp(key.modulus) >= 0) {
      throw new Error('data too long for modulus')
    }
  } else {
    throw new Error('unknown padding')
  }
  if (reverse) {
    return crt(paddedMsg, key)
  } else {
    return withPublic(paddedMsg, key)
  }
}

function oaep (key, msg) {
  var k = key.modulus.byteLength()
  var mLen = msg.length
  var iHash = createHash('sha1').update(Buffer.alloc(0)).digest()
  var hLen = iHash.length
  var hLen2 = 2 * hLen
  if (mLen > k - hLen2 - 2) {
    throw new Error('message too long')
  }
  var ps = Buffer.alloc(k - mLen - hLen2 - 2)
  var dblen = k - hLen - 1
  var seed = randomBytes(hLen)
  var maskedDb = xor(Buffer.concat([iHash, ps, Buffer.alloc(1, 1), msg], dblen), mgf(seed, dblen))
  var maskedSeed = xor(seed, mgf(maskedDb, hLen))
  return new BN(Buffer.concat([Buffer.alloc(1), maskedSeed, maskedDb], k))
}
function pkcs1 (key, msg, reverse) {
  var mLen = msg.length
  var k = key.modulus.byteLength()
  if (mLen > k - 11) {
    throw new Error('message too long')
  }
  var ps
  if (reverse) {
    ps = Buffer.alloc(k - mLen - 3, 0xff)
  } else {
    ps = nonZero(k - mLen - 3)
  }
  return new BN(Buffer.concat([Buffer.from([0, reverse ? 1 : 2]), ps, Buffer.alloc(1), msg], k))
}
function nonZero (len) {
  var out = Buffer.allocUnsafe(len)
  var i = 0
  var cache = randomBytes(len * 2)
  var cur = 0
  var num
  while (i < len) {
    if (cur === cache.length) {
      cache = randomBytes(len * 2)
      cur = 0
    }
    num = cache[cur++]
    if (num) {
      out[i++] = num
    }
  }
  return out
}

},{"./mgf":181,"./withPublic":185,"./xor":186,"bn.js":182,"browserify-rsa":66,"create-hash":82,"parse-asn1":171,"randombytes":187,"safe-buffer":215}],185:[function(require,module,exports){
var BN = require('bn.js')
var Buffer = require('safe-buffer').Buffer

function withPublic (paddedMsg, key) {
  return Buffer.from(paddedMsg
    .toRed(BN.mont(key.modulus))
    .redPow(new BN(key.publicExponent))
    .fromRed()
    .toArray())
}

module.exports = withPublic

},{"bn.js":182,"safe-buffer":215}],186:[function(require,module,exports){
module.exports = function xor (a, b) {
  var len = a.length
  var i = -1
  while (++i < len) {
    a[i] ^= b[i]
  }
  return a
}

},{}],187:[function(require,module,exports){
(function (process,global){(function (){
'use strict'

// limit of Crypto.getRandomValues()
// https://developer.mozilla.org/en-US/docs/Web/API/Crypto/getRandomValues
var MAX_BYTES = 65536

// Node supports requesting up to this number of bytes
// https://github.com/nodejs/node/blob/master/lib/internal/crypto/random.js#L48
var MAX_UINT32 = 4294967295

function oldBrowser () {
  throw new Error('Secure random number generation is not supported by this browser.\nUse Chrome, Firefox or Internet Explorer 11')
}

var Buffer = require('safe-buffer').Buffer
var crypto = global.crypto || global.msCrypto

if (crypto && crypto.getRandomValues) {
  module.exports = randomBytes
} else {
  module.exports = oldBrowser
}

function randomBytes (size, cb) {
  // phantomjs needs to throw
  if (size > MAX_UINT32) throw new RangeError('requested too many random bytes')

  var bytes = Buffer.allocUnsafe(size)

  if (size > 0) {  // getRandomValues fails on IE if size == 0
    if (size > MAX_BYTES) { // this is the max bytes crypto.getRandomValues
      // can do at once see https://developer.mozilla.org/en-US/docs/Web/API/window.crypto.getRandomValues
      for (var generated = 0; generated < size; generated += MAX_BYTES) {
        // buffer.slice automatically checks if the end is past the end of
        // the buffer so we don't have to here
        crypto.getRandomValues(bytes.slice(generated, generated + MAX_BYTES))
      }
    } else {
      crypto.getRandomValues(bytes)
    }
  }

  if (typeof cb === 'function') {
    return process.nextTick(function () {
      cb(null, bytes)
    })
  }

  return bytes
}

}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":179,"safe-buffer":215}],188:[function(require,module,exports){
(function (process,global){(function (){
'use strict'

function oldBrowser () {
  throw new Error('secure random number generation not supported by this browser\nuse chrome, FireFox or Internet Explorer 11')
}
var safeBuffer = require('safe-buffer')
var randombytes = require('randombytes')
var Buffer = safeBuffer.Buffer
var kBufferMaxLength = safeBuffer.kMaxLength
var crypto = global.crypto || global.msCrypto
var kMaxUint32 = Math.pow(2, 32) - 1
function assertOffset (offset, length) {
  if (typeof offset !== 'number' || offset !== offset) { // eslint-disable-line no-self-compare
    throw new TypeError('offset must be a number')
  }

  if (offset > kMaxUint32 || offset < 0) {
    throw new TypeError('offset must be a uint32')
  }

  if (offset > kBufferMaxLength || offset > length) {
    throw new RangeError('offset out of range')
  }
}

function assertSize (size, offset, length) {
  if (typeof size !== 'number' || size !== size) { // eslint-disable-line no-self-compare
    throw new TypeError('size must be a number')
  }

  if (size > kMaxUint32 || size < 0) {
    throw new TypeError('size must be a uint32')
  }

  if (size + offset > length || size > kBufferMaxLength) {
    throw new RangeError('buffer too small')
  }
}
if ((crypto && crypto.getRandomValues) || !process.browser) {
  exports.randomFill = randomFill
  exports.randomFillSync = randomFillSync
} else {
  exports.randomFill = oldBrowser
  exports.randomFillSync = oldBrowser
}
function randomFill (buf, offset, size, cb) {
  if (!Buffer.isBuffer(buf) && !(buf instanceof global.Uint8Array)) {
    throw new TypeError('"buf" argument must be a Buffer or Uint8Array')
  }

  if (typeof offset === 'function') {
    cb = offset
    offset = 0
    size = buf.length
  } else if (typeof size === 'function') {
    cb = size
    size = buf.length - offset
  } else if (typeof cb !== 'function') {
    throw new TypeError('"cb" argument must be a function')
  }
  assertOffset(offset, buf.length)
  assertSize(size, offset, buf.length)
  return actualFill(buf, offset, size, cb)
}

function actualFill (buf, offset, size, cb) {
  if (process.browser) {
    var ourBuf = buf.buffer
    var uint = new Uint8Array(ourBuf, offset, size)
    crypto.getRandomValues(uint)
    if (cb) {
      process.nextTick(function () {
        cb(null, buf)
      })
      return
    }
    return buf
  }
  if (cb) {
    randombytes(size, function (err, bytes) {
      if (err) {
        return cb(err)
      }
      bytes.copy(buf, offset)
      cb(null, buf)
    })
    return
  }
  var bytes = randombytes(size)
  bytes.copy(buf, offset)
  return buf
}
function randomFillSync (buf, offset, size) {
  if (typeof offset === 'undefined') {
    offset = 0
  }
  if (!Buffer.isBuffer(buf) && !(buf instanceof global.Uint8Array)) {
    throw new TypeError('"buf" argument must be a Buffer or Uint8Array')
  }

  assertOffset(offset, buf.length)

  if (size === undefined) size = buf.length - offset

  assertSize(size, offset, buf.length)

  return actualFill(buf, offset, size)
}

}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":179,"randombytes":187,"safe-buffer":215}],189:[function(require,module,exports){
/**
 * An implementation of the RDF Dataset Normalization specification.
 *
 * @author Dave Longley
 *
 * Copyright 2010-2021 Digital Bazaar, Inc.
 */
module.exports = require('./lib');

},{"./lib":198}],190:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

module.exports = class IdentifierIssuer {
  /**
   * Creates a new IdentifierIssuer. A IdentifierIssuer issues unique
   * identifiers, keeping track of any previously issued identifiers.
   *
   * @param prefix the prefix to use ('<prefix><counter>').
   * @param existing an existing Map to use.
   * @param counter the counter to use.
   */
  constructor(prefix, existing = new Map(), counter = 0) {
    this.prefix = prefix;
    this._existing = existing;
    this.counter = counter;
  }

  /**
   * Copies this IdentifierIssuer.
   *
   * @return a copy of this IdentifierIssuer.
   */
  clone() {
    const {prefix, _existing, counter} = this;
    return new IdentifierIssuer(prefix, new Map(_existing), counter);
  }

  /**
   * Gets the new identifier for the given old identifier, where if no old
   * identifier is given a new identifier will be generated.
   *
   * @param [old] the old identifier to get the new identifier for.
   *
   * @return the new identifier.
   */
  getId(old) {
    // return existing old identifier
    const existing = old && this._existing.get(old);
    if(existing) {
      return existing;
    }

    // get next identifier
    const identifier = this.prefix + this.counter;
    this.counter++;

    // save mapping
    if(old) {
      this._existing.set(old, identifier);
    }

    return identifier;
  }

  /**
   * Returns true if the given old identifer has already been assigned a new
   * identifier.
   *
   * @param old the old identifier to check.
   *
   * @return true if the old identifier has been assigned a new identifier,
   *   false if not.
   */
  hasId(old) {
    return this._existing.has(old);
  }

  /**
   * Returns all of the IDs that have been issued new IDs in the order in
   * which they were issued new IDs.
   *
   * @return the list of old IDs that has been issued new IDs in order.
   */
  getOldIds() {
    return [...this._existing.keys()];
  }
};

},{}],191:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

require('setimmediate');

const crypto = self.crypto || self.msCrypto;

// TODO: synchronous version no longer supported in browser

module.exports = class MessageDigest {
  /**
   * Creates a new MessageDigest.
   *
   * @param algorithm the algorithm to use.
   */
  constructor(algorithm) {
    // check if crypto.subtle is available
    // check is here rather than top-level to only fail if class is used
    if(!(crypto && crypto.subtle)) {
      throw new Error('crypto.subtle not found.');
    }
    if(algorithm === 'sha256') {
      this.algorithm = {name: 'SHA-256'};
    } else if(algorithm === 'sha1') {
      this.algorithm = {name: 'SHA-1'};
    } else {
      throw new Error(`Unsupport algorithm "${algorithm}".`);
    }
    this._content = '';
  }

  update(msg) {
    this._content += msg;
  }

  async digest() {
    const data = new TextEncoder().encode(this._content);
    const buffer = new Uint8Array(
      await crypto.subtle.digest(this.algorithm, data));
    // return digest in hex
    let hex = '';
    for(let i = 0; i < buffer.length; ++i) {
      hex += buffer[i].toString(16).padStart(2, '0');
    }
    return hex;
  }
};

},{"setimmediate":217}],192:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

// eslint-disable-next-line no-unused-vars
const TERMS = ['subject', 'predicate', 'object', 'graph'];
const RDF = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#';
const RDF_LANGSTRING = RDF + 'langString';
const XSD_STRING = 'http://www.w3.org/2001/XMLSchema#string';

const TYPE_NAMED_NODE = 'NamedNode';
const TYPE_BLANK_NODE = 'BlankNode';
const TYPE_LITERAL = 'Literal';
const TYPE_DEFAULT_GRAPH = 'DefaultGraph';

// build regexes
const REGEX = {};
(() => {
  const iri = '(?:<([^:]+:[^>]*)>)';
  // https://www.w3.org/TR/turtle/#grammar-production-BLANK_NODE_LABEL
  const PN_CHARS_BASE =
    'A-Z' + 'a-z' +
    '\u00C0-\u00D6' +
    '\u00D8-\u00F6' +
    '\u00F8-\u02FF' +
    '\u0370-\u037D' +
    '\u037F-\u1FFF' +
    '\u200C-\u200D' +
    '\u2070-\u218F' +
    '\u2C00-\u2FEF' +
    '\u3001-\uD7FF' +
    '\uF900-\uFDCF' +
    '\uFDF0-\uFFFD';
    // TODO:
    //'\u10000-\uEFFFF';
  const PN_CHARS_U =
    PN_CHARS_BASE +
    '_';
  const PN_CHARS =
    PN_CHARS_U +
    '0-9' +
    '-' +
    '\u00B7' +
    '\u0300-\u036F' +
    '\u203F-\u2040';
  const BLANK_NODE_LABEL =
    '(_:' +
      '(?:[' + PN_CHARS_U + '0-9])' +
      '(?:(?:[' + PN_CHARS + '.])*(?:[' + PN_CHARS + ']))?' +
    ')';
  const bnode = BLANK_NODE_LABEL;
  const plain = '"([^"\\\\]*(?:\\\\.[^"\\\\]*)*)"';
  const datatype = '(?:\\^\\^' + iri + ')';
  const language = '(?:@([a-zA-Z]+(?:-[a-zA-Z0-9]+)*))';
  const literal = '(?:' + plain + '(?:' + datatype + '|' + language + ')?)';
  const ws = '[ \\t]+';
  const wso = '[ \\t]*';

  // define quad part regexes
  const subject = '(?:' + iri + '|' + bnode + ')' + ws;
  const property = iri + ws;
  const object = '(?:' + iri + '|' + bnode + '|' + literal + ')' + wso;
  const graphName = '(?:\\.|(?:(?:' + iri + '|' + bnode + ')' + wso + '\\.))';

  // end of line and empty regexes
  REGEX.eoln = /(?:\r\n)|(?:\n)|(?:\r)/g;
  REGEX.empty = new RegExp('^' + wso + '$');

  // full quad regex
  REGEX.quad = new RegExp(
    '^' + wso + subject + property + object + graphName + wso + '$');
})();

module.exports = class NQuads {
  /**
   * Parses RDF in the form of N-Quads.
   *
   * @param input the N-Quads input to parse.
   *
   * @return an RDF dataset (an array of quads per http://rdf.js.org/).
   */
  static parse(input) {
    // build RDF dataset
    const dataset = [];

    const graphs = {};

    // split N-Quad input into lines
    const lines = input.split(REGEX.eoln);
    let lineNumber = 0;
    for(const line of lines) {
      lineNumber++;

      // skip empty lines
      if(REGEX.empty.test(line)) {
        continue;
      }

      // parse quad
      const match = line.match(REGEX.quad);
      if(match === null) {
        throw new Error('N-Quads parse error on line ' + lineNumber + '.');
      }

      // create RDF quad
      const quad = {subject: null, predicate: null, object: null, graph: null};

      // get subject
      if(match[1] !== undefined) {
        quad.subject = {termType: TYPE_NAMED_NODE, value: match[1]};
      } else {
        quad.subject = {termType: TYPE_BLANK_NODE, value: match[2]};
      }

      // get predicate
      quad.predicate = {termType: TYPE_NAMED_NODE, value: match[3]};

      // get object
      if(match[4] !== undefined) {
        quad.object = {termType: TYPE_NAMED_NODE, value: match[4]};
      } else if(match[5] !== undefined) {
        quad.object = {termType: TYPE_BLANK_NODE, value: match[5]};
      } else {
        quad.object = {
          termType: TYPE_LITERAL,
          value: undefined,
          datatype: {
            termType: TYPE_NAMED_NODE
          }
        };
        if(match[7] !== undefined) {
          quad.object.datatype.value = match[7];
        } else if(match[8] !== undefined) {
          quad.object.datatype.value = RDF_LANGSTRING;
          quad.object.language = match[8];
        } else {
          quad.object.datatype.value = XSD_STRING;
        }
        quad.object.value = _unescape(match[6]);
      }

      // get graph
      if(match[9] !== undefined) {
        quad.graph = {
          termType: TYPE_NAMED_NODE,
          value: match[9]
        };
      } else if(match[10] !== undefined) {
        quad.graph = {
          termType: TYPE_BLANK_NODE,
          value: match[10]
        };
      } else {
        quad.graph = {
          termType: TYPE_DEFAULT_GRAPH,
          value: ''
        };
      }

      // only add quad if it is unique in its graph
      if(!(quad.graph.value in graphs)) {
        graphs[quad.graph.value] = [quad];
        dataset.push(quad);
      } else {
        let unique = true;
        const quads = graphs[quad.graph.value];
        for(const q of quads) {
          if(_compareTriples(q, quad)) {
            unique = false;
            break;
          }
        }
        if(unique) {
          quads.push(quad);
          dataset.push(quad);
        }
      }
    }

    return dataset;
  }

  /**
   * Converts an RDF dataset to N-Quads.
   *
   * @param dataset (array of quads) the RDF dataset to convert.
   *
   * @return the N-Quads string.
   */
  static serialize(dataset) {
    if(!Array.isArray(dataset)) {
      dataset = NQuads.legacyDatasetToQuads(dataset);
    }
    const quads = [];
    for(const quad of dataset) {
      quads.push(NQuads.serializeQuad(quad));
    }
    return quads.sort().join('');
  }

  /**
   * Converts an RDF quad to an N-Quad string (a single quad).
   *
   * @param quad the RDF quad convert.
   *
   * @return the N-Quad string.
   */
  static serializeQuad(quad) {
    const s = quad.subject;
    const p = quad.predicate;
    const o = quad.object;
    const g = quad.graph;

    let nquad = '';

    // subject can only be NamedNode or BlankNode
    if(s.termType === TYPE_NAMED_NODE) {
      nquad += `<${s.value}>`;
    } else {
      nquad += `${s.value}`;
    }

    // predicate can only be NamedNode
    nquad += ` <${p.value}> `;

    // object is NamedNode, BlankNode, or Literal
    if(o.termType === TYPE_NAMED_NODE) {
      nquad += `<${o.value}>`;
    } else if(o.termType === TYPE_BLANK_NODE) {
      nquad += o.value;
    } else {
      nquad += `"${_escape(o.value)}"`;
      if(o.datatype.value === RDF_LANGSTRING) {
        if(o.language) {
          nquad += `@${o.language}`;
        }
      } else if(o.datatype.value !== XSD_STRING) {
        nquad += `^^<${o.datatype.value}>`;
      }
    }

    // graph can only be NamedNode or BlankNode (or DefaultGraph, but that
    // does not add to `nquad`)
    if(g.termType === TYPE_NAMED_NODE) {
      nquad += ` <${g.value}>`;
    } else if(g.termType === TYPE_BLANK_NODE) {
      nquad += ` ${g.value}`;
    }

    nquad += ' .\n';
    return nquad;
  }

  /**
   * Converts a legacy-formatted dataset to an array of quads dataset per
   * http://rdf.js.org/.
   *
   * @param dataset the legacy dataset to convert.
   *
   * @return the array of quads dataset.
   */
  static legacyDatasetToQuads(dataset) {
    const quads = [];

    const termTypeMap = {
      'blank node': TYPE_BLANK_NODE,
      IRI: TYPE_NAMED_NODE,
      literal: TYPE_LITERAL
    };

    for(const graphName in dataset) {
      const triples = dataset[graphName];
      triples.forEach(triple => {
        const quad = {};
        for(const componentName in triple) {
          const oldComponent = triple[componentName];
          const newComponent = {
            termType: termTypeMap[oldComponent.type],
            value: oldComponent.value
          };
          if(newComponent.termType === TYPE_LITERAL) {
            newComponent.datatype = {
              termType: TYPE_NAMED_NODE
            };
            if('datatype' in oldComponent) {
              newComponent.datatype.value = oldComponent.datatype;
            }
            if('language' in oldComponent) {
              if(!('datatype' in oldComponent)) {
                newComponent.datatype.value = RDF_LANGSTRING;
              }
              newComponent.language = oldComponent.language;
            } else if(!('datatype' in oldComponent)) {
              newComponent.datatype.value = XSD_STRING;
            }
          }
          quad[componentName] = newComponent;
        }
        if(graphName === '@default') {
          quad.graph = {
            termType: TYPE_DEFAULT_GRAPH,
            value: ''
          };
        } else {
          quad.graph = {
            termType: graphName.startsWith('_:') ?
              TYPE_BLANK_NODE : TYPE_NAMED_NODE,
            value: graphName
          };
        }
        quads.push(quad);
      });
    }

    return quads;
  }
};

/**
 * Compares two RDF triples for equality.
 *
 * @param t1 the first triple.
 * @param t2 the second triple.
 *
 * @return true if the triples are the same, false if not.
 */
function _compareTriples(t1, t2) {
  // compare subject and object types first as it is the quickest check
  if(!(t1.subject.termType === t2.subject.termType &&
    t1.object.termType === t2.object.termType)) {
    return false;
  }
  // compare values
  if(!(t1.subject.value === t2.subject.value &&
    t1.predicate.value === t2.predicate.value &&
    t1.object.value === t2.object.value)) {
    return false;
  }
  if(t1.object.termType !== TYPE_LITERAL) {
    // no `datatype` or `language` to check
    return true;
  }
  return (
    (t1.object.datatype.termType === t2.object.datatype.termType) &&
    (t1.object.language === t2.object.language) &&
    (t1.object.datatype.value === t2.object.datatype.value)
  );
}

const _escapeRegex = /["\\\n\r]/g;
/**
 * Escape string to N-Quads literal
 */
function _escape(s) {
  return s.replace(_escapeRegex, function(match) {
    switch(match) {
      case '"': return '\\"';
      case '\\': return '\\\\';
      case '\n': return '\\n';
      case '\r': return '\\r';
    }
  });
}

const _unescapeRegex =
  /(?:\\([tbnrf"'\\]))|(?:\\u([0-9A-Fa-f]{4}))|(?:\\U([0-9A-Fa-f]{8}))/g;
/**
 * Unescape N-Quads literal to string
 */
function _unescape(s) {
  return s.replace(_unescapeRegex, function(match, code, u, U) {
    if(code) {
      switch(code) {
        case 't': return '\t';
        case 'b': return '\b';
        case 'n': return '\n';
        case 'r': return '\r';
        case 'f': return '\f';
        case '"': return '"';
        case '\'': return '\'';
        case '\\': return '\\';
      }
    }
    if(u) {
      return String.fromCharCode(parseInt(u, 16));
    }
    if(U) {
      // FIXME: support larger values
      throw new Error('Unsupported U escape');
    }
  });
}

},{}],193:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

// TODO: convert to ES6 iterable?

module.exports = class Permuter {
  /**
   * A Permuter iterates over all possible permutations of the given array
   * of elements.
   *
   * @param list the array of elements to iterate over.
   */
  constructor(list) {
    // original array
    this.current = list.sort();
    // indicates whether there are more permutations
    this.done = false;
    // directional info for permutation algorithm
    this.dir = new Map();
    for(let i = 0; i < list.length; ++i) {
      this.dir.set(list[i], true);
    }
  }

  /**
   * Returns true if there is another permutation.
   *
   * @return true if there is another permutation, false if not.
   */
  hasNext() {
    return !this.done;
  }

  /**
   * Gets the next permutation. Call hasNext() to ensure there is another one
   * first.
   *
   * @return the next permutation.
   */
  next() {
    // copy current permutation to return it
    const {current, dir} = this;
    const rval = current.slice();

    /* Calculate the next permutation using the Steinhaus-Johnson-Trotter
     permutation algorithm. */

    // get largest mobile element k
    // (mobile: element is greater than the one it is looking at)
    let k = null;
    let pos = 0;
    const length = current.length;
    for(let i = 0; i < length; ++i) {
      const element = current[i];
      const left = dir.get(element);
      if((k === null || element > k) &&
        ((left && i > 0 && element > current[i - 1]) ||
        (!left && i < (length - 1) && element > current[i + 1]))) {
        k = element;
        pos = i;
      }
    }

    // no more permutations
    if(k === null) {
      this.done = true;
    } else {
      // swap k and the element it is looking at
      const swap = dir.get(k) ? pos - 1 : pos + 1;
      current[pos] = current[swap];
      current[swap] = k;

      // reverse the direction of all elements larger than k
      for(const element of current) {
        if(element > k) {
          dir.set(element, !dir.get(element));
        }
      }
    }

    return rval;
  }
};

},{}],194:[function(require,module,exports){
(function (setImmediate){(function (){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const IdentifierIssuer = require('./IdentifierIssuer');
const MessageDigest = require('./MessageDigest');
const Permuter = require('./Permuter');
const NQuads = require('./NQuads');

module.exports = class URDNA2015 {
  constructor() {
    this.name = 'URDNA2015';
    this.blankNodeInfo = new Map();
    this.canonicalIssuer = new IdentifierIssuer('_:c14n');
    this.hashAlgorithm = 'sha256';
    this.quads = null;
  }

  // 4.4) Normalization Algorithm
  async main(dataset) {
    this.quads = dataset;

    // 1) Create the normalization state.
    // 2) For every quad in input dataset:
    for(const quad of dataset) {
      // 2.1) For each blank node that occurs in the quad, add a reference
      // to the quad using the blank node identifier in the blank node to
      // quads map, creating a new entry if necessary.
      this._addBlankNodeQuadInfo({quad, component: quad.subject});
      this._addBlankNodeQuadInfo({quad, component: quad.object});
      this._addBlankNodeQuadInfo({quad, component: quad.graph});
    }

    // 3) Create a list of non-normalized blank node identifiers
    // non-normalized identifiers and populate it using the keys from the
    // blank node to quads map.
    // Note: We use a map here and it was generated during step 2.

    // 4) `simple` flag is skipped -- loop is optimized away. This optimization
    // is permitted because there was a typo in the hash first degree quads
    // algorithm in the URDNA2015 spec that was implemented widely making it
    // such that it could not be fixed; the result was that the loop only
    // needs to be run once and the first degree quad hashes will never change.
    // 5.1-5.2 are skipped; first degree quad hashes are generated just once
    // for all non-normalized blank nodes.

    // 5.3) For each blank node identifier identifier in non-normalized
    // identifiers:
    const hashToBlankNodes = new Map();
    const nonNormalized = [...this.blankNodeInfo.keys()];
    let i = 0;
    for(const id of nonNormalized) {
      // Note: batch hashing first degree quads 100 at a time
      if(++i % 100 === 0) {
        await this._yield();
      }
      // steps 5.3.1 and 5.3.2:
      await this._hashAndTrackBlankNode({id, hashToBlankNodes});
    }

    // 5.4) For each hash to identifier list mapping in hash to blank
    // nodes map, lexicographically-sorted by hash:
    const hashes = [...hashToBlankNodes.keys()].sort();
    // optimize away second sort, gather non-unique hashes in order as we go
    const nonUnique = [];
    for(const hash of hashes) {
      // 5.4.1) If the length of identifier list is greater than 1,
      // continue to the next mapping.
      const idList = hashToBlankNodes.get(hash);
      if(idList.length > 1) {
        nonUnique.push(idList);
        continue;
      }

      // 5.4.2) Use the Issue Identifier algorithm, passing canonical
      // issuer and the single blank node identifier in identifier
      // list, identifier, to issue a canonical replacement identifier
      // for identifier.
      const id = idList[0];
      this.canonicalIssuer.getId(id);

      // Note: These steps are skipped, optimized away since the loop
      // only needs to be run once.
      // 5.4.3) Remove identifier from non-normalized identifiers.
      // 5.4.4) Remove hash from the hash to blank nodes map.
      // 5.4.5) Set simple to true.
    }

    // 6) For each hash to identifier list mapping in hash to blank nodes map,
    // lexicographically-sorted by hash:
    // Note: sort optimized away, use `nonUnique`.
    for(const idList of nonUnique) {
      // 6.1) Create hash path list where each item will be a result of
      // running the Hash N-Degree Quads algorithm.
      const hashPathList = [];

      // 6.2) For each blank node identifier identifier in identifier list:
      for(const id of idList) {
        // 6.2.1) If a canonical identifier has already been issued for
        // identifier, continue to the next identifier.
        if(this.canonicalIssuer.hasId(id)) {
          continue;
        }

        // 6.2.2) Create temporary issuer, an identifier issuer
        // initialized with the prefix _:b.
        const issuer = new IdentifierIssuer('_:b');

        // 6.2.3) Use the Issue Identifier algorithm, passing temporary
        // issuer and identifier, to issue a new temporary blank node
        // identifier for identifier.
        issuer.getId(id);

        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing
        // temporary issuer, and append the result to the hash path list.
        const result = await this.hashNDegreeQuads(id, issuer);
        hashPathList.push(result);
      }

      // 6.3) For each result in the hash path list,
      // lexicographically-sorted by the hash in result:
      hashPathList.sort(_stringHashCompare);
      for(const result of hashPathList) {
        // 6.3.1) For each blank node identifier, existing identifier,
        // that was issued a temporary identifier by identifier issuer
        // in result, issue a canonical identifier, in the same order,
        // using the Issue Identifier algorithm, passing canonical
        // issuer and existing identifier.
        const oldIds = result.issuer.getOldIds();
        for(const id of oldIds) {
          this.canonicalIssuer.getId(id);
        }
      }
    }

    /* Note: At this point all blank nodes in the set of RDF quads have been
    assigned canonical identifiers, which have been stored in the canonical
    issuer. Here each quad is updated by assigning each of its blank nodes
    its new identifier. */

    // 7) For each quad, quad, in input dataset:
    const normalized = [];
    for(const quad of this.quads) {
      // 7.1) Create a copy, quad copy, of quad and replace any existing
      // blank node identifiers using the canonical identifiers
      // previously issued by canonical issuer.
      // Note: We optimize with shallow copies here.
      const q = {...quad};
      q.subject = this._useCanonicalId({component: q.subject});
      q.object = this._useCanonicalId({component: q.object});
      q.graph = this._useCanonicalId({component: q.graph});
      // 7.2) Add quad copy to the normalized dataset.
      normalized.push(NQuads.serializeQuad(q));
    }

    // sort normalized output
    normalized.sort();

    // 8) Return the normalized dataset.
    return normalized.join('');
  }

  // 4.6) Hash First Degree Quads
  async hashFirstDegreeQuads(id) {
    // 1) Initialize nquads to an empty list. It will be used to store quads in
    // N-Quads format.
    const nquads = [];

    // 2) Get the list of quads `quads` associated with the reference blank node
    // identifier in the blank node to quads map.
    const info = this.blankNodeInfo.get(id);
    const quads = info.quads;

    // 3) For each quad `quad` in `quads`:
    for(const quad of quads) {
      // 3.1) Serialize the quad in N-Quads format with the following special
      // rule:

      // 3.1.1) If any component in quad is an blank node, then serialize it
      // using a special identifier as follows:
      const copy = {
        subject: null, predicate: quad.predicate, object: null, graph: null
      };
      // 3.1.2) If the blank node's existing blank node identifier matches
      // the reference blank node identifier then use the blank node
      // identifier _:a, otherwise, use the blank node identifier _:z.
      copy.subject = this.modifyFirstDegreeComponent(
        id, quad.subject, 'subject');
      copy.object = this.modifyFirstDegreeComponent(
        id, quad.object, 'object');
      copy.graph = this.modifyFirstDegreeComponent(
        id, quad.graph, 'graph');
      nquads.push(NQuads.serializeQuad(copy));
    }

    // 4) Sort nquads in lexicographical order.
    nquads.sort();

    // 5) Return the hash that results from passing the sorted, joined nquads
    // through the hash algorithm.
    const md = new MessageDigest(this.hashAlgorithm);
    for(const nquad of nquads) {
      md.update(nquad);
    }
    info.hash = await md.digest();
    return info.hash;
  }

  // 4.7) Hash Related Blank Node
  async hashRelatedBlankNode(related, quad, issuer, position) {
    // 1) Set the identifier to use for related, preferring first the canonical
    // identifier for related if issued, second the identifier issued by issuer
    // if issued, and last, if necessary, the result of the Hash First Degree
    // Quads algorithm, passing related.
    let id;
    if(this.canonicalIssuer.hasId(related)) {
      id = this.canonicalIssuer.getId(related);
    } else if(issuer.hasId(related)) {
      id = issuer.getId(related);
    } else {
      id = this.blankNodeInfo.get(related).hash;
    }

    // 2) Initialize a string input to the value of position.
    // Note: We use a hash object instead.
    const md = new MessageDigest(this.hashAlgorithm);
    md.update(position);

    // 3) If position is not g, append <, the value of the predicate in quad,
    // and > to input.
    if(position !== 'g') {
      md.update(this.getRelatedPredicate(quad));
    }

    // 4) Append identifier to input.
    md.update(id);

    // 5) Return the hash that results from passing input through the hash
    // algorithm.
    return md.digest();
  }

  // 4.8) Hash N-Degree Quads
  async hashNDegreeQuads(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    // Note: 2) and 3) handled within `createHashToRelated`
    const md = new MessageDigest(this.hashAlgorithm);
    const hashToRelated = await this.createHashToRelated(id, issuer);

    // 4) Create an empty string, data to hash.
    // Note: We created a hash object `md` above instead.

    // 5) For each related hash to blank node list mapping in hash to related
    // blank nodes map, sorted lexicographically by related hash:
    const hashes = [...hashToRelated.keys()].sort();
    for(const hash of hashes) {
      // 5.1) Append the related hash to the data to hash.
      md.update(hash);

      // 5.2) Create a string chosen path.
      let chosenPath = '';

      // 5.3) Create an unset chosen issuer variable.
      let chosenIssuer;

      // 5.4) For each permutation of blank node list:
      const permuter = new Permuter(hashToRelated.get(hash));
      let i = 0;
      while(permuter.hasNext()) {
        const permutation = permuter.next();
        // Note: batch permutations 3 at a time
        if(++i % 3 === 0) {
          await this._yield();
        }

        // 5.4.1) Create a copy of issuer, issuer copy.
        let issuerCopy = issuer.clone();

        // 5.4.2) Create a string path.
        let path = '';

        // 5.4.3) Create a recursion list, to store blank node identifiers
        // that must be recursively processed by this algorithm.
        const recursionList = [];

        // 5.4.4) For each related in permutation:
        let nextPermutation = false;
        for(const related of permutation) {
          // 5.4.4.1) If a canonical identifier has been issued for
          // related, append it to path.
          if(this.canonicalIssuer.hasId(related)) {
            path += this.canonicalIssuer.getId(related);
          } else {
            // 5.4.4.2) Otherwise:
            // 5.4.4.2.1) If issuer copy has not issued an identifier for
            // related, append related to recursion list.
            if(!issuerCopy.hasId(related)) {
              recursionList.push(related);
            }
            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing
            // issuer copy and related and append the result to path.
            path += issuerCopy.getId(related);
          }

          // 5.4.4.3) If chosen path is not empty and the length of path
          // is greater than or equal to the length of chosen path and
          // path is lexicographically greater than chosen path, then
          // skip to the next permutation.
          // Note: Comparing path length to chosen path length can be optimized
          // away; only compare lexicographically.
          if(chosenPath.length !== 0 && path > chosenPath) {
            nextPermutation = true;
            break;
          }
        }

        if(nextPermutation) {
          continue;
        }

        // 5.4.5) For each related in recursion list:
        for(const related of recursionList) {
          // 5.4.5.1) Set result to the result of recursively executing
          // the Hash N-Degree Quads algorithm, passing related for
          // identifier and issuer copy for path identifier issuer.
          const result = await this.hashNDegreeQuads(related, issuerCopy);

          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer
          // copy and related and append the result to path.
          path += issuerCopy.getId(related);

          // 5.4.5.3) Append <, the hash in result, and > to path.
          path += `<${result.hash}>`;

          // 5.4.5.4) Set issuer copy to the identifier issuer in
          // result.
          issuerCopy = result.issuer;

          // 5.4.5.5) If chosen path is not empty and the length of path
          // is greater than or equal to the length of chosen path and
          // path is lexicographically greater than chosen path, then
          // skip to the next permutation.
          // Note: Comparing path length to chosen path length can be optimized
          // away; only compare lexicographically.
          if(chosenPath.length !== 0 && path > chosenPath) {
            nextPermutation = true;
            break;
          }
        }

        if(nextPermutation) {
          continue;
        }

        // 5.4.6) If chosen path is empty or path is lexicographically
        // less than chosen path, set chosen path to path and chosen
        // issuer to issuer copy.
        if(chosenPath.length === 0 || path < chosenPath) {
          chosenPath = path;
          chosenIssuer = issuerCopy;
        }
      }

      // 5.5) Append chosen path to data to hash.
      md.update(chosenPath);

      // 5.6) Replace issuer, by reference, with chosen issuer.
      issuer = chosenIssuer;
    }

    // 6) Return issuer and the hash that results from passing data to hash
    // through the hash algorithm.
    return {hash: await md.digest(), issuer};
  }

  // helper for modifying component during Hash First Degree Quads
  modifyFirstDegreeComponent(id, component) {
    if(component.termType !== 'BlankNode') {
      return component;
    }
    /* Note: A mistake in the URDNA2015 spec that made its way into
    implementations (and therefore must stay to avoid interop breakage)
    resulted in an assigned canonical ID, if available for
    `component.value`, not being used in place of `_:a`/`_:z`, so
    we don't use it here. */
    return {
      termType: 'BlankNode',
      value: component.value === id ? '_:a' : '_:z'
    };
  }

  // helper for getting a related predicate
  getRelatedPredicate(quad) {
    return `<${quad.predicate.value}>`;
  }

  // helper for creating hash to related blank nodes map
  async createHashToRelated(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    const hashToRelated = new Map();

    // 2) Get a reference, quads, to the list of quads in the blank node to
    // quads map for the key identifier.
    const quads = this.blankNodeInfo.get(id).quads;

    // 3) For each quad in quads:
    let i = 0;
    for(const quad of quads) {
      // Note: batch hashing related blank node quads 100 at a time
      if(++i % 100 === 0) {
        await this._yield();
      }
      // 3.1) For each component in quad, if component is the subject, object,
      // and graph name and it is a blank node that is not identified by
      // identifier:
      // steps 3.1.1 and 3.1.2 occur in helpers:
      await Promise.all([
        this._addRelatedBlankNodeHash({
          quad, component: quad.subject, position: 's',
          id, issuer, hashToRelated
        }),
        this._addRelatedBlankNodeHash({
          quad, component: quad.object, position: 'o',
          id, issuer, hashToRelated
        }),
        this._addRelatedBlankNodeHash({
          quad, component: quad.graph, position: 'g',
          id, issuer, hashToRelated
        })
      ]);
    }

    return hashToRelated;
  }

  async _hashAndTrackBlankNode({id, hashToBlankNodes}) {
    // 5.3.1) Create a hash, hash, according to the Hash First Degree
    // Quads algorithm.
    const hash = await this.hashFirstDegreeQuads(id);

    // 5.3.2) Add hash and identifier to hash to blank nodes map,
    // creating a new entry if necessary.
    const idList = hashToBlankNodes.get(hash);
    if(!idList) {
      hashToBlankNodes.set(hash, [id]);
    } else {
      idList.push(id);
    }
  }

  _addBlankNodeQuadInfo({quad, component}) {
    if(component.termType !== 'BlankNode') {
      return;
    }
    const id = component.value;
    const info = this.blankNodeInfo.get(id);
    if(info) {
      info.quads.add(quad);
    } else {
      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});
    }
  }

  async _addRelatedBlankNodeHash(
    {quad, component, position, id, issuer, hashToRelated}) {
    if(!(component.termType === 'BlankNode' && component.value !== id)) {
      return;
    }
    // 3.1.1) Set hash to the result of the Hash Related Blank Node
    // algorithm, passing the blank node identifier for component as
    // related, quad, path identifier issuer as issuer, and position as
    // either s, o, or g based on whether component is a subject, object,
    // graph name, respectively.
    const related = component.value;
    const hash = await this.hashRelatedBlankNode(
      related, quad, issuer, position);

    // 3.1.2) Add a mapping of hash to the blank node identifier for
    // component to hash to related blank nodes map, adding an entry as
    // necessary.
    const entries = hashToRelated.get(hash);
    if(entries) {
      entries.push(related);
    } else {
      hashToRelated.set(hash, [related]);
    }
  }

  _useCanonicalId({component}) {
    if(component.termType === 'BlankNode' &&
      !component.value.startsWith(this.canonicalIssuer.prefix)) {
      return {
        termType: 'BlankNode',
        value: this.canonicalIssuer.getId(component.value)
      };
    }
    return component;
  }

  async _yield() {
    return new Promise(resolve => setImmediate(resolve));
  }
};

function _stringHashCompare(a, b) {
  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
}

}).call(this)}).call(this,require("timers").setImmediate)
},{"./IdentifierIssuer":190,"./MessageDigest":191,"./NQuads":192,"./Permuter":193,"timers":228}],195:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const IdentifierIssuer = require('./IdentifierIssuer');
const MessageDigest = require('./MessageDigest');
const Permuter = require('./Permuter');
const NQuads = require('./NQuads');

module.exports = class URDNA2015Sync {
  constructor() {
    this.name = 'URDNA2015';
    this.blankNodeInfo = new Map();
    this.canonicalIssuer = new IdentifierIssuer('_:c14n');
    this.hashAlgorithm = 'sha256';
    this.quads = null;
  }

  // 4.4) Normalization Algorithm
  main(dataset) {
    this.quads = dataset;

    // 1) Create the normalization state.
    // 2) For every quad in input dataset:
    for(const quad of dataset) {
      // 2.1) For each blank node that occurs in the quad, add a reference
      // to the quad using the blank node identifier in the blank node to
      // quads map, creating a new entry if necessary.
      this._addBlankNodeQuadInfo({quad, component: quad.subject});
      this._addBlankNodeQuadInfo({quad, component: quad.object});
      this._addBlankNodeQuadInfo({quad, component: quad.graph});
    }

    // 3) Create a list of non-normalized blank node identifiers
    // non-normalized identifiers and populate it using the keys from the
    // blank node to quads map.
    // Note: We use a map here and it was generated during step 2.

    // 4) `simple` flag is skipped -- loop is optimized away. This optimization
    // is permitted because there was a typo in the hash first degree quads
    // algorithm in the URDNA2015 spec that was implemented widely making it
    // such that it could not be fixed; the result was that the loop only
    // needs to be run once and the first degree quad hashes will never change.
    // 5.1-5.2 are skipped; first degree quad hashes are generated just once
    // for all non-normalized blank nodes.

    // 5.3) For each blank node identifier identifier in non-normalized
    // identifiers:
    const hashToBlankNodes = new Map();
    const nonNormalized = [...this.blankNodeInfo.keys()];
    for(const id of nonNormalized) {
      // steps 5.3.1 and 5.3.2:
      this._hashAndTrackBlankNode({id, hashToBlankNodes});
    }

    // 5.4) For each hash to identifier list mapping in hash to blank
    // nodes map, lexicographically-sorted by hash:
    const hashes = [...hashToBlankNodes.keys()].sort();
    // optimize away second sort, gather non-unique hashes in order as we go
    const nonUnique = [];
    for(const hash of hashes) {
      // 5.4.1) If the length of identifier list is greater than 1,
      // continue to the next mapping.
      const idList = hashToBlankNodes.get(hash);
      if(idList.length > 1) {
        nonUnique.push(idList);
        continue;
      }

      // 5.4.2) Use the Issue Identifier algorithm, passing canonical
      // issuer and the single blank node identifier in identifier
      // list, identifier, to issue a canonical replacement identifier
      // for identifier.
      const id = idList[0];
      this.canonicalIssuer.getId(id);

      // Note: These steps are skipped, optimized away since the loop
      // only needs to be run once.
      // 5.4.3) Remove identifier from non-normalized identifiers.
      // 5.4.4) Remove hash from the hash to blank nodes map.
      // 5.4.5) Set simple to true.
    }

    // 6) For each hash to identifier list mapping in hash to blank nodes map,
    // lexicographically-sorted by hash:
    // Note: sort optimized away, use `nonUnique`.
    for(const idList of nonUnique) {
      // 6.1) Create hash path list where each item will be a result of
      // running the Hash N-Degree Quads algorithm.
      const hashPathList = [];

      // 6.2) For each blank node identifier identifier in identifier list:
      for(const id of idList) {
        // 6.2.1) If a canonical identifier has already been issued for
        // identifier, continue to the next identifier.
        if(this.canonicalIssuer.hasId(id)) {
          continue;
        }

        // 6.2.2) Create temporary issuer, an identifier issuer
        // initialized with the prefix _:b.
        const issuer = new IdentifierIssuer('_:b');

        // 6.2.3) Use the Issue Identifier algorithm, passing temporary
        // issuer and identifier, to issue a new temporary blank node
        // identifier for identifier.
        issuer.getId(id);

        // 6.2.4) Run the Hash N-Degree Quads algorithm, passing
        // temporary issuer, and append the result to the hash path list.
        const result = this.hashNDegreeQuads(id, issuer);
        hashPathList.push(result);
      }

      // 6.3) For each result in the hash path list,
      // lexicographically-sorted by the hash in result:
      hashPathList.sort(_stringHashCompare);
      for(const result of hashPathList) {
        // 6.3.1) For each blank node identifier, existing identifier,
        // that was issued a temporary identifier by identifier issuer
        // in result, issue a canonical identifier, in the same order,
        // using the Issue Identifier algorithm, passing canonical
        // issuer and existing identifier.
        const oldIds = result.issuer.getOldIds();
        for(const id of oldIds) {
          this.canonicalIssuer.getId(id);
        }
      }
    }

    /* Note: At this point all blank nodes in the set of RDF quads have been
    assigned canonical identifiers, which have been stored in the canonical
    issuer. Here each quad is updated by assigning each of its blank nodes
    its new identifier. */

    // 7) For each quad, quad, in input dataset:
    const normalized = [];
    for(const quad of this.quads) {
      // 7.1) Create a copy, quad copy, of quad and replace any existing
      // blank node identifiers using the canonical identifiers
      // previously issued by canonical issuer.
      // Note: We optimize with shallow copies here.
      const q = {...quad};
      q.subject = this._useCanonicalId({component: q.subject});
      q.object = this._useCanonicalId({component: q.object});
      q.graph = this._useCanonicalId({component: q.graph});
      // 7.2) Add quad copy to the normalized dataset.
      normalized.push(NQuads.serializeQuad(q));
    }

    // sort normalized output
    normalized.sort();

    // 8) Return the normalized dataset.
    return normalized.join('');
  }

  // 4.6) Hash First Degree Quads
  hashFirstDegreeQuads(id) {
    // 1) Initialize nquads to an empty list. It will be used to store quads in
    // N-Quads format.
    const nquads = [];

    // 2) Get the list of quads `quads` associated with the reference blank node
    // identifier in the blank node to quads map.
    const info = this.blankNodeInfo.get(id);
    const quads = info.quads;

    // 3) For each quad `quad` in `quads`:
    for(const quad of quads) {
      // 3.1) Serialize the quad in N-Quads format with the following special
      // rule:

      // 3.1.1) If any component in quad is an blank node, then serialize it
      // using a special identifier as follows:
      const copy = {
        subject: null, predicate: quad.predicate, object: null, graph: null
      };
      // 3.1.2) If the blank node's existing blank node identifier matches
      // the reference blank node identifier then use the blank node
      // identifier _:a, otherwise, use the blank node identifier _:z.
      copy.subject = this.modifyFirstDegreeComponent(
        id, quad.subject, 'subject');
      copy.object = this.modifyFirstDegreeComponent(
        id, quad.object, 'object');
      copy.graph = this.modifyFirstDegreeComponent(
        id, quad.graph, 'graph');
      nquads.push(NQuads.serializeQuad(copy));
    }

    // 4) Sort nquads in lexicographical order.
    nquads.sort();

    // 5) Return the hash that results from passing the sorted, joined nquads
    // through the hash algorithm.
    const md = new MessageDigest(this.hashAlgorithm);
    for(const nquad of nquads) {
      md.update(nquad);
    }
    info.hash = md.digest();
    return info.hash;
  }

  // 4.7) Hash Related Blank Node
  hashRelatedBlankNode(related, quad, issuer, position) {
    // 1) Set the identifier to use for related, preferring first the canonical
    // identifier for related if issued, second the identifier issued by issuer
    // if issued, and last, if necessary, the result of the Hash First Degree
    // Quads algorithm, passing related.
    let id;
    if(this.canonicalIssuer.hasId(related)) {
      id = this.canonicalIssuer.getId(related);
    } else if(issuer.hasId(related)) {
      id = issuer.getId(related);
    } else {
      id = this.blankNodeInfo.get(related).hash;
    }

    // 2) Initialize a string input to the value of position.
    // Note: We use a hash object instead.
    const md = new MessageDigest(this.hashAlgorithm);
    md.update(position);

    // 3) If position is not g, append <, the value of the predicate in quad,
    // and > to input.
    if(position !== 'g') {
      md.update(this.getRelatedPredicate(quad));
    }

    // 4) Append identifier to input.
    md.update(id);

    // 5) Return the hash that results from passing input through the hash
    // algorithm.
    return md.digest();
  }

  // 4.8) Hash N-Degree Quads
  hashNDegreeQuads(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    // Note: 2) and 3) handled within `createHashToRelated`
    const md = new MessageDigest(this.hashAlgorithm);
    const hashToRelated = this.createHashToRelated(id, issuer);

    // 4) Create an empty string, data to hash.
    // Note: We created a hash object `md` above instead.

    // 5) For each related hash to blank node list mapping in hash to related
    // blank nodes map, sorted lexicographically by related hash:
    const hashes = [...hashToRelated.keys()].sort();
    for(const hash of hashes) {
      // 5.1) Append the related hash to the data to hash.
      md.update(hash);

      // 5.2) Create a string chosen path.
      let chosenPath = '';

      // 5.3) Create an unset chosen issuer variable.
      let chosenIssuer;

      // 5.4) For each permutation of blank node list:
      const permuter = new Permuter(hashToRelated.get(hash));
      while(permuter.hasNext()) {
        const permutation = permuter.next();

        // 5.4.1) Create a copy of issuer, issuer copy.
        let issuerCopy = issuer.clone();

        // 5.4.2) Create a string path.
        let path = '';

        // 5.4.3) Create a recursion list, to store blank node identifiers
        // that must be recursively processed by this algorithm.
        const recursionList = [];

        // 5.4.4) For each related in permutation:
        let nextPermutation = false;
        for(const related of permutation) {
          // 5.4.4.1) If a canonical identifier has been issued for
          // related, append it to path.
          if(this.canonicalIssuer.hasId(related)) {
            path += this.canonicalIssuer.getId(related);
          } else {
            // 5.4.4.2) Otherwise:
            // 5.4.4.2.1) If issuer copy has not issued an identifier for
            // related, append related to recursion list.
            if(!issuerCopy.hasId(related)) {
              recursionList.push(related);
            }
            // 5.4.4.2.2) Use the Issue Identifier algorithm, passing
            // issuer copy and related and append the result to path.
            path += issuerCopy.getId(related);
          }

          // 5.4.4.3) If chosen path is not empty and the length of path
          // is greater than or equal to the length of chosen path and
          // path is lexicographically greater than chosen path, then
          // skip to the next permutation.
          // Note: Comparing path length to chosen path length can be optimized
          // away; only compare lexicographically.
          if(chosenPath.length !== 0 && path > chosenPath) {
            nextPermutation = true;
            break;
          }
        }

        if(nextPermutation) {
          continue;
        }

        // 5.4.5) For each related in recursion list:
        for(const related of recursionList) {
          // 5.4.5.1) Set result to the result of recursively executing
          // the Hash N-Degree Quads algorithm, passing related for
          // identifier and issuer copy for path identifier issuer.
          const result = this.hashNDegreeQuads(related, issuerCopy);

          // 5.4.5.2) Use the Issue Identifier algorithm, passing issuer
          // copy and related and append the result to path.
          path += issuerCopy.getId(related);

          // 5.4.5.3) Append <, the hash in result, and > to path.
          path += `<${result.hash}>`;

          // 5.4.5.4) Set issuer copy to the identifier issuer in
          // result.
          issuerCopy = result.issuer;

          // 5.4.5.5) If chosen path is not empty and the length of path
          // is greater than or equal to the length of chosen path and
          // path is lexicographically greater than chosen path, then
          // skip to the next permutation.
          // Note: Comparing path length to chosen path length can be optimized
          // away; only compare lexicographically.
          if(chosenPath.length !== 0 && path > chosenPath) {
            nextPermutation = true;
            break;
          }
        }

        if(nextPermutation) {
          continue;
        }

        // 5.4.6) If chosen path is empty or path is lexicographically
        // less than chosen path, set chosen path to path and chosen
        // issuer to issuer copy.
        if(chosenPath.length === 0 || path < chosenPath) {
          chosenPath = path;
          chosenIssuer = issuerCopy;
        }
      }

      // 5.5) Append chosen path to data to hash.
      md.update(chosenPath);

      // 5.6) Replace issuer, by reference, with chosen issuer.
      issuer = chosenIssuer;
    }

    // 6) Return issuer and the hash that results from passing data to hash
    // through the hash algorithm.
    return {hash: md.digest(), issuer};
  }

  // helper for modifying component during Hash First Degree Quads
  modifyFirstDegreeComponent(id, component) {
    if(component.termType !== 'BlankNode') {
      return component;
    }
    /* Note: A mistake in the URDNA2015 spec that made its way into
    implementations (and therefore must stay to avoid interop breakage)
    resulted in an assigned canonical ID, if available for
    `component.value`, not being used in place of `_:a`/`_:z`, so
    we don't use it here. */
    return {
      termType: 'BlankNode',
      value: component.value === id ? '_:a' : '_:z'
    };
  }

  // helper for getting a related predicate
  getRelatedPredicate(quad) {
    return `<${quad.predicate.value}>`;
  }

  // helper for creating hash to related blank nodes map
  createHashToRelated(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    const hashToRelated = new Map();

    // 2) Get a reference, quads, to the list of quads in the blank node to
    // quads map for the key identifier.
    const quads = this.blankNodeInfo.get(id).quads;

    // 3) For each quad in quads:
    for(const quad of quads) {
      // 3.1) For each component in quad, if component is the subject, object,
      // or graph name and it is a blank node that is not identified by
      // identifier:
      // steps 3.1.1 and 3.1.2 occur in helpers:
      this._addRelatedBlankNodeHash({
        quad, component: quad.subject, position: 's',
        id, issuer, hashToRelated
      });
      this._addRelatedBlankNodeHash({
        quad, component: quad.object, position: 'o',
        id, issuer, hashToRelated
      });
      this._addRelatedBlankNodeHash({
        quad, component: quad.graph, position: 'g',
        id, issuer, hashToRelated
      });
    }

    return hashToRelated;
  }

  _hashAndTrackBlankNode({id, hashToBlankNodes}) {
    // 5.3.1) Create a hash, hash, according to the Hash First Degree
    // Quads algorithm.
    const hash = this.hashFirstDegreeQuads(id);

    // 5.3.2) Add hash and identifier to hash to blank nodes map,
    // creating a new entry if necessary.
    const idList = hashToBlankNodes.get(hash);
    if(!idList) {
      hashToBlankNodes.set(hash, [id]);
    } else {
      idList.push(id);
    }
  }

  _addBlankNodeQuadInfo({quad, component}) {
    if(component.termType !== 'BlankNode') {
      return;
    }
    const id = component.value;
    const info = this.blankNodeInfo.get(id);
    if(info) {
      info.quads.add(quad);
    } else {
      this.blankNodeInfo.set(id, {quads: new Set([quad]), hash: null});
    }
  }

  _addRelatedBlankNodeHash(
    {quad, component, position, id, issuer, hashToRelated}) {
    if(!(component.termType === 'BlankNode' && component.value !== id)) {
      return;
    }
    // 3.1.1) Set hash to the result of the Hash Related Blank Node
    // algorithm, passing the blank node identifier for component as
    // related, quad, path identifier issuer as issuer, and position as
    // either s, o, or g based on whether component is a subject, object,
    // graph name, respectively.
    const related = component.value;
    const hash = this.hashRelatedBlankNode(related, quad, issuer, position);

    // 3.1.2) Add a mapping of hash to the blank node identifier for
    // component to hash to related blank nodes map, adding an entry as
    // necessary.
    const entries = hashToRelated.get(hash);
    if(entries) {
      entries.push(related);
    } else {
      hashToRelated.set(hash, [related]);
    }
  }

  _useCanonicalId({component}) {
    if(component.termType === 'BlankNode' &&
      !component.value.startsWith(this.canonicalIssuer.prefix)) {
      return {
        termType: 'BlankNode',
        value: this.canonicalIssuer.getId(component.value)
      };
    }
    return component;
  }
};

function _stringHashCompare(a, b) {
  return a.hash < b.hash ? -1 : a.hash > b.hash ? 1 : 0;
}

},{"./IdentifierIssuer":190,"./MessageDigest":191,"./NQuads":192,"./Permuter":193}],196:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const URDNA2015 = require('./URDNA2015');

module.exports = class URDNA2012 extends URDNA2015 {
  constructor() {
    super();
    this.name = 'URGNA2012';
    this.hashAlgorithm = 'sha1';
  }

  // helper for modifying component during Hash First Degree Quads
  modifyFirstDegreeComponent(id, component, key) {
    if(component.termType !== 'BlankNode') {
      return component;
    }
    if(key === 'graph') {
      return {
        termType: 'BlankNode',
        value: '_:g'
      };
    }
    return {
      termType: 'BlankNode',
      value: (component.value === id ? '_:a' : '_:z')
    };
  }

  // helper for getting a related predicate
  getRelatedPredicate(quad) {
    return quad.predicate.value;
  }

  // helper for creating hash to related blank nodes map
  async createHashToRelated(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    const hashToRelated = new Map();

    // 2) Get a reference, quads, to the list of quads in the blank node to
    // quads map for the key identifier.
    const quads = this.blankNodeInfo.get(id).quads;

    // 3) For each quad in quads:
    let i = 0;
    for(const quad of quads) {
      // 3.1) If the quad's subject is a blank node that does not match
      // identifier, set hash to the result of the Hash Related Blank Node
      // algorithm, passing the blank node identifier for subject as related,
      // quad, path identifier issuer as issuer, and p as position.
      let position;
      let related;
      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {
        related = quad.subject.value;
        position = 'p';
      } else if(
        quad.object.termType === 'BlankNode' && quad.object.value !== id) {
        // 3.2) Otherwise, if quad's object is a blank node that does not match
        // identifier, to the result of the Hash Related Blank Node algorithm,
        // passing the blank node identifier for object as related, quad, path
        // identifier issuer as issuer, and r as position.
        related = quad.object.value;
        position = 'r';
      } else {
        // 3.3) Otherwise, continue to the next quad.
        continue;
      }
      // Note: batch hashing related blank nodes 100 at a time
      if(++i % 100 === 0) {
        await this._yield();
      }
      // 3.4) Add a mapping of hash to the blank node identifier for the
      // component that matched (subject or object) to hash to related blank
      // nodes map, adding an entry as necessary.
      const hash = await this.hashRelatedBlankNode(
        related, quad, issuer, position);
      const entries = hashToRelated.get(hash);
      if(entries) {
        entries.push(related);
      } else {
        hashToRelated.set(hash, [related]);
      }
    }

    return hashToRelated;
  }
};

},{"./URDNA2015":194}],197:[function(require,module,exports){
/*
 * Copyright (c) 2016-2021 Digital Bazaar, Inc. All rights reserved.
 */
'use strict';

const URDNA2015Sync = require('./URDNA2015Sync');

module.exports = class URDNA2012Sync extends URDNA2015Sync {
  constructor() {
    super();
    this.name = 'URGNA2012';
    this.hashAlgorithm = 'sha1';
  }

  // helper for modifying component during Hash First Degree Quads
  modifyFirstDegreeComponent(id, component, key) {
    if(component.termType !== 'BlankNode') {
      return component;
    }
    if(key === 'graph') {
      return {
        termType: 'BlankNode',
        value: '_:g'
      };
    }
    return {
      termType: 'BlankNode',
      value: (component.value === id ? '_:a' : '_:z')
    };
  }

  // helper for getting a related predicate
  getRelatedPredicate(quad) {
    return quad.predicate.value;
  }

  // helper for creating hash to related blank nodes map
  createHashToRelated(id, issuer) {
    // 1) Create a hash to related blank nodes map for storing hashes that
    // identify related blank nodes.
    const hashToRelated = new Map();

    // 2) Get a reference, quads, to the list of quads in the blank node to
    // quads map for the key identifier.
    const quads = this.blankNodeInfo.get(id).quads;

    // 3) For each quad in quads:
    for(const quad of quads) {
      // 3.1) If the quad's subject is a blank node that does not match
      // identifier, set hash to the result of the Hash Related Blank Node
      // algorithm, passing the blank node identifier for subject as related,
      // quad, path identifier issuer as issuer, and p as position.
      let position;
      let related;
      if(quad.subject.termType === 'BlankNode' && quad.subject.value !== id) {
        related = quad.subject.value;
        position = 'p';
      } else if(
        quad.object.termType === 'BlankNode' && quad.object.value !== id) {
        // 3.2) Otherwise, if quad's object is a blank node that does not match
        // identifier, to the result of the Hash Related Blank Node algorithm,
        // passing the blank node identifier for object as related, quad, path
        // identifier issuer as issuer, and r as position.
        related = quad.object.value;
        position = 'r';
      } else {
        // 3.3) Otherwise, continue to the next quad.
        continue;
      }
      // 3.4) Add a mapping of hash to the blank node identifier for the
      // component that matched (subject or object) to hash to related blank
      // nodes map, adding an entry as necessary.
      const hash = this.hashRelatedBlankNode(related, quad, issuer, position);
      const entries = hashToRelated.get(hash);
      if(entries) {
        entries.push(related);
      } else {
        hashToRelated.set(hash, [related]);
      }
    }

    return hashToRelated;
  }
};

},{"./URDNA2015Sync":195}],198:[function(require,module,exports){
/**
 * An implementation of the RDF Dataset Normalization specification.
 * This library works in the browser and node.js.
 *
 * BSD 3-Clause License
 * Copyright (c) 2016-2021 Digital Bazaar, Inc.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions are met:
 *
 * Redistributions of source code must retain the above copyright notice,
 * this list of conditions and the following disclaimer.
 *
 * Redistributions in binary form must reproduce the above copyright
 * notice, this list of conditions and the following disclaimer in the
 * documentation and/or other materials provided with the distribution.
 *
 * Neither the name of the Digital Bazaar, Inc. nor the names of its
 * contributors may be used to endorse or promote products derived from
 * this software without specific prior written permission.
 *
 * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS
 * IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED
 * TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A
 * PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
 * HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
 * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
 * TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
 * PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
 * LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 * SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
'use strict';

const URDNA2015 = require('./URDNA2015');
const URGNA2012 = require('./URGNA2012');
const URDNA2015Sync = require('./URDNA2015Sync');
const URGNA2012Sync = require('./URGNA2012Sync');

// optional native support
let rdfCanonizeNative;
try {
  rdfCanonizeNative = require('rdf-canonize-native');
} catch(e) {}

const api = {};
module.exports = api;

// expose helpers
api.NQuads = require('./NQuads');
api.IdentifierIssuer = require('./IdentifierIssuer');

/**
 * Get or set native API.
 *
 * @param api the native API.
 *
 * @return the currently set native API.
 */
api._rdfCanonizeNative = function(api) {
  if(api) {
    rdfCanonizeNative = api;
  }
  return rdfCanonizeNative;
};

/**
 * Asynchronously canonizes an RDF dataset.
 *
 * @param dataset the dataset to canonize.
 * @param options the options to use:
 *          algorithm the canonicalization algorithm to use, `URDNA2015` or
 *            `URGNA2012`.
 *          [useNative] use native implementation (default: false).
 *
 * @return a Promise that resolves to the canonicalized RDF Dataset.
 */
api.canonize = async function(dataset, options) {
  // back-compat with legacy dataset
  if(!Array.isArray(dataset)) {
    dataset = api.NQuads.legacyDatasetToQuads(dataset);
  }

  if(options.useNative) {
    if(!rdfCanonizeNative) {
      throw new Error('rdf-canonize-native not available');
    }
    // TODO: convert native algorithm to Promise-based async
    return new Promise((resolve, reject) =>
      rdfCanonizeNative.canonize(dataset, options, (err, canonical) =>
        err ? reject(err) : resolve(canonical)));
  }

  if(options.algorithm === 'URDNA2015') {
    return new URDNA2015(options).main(dataset);
  }
  if(options.algorithm === 'URGNA2012') {
    return new URGNA2012(options).main(dataset);
  }
  if(!('algorithm' in options)) {
    throw new Error('No RDF Dataset Canonicalization algorithm specified.');
  }
  throw new Error(
    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);
};

/**
 * This method is no longer available in the public API, it is for testing
 * only. It synchronously canonizes an RDF dataset and does not work in the
 * browser.
 *
 * @param dataset the dataset to canonize.
 * @param options the options to use:
 *          algorithm the canonicalization algorithm to use, `URDNA2015` or
 *            `URGNA2012`.
 *          [useNative] use native implementation (default: false).
 *
 * @return the RDF dataset in canonical form.
 */
api._canonizeSync = function(dataset, options) {
  // back-compat with legacy dataset
  if(!Array.isArray(dataset)) {
    dataset = api.NQuads.legacyDatasetToQuads(dataset);
  }

  if(options.useNative) {
    if(rdfCanonizeNative) {
      return rdfCanonizeNative.canonizeSync(dataset, options);
    }
    throw new Error('rdf-canonize-native not available');
  }
  if(options.algorithm === 'URDNA2015') {
    return new URDNA2015Sync(options).main(dataset);
  }
  if(options.algorithm === 'URGNA2012') {
    return new URGNA2012Sync(options).main(dataset);
  }
  if(!('algorithm' in options)) {
    throw new Error('No RDF Dataset Canonicalization algorithm specified.');
  }
  throw new Error(
    'Invalid RDF Dataset Canonicalization algorithm: ' + options.algorithm);
};

},{"./IdentifierIssuer":190,"./NQuads":192,"./URDNA2015":194,"./URDNA2015Sync":195,"./URGNA2012":196,"./URGNA2012Sync":197,"rdf-canonize-native":45}],199:[function(require,module,exports){
'use strict';

function _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }

var codes = {};

function createErrorType(code, message, Base) {
  if (!Base) {
    Base = Error;
  }

  function getMessage(arg1, arg2, arg3) {
    if (typeof message === 'string') {
      return message;
    } else {
      return message(arg1, arg2, arg3);
    }
  }

  var NodeError =
  /*#__PURE__*/
  function (_Base) {
    _inheritsLoose(NodeError, _Base);

    function NodeError(arg1, arg2, arg3) {
      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;
    }

    return NodeError;
  }(Base);

  NodeError.prototype.name = Base.name;
  NodeError.prototype.code = code;
  codes[code] = NodeError;
} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js


function oneOf(expected, thing) {
  if (Array.isArray(expected)) {
    var len = expected.length;
    expected = expected.map(function (i) {
      return String(i);
    });

    if (len > 2) {
      return "one of ".concat(thing, " ").concat(expected.slice(0, len - 1).join(', '), ", or ") + expected[len - 1];
    } else if (len === 2) {
      return "one of ".concat(thing, " ").concat(expected[0], " or ").concat(expected[1]);
    } else {
      return "of ".concat(thing, " ").concat(expected[0]);
    }
  } else {
    return "of ".concat(thing, " ").concat(String(expected));
  }
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith


function startsWith(str, search, pos) {
  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith


function endsWith(str, search, this_len) {
  if (this_len === undefined || this_len > str.length) {
    this_len = str.length;
  }

  return str.substring(this_len - search.length, this_len) === search;
} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes


function includes(str, search, start) {
  if (typeof start !== 'number') {
    start = 0;
  }

  if (start + search.length > str.length) {
    return false;
  } else {
    return str.indexOf(search, start) !== -1;
  }
}

createErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {
  return 'The value "' + value + '" is invalid for option "' + name + '"';
}, TypeError);
createErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {
  // determiner: 'must be' or 'must not be'
  var determiner;

  if (typeof expected === 'string' && startsWith(expected, 'not ')) {
    determiner = 'must not be';
    expected = expected.replace(/^not /, '');
  } else {
    determiner = 'must be';
  }

  var msg;

  if (endsWith(name, ' argument')) {
    // For cases like 'first argument'
    msg = "The ".concat(name, " ").concat(determiner, " ").concat(oneOf(expected, 'type'));
  } else {
    var type = includes(name, '.') ? 'property' : 'argument';
    msg = "The \"".concat(name, "\" ").concat(type, " ").concat(determiner, " ").concat(oneOf(expected, 'type'));
  }

  msg += ". Received type ".concat(typeof actual);
  return msg;
}, TypeError);
createErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');
createErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {
  return 'The ' + name + ' method is not implemented';
});
createErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');
createErrorType('ERR_STREAM_DESTROYED', function (name) {
  return 'Cannot call ' + name + ' after a stream was destroyed';
});
createErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');
createErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');
createErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');
createErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);
createErrorType('ERR_UNKNOWN_ENCODING', function (arg) {
  return 'Unknown encoding: ' + arg;
}, TypeError);
createErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');
module.exports.codes = codes;

},{}],200:[function(require,module,exports){
(function (process){(function (){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a duplex stream is just a stream that is both readable and writable.
// Since JS doesn't have multiple prototypal inheritance, this class
// prototypally inherits from Readable, and then parasitically from
// Writable.
'use strict';
/*<replacement>*/

var objectKeys = Object.keys || function (obj) {
  var keys = [];

  for (var key in obj) {
    keys.push(key);
  }

  return keys;
};
/*</replacement>*/


module.exports = Duplex;

var Readable = require('./_stream_readable');

var Writable = require('./_stream_writable');

require('inherits')(Duplex, Readable);

{
  // Allow the keys array to be GC'ed.
  var keys = objectKeys(Writable.prototype);

  for (var v = 0; v < keys.length; v++) {
    var method = keys[v];
    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];
  }
}

function Duplex(options) {
  if (!(this instanceof Duplex)) return new Duplex(options);
  Readable.call(this, options);
  Writable.call(this, options);
  this.allowHalfOpen = true;

  if (options) {
    if (options.readable === false) this.readable = false;
    if (options.writable === false) this.writable = false;

    if (options.allowHalfOpen === false) {
      this.allowHalfOpen = false;
      this.once('end', onend);
    }
  }
}

Object.defineProperty(Duplex.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
});
Object.defineProperty(Duplex.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});
Object.defineProperty(Duplex.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
}); // the no-half-open enforcer

function onend() {
  // If the writable side ended, then we're ok.
  if (this._writableState.ended) return; // no more data can be written.
  // But allow more writes to happen in this tick.

  process.nextTick(onEndNT, this);
}

function onEndNT(self) {
  self.end();
}

Object.defineProperty(Duplex.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined || this._writableState === undefined) {
      return false;
    }

    return this._readableState.destroyed && this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (this._readableState === undefined || this._writableState === undefined) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
    this._writableState.destroyed = value;
  }
});
}).call(this)}).call(this,require('_process'))
},{"./_stream_readable":202,"./_stream_writable":204,"_process":179,"inherits":136}],201:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a passthrough stream.
// basically just the most minimal sort of Transform stream.
// Every written chunk gets output as-is.
'use strict';

module.exports = PassThrough;

var Transform = require('./_stream_transform');

require('inherits')(PassThrough, Transform);

function PassThrough(options) {
  if (!(this instanceof PassThrough)) return new PassThrough(options);
  Transform.call(this, options);
}

PassThrough.prototype._transform = function (chunk, encoding, cb) {
  cb(null, chunk);
};
},{"./_stream_transform":203,"inherits":136}],202:[function(require,module,exports){
(function (process,global){(function (){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
'use strict';

module.exports = Readable;
/*<replacement>*/

var Duplex;
/*</replacement>*/

Readable.ReadableState = ReadableState;
/*<replacement>*/

var EE = require('events').EventEmitter;

var EElistenerCount = function EElistenerCount(emitter, type) {
  return emitter.listeners(type).length;
};
/*</replacement>*/

/*<replacement>*/


var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}
/*<replacement>*/


var debugUtil = require('util');

var debug;

if (debugUtil && debugUtil.debuglog) {
  debug = debugUtil.debuglog('stream');
} else {
  debug = function debug() {};
}
/*</replacement>*/


var BufferList = require('./internal/streams/buffer_list');

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.


var StringDecoder;
var createReadableStreamAsyncIterator;
var from;

require('inherits')(Readable, Stream);

var errorOrDestroy = destroyImpl.errorOrDestroy;
var kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];

function prependListener(emitter, event, fn) {
  // Sadly this is not cacheable as some libraries bundle their own
  // event emitter implementation with them.
  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any
  // userland ones.  NEVER DO THIS. This is here only because this code needs
  // to continue to work with older versions of Node.js that do not include
  // the prependListener() method. The goal is to eventually remove this hack.

  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];
}

function ReadableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream.
  // These options can be provided separately as readableXXX and writableXXX.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to
  // make all the buffer merging and length checks go away

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer
  // Note: 0 is a valid value, means "don't call _read preemptively ever"

  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the
  // linked list can remove elements from the beginning faster than
  // array.shift()

  this.buffer = new BufferList();
  this.length = 0;
  this.pipes = null;
  this.pipesCount = 0;
  this.flowing = null;
  this.ended = false;
  this.endEmitted = false;
  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted
  // immediately, or on a later tick.  We set this to true at first, because
  // any actions that shouldn't happen until "later" should generally also
  // not happen before the first read call.

  this.sync = true; // whenever we return null, then we set a flag to say
  // that we're awaiting a 'readable' event emission.

  this.needReadable = false;
  this.emittedReadable = false;
  this.readableListening = false;
  this.resumeScheduled = false;
  this.paused = true; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')

  this.autoDestroy = !!options.autoDestroy; // has it been destroyed

  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s

  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled

  this.readingMore = false;
  this.decoder = null;
  this.encoding = null;

  if (options.encoding) {
    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
    this.decoder = new StringDecoder(options.encoding);
    this.encoding = options.encoding;
  }
}

function Readable(options) {
  Duplex = Duplex || require('./_stream_duplex');
  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside
  // the ReadableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  this._readableState = new ReadableState(options, this, isDuplex); // legacy

  this.readable = true;

  if (options) {
    if (typeof options.read === 'function') this._read = options.read;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
  }

  Stream.call(this);
}

Object.defineProperty(Readable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._readableState === undefined) {
      return false;
    }

    return this._readableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._readableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._readableState.destroyed = value;
  }
});
Readable.prototype.destroy = destroyImpl.destroy;
Readable.prototype._undestroy = destroyImpl.undestroy;

Readable.prototype._destroy = function (err, cb) {
  cb(err);
}; // Manually shove something into the read() buffer.
// This returns true if the highWaterMark has not been hit yet,
// similar to how Writable.write() returns true if you should
// write() some more.


Readable.prototype.push = function (chunk, encoding) {
  var state = this._readableState;
  var skipChunkCheck;

  if (!state.objectMode) {
    if (typeof chunk === 'string') {
      encoding = encoding || state.defaultEncoding;

      if (encoding !== state.encoding) {
        chunk = Buffer.from(chunk, encoding);
        encoding = '';
      }

      skipChunkCheck = true;
    }
  } else {
    skipChunkCheck = true;
  }

  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);
}; // Unshift should *always* be something directly out of read()


Readable.prototype.unshift = function (chunk) {
  return readableAddChunk(this, chunk, null, true, false);
};

function readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {
  debug('readableAddChunk', chunk);
  var state = stream._readableState;

  if (chunk === null) {
    state.reading = false;
    onEofChunk(stream, state);
  } else {
    var er;
    if (!skipChunkCheck) er = chunkInvalid(state, chunk);

    if (er) {
      errorOrDestroy(stream, er);
    } else if (state.objectMode || chunk && chunk.length > 0) {
      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {
        chunk = _uint8ArrayToBuffer(chunk);
      }

      if (addToFront) {
        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);
      } else if (state.ended) {
        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());
      } else if (state.destroyed) {
        return false;
      } else {
        state.reading = false;

        if (state.decoder && !encoding) {
          chunk = state.decoder.write(chunk);
          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);
        } else {
          addChunk(stream, state, chunk, false);
        }
      }
    } else if (!addToFront) {
      state.reading = false;
      maybeReadMore(stream, state);
    }
  } // We can push more data if we are below the highWaterMark.
  // Also, if we have no data yet, we can stand some more bytes.
  // This is to work around cases where hwm=0, such as the repl.


  return !state.ended && (state.length < state.highWaterMark || state.length === 0);
}

function addChunk(stream, state, chunk, addToFront) {
  if (state.flowing && state.length === 0 && !state.sync) {
    state.awaitDrain = 0;
    stream.emit('data', chunk);
  } else {
    // update the buffer info.
    state.length += state.objectMode ? 1 : chunk.length;
    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);
    if (state.needReadable) emitReadable(stream);
  }

  maybeReadMore(stream, state);
}

function chunkInvalid(state, chunk) {
  var er;

  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);
  }

  return er;
}

Readable.prototype.isPaused = function () {
  return this._readableState.flowing === false;
}; // backwards compatibility.


Readable.prototype.setEncoding = function (enc) {
  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;
  var decoder = new StringDecoder(enc);
  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8

  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:

  var p = this._readableState.buffer.head;
  var content = '';

  while (p !== null) {
    content += decoder.write(p.data);
    p = p.next;
  }

  this._readableState.buffer.clear();

  if (content !== '') this._readableState.buffer.push(content);
  this._readableState.length = content.length;
  return this;
}; // Don't raise the hwm > 1GB


var MAX_HWM = 0x40000000;

function computeNewHighWaterMark(n) {
  if (n >= MAX_HWM) {
    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.
    n = MAX_HWM;
  } else {
    // Get the next highest power of 2 to prevent increasing hwm excessively in
    // tiny amounts
    n--;
    n |= n >>> 1;
    n |= n >>> 2;
    n |= n >>> 4;
    n |= n >>> 8;
    n |= n >>> 16;
    n++;
  }

  return n;
} // This function is designed to be inlinable, so please take care when making
// changes to the function body.


function howMuchToRead(n, state) {
  if (n <= 0 || state.length === 0 && state.ended) return 0;
  if (state.objectMode) return 1;

  if (n !== n) {
    // Only flow one buffer at a time
    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;
  } // If we're asking for more than the current hwm, then raise the hwm.


  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);
  if (n <= state.length) return n; // Don't have enough

  if (!state.ended) {
    state.needReadable = true;
    return 0;
  }

  return state.length;
} // you can override either this method, or the async _read(n) below.


Readable.prototype.read = function (n) {
  debug('read', n);
  n = parseInt(n, 10);
  var state = this._readableState;
  var nOrig = n;
  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we
  // already have a bunch of data in the buffer, then just trigger
  // the 'readable' event and move on.

  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {
    debug('read: emitReadable', state.length, state.ended);
    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);
    return null;
  }

  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.

  if (n === 0 && state.ended) {
    if (state.length === 0) endReadable(this);
    return null;
  } // All the actual chunk generation logic needs to be
  // *below* the call to _read.  The reason is that in certain
  // synthetic stream cases, such as passthrough streams, _read
  // may be a completely synchronous operation which may change
  // the state of the read buffer, providing enough data when
  // before there was *not* enough.
  //
  // So, the steps are:
  // 1. Figure out what the state of things will be after we do
  // a read from the buffer.
  //
  // 2. If that resulting state will trigger a _read, then call _read.
  // Note that this may be asynchronous, or synchronous.  Yes, it is
  // deeply ugly to write APIs this way, but that still doesn't mean
  // that the Readable class should behave improperly, as streams are
  // designed to be sync/async agnostic.
  // Take note if the _read call is sync or async (ie, if the read call
  // has returned yet), so that we know whether or not it's safe to emit
  // 'readable' etc.
  //
  // 3. Actually pull the requested chunks out of the buffer and return.
  // if we need a readable event, then we need to do some reading.


  var doRead = state.needReadable;
  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some

  if (state.length === 0 || state.length - n < state.highWaterMark) {
    doRead = true;
    debug('length less than watermark', doRead);
  } // however, if we've ended, then there's no point, and if we're already
  // reading, then it's unnecessary.


  if (state.ended || state.reading) {
    doRead = false;
    debug('reading or ended', doRead);
  } else if (doRead) {
    debug('do read');
    state.reading = true;
    state.sync = true; // if the length is currently zero, then we *need* a readable event.

    if (state.length === 0) state.needReadable = true; // call internal read method

    this._read(state.highWaterMark);

    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,
    // and we need to re-evaluate how much data we can return to the user.

    if (!state.reading) n = howMuchToRead(nOrig, state);
  }

  var ret;
  if (n > 0) ret = fromList(n, state);else ret = null;

  if (ret === null) {
    state.needReadable = state.length <= state.highWaterMark;
    n = 0;
  } else {
    state.length -= n;
    state.awaitDrain = 0;
  }

  if (state.length === 0) {
    // If we have nothing in the buffer, then we want to know
    // as soon as we *do* get something into the buffer.
    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.

    if (nOrig !== n && state.ended) endReadable(this);
  }

  if (ret !== null) this.emit('data', ret);
  return ret;
};

function onEofChunk(stream, state) {
  debug('onEofChunk');
  if (state.ended) return;

  if (state.decoder) {
    var chunk = state.decoder.end();

    if (chunk && chunk.length) {
      state.buffer.push(chunk);
      state.length += state.objectMode ? 1 : chunk.length;
    }
  }

  state.ended = true;

  if (state.sync) {
    // if we are sync, wait until next tick to emit the data.
    // Otherwise we risk emitting data in the flow()
    // the readable code triggers during a read() call
    emitReadable(stream);
  } else {
    // emit 'readable' now to make sure it gets picked up.
    state.needReadable = false;

    if (!state.emittedReadable) {
      state.emittedReadable = true;
      emitReadable_(stream);
    }
  }
} // Don't emit readable right away in sync mode, because this can trigger
// another read() call => stack overflow.  This way, it might trigger
// a nextTick recursion warning, but that's not so bad.


function emitReadable(stream) {
  var state = stream._readableState;
  debug('emitReadable', state.needReadable, state.emittedReadable);
  state.needReadable = false;

  if (!state.emittedReadable) {
    debug('emitReadable', state.flowing);
    state.emittedReadable = true;
    process.nextTick(emitReadable_, stream);
  }
}

function emitReadable_(stream) {
  var state = stream._readableState;
  debug('emitReadable_', state.destroyed, state.length, state.ended);

  if (!state.destroyed && (state.length || state.ended)) {
    stream.emit('readable');
    state.emittedReadable = false;
  } // The stream needs another readable event if
  // 1. It is not flowing, as the flow mechanism will take
  //    care of it.
  // 2. It is not ended.
  // 3. It is below the highWaterMark, so we can schedule
  //    another readable later.


  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;
  flow(stream);
} // at this point, the user has presumably seen the 'readable' event,
// and called read() to consume some data.  that may have triggered
// in turn another _read(n) call, in which case reading = true if
// it's in progress.
// However, if we're not ended, or reading, and the length < hwm,
// then go ahead and try to read some more preemptively.


function maybeReadMore(stream, state) {
  if (!state.readingMore) {
    state.readingMore = true;
    process.nextTick(maybeReadMore_, stream, state);
  }
}

function maybeReadMore_(stream, state) {
  // Attempt to read more data if we should.
  //
  // The conditions for reading more data are (one of):
  // - Not enough data buffered (state.length < state.highWaterMark). The loop
  //   is responsible for filling the buffer with enough data if such data
  //   is available. If highWaterMark is 0 and we are not in the flowing mode
  //   we should _not_ attempt to buffer any extra data. We'll get more data
  //   when the stream consumer calls read() instead.
  // - No data in the buffer, and the stream is in flowing mode. In this mode
  //   the loop below is responsible for ensuring read() is called. Failing to
  //   call read here would abort the flow and there's no other mechanism for
  //   continuing the flow if the stream consumer has just subscribed to the
  //   'data' event.
  //
  // In addition to the above conditions to keep reading data, the following
  // conditions prevent the data from being read:
  // - The stream has ended (state.ended).
  // - There is already a pending 'read' operation (state.reading). This is a
  //   case where the the stream has called the implementation defined _read()
  //   method, but they are processing the call asynchronously and have _not_
  //   called push() with new data. In this case we skip performing more
  //   read()s. The execution ends in this method again after the _read() ends
  //   up calling push() with more data.
  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {
    var len = state.length;
    debug('maybeReadMore read 0');
    stream.read(0);
    if (len === state.length) // didn't get any data, stop spinning.
      break;
  }

  state.readingMore = false;
} // abstract method.  to be overridden in specific implementation classes.
// call cb(er, data) where data is <= n in length.
// for virtual (non-string, non-buffer) streams, "length" is somewhat
// arbitrary, and perhaps not very meaningful.


Readable.prototype._read = function (n) {
  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));
};

Readable.prototype.pipe = function (dest, pipeOpts) {
  var src = this;
  var state = this._readableState;

  switch (state.pipesCount) {
    case 0:
      state.pipes = dest;
      break;

    case 1:
      state.pipes = [state.pipes, dest];
      break;

    default:
      state.pipes.push(dest);
      break;
  }

  state.pipesCount += 1;
  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);
  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;
  var endFn = doEnd ? onend : unpipe;
  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);
  dest.on('unpipe', onunpipe);

  function onunpipe(readable, unpipeInfo) {
    debug('onunpipe');

    if (readable === src) {
      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {
        unpipeInfo.hasUnpiped = true;
        cleanup();
      }
    }
  }

  function onend() {
    debug('onend');
    dest.end();
  } // when the dest drains, it reduces the awaitDrain counter
  // on the source.  This would be more elegant with a .once()
  // handler in flow(), but adding and removing repeatedly is
  // too slow.


  var ondrain = pipeOnDrain(src);
  dest.on('drain', ondrain);
  var cleanedUp = false;

  function cleanup() {
    debug('cleanup'); // cleanup event handlers once the pipe is broken

    dest.removeListener('close', onclose);
    dest.removeListener('finish', onfinish);
    dest.removeListener('drain', ondrain);
    dest.removeListener('error', onerror);
    dest.removeListener('unpipe', onunpipe);
    src.removeListener('end', onend);
    src.removeListener('end', unpipe);
    src.removeListener('data', ondata);
    cleanedUp = true; // if the reader is waiting for a drain event from this
    // specific writer, then it would cause it to never start
    // flowing again.
    // So, if this is awaiting a drain, then we just call it now.
    // If we don't know, then assume that we are waiting for one.

    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();
  }

  src.on('data', ondata);

  function ondata(chunk) {
    debug('ondata');
    var ret = dest.write(chunk);
    debug('dest.write', ret);

    if (ret === false) {
      // If the user unpiped during `dest.write()`, it is possible
      // to get stuck in a permanently paused state if that write
      // also returned false.
      // => Check whether `dest` is still a piping destination.
      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {
        debug('false write response, pause', state.awaitDrain);
        state.awaitDrain++;
      }

      src.pause();
    }
  } // if the dest has an error, then stop piping into it.
  // however, don't suppress the throwing behavior for this.


  function onerror(er) {
    debug('onerror', er);
    unpipe();
    dest.removeListener('error', onerror);
    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);
  } // Make sure our error handler is attached before userland ones.


  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.

  function onclose() {
    dest.removeListener('finish', onfinish);
    unpipe();
  }

  dest.once('close', onclose);

  function onfinish() {
    debug('onfinish');
    dest.removeListener('close', onclose);
    unpipe();
  }

  dest.once('finish', onfinish);

  function unpipe() {
    debug('unpipe');
    src.unpipe(dest);
  } // tell the dest that it's being piped to


  dest.emit('pipe', src); // start the flow if it hasn't been started already.

  if (!state.flowing) {
    debug('pipe resume');
    src.resume();
  }

  return dest;
};

function pipeOnDrain(src) {
  return function pipeOnDrainFunctionResult() {
    var state = src._readableState;
    debug('pipeOnDrain', state.awaitDrain);
    if (state.awaitDrain) state.awaitDrain--;

    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {
      state.flowing = true;
      flow(src);
    }
  };
}

Readable.prototype.unpipe = function (dest) {
  var state = this._readableState;
  var unpipeInfo = {
    hasUnpiped: false
  }; // if we're not piping anywhere, then do nothing.

  if (state.pipesCount === 0) return this; // just one destination.  most common case.

  if (state.pipesCount === 1) {
    // passed in one, but it's not the right one.
    if (dest && dest !== state.pipes) return this;
    if (!dest) dest = state.pipes; // got a match.

    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;
    if (dest) dest.emit('unpipe', this, unpipeInfo);
    return this;
  } // slow case. multiple pipe destinations.


  if (!dest) {
    // remove all.
    var dests = state.pipes;
    var len = state.pipesCount;
    state.pipes = null;
    state.pipesCount = 0;
    state.flowing = false;

    for (var i = 0; i < len; i++) {
      dests[i].emit('unpipe', this, {
        hasUnpiped: false
      });
    }

    return this;
  } // try to find the right one.


  var index = indexOf(state.pipes, dest);
  if (index === -1) return this;
  state.pipes.splice(index, 1);
  state.pipesCount -= 1;
  if (state.pipesCount === 1) state.pipes = state.pipes[0];
  dest.emit('unpipe', this, unpipeInfo);
  return this;
}; // set up data events if they are asked for
// Ensure readable listeners eventually get something


Readable.prototype.on = function (ev, fn) {
  var res = Stream.prototype.on.call(this, ev, fn);
  var state = this._readableState;

  if (ev === 'data') {
    // update readableListening so that resume() may be a no-op
    // a few lines down. This is needed to support once('readable').
    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused

    if (state.flowing !== false) this.resume();
  } else if (ev === 'readable') {
    if (!state.endEmitted && !state.readableListening) {
      state.readableListening = state.needReadable = true;
      state.flowing = false;
      state.emittedReadable = false;
      debug('on readable', state.length, state.reading);

      if (state.length) {
        emitReadable(this);
      } else if (!state.reading) {
        process.nextTick(nReadingNextTick, this);
      }
    }
  }

  return res;
};

Readable.prototype.addListener = Readable.prototype.on;

Readable.prototype.removeListener = function (ev, fn) {
  var res = Stream.prototype.removeListener.call(this, ev, fn);

  if (ev === 'readable') {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

Readable.prototype.removeAllListeners = function (ev) {
  var res = Stream.prototype.removeAllListeners.apply(this, arguments);

  if (ev === 'readable' || ev === undefined) {
    // We need to check if there is someone still listening to
    // readable and reset the state. However this needs to happen
    // after readable has been emitted but before I/O (nextTick) to
    // support once('readable', fn) cycles. This means that calling
    // resume within the same tick will have no
    // effect.
    process.nextTick(updateReadableListening, this);
  }

  return res;
};

function updateReadableListening(self) {
  var state = self._readableState;
  state.readableListening = self.listenerCount('readable') > 0;

  if (state.resumeScheduled && !state.paused) {
    // flowing needs to be set to true now, otherwise
    // the upcoming resume will not flow.
    state.flowing = true; // crude way to check if we should resume
  } else if (self.listenerCount('data') > 0) {
    self.resume();
  }
}

function nReadingNextTick(self) {
  debug('readable nexttick read 0');
  self.read(0);
} // pause() and resume() are remnants of the legacy readable stream API
// If the user uses them, then switch into old mode.


Readable.prototype.resume = function () {
  var state = this._readableState;

  if (!state.flowing) {
    debug('resume'); // we flow only if there is no one listening
    // for readable, but we still have to call
    // resume()

    state.flowing = !state.readableListening;
    resume(this, state);
  }

  state.paused = false;
  return this;
};

function resume(stream, state) {
  if (!state.resumeScheduled) {
    state.resumeScheduled = true;
    process.nextTick(resume_, stream, state);
  }
}

function resume_(stream, state) {
  debug('resume', state.reading);

  if (!state.reading) {
    stream.read(0);
  }

  state.resumeScheduled = false;
  stream.emit('resume');
  flow(stream);
  if (state.flowing && !state.reading) stream.read(0);
}

Readable.prototype.pause = function () {
  debug('call pause flowing=%j', this._readableState.flowing);

  if (this._readableState.flowing !== false) {
    debug('pause');
    this._readableState.flowing = false;
    this.emit('pause');
  }

  this._readableState.paused = true;
  return this;
};

function flow(stream) {
  var state = stream._readableState;
  debug('flow', state.flowing);

  while (state.flowing && stream.read() !== null) {
    ;
  }
} // wrap an old-style stream as the async data source.
// This is *not* part of the readable stream interface.
// It is an ugly unfortunate mess of history.


Readable.prototype.wrap = function (stream) {
  var _this = this;

  var state = this._readableState;
  var paused = false;
  stream.on('end', function () {
    debug('wrapped end');

    if (state.decoder && !state.ended) {
      var chunk = state.decoder.end();
      if (chunk && chunk.length) _this.push(chunk);
    }

    _this.push(null);
  });
  stream.on('data', function (chunk) {
    debug('wrapped data');
    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode

    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;

    var ret = _this.push(chunk);

    if (!ret) {
      paused = true;
      stream.pause();
    }
  }); // proxy all the other methods.
  // important when wrapping filters and duplexes.

  for (var i in stream) {
    if (this[i] === undefined && typeof stream[i] === 'function') {
      this[i] = function methodWrap(method) {
        return function methodWrapReturnFunction() {
          return stream[method].apply(stream, arguments);
        };
      }(i);
    }
  } // proxy certain important events.


  for (var n = 0; n < kProxyEvents.length; n++) {
    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));
  } // when we try to consume some more bytes, simply unpause the
  // underlying stream.


  this._read = function (n) {
    debug('wrapped _read', n);

    if (paused) {
      paused = false;
      stream.resume();
    }
  };

  return this;
};

if (typeof Symbol === 'function') {
  Readable.prototype[Symbol.asyncIterator] = function () {
    if (createReadableStreamAsyncIterator === undefined) {
      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');
    }

    return createReadableStreamAsyncIterator(this);
  };
}

Object.defineProperty(Readable.prototype, 'readableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.highWaterMark;
  }
});
Object.defineProperty(Readable.prototype, 'readableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState && this._readableState.buffer;
  }
});
Object.defineProperty(Readable.prototype, 'readableFlowing', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.flowing;
  },
  set: function set(state) {
    if (this._readableState) {
      this._readableState.flowing = state;
    }
  }
}); // exposed for testing purposes only.

Readable._fromList = fromList;
Object.defineProperty(Readable.prototype, 'readableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._readableState.length;
  }
}); // Pluck off n bytes from an array of buffers.
// Length is the combined lengths of all the buffers in the list.
// This function is designed to be inlinable, so please take care when making
// changes to the function body.

function fromList(n, state) {
  // nothing buffered
  if (state.length === 0) return null;
  var ret;
  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {
    // read it all, truncate the list
    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);
    state.buffer.clear();
  } else {
    // read part of list
    ret = state.buffer.consume(n, state.decoder);
  }
  return ret;
}

function endReadable(stream) {
  var state = stream._readableState;
  debug('endReadable', state.endEmitted);

  if (!state.endEmitted) {
    state.ended = true;
    process.nextTick(endReadableNT, state, stream);
  }
}

function endReadableNT(state, stream) {
  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.

  if (!state.endEmitted && state.length === 0) {
    state.endEmitted = true;
    stream.readable = false;
    stream.emit('end');

    if (state.autoDestroy) {
      // In case of duplex streams we need a way to detect
      // if the writable side is ready for autoDestroy as well
      var wState = stream._writableState;

      if (!wState || wState.autoDestroy && wState.finished) {
        stream.destroy();
      }
    }
  }
}

if (typeof Symbol === 'function') {
  Readable.from = function (iterable, opts) {
    if (from === undefined) {
      from = require('./internal/streams/from');
    }

    return from(Readable, iterable, opts);
  };
}

function indexOf(xs, x) {
  for (var i = 0, l = xs.length; i < l; i++) {
    if (xs[i] === x) return i;
  }

  return -1;
}
}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"../errors":199,"./_stream_duplex":200,"./internal/streams/async_iterator":205,"./internal/streams/buffer_list":206,"./internal/streams/destroy":207,"./internal/streams/from":209,"./internal/streams/state":211,"./internal/streams/stream":212,"_process":179,"buffer":74,"events":118,"inherits":136,"string_decoder/":227,"util":45}],203:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// a transform stream is a readable/writable stream where you do
// something with the data.  Sometimes it's called a "filter",
// but that's not a great name for it, since that implies a thing where
// some bits pass through, and others are simply ignored.  (That would
// be a valid example of a transform, of course.)
//
// While the output is causally related to the input, it's not a
// necessarily symmetric or synchronous transformation.  For example,
// a zlib stream might take multiple plain-text writes(), and then
// emit a single compressed chunk some time in the future.
//
// Here's how this works:
//
// The Transform stream has all the aspects of the readable and writable
// stream classes.  When you write(chunk), that calls _write(chunk,cb)
// internally, and returns false if there's a lot of pending writes
// buffered up.  When you call read(), that calls _read(n) until
// there's enough pending readable data buffered up.
//
// In a transform stream, the written data is placed in a buffer.  When
// _read(n) is called, it transforms the queued up data, calling the
// buffered _write cb's as it consumes chunks.  If consuming a single
// written chunk would result in multiple output chunks, then the first
// outputted bit calls the readcb, and subsequent chunks just go into
// the read buffer, and will cause it to emit 'readable' if necessary.
//
// This way, back-pressure is actually determined by the reading side,
// since _read has to be called to start processing a new chunk.  However,
// a pathological inflate type of transform can cause excessive buffering
// here.  For example, imagine a stream where every byte of input is
// interpreted as an integer from 0-255, and then results in that many
// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in
// 1kb of data being output.  In this case, you could write a very small
// amount of input, and end up with a very large amount of output.  In
// such a pathological inflating mechanism, there'd be no way to tell
// the system to stop doing the transform.  A single 4MB write could
// cause the system to run out of memory.
//
// However, even in such a pathological case, only a single written chunk
// would be consumed, and then the rest would wait (un-transformed) until
// the results of the previous transformed chunk were consumed.
'use strict';

module.exports = Transform;

var _require$codes = require('../errors').codes,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,
    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;

var Duplex = require('./_stream_duplex');

require('inherits')(Transform, Duplex);

function afterTransform(er, data) {
  var ts = this._transformState;
  ts.transforming = false;
  var cb = ts.writecb;

  if (cb === null) {
    return this.emit('error', new ERR_MULTIPLE_CALLBACK());
  }

  ts.writechunk = null;
  ts.writecb = null;
  if (data != null) // single equals check for both `null` and `undefined`
    this.push(data);
  cb(er);
  var rs = this._readableState;
  rs.reading = false;

  if (rs.needReadable || rs.length < rs.highWaterMark) {
    this._read(rs.highWaterMark);
  }
}

function Transform(options) {
  if (!(this instanceof Transform)) return new Transform(options);
  Duplex.call(this, options);
  this._transformState = {
    afterTransform: afterTransform.bind(this),
    needTransform: false,
    transforming: false,
    writecb: null,
    writechunk: null,
    writeencoding: null
  }; // start out asking for a readable event once data is transformed.

  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things
  // that Readable wants before the first _read call, so unset the
  // sync guard flag.

  this._readableState.sync = false;

  if (options) {
    if (typeof options.transform === 'function') this._transform = options.transform;
    if (typeof options.flush === 'function') this._flush = options.flush;
  } // When the writable side finishes, then flush out anything remaining.


  this.on('prefinish', prefinish);
}

function prefinish() {
  var _this = this;

  if (typeof this._flush === 'function' && !this._readableState.destroyed) {
    this._flush(function (er, data) {
      done(_this, er, data);
    });
  } else {
    done(this, null, null);
  }
}

Transform.prototype.push = function (chunk, encoding) {
  this._transformState.needTransform = false;
  return Duplex.prototype.push.call(this, chunk, encoding);
}; // This is the part where you do stuff!
// override this function in implementation classes.
// 'chunk' is an input chunk.
//
// Call `push(newChunk)` to pass along transformed output
// to the readable side.  You may call 'push' zero or more times.
//
// Call `cb(err)` when you are done with this chunk.  If you pass
// an error, then that'll put the hurt on the whole operation.  If you
// never call cb(), then you'll never get another chunk.


Transform.prototype._transform = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));
};

Transform.prototype._write = function (chunk, encoding, cb) {
  var ts = this._transformState;
  ts.writecb = cb;
  ts.writechunk = chunk;
  ts.writeencoding = encoding;

  if (!ts.transforming) {
    var rs = this._readableState;
    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);
  }
}; // Doesn't matter what the args are here.
// _transform does all the work.
// That we got here means that the readable side wants more data.


Transform.prototype._read = function (n) {
  var ts = this._transformState;

  if (ts.writechunk !== null && !ts.transforming) {
    ts.transforming = true;

    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);
  } else {
    // mark that we need a transform, so that any data that comes in
    // will get processed, now that we've asked for it.
    ts.needTransform = true;
  }
};

Transform.prototype._destroy = function (err, cb) {
  Duplex.prototype._destroy.call(this, err, function (err2) {
    cb(err2);
  });
};

function done(stream, er, data) {
  if (er) return stream.emit('error', er);
  if (data != null) // single equals check for both `null` and `undefined`
    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases
  // if there's nothing in the write buffer, then that means
  // that nothing more will ever be provided

  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();
  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();
  return stream.push(null);
}
},{"../errors":199,"./_stream_duplex":200,"inherits":136}],204:[function(require,module,exports){
(function (process,global){(function (){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.
// A bit simpler than readable streams.
// Implement an async ._write(chunk, encoding, cb), and it'll handle all
// the drain event emission and buffering.
'use strict';

module.exports = Writable;
/* <replacement> */

function WriteReq(chunk, encoding, cb) {
  this.chunk = chunk;
  this.encoding = encoding;
  this.callback = cb;
  this.next = null;
} // It seems a linked list but it is not
// there will be only 2 of these for each stream


function CorkedRequest(state) {
  var _this = this;

  this.next = null;
  this.entry = null;

  this.finish = function () {
    onCorkedFinish(_this, state);
  };
}
/* </replacement> */

/*<replacement>*/


var Duplex;
/*</replacement>*/

Writable.WritableState = WritableState;
/*<replacement>*/

var internalUtil = {
  deprecate: require('util-deprecate')
};
/*</replacement>*/

/*<replacement>*/

var Stream = require('./internal/streams/stream');
/*</replacement>*/


var Buffer = require('buffer').Buffer;

var OurUint8Array = global.Uint8Array || function () {};

function _uint8ArrayToBuffer(chunk) {
  return Buffer.from(chunk);
}

function _isUint8Array(obj) {
  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;
}

var destroyImpl = require('./internal/streams/destroy');

var _require = require('./internal/streams/state'),
    getHighWaterMark = _require.getHighWaterMark;

var _require$codes = require('../errors').codes,
    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,
    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,
    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,
    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,
    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,
    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,
    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;

var errorOrDestroy = destroyImpl.errorOrDestroy;

require('inherits')(Writable, Stream);

function nop() {}

function WritableState(options, stream, isDuplex) {
  Duplex = Duplex || require('./_stream_duplex');
  options = options || {}; // Duplex streams are both readable and writable, but share
  // the same options object.
  // However, some cases require setting options to different
  // values for the readable and the writable sides of the duplex stream,
  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.

  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream
  // contains buffers or objects.

  this.objectMode = !!options.objectMode;
  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false
  // Note: 0 is a valid value, means that we always return false if
  // the entire buffer is not flushed immediately on write()

  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called

  this.finalCalled = false; // drain event flag.

  this.needDrain = false; // at the start of calling end()

  this.ending = false; // when end() has been called, and returned

  this.ended = false; // when 'finish' is emitted

  this.finished = false; // has it been destroyed

  this.destroyed = false; // should we decode strings into buffers before passing to _write?
  // this is here so that some node-core streams can optimize string
  // handling at a lower level.

  var noDecode = options.decodeStrings === false;
  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string
  // encoding is 'binary' so we have to make this configurable.
  // Everything else in the universe uses 'utf8', though.

  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement
  // of how much we're waiting to get pushed to some underlying
  // socket or file.

  this.length = 0; // a flag to see when we're in the middle of a write.

  this.writing = false; // when true all writes will be buffered until .uncork() call

  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,
  // or on a later tick.  We set this to true at first, because any
  // actions that shouldn't happen until "later" should generally also
  // not happen before the first write call.

  this.sync = true; // a flag to know if we're processing previously buffered items, which
  // may call the _write() callback in the same tick, so that we don't
  // end up in an overlapped onwrite situation.

  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)

  this.onwrite = function (er) {
    onwrite(stream, er);
  }; // the callback that the user supplies to write(chunk,encoding,cb)


  this.writecb = null; // the amount that is being written when _write is called.

  this.writelen = 0;
  this.bufferedRequest = null;
  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks
  // this must be 0 before 'finish' can be emitted

  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs
  // This is relevant for synchronous Transform streams

  this.prefinished = false; // True if the error was already emitted and should not be thrown again

  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.

  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')

  this.autoDestroy = !!options.autoDestroy; // count buffered requests

  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always
  // one allocated and free to use, and we maintain at most two

  this.corkedRequestsFree = new CorkedRequest(this);
}

WritableState.prototype.getBuffer = function getBuffer() {
  var current = this.bufferedRequest;
  var out = [];

  while (current) {
    out.push(current);
    current = current.next;
  }

  return out;
};

(function () {
  try {
    Object.defineProperty(WritableState.prototype, 'buffer', {
      get: internalUtil.deprecate(function writableStateBufferGetter() {
        return this.getBuffer();
      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')
    });
  } catch (_) {}
})(); // Test _writableState for inheritance to account for Duplex streams,
// whose prototype chain only points to Readable.


var realHasInstance;

if (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {
  realHasInstance = Function.prototype[Symbol.hasInstance];
  Object.defineProperty(Writable, Symbol.hasInstance, {
    value: function value(object) {
      if (realHasInstance.call(this, object)) return true;
      if (this !== Writable) return false;
      return object && object._writableState instanceof WritableState;
    }
  });
} else {
  realHasInstance = function realHasInstance(object) {
    return object instanceof this;
  };
}

function Writable(options) {
  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.
  // `realHasInstance` is necessary because using plain `instanceof`
  // would return false, as no `_writableState` property is attached.
  // Trying to use the custom `instanceof` for Writable here will also break the
  // Node.js LazyTransform implementation, which has a non-trivial getter for
  // `_writableState` that would lead to infinite recursion.
  // Checking for a Stream.Duplex instance is faster here instead of inside
  // the WritableState constructor, at least with V8 6.5

  var isDuplex = this instanceof Duplex;
  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);
  this._writableState = new WritableState(options, this, isDuplex); // legacy.

  this.writable = true;

  if (options) {
    if (typeof options.write === 'function') this._write = options.write;
    if (typeof options.writev === 'function') this._writev = options.writev;
    if (typeof options.destroy === 'function') this._destroy = options.destroy;
    if (typeof options.final === 'function') this._final = options.final;
  }

  Stream.call(this);
} // Otherwise people can pipe Writable streams, which is just wrong.


Writable.prototype.pipe = function () {
  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());
};

function writeAfterEnd(stream, cb) {
  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb

  errorOrDestroy(stream, er);
  process.nextTick(cb, er);
} // Checks that a user-supplied chunk is valid, especially for the particular
// mode the stream is in. Currently this means that `null` is never accepted
// and undefined/non-string values are only allowed in object mode.


function validChunk(stream, state, chunk, cb) {
  var er;

  if (chunk === null) {
    er = new ERR_STREAM_NULL_VALUES();
  } else if (typeof chunk !== 'string' && !state.objectMode) {
    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);
  }

  if (er) {
    errorOrDestroy(stream, er);
    process.nextTick(cb, er);
    return false;
  }

  return true;
}

Writable.prototype.write = function (chunk, encoding, cb) {
  var state = this._writableState;
  var ret = false;

  var isBuf = !state.objectMode && _isUint8Array(chunk);

  if (isBuf && !Buffer.isBuffer(chunk)) {
    chunk = _uint8ArrayToBuffer(chunk);
  }

  if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;
  if (typeof cb !== 'function') cb = nop;
  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {
    state.pendingcb++;
    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);
  }
  return ret;
};

Writable.prototype.cork = function () {
  this._writableState.corked++;
};

Writable.prototype.uncork = function () {
  var state = this._writableState;

  if (state.corked) {
    state.corked--;
    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);
  }
};

Writable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {
  // node::ParseEncoding() requires lower case.
  if (typeof encoding === 'string') encoding = encoding.toLowerCase();
  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);
  this._writableState.defaultEncoding = encoding;
  return this;
};

Object.defineProperty(Writable.prototype, 'writableBuffer', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState && this._writableState.getBuffer();
  }
});

function decodeChunk(state, chunk, encoding) {
  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {
    chunk = Buffer.from(chunk, encoding);
  }

  return chunk;
}

Object.defineProperty(Writable.prototype, 'writableHighWaterMark', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.highWaterMark;
  }
}); // if we're already writing something, then just put this
// in the queue, and wait our turn.  Otherwise, call _write
// If we return false, then we need a drain event, so set that flag.

function writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {
  if (!isBuf) {
    var newChunk = decodeChunk(state, chunk, encoding);

    if (chunk !== newChunk) {
      isBuf = true;
      encoding = 'buffer';
      chunk = newChunk;
    }
  }

  var len = state.objectMode ? 1 : chunk.length;
  state.length += len;
  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.

  if (!ret) state.needDrain = true;

  if (state.writing || state.corked) {
    var last = state.lastBufferedRequest;
    state.lastBufferedRequest = {
      chunk: chunk,
      encoding: encoding,
      isBuf: isBuf,
      callback: cb,
      next: null
    };

    if (last) {
      last.next = state.lastBufferedRequest;
    } else {
      state.bufferedRequest = state.lastBufferedRequest;
    }

    state.bufferedRequestCount += 1;
  } else {
    doWrite(stream, state, false, len, chunk, encoding, cb);
  }

  return ret;
}

function doWrite(stream, state, writev, len, chunk, encoding, cb) {
  state.writelen = len;
  state.writecb = cb;
  state.writing = true;
  state.sync = true;
  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);
  state.sync = false;
}

function onwriteError(stream, state, sync, er, cb) {
  --state.pendingcb;

  if (sync) {
    // defer the callback if we are being called synchronously
    // to avoid piling up things on the stack
    process.nextTick(cb, er); // this can emit finish, and it will always happen
    // after error

    process.nextTick(finishMaybe, stream, state);
    stream._writableState.errorEmitted = true;
    errorOrDestroy(stream, er);
  } else {
    // the caller expect this to happen before if
    // it is async
    cb(er);
    stream._writableState.errorEmitted = true;
    errorOrDestroy(stream, er); // this can emit finish, but finish must
    // always follow error

    finishMaybe(stream, state);
  }
}

function onwriteStateUpdate(state) {
  state.writing = false;
  state.writecb = null;
  state.length -= state.writelen;
  state.writelen = 0;
}

function onwrite(stream, er) {
  var state = stream._writableState;
  var sync = state.sync;
  var cb = state.writecb;
  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();
  onwriteStateUpdate(state);
  if (er) onwriteError(stream, state, sync, er, cb);else {
    // Check if we're actually ready to finish, but don't emit yet
    var finished = needFinish(state) || stream.destroyed;

    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {
      clearBuffer(stream, state);
    }

    if (sync) {
      process.nextTick(afterWrite, stream, state, finished, cb);
    } else {
      afterWrite(stream, state, finished, cb);
    }
  }
}

function afterWrite(stream, state, finished, cb) {
  if (!finished) onwriteDrain(stream, state);
  state.pendingcb--;
  cb();
  finishMaybe(stream, state);
} // Must force callback to be called on nextTick, so that we don't
// emit 'drain' before the write() consumer gets the 'false' return
// value, and has a chance to attach a 'drain' listener.


function onwriteDrain(stream, state) {
  if (state.length === 0 && state.needDrain) {
    state.needDrain = false;
    stream.emit('drain');
  }
} // if there's something in the buffer waiting, then process it


function clearBuffer(stream, state) {
  state.bufferProcessing = true;
  var entry = state.bufferedRequest;

  if (stream._writev && entry && entry.next) {
    // Fast case, write everything using _writev()
    var l = state.bufferedRequestCount;
    var buffer = new Array(l);
    var holder = state.corkedRequestsFree;
    holder.entry = entry;
    var count = 0;
    var allBuffers = true;

    while (entry) {
      buffer[count] = entry;
      if (!entry.isBuf) allBuffers = false;
      entry = entry.next;
      count += 1;
    }

    buffer.allBuffers = allBuffers;
    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time
    // as the hot path ends with doWrite

    state.pendingcb++;
    state.lastBufferedRequest = null;

    if (holder.next) {
      state.corkedRequestsFree = holder.next;
      holder.next = null;
    } else {
      state.corkedRequestsFree = new CorkedRequest(state);
    }

    state.bufferedRequestCount = 0;
  } else {
    // Slow case, write chunks one-by-one
    while (entry) {
      var chunk = entry.chunk;
      var encoding = entry.encoding;
      var cb = entry.callback;
      var len = state.objectMode ? 1 : chunk.length;
      doWrite(stream, state, false, len, chunk, encoding, cb);
      entry = entry.next;
      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then
      // it means that we need to wait until it does.
      // also, that means that the chunk and cb are currently
      // being processed, so move the buffer counter past them.

      if (state.writing) {
        break;
      }
    }

    if (entry === null) state.lastBufferedRequest = null;
  }

  state.bufferedRequest = entry;
  state.bufferProcessing = false;
}

Writable.prototype._write = function (chunk, encoding, cb) {
  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));
};

Writable.prototype._writev = null;

Writable.prototype.end = function (chunk, encoding, cb) {
  var state = this._writableState;

  if (typeof chunk === 'function') {
    cb = chunk;
    chunk = null;
    encoding = null;
  } else if (typeof encoding === 'function') {
    cb = encoding;
    encoding = null;
  }

  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks

  if (state.corked) {
    state.corked = 1;
    this.uncork();
  } // ignore unnecessary end() calls.


  if (!state.ending) endWritable(this, state, cb);
  return this;
};

Object.defineProperty(Writable.prototype, 'writableLength', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    return this._writableState.length;
  }
});

function needFinish(state) {
  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;
}

function callFinal(stream, state) {
  stream._final(function (err) {
    state.pendingcb--;

    if (err) {
      errorOrDestroy(stream, err);
    }

    state.prefinished = true;
    stream.emit('prefinish');
    finishMaybe(stream, state);
  });
}

function prefinish(stream, state) {
  if (!state.prefinished && !state.finalCalled) {
    if (typeof stream._final === 'function' && !state.destroyed) {
      state.pendingcb++;
      state.finalCalled = true;
      process.nextTick(callFinal, stream, state);
    } else {
      state.prefinished = true;
      stream.emit('prefinish');
    }
  }
}

function finishMaybe(stream, state) {
  var need = needFinish(state);

  if (need) {
    prefinish(stream, state);

    if (state.pendingcb === 0) {
      state.finished = true;
      stream.emit('finish');

      if (state.autoDestroy) {
        // In case of duplex streams we need a way to detect
        // if the readable side is ready for autoDestroy as well
        var rState = stream._readableState;

        if (!rState || rState.autoDestroy && rState.endEmitted) {
          stream.destroy();
        }
      }
    }
  }

  return need;
}

function endWritable(stream, state, cb) {
  state.ending = true;
  finishMaybe(stream, state);

  if (cb) {
    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);
  }

  state.ended = true;
  stream.writable = false;
}

function onCorkedFinish(corkReq, state, err) {
  var entry = corkReq.entry;
  corkReq.entry = null;

  while (entry) {
    var cb = entry.callback;
    state.pendingcb--;
    cb(err);
    entry = entry.next;
  } // reuse the free corkReq.


  state.corkedRequestsFree.next = corkReq;
}

Object.defineProperty(Writable.prototype, 'destroyed', {
  // making it explicit this property is not enumerable
  // because otherwise some prototype manipulation in
  // userland will fail
  enumerable: false,
  get: function get() {
    if (this._writableState === undefined) {
      return false;
    }

    return this._writableState.destroyed;
  },
  set: function set(value) {
    // we ignore the value if the stream
    // has not been initialized yet
    if (!this._writableState) {
      return;
    } // backward compatibility, the user is explicitly
    // managing destroyed


    this._writableState.destroyed = value;
  }
});
Writable.prototype.destroy = destroyImpl.destroy;
Writable.prototype._undestroy = destroyImpl.undestroy;

Writable.prototype._destroy = function (err, cb) {
  cb(err);
};
}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"../errors":199,"./_stream_duplex":200,"./internal/streams/destroy":207,"./internal/streams/state":211,"./internal/streams/stream":212,"_process":179,"buffer":74,"inherits":136,"util-deprecate":230}],205:[function(require,module,exports){
(function (process){(function (){
'use strict';

var _Object$setPrototypeO;

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

var finished = require('./end-of-stream');

var kLastResolve = Symbol('lastResolve');
var kLastReject = Symbol('lastReject');
var kError = Symbol('error');
var kEnded = Symbol('ended');
var kLastPromise = Symbol('lastPromise');
var kHandlePromise = Symbol('handlePromise');
var kStream = Symbol('stream');

function createIterResult(value, done) {
  return {
    value: value,
    done: done
  };
}

function readAndResolve(iter) {
  var resolve = iter[kLastResolve];

  if (resolve !== null) {
    var data = iter[kStream].read(); // we defer if data is null
    // we can be expecting either 'end' or
    // 'error'

    if (data !== null) {
      iter[kLastPromise] = null;
      iter[kLastResolve] = null;
      iter[kLastReject] = null;
      resolve(createIterResult(data, false));
    }
  }
}

function onReadable(iter) {
  // we wait for the next tick, because it might
  // emit an error with process.nextTick
  process.nextTick(readAndResolve, iter);
}

function wrapForNext(lastPromise, iter) {
  return function (resolve, reject) {
    lastPromise.then(function () {
      if (iter[kEnded]) {
        resolve(createIterResult(undefined, true));
        return;
      }

      iter[kHandlePromise](resolve, reject);
    }, reject);
  };
}

var AsyncIteratorPrototype = Object.getPrototypeOf(function () {});
var ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {
  get stream() {
    return this[kStream];
  },

  next: function next() {
    var _this = this;

    // if we have detected an error in the meanwhile
    // reject straight away
    var error = this[kError];

    if (error !== null) {
      return Promise.reject(error);
    }

    if (this[kEnded]) {
      return Promise.resolve(createIterResult(undefined, true));
    }

    if (this[kStream].destroyed) {
      // We need to defer via nextTick because if .destroy(err) is
      // called, the error will be emitted via nextTick, and
      // we cannot guarantee that there is no error lingering around
      // waiting to be emitted.
      return new Promise(function (resolve, reject) {
        process.nextTick(function () {
          if (_this[kError]) {
            reject(_this[kError]);
          } else {
            resolve(createIterResult(undefined, true));
          }
        });
      });
    } // if we have multiple next() calls
    // we will wait for the previous Promise to finish
    // this logic is optimized to support for await loops,
    // where next() is only called once at a time


    var lastPromise = this[kLastPromise];
    var promise;

    if (lastPromise) {
      promise = new Promise(wrapForNext(lastPromise, this));
    } else {
      // fast path needed to support multiple this.push()
      // without triggering the next() queue
      var data = this[kStream].read();

      if (data !== null) {
        return Promise.resolve(createIterResult(data, false));
      }

      promise = new Promise(this[kHandlePromise]);
    }

    this[kLastPromise] = promise;
    return promise;
  }
}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {
  return this;
}), _defineProperty(_Object$setPrototypeO, "return", function _return() {
  var _this2 = this;

  // destroy(err, cb) is a private API
  // we can guarantee we have that here, because we control the
  // Readable class this is attached to
  return new Promise(function (resolve, reject) {
    _this2[kStream].destroy(null, function (err) {
      if (err) {
        reject(err);
        return;
      }

      resolve(createIterResult(undefined, true));
    });
  });
}), _Object$setPrototypeO), AsyncIteratorPrototype);

var createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {
  var _Object$create;

  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {
    value: stream,
    writable: true
  }), _defineProperty(_Object$create, kLastResolve, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kLastReject, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kError, {
    value: null,
    writable: true
  }), _defineProperty(_Object$create, kEnded, {
    value: stream._readableState.endEmitted,
    writable: true
  }), _defineProperty(_Object$create, kHandlePromise, {
    value: function value(resolve, reject) {
      var data = iterator[kStream].read();

      if (data) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        resolve(createIterResult(data, false));
      } else {
        iterator[kLastResolve] = resolve;
        iterator[kLastReject] = reject;
      }
    },
    writable: true
  }), _Object$create));
  iterator[kLastPromise] = null;
  finished(stream, function (err) {
    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {
      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise
      // returned by next() and store the error

      if (reject !== null) {
        iterator[kLastPromise] = null;
        iterator[kLastResolve] = null;
        iterator[kLastReject] = null;
        reject(err);
      }

      iterator[kError] = err;
      return;
    }

    var resolve = iterator[kLastResolve];

    if (resolve !== null) {
      iterator[kLastPromise] = null;
      iterator[kLastResolve] = null;
      iterator[kLastReject] = null;
      resolve(createIterResult(undefined, true));
    }

    iterator[kEnded] = true;
  });
  stream.on('readable', onReadable.bind(null, iterator));
  return iterator;
};

module.exports = createReadableStreamAsyncIterator;
}).call(this)}).call(this,require('_process'))
},{"./end-of-stream":208,"_process":179}],206:[function(require,module,exports){
'use strict';

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

function _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }

function _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError("Cannot call a class as a function"); } }

function _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if ("value" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }

function _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }

var _require = require('buffer'),
    Buffer = _require.Buffer;

var _require2 = require('util'),
    inspect = _require2.inspect;

var custom = inspect && inspect.custom || 'inspect';

function copyBuffer(src, target, offset) {
  Buffer.prototype.copy.call(src, target, offset);
}

module.exports =
/*#__PURE__*/
function () {
  function BufferList() {
    _classCallCheck(this, BufferList);

    this.head = null;
    this.tail = null;
    this.length = 0;
  }

  _createClass(BufferList, [{
    key: "push",
    value: function push(v) {
      var entry = {
        data: v,
        next: null
      };
      if (this.length > 0) this.tail.next = entry;else this.head = entry;
      this.tail = entry;
      ++this.length;
    }
  }, {
    key: "unshift",
    value: function unshift(v) {
      var entry = {
        data: v,
        next: this.head
      };
      if (this.length === 0) this.tail = entry;
      this.head = entry;
      ++this.length;
    }
  }, {
    key: "shift",
    value: function shift() {
      if (this.length === 0) return;
      var ret = this.head.data;
      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;
      --this.length;
      return ret;
    }
  }, {
    key: "clear",
    value: function clear() {
      this.head = this.tail = null;
      this.length = 0;
    }
  }, {
    key: "join",
    value: function join(s) {
      if (this.length === 0) return '';
      var p = this.head;
      var ret = '' + p.data;

      while (p = p.next) {
        ret += s + p.data;
      }

      return ret;
    }
  }, {
    key: "concat",
    value: function concat(n) {
      if (this.length === 0) return Buffer.alloc(0);
      var ret = Buffer.allocUnsafe(n >>> 0);
      var p = this.head;
      var i = 0;

      while (p) {
        copyBuffer(p.data, ret, i);
        i += p.data.length;
        p = p.next;
      }

      return ret;
    } // Consumes a specified amount of bytes or characters from the buffered data.

  }, {
    key: "consume",
    value: function consume(n, hasStrings) {
      var ret;

      if (n < this.head.data.length) {
        // `slice` is the same for buffers and strings.
        ret = this.head.data.slice(0, n);
        this.head.data = this.head.data.slice(n);
      } else if (n === this.head.data.length) {
        // First chunk is a perfect match.
        ret = this.shift();
      } else {
        // Result spans more than one buffer.
        ret = hasStrings ? this._getString(n) : this._getBuffer(n);
      }

      return ret;
    }
  }, {
    key: "first",
    value: function first() {
      return this.head.data;
    } // Consumes a specified amount of characters from the buffered data.

  }, {
    key: "_getString",
    value: function _getString(n) {
      var p = this.head;
      var c = 1;
      var ret = p.data;
      n -= ret.length;

      while (p = p.next) {
        var str = p.data;
        var nb = n > str.length ? str.length : n;
        if (nb === str.length) ret += str;else ret += str.slice(0, n);
        n -= nb;

        if (n === 0) {
          if (nb === str.length) {
            ++c;
            if (p.next) this.head = p.next;else this.head = this.tail = null;
          } else {
            this.head = p;
            p.data = str.slice(nb);
          }

          break;
        }

        ++c;
      }

      this.length -= c;
      return ret;
    } // Consumes a specified amount of bytes from the buffered data.

  }, {
    key: "_getBuffer",
    value: function _getBuffer(n) {
      var ret = Buffer.allocUnsafe(n);
      var p = this.head;
      var c = 1;
      p.data.copy(ret);
      n -= p.data.length;

      while (p = p.next) {
        var buf = p.data;
        var nb = n > buf.length ? buf.length : n;
        buf.copy(ret, ret.length - n, 0, nb);
        n -= nb;

        if (n === 0) {
          if (nb === buf.length) {
            ++c;
            if (p.next) this.head = p.next;else this.head = this.tail = null;
          } else {
            this.head = p;
            p.data = buf.slice(nb);
          }

          break;
        }

        ++c;
      }

      this.length -= c;
      return ret;
    } // Make sure the linked list only shows the minimal necessary information.

  }, {
    key: custom,
    value: function value(_, options) {
      return inspect(this, _objectSpread({}, options, {
        // Only inspect one level.
        depth: 0,
        // It should not recurse.
        customInspect: false
      }));
    }
  }]);

  return BufferList;
}();
},{"buffer":74,"util":45}],207:[function(require,module,exports){
(function (process){(function (){
'use strict'; // undocumented cb() API, needed for core, not for public API

function destroy(err, cb) {
  var _this = this;

  var readableDestroyed = this._readableState && this._readableState.destroyed;
  var writableDestroyed = this._writableState && this._writableState.destroyed;

  if (readableDestroyed || writableDestroyed) {
    if (cb) {
      cb(err);
    } else if (err) {
      if (!this._writableState) {
        process.nextTick(emitErrorNT, this, err);
      } else if (!this._writableState.errorEmitted) {
        this._writableState.errorEmitted = true;
        process.nextTick(emitErrorNT, this, err);
      }
    }

    return this;
  } // we set destroyed to true before firing error callbacks in order
  // to make it re-entrance safe in case destroy() is called within callbacks


  if (this._readableState) {
    this._readableState.destroyed = true;
  } // if this is a duplex stream mark the writable part as destroyed as well


  if (this._writableState) {
    this._writableState.destroyed = true;
  }

  this._destroy(err || null, function (err) {
    if (!cb && err) {
      if (!_this._writableState) {
        process.nextTick(emitErrorAndCloseNT, _this, err);
      } else if (!_this._writableState.errorEmitted) {
        _this._writableState.errorEmitted = true;
        process.nextTick(emitErrorAndCloseNT, _this, err);
      } else {
        process.nextTick(emitCloseNT, _this);
      }
    } else if (cb) {
      process.nextTick(emitCloseNT, _this);
      cb(err);
    } else {
      process.nextTick(emitCloseNT, _this);
    }
  });

  return this;
}

function emitErrorAndCloseNT(self, err) {
  emitErrorNT(self, err);
  emitCloseNT(self);
}

function emitCloseNT(self) {
  if (self._writableState && !self._writableState.emitClose) return;
  if (self._readableState && !self._readableState.emitClose) return;
  self.emit('close');
}

function undestroy() {
  if (this._readableState) {
    this._readableState.destroyed = false;
    this._readableState.reading = false;
    this._readableState.ended = false;
    this._readableState.endEmitted = false;
  }

  if (this._writableState) {
    this._writableState.destroyed = false;
    this._writableState.ended = false;
    this._writableState.ending = false;
    this._writableState.finalCalled = false;
    this._writableState.prefinished = false;
    this._writableState.finished = false;
    this._writableState.errorEmitted = false;
  }
}

function emitErrorNT(self, err) {
  self.emit('error', err);
}

function errorOrDestroy(stream, err) {
  // We have tests that rely on errors being emitted
  // in the same tick, so changing this is semver major.
  // For now when you opt-in to autoDestroy we allow
  // the error to be emitted nextTick. In a future
  // semver major update we should change the default to this.
  var rState = stream._readableState;
  var wState = stream._writableState;
  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);
}

module.exports = {
  destroy: destroy,
  undestroy: undestroy,
  errorOrDestroy: errorOrDestroy
};
}).call(this)}).call(this,require('_process'))
},{"_process":179}],208:[function(require,module,exports){
// Ported from https://github.com/mafintosh/end-of-stream with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;

    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {
      args[_key] = arguments[_key];
    }

    callback.apply(this, args);
  };
}

function noop() {}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function eos(stream, opts, callback) {
  if (typeof opts === 'function') return eos(stream, null, opts);
  if (!opts) opts = {};
  callback = once(callback || noop);
  var readable = opts.readable || opts.readable !== false && stream.readable;
  var writable = opts.writable || opts.writable !== false && stream.writable;

  var onlegacyfinish = function onlegacyfinish() {
    if (!stream.writable) onfinish();
  };

  var writableEnded = stream._writableState && stream._writableState.finished;

  var onfinish = function onfinish() {
    writable = false;
    writableEnded = true;
    if (!readable) callback.call(stream);
  };

  var readableEnded = stream._readableState && stream._readableState.endEmitted;

  var onend = function onend() {
    readable = false;
    readableEnded = true;
    if (!writable) callback.call(stream);
  };

  var onerror = function onerror(err) {
    callback.call(stream, err);
  };

  var onclose = function onclose() {
    var err;

    if (readable && !readableEnded) {
      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }

    if (writable && !writableEnded) {
      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();
      return callback.call(stream, err);
    }
  };

  var onrequest = function onrequest() {
    stream.req.on('finish', onfinish);
  };

  if (isRequest(stream)) {
    stream.on('complete', onfinish);
    stream.on('abort', onclose);
    if (stream.req) onrequest();else stream.on('request', onrequest);
  } else if (writable && !stream._writableState) {
    // legacy streams
    stream.on('end', onlegacyfinish);
    stream.on('close', onlegacyfinish);
  }

  stream.on('end', onend);
  stream.on('finish', onfinish);
  if (opts.error !== false) stream.on('error', onerror);
  stream.on('close', onclose);
  return function () {
    stream.removeListener('complete', onfinish);
    stream.removeListener('abort', onclose);
    stream.removeListener('request', onrequest);
    if (stream.req) stream.req.removeListener('finish', onfinish);
    stream.removeListener('end', onlegacyfinish);
    stream.removeListener('close', onlegacyfinish);
    stream.removeListener('finish', onfinish);
    stream.removeListener('end', onend);
    stream.removeListener('error', onerror);
    stream.removeListener('close', onclose);
  };
}

module.exports = eos;
},{"../../../errors":199}],209:[function(require,module,exports){
module.exports = function () {
  throw new Error('Readable.from is not available in the browser')
};

},{}],210:[function(require,module,exports){
// Ported from https://github.com/mafintosh/pump with
// permission from the author, Mathias Buus (@mafintosh).
'use strict';

var eos;

function once(callback) {
  var called = false;
  return function () {
    if (called) return;
    called = true;
    callback.apply(void 0, arguments);
  };
}

var _require$codes = require('../../../errors').codes,
    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,
    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;

function noop(err) {
  // Rethrow the error if it exists to avoid swallowing it
  if (err) throw err;
}

function isRequest(stream) {
  return stream.setHeader && typeof stream.abort === 'function';
}

function destroyer(stream, reading, writing, callback) {
  callback = once(callback);
  var closed = false;
  stream.on('close', function () {
    closed = true;
  });
  if (eos === undefined) eos = require('./end-of-stream');
  eos(stream, {
    readable: reading,
    writable: writing
  }, function (err) {
    if (err) return callback(err);
    closed = true;
    callback();
  });
  var destroyed = false;
  return function (err) {
    if (closed) return;
    if (destroyed) return;
    destroyed = true; // request.destroy just do .end - .abort is what we want

    if (isRequest(stream)) return stream.abort();
    if (typeof stream.destroy === 'function') return stream.destroy();
    callback(err || new ERR_STREAM_DESTROYED('pipe'));
  };
}

function call(fn) {
  fn();
}

function pipe(from, to) {
  return from.pipe(to);
}

function popCallback(streams) {
  if (!streams.length) return noop;
  if (typeof streams[streams.length - 1] !== 'function') return noop;
  return streams.pop();
}

function pipeline() {
  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {
    streams[_key] = arguments[_key];
  }

  var callback = popCallback(streams);
  if (Array.isArray(streams[0])) streams = streams[0];

  if (streams.length < 2) {
    throw new ERR_MISSING_ARGS('streams');
  }

  var error;
  var destroys = streams.map(function (stream, i) {
    var reading = i < streams.length - 1;
    var writing = i > 0;
    return destroyer(stream, reading, writing, function (err) {
      if (!error) error = err;
      if (err) destroys.forEach(call);
      if (reading) return;
      destroys.forEach(call);
      callback(error);
    });
  });
  return streams.reduce(pipe);
}

module.exports = pipeline;
},{"../../../errors":199,"./end-of-stream":208}],211:[function(require,module,exports){
'use strict';

var ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;

function highWaterMarkFrom(options, isDuplex, duplexKey) {
  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;
}

function getHighWaterMark(state, options, duplexKey, isDuplex) {
  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);

  if (hwm != null) {
    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {
      var name = isDuplex ? duplexKey : 'highWaterMark';
      throw new ERR_INVALID_OPT_VALUE(name, hwm);
    }

    return Math.floor(hwm);
  } // Default value


  return state.objectMode ? 16 : 16 * 1024;
}

module.exports = {
  getHighWaterMark: getHighWaterMark
};
},{"../../../errors":199}],212:[function(require,module,exports){
module.exports = require('events').EventEmitter;

},{"events":118}],213:[function(require,module,exports){
exports = module.exports = require('./lib/_stream_readable.js');
exports.Stream = exports;
exports.Readable = exports;
exports.Writable = require('./lib/_stream_writable.js');
exports.Duplex = require('./lib/_stream_duplex.js');
exports.Transform = require('./lib/_stream_transform.js');
exports.PassThrough = require('./lib/_stream_passthrough.js');
exports.finished = require('./lib/internal/streams/end-of-stream.js');
exports.pipeline = require('./lib/internal/streams/pipeline.js');

},{"./lib/_stream_duplex.js":200,"./lib/_stream_passthrough.js":201,"./lib/_stream_readable.js":202,"./lib/_stream_transform.js":203,"./lib/_stream_writable.js":204,"./lib/internal/streams/end-of-stream.js":208,"./lib/internal/streams/pipeline.js":210}],214:[function(require,module,exports){
'use strict'
var Buffer = require('buffer').Buffer
var inherits = require('inherits')
var HashBase = require('hash-base')

var ARRAY16 = new Array(16)

var zl = [
  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,
  7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8,
  3, 10, 14, 4, 9, 15, 8, 1, 2, 7, 0, 6, 13, 11, 5, 12,
  1, 9, 11, 10, 0, 8, 12, 4, 13, 3, 7, 15, 14, 5, 6, 2,
  4, 0, 5, 9, 7, 12, 2, 10, 14, 1, 3, 8, 11, 6, 15, 13
]

var zr = [
  5, 14, 7, 0, 9, 2, 11, 4, 13, 6, 15, 8, 1, 10, 3, 12,
  6, 11, 3, 7, 0, 13, 5, 10, 14, 15, 8, 12, 4, 9, 1, 2,
  15, 5, 1, 3, 7, 14, 6, 9, 11, 8, 12, 2, 10, 0, 4, 13,
  8, 6, 4, 1, 3, 11, 15, 0, 5, 12, 2, 13, 9, 7, 10, 14,
  12, 15, 10, 4, 1, 5, 8, 7, 6, 2, 13, 14, 0, 3, 9, 11
]

var sl = [
  11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8,
  7, 6, 8, 13, 11, 9, 7, 15, 7, 12, 15, 9, 11, 7, 13, 12,
  11, 13, 6, 7, 14, 9, 13, 15, 14, 8, 13, 6, 5, 12, 7, 5,
  11, 12, 14, 15, 14, 15, 9, 8, 9, 14, 5, 6, 8, 6, 5, 12,
  9, 15, 5, 11, 6, 8, 13, 12, 5, 12, 13, 14, 11, 8, 5, 6
]

var sr = [
  8, 9, 9, 11, 13, 15, 15, 5, 7, 7, 8, 11, 14, 14, 12, 6,
  9, 13, 15, 7, 12, 8, 9, 11, 7, 7, 12, 7, 6, 15, 13, 11,
  9, 7, 15, 11, 8, 6, 6, 14, 12, 13, 5, 14, 13, 13, 7, 5,
  15, 5, 8, 11, 14, 14, 6, 14, 6, 9, 12, 9, 12, 5, 15, 8,
  8, 5, 12, 9, 12, 5, 14, 6, 8, 13, 6, 5, 15, 13, 11, 11
]

var hl = [0x00000000, 0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xa953fd4e]
var hr = [0x50a28be6, 0x5c4dd124, 0x6d703ef3, 0x7a6d76e9, 0x00000000]

function RIPEMD160 () {
  HashBase.call(this, 64)

  // state
  this._a = 0x67452301
  this._b = 0xefcdab89
  this._c = 0x98badcfe
  this._d = 0x10325476
  this._e = 0xc3d2e1f0
}

inherits(RIPEMD160, HashBase)

RIPEMD160.prototype._update = function () {
  var words = ARRAY16
  for (var j = 0; j < 16; ++j) words[j] = this._block.readInt32LE(j * 4)

  var al = this._a | 0
  var bl = this._b | 0
  var cl = this._c | 0
  var dl = this._d | 0
  var el = this._e | 0

  var ar = this._a | 0
  var br = this._b | 0
  var cr = this._c | 0
  var dr = this._d | 0
  var er = this._e | 0

  // computation
  for (var i = 0; i < 80; i += 1) {
    var tl
    var tr
    if (i < 16) {
      tl = fn1(al, bl, cl, dl, el, words[zl[i]], hl[0], sl[i])
      tr = fn5(ar, br, cr, dr, er, words[zr[i]], hr[0], sr[i])
    } else if (i < 32) {
      tl = fn2(al, bl, cl, dl, el, words[zl[i]], hl[1], sl[i])
      tr = fn4(ar, br, cr, dr, er, words[zr[i]], hr[1], sr[i])
    } else if (i < 48) {
      tl = fn3(al, bl, cl, dl, el, words[zl[i]], hl[2], sl[i])
      tr = fn3(ar, br, cr, dr, er, words[zr[i]], hr[2], sr[i])
    } else if (i < 64) {
      tl = fn4(al, bl, cl, dl, el, words[zl[i]], hl[3], sl[i])
      tr = fn2(ar, br, cr, dr, er, words[zr[i]], hr[3], sr[i])
    } else { // if (i<80) {
      tl = fn5(al, bl, cl, dl, el, words[zl[i]], hl[4], sl[i])
      tr = fn1(ar, br, cr, dr, er, words[zr[i]], hr[4], sr[i])
    }

    al = el
    el = dl
    dl = rotl(cl, 10)
    cl = bl
    bl = tl

    ar = er
    er = dr
    dr = rotl(cr, 10)
    cr = br
    br = tr
  }

  // update state
  var t = (this._b + cl + dr) | 0
  this._b = (this._c + dl + er) | 0
  this._c = (this._d + el + ar) | 0
  this._d = (this._e + al + br) | 0
  this._e = (this._a + bl + cr) | 0
  this._a = t
}

RIPEMD160.prototype._digest = function () {
  // create padding and handle blocks
  this._block[this._blockOffset++] = 0x80
  if (this._blockOffset > 56) {
    this._block.fill(0, this._blockOffset, 64)
    this._update()
    this._blockOffset = 0
  }

  this._block.fill(0, this._blockOffset, 56)
  this._block.writeUInt32LE(this._length[0], 56)
  this._block.writeUInt32LE(this._length[1], 60)
  this._update()

  // produce result
  var buffer = Buffer.alloc ? Buffer.alloc(20) : new Buffer(20)
  buffer.writeInt32LE(this._a, 0)
  buffer.writeInt32LE(this._b, 4)
  buffer.writeInt32LE(this._c, 8)
  buffer.writeInt32LE(this._d, 12)
  buffer.writeInt32LE(this._e, 16)
  return buffer
}

function rotl (x, n) {
  return (x << n) | (x >>> (32 - n))
}

function fn1 (a, b, c, d, e, m, k, s) {
  return (rotl((a + (b ^ c ^ d) + m + k) | 0, s) + e) | 0
}

function fn2 (a, b, c, d, e, m, k, s) {
  return (rotl((a + ((b & c) | ((~b) & d)) + m + k) | 0, s) + e) | 0
}

function fn3 (a, b, c, d, e, m, k, s) {
  return (rotl((a + ((b | (~c)) ^ d) + m + k) | 0, s) + e) | 0
}

function fn4 (a, b, c, d, e, m, k, s) {
  return (rotl((a + ((b & d) | (c & (~d))) + m + k) | 0, s) + e) | 0
}

function fn5 (a, b, c, d, e, m, k, s) {
  return (rotl((a + (b ^ (c | (~d))) + m + k) | 0, s) + e) | 0
}

module.exports = RIPEMD160

},{"buffer":74,"hash-base":121,"inherits":136}],215:[function(require,module,exports){
/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */
/* eslint-disable node/no-deprecated-api */
var buffer = require('buffer')
var Buffer = buffer.Buffer

// alternative to using Object.keys for old browsers
function copyProps (src, dst) {
  for (var key in src) {
    dst[key] = src[key]
  }
}
if (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {
  module.exports = buffer
} else {
  // Copy properties from require('buffer')
  copyProps(buffer, exports)
  exports.Buffer = SafeBuffer
}

function SafeBuffer (arg, encodingOrOffset, length) {
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.prototype = Object.create(Buffer.prototype)

// Copy static methods from Buffer
copyProps(Buffer, SafeBuffer)

SafeBuffer.from = function (arg, encodingOrOffset, length) {
  if (typeof arg === 'number') {
    throw new TypeError('Argument must not be a number')
  }
  return Buffer(arg, encodingOrOffset, length)
}

SafeBuffer.alloc = function (size, fill, encoding) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  var buf = Buffer(size)
  if (fill !== undefined) {
    if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
  } else {
    buf.fill(0)
  }
  return buf
}

SafeBuffer.allocUnsafe = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return Buffer(size)
}

SafeBuffer.allocUnsafeSlow = function (size) {
  if (typeof size !== 'number') {
    throw new TypeError('Argument must be a number')
  }
  return buffer.SlowBuffer(size)
}

},{"buffer":74}],216:[function(require,module,exports){
(function (process){(function (){
/* eslint-disable node/no-deprecated-api */

'use strict'

var buffer = require('buffer')
var Buffer = buffer.Buffer

var safer = {}

var key

for (key in buffer) {
  if (!buffer.hasOwnProperty(key)) continue
  if (key === 'SlowBuffer' || key === 'Buffer') continue
  safer[key] = buffer[key]
}

var Safer = safer.Buffer = {}
for (key in Buffer) {
  if (!Buffer.hasOwnProperty(key)) continue
  if (key === 'allocUnsafe' || key === 'allocUnsafeSlow') continue
  Safer[key] = Buffer[key]
}

safer.Buffer.prototype = Buffer.prototype

if (!Safer.from || Safer.from === Uint8Array.from) {
  Safer.from = function (value, encodingOrOffset, length) {
    if (typeof value === 'number') {
      throw new TypeError('The "value" argument must not be of type number. Received type ' + typeof value)
    }
    if (value && typeof value.length === 'undefined') {
      throw new TypeError('The first argument must be one of type string, Buffer, ArrayBuffer, Array, or Array-like Object. Received type ' + typeof value)
    }
    return Buffer(value, encodingOrOffset, length)
  }
}

if (!Safer.alloc) {
  Safer.alloc = function (size, fill, encoding) {
    if (typeof size !== 'number') {
      throw new TypeError('The "size" argument must be of type number. Received type ' + typeof size)
    }
    if (size < 0 || size >= 2 * (1 << 30)) {
      throw new RangeError('The value "' + size + '" is invalid for option "size"')
    }
    var buf = Buffer(size)
    if (!fill || fill.length === 0) {
      buf.fill(0)
    } else if (typeof encoding === 'string') {
      buf.fill(fill, encoding)
    } else {
      buf.fill(fill)
    }
    return buf
  }
}

if (!safer.kStringMaxLength) {
  try {
    safer.kStringMaxLength = process.binding('buffer').kStringMaxLength
  } catch (e) {
    // we can't determine kStringMaxLength in environments where process.binding
    // is unsupported, so let's not set it
  }
}

if (!safer.constants) {
  safer.constants = {
    MAX_LENGTH: safer.kMaxLength
  }
  if (safer.kStringMaxLength) {
    safer.constants.MAX_STRING_LENGTH = safer.kStringMaxLength
  }
}

module.exports = safer

}).call(this)}).call(this,require('_process'))
},{"_process":179,"buffer":74}],217:[function(require,module,exports){
(function (process,global){(function (){
(function (global, undefined) {
    "use strict";

    if (global.setImmediate) {
        return;
    }

    var nextHandle = 1; // Spec says greater than zero
    var tasksByHandle = {};
    var currentlyRunningATask = false;
    var doc = global.document;
    var registerImmediate;

    function setImmediate(callback) {
      // Callback can either be a function or a string
      if (typeof callback !== "function") {
        callback = new Function("" + callback);
      }
      // Copy function arguments
      var args = new Array(arguments.length - 1);
      for (var i = 0; i < args.length; i++) {
          args[i] = arguments[i + 1];
      }
      // Store and register the task
      var task = { callback: callback, args: args };
      tasksByHandle[nextHandle] = task;
      registerImmediate(nextHandle);
      return nextHandle++;
    }

    function clearImmediate(handle) {
        delete tasksByHandle[handle];
    }

    function run(task) {
        var callback = task.callback;
        var args = task.args;
        switch (args.length) {
        case 0:
            callback();
            break;
        case 1:
            callback(args[0]);
            break;
        case 2:
            callback(args[0], args[1]);
            break;
        case 3:
            callback(args[0], args[1], args[2]);
            break;
        default:
            callback.apply(undefined, args);
            break;
        }
    }

    function runIfPresent(handle) {
        // From the spec: "Wait until any invocations of this algorithm started before this one have completed."
        // So if we're currently running a task, we'll need to delay this invocation.
        if (currentlyRunningATask) {
            // Delay by doing a setTimeout. setImmediate was tried instead, but in Firefox 7 it generated a
            // "too much recursion" error.
            setTimeout(runIfPresent, 0, handle);
        } else {
            var task = tasksByHandle[handle];
            if (task) {
                currentlyRunningATask = true;
                try {
                    run(task);
                } finally {
                    clearImmediate(handle);
                    currentlyRunningATask = false;
                }
            }
        }
    }

    function installNextTickImplementation() {
        registerImmediate = function(handle) {
            process.nextTick(function () { runIfPresent(handle); });
        };
    }

    function canUsePostMessage() {
        // The test against `importScripts` prevents this implementation from being installed inside a web worker,
        // where `global.postMessage` means something completely different and can't be used for this purpose.
        if (global.postMessage && !global.importScripts) {
            var postMessageIsAsynchronous = true;
            var oldOnMessage = global.onmessage;
            global.onmessage = function() {
                postMessageIsAsynchronous = false;
            };
            global.postMessage("", "*");
            global.onmessage = oldOnMessage;
            return postMessageIsAsynchronous;
        }
    }

    function installPostMessageImplementation() {
        // Installs an event handler on `global` for the `message` event: see
        // * https://developer.mozilla.org/en/DOM/window.postMessage
        // * http://www.whatwg.org/specs/web-apps/current-work/multipage/comms.html#crossDocumentMessages

        var messagePrefix = "setImmediate$" + Math.random() + "$";
        var onGlobalMessage = function(event) {
            if (event.source === global &&
                typeof event.data === "string" &&
                event.data.indexOf(messagePrefix) === 0) {
                runIfPresent(+event.data.slice(messagePrefix.length));
            }
        };

        if (global.addEventListener) {
            global.addEventListener("message", onGlobalMessage, false);
        } else {
            global.attachEvent("onmessage", onGlobalMessage);
        }

        registerImmediate = function(handle) {
            global.postMessage(messagePrefix + handle, "*");
        };
    }

    function installMessageChannelImplementation() {
        var channel = new MessageChannel();
        channel.port1.onmessage = function(event) {
            var handle = event.data;
            runIfPresent(handle);
        };

        registerImmediate = function(handle) {
            channel.port2.postMessage(handle);
        };
    }

    function installReadyStateChangeImplementation() {
        var html = doc.documentElement;
        registerImmediate = function(handle) {
            // Create a <script> element; its readystatechange event will be fired asynchronously once it is inserted
            // into the document. Do so, thus queuing up the task. Remember to clean up once it's been called.
            var script = doc.createElement("script");
            script.onreadystatechange = function () {
                runIfPresent(handle);
                script.onreadystatechange = null;
                html.removeChild(script);
                script = null;
            };
            html.appendChild(script);
        };
    }

    function installSetTimeoutImplementation() {
        registerImmediate = function(handle) {
            setTimeout(runIfPresent, 0, handle);
        };
    }

    // If supported, we should attach to the prototype of global, since that is where setTimeout et al. live.
    var attachTo = Object.getPrototypeOf && Object.getPrototypeOf(global);
    attachTo = attachTo && attachTo.setTimeout ? attachTo : global;

    // Don't get fooled by e.g. browserify environments.
    if ({}.toString.call(global.process) === "[object process]") {
        // For Node.js before 0.9
        installNextTickImplementation();

    } else if (canUsePostMessage()) {
        // For non-IE10 modern browsers
        installPostMessageImplementation();

    } else if (global.MessageChannel) {
        // For web workers, where supported
        installMessageChannelImplementation();

    } else if (doc && "onreadystatechange" in doc.createElement("script")) {
        // For IE 6–8
        installReadyStateChangeImplementation();

    } else {
        // For older browsers
        installSetTimeoutImplementation();
    }

    attachTo.setImmediate = setImmediate;
    attachTo.clearImmediate = clearImmediate;
}(typeof self === "undefined" ? typeof global === "undefined" ? this : global : self));

}).call(this)}).call(this,require('_process'),typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{"_process":179}],218:[function(require,module,exports){
var Buffer = require('safe-buffer').Buffer

// prototype class for hash functions
function Hash (blockSize, finalSize) {
  this._block = Buffer.alloc(blockSize)
  this._finalSize = finalSize
  this._blockSize = blockSize
  this._len = 0
}

Hash.prototype.update = function (data, enc) {
  if (typeof data === 'string') {
    enc = enc || 'utf8'
    data = Buffer.from(data, enc)
  }

  var block = this._block
  var blockSize = this._blockSize
  var length = data.length
  var accum = this._len

  for (var offset = 0; offset < length;) {
    var assigned = accum % blockSize
    var remainder = Math.min(length - offset, blockSize - assigned)

    for (var i = 0; i < remainder; i++) {
      block[assigned + i] = data[offset + i]
    }

    accum += remainder
    offset += remainder

    if ((accum % blockSize) === 0) {
      this._update(block)
    }
  }

  this._len += length
  return this
}

Hash.prototype.digest = function (enc) {
  var rem = this._len % this._blockSize

  this._block[rem] = 0x80

  // zero (rem + 1) trailing bits, where (rem + 1) is the smallest
  // non-negative solution to the equation (length + 1 + (rem + 1)) === finalSize mod blockSize
  this._block.fill(0, rem + 1)

  if (rem >= this._finalSize) {
    this._update(this._block)
    this._block.fill(0)
  }

  var bits = this._len * 8

  // uint32
  if (bits <= 0xffffffff) {
    this._block.writeUInt32BE(bits, this._blockSize - 4)

  // uint64
  } else {
    var lowBits = (bits & 0xffffffff) >>> 0
    var highBits = (bits - lowBits) / 0x100000000

    this._block.writeUInt32BE(highBits, this._blockSize - 8)
    this._block.writeUInt32BE(lowBits, this._blockSize - 4)
  }

  this._update(this._block)
  var hash = this._hash()

  return enc ? hash.toString(enc) : hash
}

Hash.prototype._update = function () {
  throw new Error('_update must be implemented by subclass')
}

module.exports = Hash

},{"safe-buffer":215}],219:[function(require,module,exports){
var exports = module.exports = function SHA (algorithm) {
  algorithm = algorithm.toLowerCase()

  var Algorithm = exports[algorithm]
  if (!Algorithm) throw new Error(algorithm + ' is not supported (we accept pull requests)')

  return new Algorithm()
}

exports.sha = require('./sha')
exports.sha1 = require('./sha1')
exports.sha224 = require('./sha224')
exports.sha256 = require('./sha256')
exports.sha384 = require('./sha384')
exports.sha512 = require('./sha512')

},{"./sha":220,"./sha1":221,"./sha224":222,"./sha256":223,"./sha384":224,"./sha512":225}],220:[function(require,module,exports){
/*
 * A JavaScript implementation of the Secure Hash Algorithm, SHA-0, as defined
 * in FIPS PUB 180-1
 * This source code is derived from sha1.js of the same repository.
 * The difference between SHA-0 and SHA-1 is just a bitwise rotate left
 * operation was added.
 */

var inherits = require('inherits')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var K = [
  0x5a827999, 0x6ed9eba1, 0x8f1bbcdc | 0, 0xca62c1d6 | 0
]

var W = new Array(80)

function Sha () {
  this.init()
  this._w = W

  Hash.call(this, 64, 56)
}

inherits(Sha, Hash)

Sha.prototype.init = function () {
  this._a = 0x67452301
  this._b = 0xefcdab89
  this._c = 0x98badcfe
  this._d = 0x10325476
  this._e = 0xc3d2e1f0

  return this
}

function rotl5 (num) {
  return (num << 5) | (num >>> 27)
}

function rotl30 (num) {
  return (num << 30) | (num >>> 2)
}

function ft (s, b, c, d) {
  if (s === 0) return (b & c) | ((~b) & d)
  if (s === 2) return (b & c) | (b & d) | (c & d)
  return b ^ c ^ d
}

Sha.prototype._update = function (M) {
  var W = this._w

  var a = this._a | 0
  var b = this._b | 0
  var c = this._c | 0
  var d = this._d | 0
  var e = this._e | 0

  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)
  for (; i < 80; ++i) W[i] = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16]

  for (var j = 0; j < 80; ++j) {
    var s = ~~(j / 20)
    var t = (rotl5(a) + ft(s, b, c, d) + e + W[j] + K[s]) | 0

    e = d
    d = c
    c = rotl30(b)
    b = a
    a = t
  }

  this._a = (a + this._a) | 0
  this._b = (b + this._b) | 0
  this._c = (c + this._c) | 0
  this._d = (d + this._d) | 0
  this._e = (e + this._e) | 0
}

Sha.prototype._hash = function () {
  var H = Buffer.allocUnsafe(20)

  H.writeInt32BE(this._a | 0, 0)
  H.writeInt32BE(this._b | 0, 4)
  H.writeInt32BE(this._c | 0, 8)
  H.writeInt32BE(this._d | 0, 12)
  H.writeInt32BE(this._e | 0, 16)

  return H
}

module.exports = Sha

},{"./hash":218,"inherits":136,"safe-buffer":215}],221:[function(require,module,exports){
/*
 * A JavaScript implementation of the Secure Hash Algorithm, SHA-1, as defined
 * in FIPS PUB 180-1
 * Version 2.1a Copyright Paul Johnston 2000 - 2002.
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 * Distributed under the BSD License
 * See http://pajhome.org.uk/crypt/md5 for details.
 */

var inherits = require('inherits')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var K = [
  0x5a827999, 0x6ed9eba1, 0x8f1bbcdc | 0, 0xca62c1d6 | 0
]

var W = new Array(80)

function Sha1 () {
  this.init()
  this._w = W

  Hash.call(this, 64, 56)
}

inherits(Sha1, Hash)

Sha1.prototype.init = function () {
  this._a = 0x67452301
  this._b = 0xefcdab89
  this._c = 0x98badcfe
  this._d = 0x10325476
  this._e = 0xc3d2e1f0

  return this
}

function rotl1 (num) {
  return (num << 1) | (num >>> 31)
}

function rotl5 (num) {
  return (num << 5) | (num >>> 27)
}

function rotl30 (num) {
  return (num << 30) | (num >>> 2)
}

function ft (s, b, c, d) {
  if (s === 0) return (b & c) | ((~b) & d)
  if (s === 2) return (b & c) | (b & d) | (c & d)
  return b ^ c ^ d
}

Sha1.prototype._update = function (M) {
  var W = this._w

  var a = this._a | 0
  var b = this._b | 0
  var c = this._c | 0
  var d = this._d | 0
  var e = this._e | 0

  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)
  for (; i < 80; ++i) W[i] = rotl1(W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16])

  for (var j = 0; j < 80; ++j) {
    var s = ~~(j / 20)
    var t = (rotl5(a) + ft(s, b, c, d) + e + W[j] + K[s]) | 0

    e = d
    d = c
    c = rotl30(b)
    b = a
    a = t
  }

  this._a = (a + this._a) | 0
  this._b = (b + this._b) | 0
  this._c = (c + this._c) | 0
  this._d = (d + this._d) | 0
  this._e = (e + this._e) | 0
}

Sha1.prototype._hash = function () {
  var H = Buffer.allocUnsafe(20)

  H.writeInt32BE(this._a | 0, 0)
  H.writeInt32BE(this._b | 0, 4)
  H.writeInt32BE(this._c | 0, 8)
  H.writeInt32BE(this._d | 0, 12)
  H.writeInt32BE(this._e | 0, 16)

  return H
}

module.exports = Sha1

},{"./hash":218,"inherits":136,"safe-buffer":215}],222:[function(require,module,exports){
/**
 * A JavaScript implementation of the Secure Hash Algorithm, SHA-256, as defined
 * in FIPS 180-2
 * Version 2.2-beta Copyright Angel Marin, Paul Johnston 2000 - 2009.
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 *
 */

var inherits = require('inherits')
var Sha256 = require('./sha256')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var W = new Array(64)

function Sha224 () {
  this.init()

  this._w = W // new Array(64)

  Hash.call(this, 64, 56)
}

inherits(Sha224, Sha256)

Sha224.prototype.init = function () {
  this._a = 0xc1059ed8
  this._b = 0x367cd507
  this._c = 0x3070dd17
  this._d = 0xf70e5939
  this._e = 0xffc00b31
  this._f = 0x68581511
  this._g = 0x64f98fa7
  this._h = 0xbefa4fa4

  return this
}

Sha224.prototype._hash = function () {
  var H = Buffer.allocUnsafe(28)

  H.writeInt32BE(this._a, 0)
  H.writeInt32BE(this._b, 4)
  H.writeInt32BE(this._c, 8)
  H.writeInt32BE(this._d, 12)
  H.writeInt32BE(this._e, 16)
  H.writeInt32BE(this._f, 20)
  H.writeInt32BE(this._g, 24)

  return H
}

module.exports = Sha224

},{"./hash":218,"./sha256":223,"inherits":136,"safe-buffer":215}],223:[function(require,module,exports){
/**
 * A JavaScript implementation of the Secure Hash Algorithm, SHA-256, as defined
 * in FIPS 180-2
 * Version 2.2-beta Copyright Angel Marin, Paul Johnston 2000 - 2009.
 * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet
 *
 */

var inherits = require('inherits')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var K = [
  0x428A2F98, 0x71374491, 0xB5C0FBCF, 0xE9B5DBA5,
  0x3956C25B, 0x59F111F1, 0x923F82A4, 0xAB1C5ED5,
  0xD807AA98, 0x12835B01, 0x243185BE, 0x550C7DC3,
  0x72BE5D74, 0x80DEB1FE, 0x9BDC06A7, 0xC19BF174,
  0xE49B69C1, 0xEFBE4786, 0x0FC19DC6, 0x240CA1CC,
  0x2DE92C6F, 0x4A7484AA, 0x5CB0A9DC, 0x76F988DA,
  0x983E5152, 0xA831C66D, 0xB00327C8, 0xBF597FC7,
  0xC6E00BF3, 0xD5A79147, 0x06CA6351, 0x14292967,
  0x27B70A85, 0x2E1B2138, 0x4D2C6DFC, 0x53380D13,
  0x650A7354, 0x766A0ABB, 0x81C2C92E, 0x92722C85,
  0xA2BFE8A1, 0xA81A664B, 0xC24B8B70, 0xC76C51A3,
  0xD192E819, 0xD6990624, 0xF40E3585, 0x106AA070,
  0x19A4C116, 0x1E376C08, 0x2748774C, 0x34B0BCB5,
  0x391C0CB3, 0x4ED8AA4A, 0x5B9CCA4F, 0x682E6FF3,
  0x748F82EE, 0x78A5636F, 0x84C87814, 0x8CC70208,
  0x90BEFFFA, 0xA4506CEB, 0xBEF9A3F7, 0xC67178F2
]

var W = new Array(64)

function Sha256 () {
  this.init()

  this._w = W // new Array(64)

  Hash.call(this, 64, 56)
}

inherits(Sha256, Hash)

Sha256.prototype.init = function () {
  this._a = 0x6a09e667
  this._b = 0xbb67ae85
  this._c = 0x3c6ef372
  this._d = 0xa54ff53a
  this._e = 0x510e527f
  this._f = 0x9b05688c
  this._g = 0x1f83d9ab
  this._h = 0x5be0cd19

  return this
}

function ch (x, y, z) {
  return z ^ (x & (y ^ z))
}

function maj (x, y, z) {
  return (x & y) | (z & (x | y))
}

function sigma0 (x) {
  return (x >>> 2 | x << 30) ^ (x >>> 13 | x << 19) ^ (x >>> 22 | x << 10)
}

function sigma1 (x) {
  return (x >>> 6 | x << 26) ^ (x >>> 11 | x << 21) ^ (x >>> 25 | x << 7)
}

function gamma0 (x) {
  return (x >>> 7 | x << 25) ^ (x >>> 18 | x << 14) ^ (x >>> 3)
}

function gamma1 (x) {
  return (x >>> 17 | x << 15) ^ (x >>> 19 | x << 13) ^ (x >>> 10)
}

Sha256.prototype._update = function (M) {
  var W = this._w

  var a = this._a | 0
  var b = this._b | 0
  var c = this._c | 0
  var d = this._d | 0
  var e = this._e | 0
  var f = this._f | 0
  var g = this._g | 0
  var h = this._h | 0

  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)
  for (; i < 64; ++i) W[i] = (gamma1(W[i - 2]) + W[i - 7] + gamma0(W[i - 15]) + W[i - 16]) | 0

  for (var j = 0; j < 64; ++j) {
    var T1 = (h + sigma1(e) + ch(e, f, g) + K[j] + W[j]) | 0
    var T2 = (sigma0(a) + maj(a, b, c)) | 0

    h = g
    g = f
    f = e
    e = (d + T1) | 0
    d = c
    c = b
    b = a
    a = (T1 + T2) | 0
  }

  this._a = (a + this._a) | 0
  this._b = (b + this._b) | 0
  this._c = (c + this._c) | 0
  this._d = (d + this._d) | 0
  this._e = (e + this._e) | 0
  this._f = (f + this._f) | 0
  this._g = (g + this._g) | 0
  this._h = (h + this._h) | 0
}

Sha256.prototype._hash = function () {
  var H = Buffer.allocUnsafe(32)

  H.writeInt32BE(this._a, 0)
  H.writeInt32BE(this._b, 4)
  H.writeInt32BE(this._c, 8)
  H.writeInt32BE(this._d, 12)
  H.writeInt32BE(this._e, 16)
  H.writeInt32BE(this._f, 20)
  H.writeInt32BE(this._g, 24)
  H.writeInt32BE(this._h, 28)

  return H
}

module.exports = Sha256

},{"./hash":218,"inherits":136,"safe-buffer":215}],224:[function(require,module,exports){
var inherits = require('inherits')
var SHA512 = require('./sha512')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var W = new Array(160)

function Sha384 () {
  this.init()
  this._w = W

  Hash.call(this, 128, 112)
}

inherits(Sha384, SHA512)

Sha384.prototype.init = function () {
  this._ah = 0xcbbb9d5d
  this._bh = 0x629a292a
  this._ch = 0x9159015a
  this._dh = 0x152fecd8
  this._eh = 0x67332667
  this._fh = 0x8eb44a87
  this._gh = 0xdb0c2e0d
  this._hh = 0x47b5481d

  this._al = 0xc1059ed8
  this._bl = 0x367cd507
  this._cl = 0x3070dd17
  this._dl = 0xf70e5939
  this._el = 0xffc00b31
  this._fl = 0x68581511
  this._gl = 0x64f98fa7
  this._hl = 0xbefa4fa4

  return this
}

Sha384.prototype._hash = function () {
  var H = Buffer.allocUnsafe(48)

  function writeInt64BE (h, l, offset) {
    H.writeInt32BE(h, offset)
    H.writeInt32BE(l, offset + 4)
  }

  writeInt64BE(this._ah, this._al, 0)
  writeInt64BE(this._bh, this._bl, 8)
  writeInt64BE(this._ch, this._cl, 16)
  writeInt64BE(this._dh, this._dl, 24)
  writeInt64BE(this._eh, this._el, 32)
  writeInt64BE(this._fh, this._fl, 40)

  return H
}

module.exports = Sha384

},{"./hash":218,"./sha512":225,"inherits":136,"safe-buffer":215}],225:[function(require,module,exports){
var inherits = require('inherits')
var Hash = require('./hash')
var Buffer = require('safe-buffer').Buffer

var K = [
  0x428a2f98, 0xd728ae22, 0x71374491, 0x23ef65cd,
  0xb5c0fbcf, 0xec4d3b2f, 0xe9b5dba5, 0x8189dbbc,
  0x3956c25b, 0xf348b538, 0x59f111f1, 0xb605d019,
  0x923f82a4, 0xaf194f9b, 0xab1c5ed5, 0xda6d8118,
  0xd807aa98, 0xa3030242, 0x12835b01, 0x45706fbe,
  0x243185be, 0x4ee4b28c, 0x550c7dc3, 0xd5ffb4e2,
  0x72be5d74, 0xf27b896f, 0x80deb1fe, 0x3b1696b1,
  0x9bdc06a7, 0x25c71235, 0xc19bf174, 0xcf692694,
  0xe49b69c1, 0x9ef14ad2, 0xefbe4786, 0x384f25e3,
  0x0fc19dc6, 0x8b8cd5b5, 0x240ca1cc, 0x77ac9c65,
  0x2de92c6f, 0x592b0275, 0x4a7484aa, 0x6ea6e483,
  0x5cb0a9dc, 0xbd41fbd4, 0x76f988da, 0x831153b5,
  0x983e5152, 0xee66dfab, 0xa831c66d, 0x2db43210,
  0xb00327c8, 0x98fb213f, 0xbf597fc7, 0xbeef0ee4,
  0xc6e00bf3, 0x3da88fc2, 0xd5a79147, 0x930aa725,
  0x06ca6351, 0xe003826f, 0x14292967, 0x0a0e6e70,
  0x27b70a85, 0x46d22ffc, 0x2e1b2138, 0x5c26c926,
  0x4d2c6dfc, 0x5ac42aed, 0x53380d13, 0x9d95b3df,
  0x650a7354, 0x8baf63de, 0x766a0abb, 0x3c77b2a8,
  0x81c2c92e, 0x47edaee6, 0x92722c85, 0x1482353b,
  0xa2bfe8a1, 0x4cf10364, 0xa81a664b, 0xbc423001,
  0xc24b8b70, 0xd0f89791, 0xc76c51a3, 0x0654be30,
  0xd192e819, 0xd6ef5218, 0xd6990624, 0x5565a910,
  0xf40e3585, 0x5771202a, 0x106aa070, 0x32bbd1b8,
  0x19a4c116, 0xb8d2d0c8, 0x1e376c08, 0x5141ab53,
  0x2748774c, 0xdf8eeb99, 0x34b0bcb5, 0xe19b48a8,
  0x391c0cb3, 0xc5c95a63, 0x4ed8aa4a, 0xe3418acb,
  0x5b9cca4f, 0x7763e373, 0x682e6ff3, 0xd6b2b8a3,
  0x748f82ee, 0x5defb2fc, 0x78a5636f, 0x43172f60,
  0x84c87814, 0xa1f0ab72, 0x8cc70208, 0x1a6439ec,
  0x90befffa, 0x23631e28, 0xa4506ceb, 0xde82bde9,
  0xbef9a3f7, 0xb2c67915, 0xc67178f2, 0xe372532b,
  0xca273ece, 0xea26619c, 0xd186b8c7, 0x21c0c207,
  0xeada7dd6, 0xcde0eb1e, 0xf57d4f7f, 0xee6ed178,
  0x06f067aa, 0x72176fba, 0x0a637dc5, 0xa2c898a6,
  0x113f9804, 0xbef90dae, 0x1b710b35, 0x131c471b,
  0x28db77f5, 0x23047d84, 0x32caab7b, 0x40c72493,
  0x3c9ebe0a, 0x15c9bebc, 0x431d67c4, 0x9c100d4c,
  0x4cc5d4be, 0xcb3e42b6, 0x597f299c, 0xfc657e2a,
  0x5fcb6fab, 0x3ad6faec, 0x6c44198c, 0x4a475817
]

var W = new Array(160)

function Sha512 () {
  this.init()
  this._w = W

  Hash.call(this, 128, 112)
}

inherits(Sha512, Hash)

Sha512.prototype.init = function () {
  this._ah = 0x6a09e667
  this._bh = 0xbb67ae85
  this._ch = 0x3c6ef372
  this._dh = 0xa54ff53a
  this._eh = 0x510e527f
  this._fh = 0x9b05688c
  this._gh = 0x1f83d9ab
  this._hh = 0x5be0cd19

  this._al = 0xf3bcc908
  this._bl = 0x84caa73b
  this._cl = 0xfe94f82b
  this._dl = 0x5f1d36f1
  this._el = 0xade682d1
  this._fl = 0x2b3e6c1f
  this._gl = 0xfb41bd6b
  this._hl = 0x137e2179

  return this
}

function Ch (x, y, z) {
  return z ^ (x & (y ^ z))
}

function maj (x, y, z) {
  return (x & y) | (z & (x | y))
}

function sigma0 (x, xl) {
  return (x >>> 28 | xl << 4) ^ (xl >>> 2 | x << 30) ^ (xl >>> 7 | x << 25)
}

function sigma1 (x, xl) {
  return (x >>> 14 | xl << 18) ^ (x >>> 18 | xl << 14) ^ (xl >>> 9 | x << 23)
}

function Gamma0 (x, xl) {
  return (x >>> 1 | xl << 31) ^ (x >>> 8 | xl << 24) ^ (x >>> 7)
}

function Gamma0l (x, xl) {
  return (x >>> 1 | xl << 31) ^ (x >>> 8 | xl << 24) ^ (x >>> 7 | xl << 25)
}

function Gamma1 (x, xl) {
  return (x >>> 19 | xl << 13) ^ (xl >>> 29 | x << 3) ^ (x >>> 6)
}

function Gamma1l (x, xl) {
  return (x >>> 19 | xl << 13) ^ (xl >>> 29 | x << 3) ^ (x >>> 6 | xl << 26)
}

function getCarry (a, b) {
  return (a >>> 0) < (b >>> 0) ? 1 : 0
}

Sha512.prototype._update = function (M) {
  var W = this._w

  var ah = this._ah | 0
  var bh = this._bh | 0
  var ch = this._ch | 0
  var dh = this._dh | 0
  var eh = this._eh | 0
  var fh = this._fh | 0
  var gh = this._gh | 0
  var hh = this._hh | 0

  var al = this._al | 0
  var bl = this._bl | 0
  var cl = this._cl | 0
  var dl = this._dl | 0
  var el = this._el | 0
  var fl = this._fl | 0
  var gl = this._gl | 0
  var hl = this._hl | 0

  for (var i = 0; i < 32; i += 2) {
    W[i] = M.readInt32BE(i * 4)
    W[i + 1] = M.readInt32BE(i * 4 + 4)
  }
  for (; i < 160; i += 2) {
    var xh = W[i - 15 * 2]
    var xl = W[i - 15 * 2 + 1]
    var gamma0 = Gamma0(xh, xl)
    var gamma0l = Gamma0l(xl, xh)

    xh = W[i - 2 * 2]
    xl = W[i - 2 * 2 + 1]
    var gamma1 = Gamma1(xh, xl)
    var gamma1l = Gamma1l(xl, xh)

    // W[i] = gamma0 + W[i - 7] + gamma1 + W[i - 16]
    var Wi7h = W[i - 7 * 2]
    var Wi7l = W[i - 7 * 2 + 1]

    var Wi16h = W[i - 16 * 2]
    var Wi16l = W[i - 16 * 2 + 1]

    var Wil = (gamma0l + Wi7l) | 0
    var Wih = (gamma0 + Wi7h + getCarry(Wil, gamma0l)) | 0
    Wil = (Wil + gamma1l) | 0
    Wih = (Wih + gamma1 + getCarry(Wil, gamma1l)) | 0
    Wil = (Wil + Wi16l) | 0
    Wih = (Wih + Wi16h + getCarry(Wil, Wi16l)) | 0

    W[i] = Wih
    W[i + 1] = Wil
  }

  for (var j = 0; j < 160; j += 2) {
    Wih = W[j]
    Wil = W[j + 1]

    var majh = maj(ah, bh, ch)
    var majl = maj(al, bl, cl)

    var sigma0h = sigma0(ah, al)
    var sigma0l = sigma0(al, ah)
    var sigma1h = sigma1(eh, el)
    var sigma1l = sigma1(el, eh)

    // t1 = h + sigma1 + ch + K[j] + W[j]
    var Kih = K[j]
    var Kil = K[j + 1]

    var chh = Ch(eh, fh, gh)
    var chl = Ch(el, fl, gl)

    var t1l = (hl + sigma1l) | 0
    var t1h = (hh + sigma1h + getCarry(t1l, hl)) | 0
    t1l = (t1l + chl) | 0
    t1h = (t1h + chh + getCarry(t1l, chl)) | 0
    t1l = (t1l + Kil) | 0
    t1h = (t1h + Kih + getCarry(t1l, Kil)) | 0
    t1l = (t1l + Wil) | 0
    t1h = (t1h + Wih + getCarry(t1l, Wil)) | 0

    // t2 = sigma0 + maj
    var t2l = (sigma0l + majl) | 0
    var t2h = (sigma0h + majh + getCarry(t2l, sigma0l)) | 0

    hh = gh
    hl = gl
    gh = fh
    gl = fl
    fh = eh
    fl = el
    el = (dl + t1l) | 0
    eh = (dh + t1h + getCarry(el, dl)) | 0
    dh = ch
    dl = cl
    ch = bh
    cl = bl
    bh = ah
    bl = al
    al = (t1l + t2l) | 0
    ah = (t1h + t2h + getCarry(al, t1l)) | 0
  }

  this._al = (this._al + al) | 0
  this._bl = (this._bl + bl) | 0
  this._cl = (this._cl + cl) | 0
  this._dl = (this._dl + dl) | 0
  this._el = (this._el + el) | 0
  this._fl = (this._fl + fl) | 0
  this._gl = (this._gl + gl) | 0
  this._hl = (this._hl + hl) | 0

  this._ah = (this._ah + ah + getCarry(this._al, al)) | 0
  this._bh = (this._bh + bh + getCarry(this._bl, bl)) | 0
  this._ch = (this._ch + ch + getCarry(this._cl, cl)) | 0
  this._dh = (this._dh + dh + getCarry(this._dl, dl)) | 0
  this._eh = (this._eh + eh + getCarry(this._el, el)) | 0
  this._fh = (this._fh + fh + getCarry(this._fl, fl)) | 0
  this._gh = (this._gh + gh + getCarry(this._gl, gl)) | 0
  this._hh = (this._hh + hh + getCarry(this._hl, hl)) | 0
}

Sha512.prototype._hash = function () {
  var H = Buffer.allocUnsafe(64)

  function writeInt64BE (h, l, offset) {
    H.writeInt32BE(h, offset)
    H.writeInt32BE(l, offset + 4)
  }

  writeInt64BE(this._ah, this._al, 0)
  writeInt64BE(this._bh, this._bl, 8)
  writeInt64BE(this._ch, this._cl, 16)
  writeInt64BE(this._dh, this._dl, 24)
  writeInt64BE(this._eh, this._el, 32)
  writeInt64BE(this._fh, this._fl, 40)
  writeInt64BE(this._gh, this._gl, 48)
  writeInt64BE(this._hh, this._hl, 56)

  return H
}

module.exports = Sha512

},{"./hash":218,"inherits":136,"safe-buffer":215}],226:[function(require,module,exports){
// Copyright Joyent, Inc. and other Node contributors.
//
// Permission is hereby granted, free of charge, to any person obtaining a
// copy of this software and associated documentation files (the
// "Software"), to deal in the Software without restriction, including
// without limitation the rights to use, copy, modify, merge, publish,
// distribute, sublicense, and/or sell copies of the Software, and to permit
// persons to whom the Software is furnished to do so, subject to the
// following conditions:
//
// The above copyright notice and this permission notice shall be included
// in all copies or substantial portions of the Software.
//
// THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN
// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,
// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR
// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE
// USE OR OTHER DEALINGS IN THE SOFTWARE.

module.exports = Stream;

var EE = require('events').EventEmitter;
var inherits = require('inherits');

inherits(Stream, EE);
Stream.Readable = require('readable-stream/lib/_stream_readable.js');
Stream.Writable = require('readable-stream/lib/_stream_writable.js');
Stream.Duplex = require('readable-stream/lib/_stream_duplex.js');
Stream.Transform = require('readable-stream/lib/_stream_transform.js');
Stream.PassThrough = require('readable-stream/lib/_stream_passthrough.js');
Stream.finished = require('readable-stream/lib/internal/streams/end-of-stream.js')
Stream.pipeline = require('readable-stream/lib/internal/streams/pipeline.js')

// Backwards-compat with node 0.4.x
Stream.Stream = Stream;



// old-style streams.  Note that the pipe method (the only relevant
// part of this class) is overridden in the Readable class.

function Stream() {
  EE.call(this);
}

Stream.prototype.pipe = function(dest, options) {
  var source = this;

  function ondata(chunk) {
    if (dest.writable) {
      if (false === dest.write(chunk) && source.pause) {
        source.pause();
      }
    }
  }

  source.on('data', ondata);

  function ondrain() {
    if (source.readable && source.resume) {
      source.resume();
    }
  }

  dest.on('drain', ondrain);

  // If the 'end' option is not supplied, dest.end() will be called when
  // source gets the 'end' or 'close' events.  Only dest.end() once.
  if (!dest._isStdio && (!options || options.end !== false)) {
    source.on('end', onend);
    source.on('close', onclose);
  }

  var didOnEnd = false;
  function onend() {
    if (didOnEnd) return;
    didOnEnd = true;

    dest.end();
  }


  function onclose() {
    if (didOnEnd) return;
    didOnEnd = true;

    if (typeof dest.destroy === 'function') dest.destroy();
  }

  // don't leave dangling pipes when there are errors.
  function onerror(er) {
    cleanup();
    if (EE.listenerCount(this, 'error') === 0) {
      throw er; // Unhandled stream error in pipe.
    }
  }

  source.on('error', onerror);
  dest.on('error', onerror);

  // remove all the event listeners that were added.
  function cleanup() {
    source.removeListener('data', ondata);
    dest.removeListener('drain', ondrain);

    source.removeListener('end', onend);
    source.removeListener('close', onclose);

    source.removeListener('error', onerror);
    dest.removeListener('error', onerror);

    source.removeListener('end', cleanup);
    source.removeListener('close', cleanup);

    dest.removeListener('close', cleanup);
  }

  source.on('end', cleanup);
  source.on('close', cleanup);

  dest.on('close', cleanup);

  dest.emit('pipe', source);

  // Allow for unix-like usage: A.pipe(B).pipe(C)
  return dest;
};

},{"events":118,"inherits":136,"readable-stream/lib/_stream_duplex.js":200,"readable-stream/lib/_stream_passthrough.js":201,"readable-stream/lib/_stream_readable.js":202,"readable-stream/lib/_stream_transform.js":203,"readable-stream/lib/_stream_writable.js":204,"readable-stream/lib/internal/streams/end-of-stream.js":208,"readable-stream/lib/internal/streams/pipeline.js":210}],227:[function(require,module,exports){
arguments[4][76][0].apply(exports,arguments)
},{"dup":76,"safe-buffer":215}],228:[function(require,module,exports){
(function (setImmediate,clearImmediate){(function (){
var nextTick = require('process/browser.js').nextTick;
var apply = Function.prototype.apply;
var slice = Array.prototype.slice;
var immediateIds = {};
var nextImmediateId = 0;

// DOM APIs, for completeness

exports.setTimeout = function() {
  return new Timeout(apply.call(setTimeout, window, arguments), clearTimeout);
};
exports.setInterval = function() {
  return new Timeout(apply.call(setInterval, window, arguments), clearInterval);
};
exports.clearTimeout =
exports.clearInterval = function(timeout) { timeout.close(); };

function Timeout(id, clearFn) {
  this._id = id;
  this._clearFn = clearFn;
}
Timeout.prototype.unref = Timeout.prototype.ref = function() {};
Timeout.prototype.close = function() {
  this._clearFn.call(window, this._id);
};

// Does not start the time, just sets up the members needed.
exports.enroll = function(item, msecs) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = msecs;
};

exports.unenroll = function(item) {
  clearTimeout(item._idleTimeoutId);
  item._idleTimeout = -1;
};

exports._unrefActive = exports.active = function(item) {
  clearTimeout(item._idleTimeoutId);

  var msecs = item._idleTimeout;
  if (msecs >= 0) {
    item._idleTimeoutId = setTimeout(function onTimeout() {
      if (item._onTimeout)
        item._onTimeout();
    }, msecs);
  }
};

// That's not how node.js implements it but the exposed api is the same.
exports.setImmediate = typeof setImmediate === "function" ? setImmediate : function(fn) {
  var id = nextImmediateId++;
  var args = arguments.length < 2 ? false : slice.call(arguments, 1);

  immediateIds[id] = true;

  nextTick(function onNextTick() {
    if (immediateIds[id]) {
      // fn.call() is faster so we optimize for the common use-case
      // @see http://jsperf.com/call-apply-segu
      if (args) {
        fn.apply(null, args);
      } else {
        fn.call(null);
      }
      // Prevent ids from leaking
      exports.clearImmediate(id);
    }
  });

  return id;
};

exports.clearImmediate = typeof clearImmediate === "function" ? clearImmediate : function(id) {
  delete immediateIds[id];
};
}).call(this)}).call(this,require("timers").setImmediate,require("timers").clearImmediate)
},{"process/browser.js":179,"timers":228}],229:[function(require,module,exports){
/** @license URI.js v4.4.1 (c) 2011 Gary Court. License: http://github.com/garycourt/uri-js */
(function (global, factory) {
	typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :
	typeof define === 'function' && define.amd ? define(['exports'], factory) :
	(factory((global.URI = global.URI || {})));
}(this, (function (exports) { 'use strict';

function merge() {
    for (var _len = arguments.length, sets = Array(_len), _key = 0; _key < _len; _key++) {
        sets[_key] = arguments[_key];
    }

    if (sets.length > 1) {
        sets[0] = sets[0].slice(0, -1);
        var xl = sets.length - 1;
        for (var x = 1; x < xl; ++x) {
            sets[x] = sets[x].slice(1, -1);
        }
        sets[xl] = sets[xl].slice(1);
        return sets.join('');
    } else {
        return sets[0];
    }
}
function subexp(str) {
    return "(?:" + str + ")";
}
function typeOf(o) {
    return o === undefined ? "undefined" : o === null ? "null" : Object.prototype.toString.call(o).split(" ").pop().split("]").shift().toLowerCase();
}
function toUpperCase(str) {
    return str.toUpperCase();
}
function toArray(obj) {
    return obj !== undefined && obj !== null ? obj instanceof Array ? obj : typeof obj.length !== "number" || obj.split || obj.setInterval || obj.call ? [obj] : Array.prototype.slice.call(obj) : [];
}
function assign(target, source) {
    var obj = target;
    if (source) {
        for (var key in source) {
            obj[key] = source[key];
        }
    }
    return obj;
}

function buildExps(isIRI) {
    var ALPHA$$ = "[A-Za-z]",
        CR$ = "[\\x0D]",
        DIGIT$$ = "[0-9]",
        DQUOTE$$ = "[\\x22]",
        HEXDIG$$ = merge(DIGIT$$, "[A-Fa-f]"),
        //case-insensitive
    LF$$ = "[\\x0A]",
        SP$$ = "[\\x20]",
        PCT_ENCODED$ = subexp(subexp("%[EFef]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%[89A-Fa-f]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%" + HEXDIG$$ + HEXDIG$$)),
        //expanded
    GEN_DELIMS$$ = "[\\:\\/\\?\\#\\[\\]\\@]",
        SUB_DELIMS$$ = "[\\!\\$\\&\\'\\(\\)\\*\\+\\,\\;\\=]",
        RESERVED$$ = merge(GEN_DELIMS$$, SUB_DELIMS$$),
        UCSCHAR$$ = isIRI ? "[\\xA0-\\u200D\\u2010-\\u2029\\u202F-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF]" : "[]",
        //subset, excludes bidi control characters
    IPRIVATE$$ = isIRI ? "[\\uE000-\\uF8FF]" : "[]",
        //subset
    UNRESERVED$$ = merge(ALPHA$$, DIGIT$$, "[\\-\\.\\_\\~]", UCSCHAR$$),
        SCHEME$ = subexp(ALPHA$$ + merge(ALPHA$$, DIGIT$$, "[\\+\\-\\.]") + "*"),
        USERINFO$ = subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:]")) + "*"),
        DEC_OCTET$ = subexp(subexp("25[0-5]") + "|" + subexp("2[0-4]" + DIGIT$$) + "|" + subexp("1" + DIGIT$$ + DIGIT$$) + "|" + subexp("[1-9]" + DIGIT$$) + "|" + DIGIT$$),
        DEC_OCTET_RELAXED$ = subexp(subexp("25[0-5]") + "|" + subexp("2[0-4]" + DIGIT$$) + "|" + subexp("1" + DIGIT$$ + DIGIT$$) + "|" + subexp("0?[1-9]" + DIGIT$$) + "|0?0?" + DIGIT$$),
        //relaxed parsing rules
    IPV4ADDRESS$ = subexp(DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$ + "\\." + DEC_OCTET_RELAXED$),
        H16$ = subexp(HEXDIG$$ + "{1,4}"),
        LS32$ = subexp(subexp(H16$ + "\\:" + H16$) + "|" + IPV4ADDRESS$),
        IPV6ADDRESS1$ = subexp(subexp(H16$ + "\\:") + "{6}" + LS32$),
        //                           6( h16 ":" ) ls32
    IPV6ADDRESS2$ = subexp("\\:\\:" + subexp(H16$ + "\\:") + "{5}" + LS32$),
        //                      "::" 5( h16 ":" ) ls32
    IPV6ADDRESS3$ = subexp(subexp(H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{4}" + LS32$),
        //[               h16 ] "::" 4( h16 ":" ) ls32
    IPV6ADDRESS4$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,1}" + H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{3}" + LS32$),
        //[ *1( h16 ":" ) h16 ] "::" 3( h16 ":" ) ls32
    IPV6ADDRESS5$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,2}" + H16$) + "?\\:\\:" + subexp(H16$ + "\\:") + "{2}" + LS32$),
        //[ *2( h16 ":" ) h16 ] "::" 2( h16 ":" ) ls32
    IPV6ADDRESS6$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,3}" + H16$) + "?\\:\\:" + H16$ + "\\:" + LS32$),
        //[ *3( h16 ":" ) h16 ] "::"    h16 ":"   ls32
    IPV6ADDRESS7$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,4}" + H16$) + "?\\:\\:" + LS32$),
        //[ *4( h16 ":" ) h16 ] "::"              ls32
    IPV6ADDRESS8$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,5}" + H16$) + "?\\:\\:" + H16$),
        //[ *5( h16 ":" ) h16 ] "::"              h16
    IPV6ADDRESS9$ = subexp(subexp(subexp(H16$ + "\\:") + "{0,6}" + H16$) + "?\\:\\:"),
        //[ *6( h16 ":" ) h16 ] "::"
    IPV6ADDRESS$ = subexp([IPV6ADDRESS1$, IPV6ADDRESS2$, IPV6ADDRESS3$, IPV6ADDRESS4$, IPV6ADDRESS5$, IPV6ADDRESS6$, IPV6ADDRESS7$, IPV6ADDRESS8$, IPV6ADDRESS9$].join("|")),
        ZONEID$ = subexp(subexp(UNRESERVED$$ + "|" + PCT_ENCODED$) + "+"),
        //RFC 6874
    IPV6ADDRZ$ = subexp(IPV6ADDRESS$ + "\\%25" + ZONEID$),
        //RFC 6874
    IPV6ADDRZ_RELAXED$ = subexp(IPV6ADDRESS$ + subexp("\\%25|\\%(?!" + HEXDIG$$ + "{2})") + ZONEID$),
        //RFC 6874, with relaxed parsing rules
    IPVFUTURE$ = subexp("[vV]" + HEXDIG$$ + "+\\." + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:]") + "+"),
        IP_LITERAL$ = subexp("\\[" + subexp(IPV6ADDRZ_RELAXED$ + "|" + IPV6ADDRESS$ + "|" + IPVFUTURE$) + "\\]"),
        //RFC 6874
    REG_NAME$ = subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$)) + "*"),
        HOST$ = subexp(IP_LITERAL$ + "|" + IPV4ADDRESS$ + "(?!" + REG_NAME$ + ")" + "|" + REG_NAME$),
        PORT$ = subexp(DIGIT$$ + "*"),
        AUTHORITY$ = subexp(subexp(USERINFO$ + "@") + "?" + HOST$ + subexp("\\:" + PORT$) + "?"),
        PCHAR$ = subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@]")),
        SEGMENT$ = subexp(PCHAR$ + "*"),
        SEGMENT_NZ$ = subexp(PCHAR$ + "+"),
        SEGMENT_NZ_NC$ = subexp(subexp(PCT_ENCODED$ + "|" + merge(UNRESERVED$$, SUB_DELIMS$$, "[\\@]")) + "+"),
        PATH_ABEMPTY$ = subexp(subexp("\\/" + SEGMENT$) + "*"),
        PATH_ABSOLUTE$ = subexp("\\/" + subexp(SEGMENT_NZ$ + PATH_ABEMPTY$) + "?"),
        //simplified
    PATH_NOSCHEME$ = subexp(SEGMENT_NZ_NC$ + PATH_ABEMPTY$),
        //simplified
    PATH_ROOTLESS$ = subexp(SEGMENT_NZ$ + PATH_ABEMPTY$),
        //simplified
    PATH_EMPTY$ = "(?!" + PCHAR$ + ")",
        PATH$ = subexp(PATH_ABEMPTY$ + "|" + PATH_ABSOLUTE$ + "|" + PATH_NOSCHEME$ + "|" + PATH_ROOTLESS$ + "|" + PATH_EMPTY$),
        QUERY$ = subexp(subexp(PCHAR$ + "|" + merge("[\\/\\?]", IPRIVATE$$)) + "*"),
        FRAGMENT$ = subexp(subexp(PCHAR$ + "|[\\/\\?]") + "*"),
        HIER_PART$ = subexp(subexp("\\/\\/" + AUTHORITY$ + PATH_ABEMPTY$) + "|" + PATH_ABSOLUTE$ + "|" + PATH_ROOTLESS$ + "|" + PATH_EMPTY$),
        URI$ = subexp(SCHEME$ + "\\:" + HIER_PART$ + subexp("\\?" + QUERY$) + "?" + subexp("\\#" + FRAGMENT$) + "?"),
        RELATIVE_PART$ = subexp(subexp("\\/\\/" + AUTHORITY$ + PATH_ABEMPTY$) + "|" + PATH_ABSOLUTE$ + "|" + PATH_NOSCHEME$ + "|" + PATH_EMPTY$),
        RELATIVE$ = subexp(RELATIVE_PART$ + subexp("\\?" + QUERY$) + "?" + subexp("\\#" + FRAGMENT$) + "?"),
        URI_REFERENCE$ = subexp(URI$ + "|" + RELATIVE$),
        ABSOLUTE_URI$ = subexp(SCHEME$ + "\\:" + HIER_PART$ + subexp("\\?" + QUERY$) + "?"),
        GENERIC_REF$ = "^(" + SCHEME$ + ")\\:" + subexp(subexp("\\/\\/(" + subexp("(" + USERINFO$ + ")@") + "?(" + HOST$ + ")" + subexp("\\:(" + PORT$ + ")") + "?)") + "?(" + PATH_ABEMPTY$ + "|" + PATH_ABSOLUTE$ + "|" + PATH_ROOTLESS$ + "|" + PATH_EMPTY$ + ")") + subexp("\\?(" + QUERY$ + ")") + "?" + subexp("\\#(" + FRAGMENT$ + ")") + "?$",
        RELATIVE_REF$ = "^(){0}" + subexp(subexp("\\/\\/(" + subexp("(" + USERINFO$ + ")@") + "?(" + HOST$ + ")" + subexp("\\:(" + PORT$ + ")") + "?)") + "?(" + PATH_ABEMPTY$ + "|" + PATH_ABSOLUTE$ + "|" + PATH_NOSCHEME$ + "|" + PATH_EMPTY$ + ")") + subexp("\\?(" + QUERY$ + ")") + "?" + subexp("\\#(" + FRAGMENT$ + ")") + "?$",
        ABSOLUTE_REF$ = "^(" + SCHEME$ + ")\\:" + subexp(subexp("\\/\\/(" + subexp("(" + USERINFO$ + ")@") + "?(" + HOST$ + ")" + subexp("\\:(" + PORT$ + ")") + "?)") + "?(" + PATH_ABEMPTY$ + "|" + PATH_ABSOLUTE$ + "|" + PATH_ROOTLESS$ + "|" + PATH_EMPTY$ + ")") + subexp("\\?(" + QUERY$ + ")") + "?$",
        SAMEDOC_REF$ = "^" + subexp("\\#(" + FRAGMENT$ + ")") + "?$",
        AUTHORITY_REF$ = "^" + subexp("(" + USERINFO$ + ")@") + "?(" + HOST$ + ")" + subexp("\\:(" + PORT$ + ")") + "?$";
    return {
        NOT_SCHEME: new RegExp(merge("[^]", ALPHA$$, DIGIT$$, "[\\+\\-\\.]"), "g"),
        NOT_USERINFO: new RegExp(merge("[^\\%\\:]", UNRESERVED$$, SUB_DELIMS$$), "g"),
        NOT_HOST: new RegExp(merge("[^\\%\\[\\]\\:]", UNRESERVED$$, SUB_DELIMS$$), "g"),
        NOT_PATH: new RegExp(merge("[^\\%\\/\\:\\@]", UNRESERVED$$, SUB_DELIMS$$), "g"),
        NOT_PATH_NOSCHEME: new RegExp(merge("[^\\%\\/\\@]", UNRESERVED$$, SUB_DELIMS$$), "g"),
        NOT_QUERY: new RegExp(merge("[^\\%]", UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@\\/\\?]", IPRIVATE$$), "g"),
        NOT_FRAGMENT: new RegExp(merge("[^\\%]", UNRESERVED$$, SUB_DELIMS$$, "[\\:\\@\\/\\?]"), "g"),
        ESCAPE: new RegExp(merge("[^]", UNRESERVED$$, SUB_DELIMS$$), "g"),
        UNRESERVED: new RegExp(UNRESERVED$$, "g"),
        OTHER_CHARS: new RegExp(merge("[^\\%]", UNRESERVED$$, RESERVED$$), "g"),
        PCT_ENCODED: new RegExp(PCT_ENCODED$, "g"),
        IPV4ADDRESS: new RegExp("^(" + IPV4ADDRESS$ + ")$"),
        IPV6ADDRESS: new RegExp("^\\[?(" + IPV6ADDRESS$ + ")" + subexp(subexp("\\%25|\\%(?!" + HEXDIG$$ + "{2})") + "(" + ZONEID$ + ")") + "?\\]?$") //RFC 6874, with relaxed parsing rules
    };
}
var URI_PROTOCOL = buildExps(false);

var IRI_PROTOCOL = buildExps(true);

var slicedToArray = function () {
  function sliceIterator(arr, i) {
    var _arr = [];
    var _n = true;
    var _d = false;
    var _e = undefined;

    try {
      for (var _i = arr[Symbol.iterator](), _s; !(_n = (_s = _i.next()).done); _n = true) {
        _arr.push(_s.value);

        if (i && _arr.length === i) break;
      }
    } catch (err) {
      _d = true;
      _e = err;
    } finally {
      try {
        if (!_n && _i["return"]) _i["return"]();
      } finally {
        if (_d) throw _e;
      }
    }

    return _arr;
  }

  return function (arr, i) {
    if (Array.isArray(arr)) {
      return arr;
    } else if (Symbol.iterator in Object(arr)) {
      return sliceIterator(arr, i);
    } else {
      throw new TypeError("Invalid attempt to destructure non-iterable instance");
    }
  };
}();













var toConsumableArray = function (arr) {
  if (Array.isArray(arr)) {
    for (var i = 0, arr2 = Array(arr.length); i < arr.length; i++) arr2[i] = arr[i];

    return arr2;
  } else {
    return Array.from(arr);
  }
};

/** Highest positive signed 32-bit float value */

var maxInt = 2147483647; // aka. 0x7FFFFFFF or 2^31-1

/** Bootstring parameters */
var base = 36;
var tMin = 1;
var tMax = 26;
var skew = 38;
var damp = 700;
var initialBias = 72;
var initialN = 128; // 0x80
var delimiter = '-'; // '\x2D'

/** Regular expressions */
var regexPunycode = /^xn--/;
var regexNonASCII = /[^\0-\x7E]/; // non-ASCII chars
var regexSeparators = /[\x2E\u3002\uFF0E\uFF61]/g; // RFC 3490 separators

/** Error messages */
var errors = {
	'overflow': 'Overflow: input needs wider integers to process',
	'not-basic': 'Illegal input >= 0x80 (not a basic code point)',
	'invalid-input': 'Invalid input'
};

/** Convenience shortcuts */
var baseMinusTMin = base - tMin;
var floor = Math.floor;
var stringFromCharCode = String.fromCharCode;

/*--------------------------------------------------------------------------*/

/**
 * A generic error utility function.
 * @private
 * @param {String} type The error type.
 * @returns {Error} Throws a `RangeError` with the applicable error message.
 */
function error$1(type) {
	throw new RangeError(errors[type]);
}

/**
 * A generic `Array#map` utility function.
 * @private
 * @param {Array} array The array to iterate over.
 * @param {Function} callback The function that gets called for every array
 * item.
 * @returns {Array} A new array of values returned by the callback function.
 */
function map(array, fn) {
	var result = [];
	var length = array.length;
	while (length--) {
		result[length] = fn(array[length]);
	}
	return result;
}

/**
 * A simple `Array#map`-like wrapper to work with domain name strings or email
 * addresses.
 * @private
 * @param {String} domain The domain name or email address.
 * @param {Function} callback The function that gets called for every
 * character.
 * @returns {Array} A new string of characters returned by the callback
 * function.
 */
function mapDomain(string, fn) {
	var parts = string.split('@');
	var result = '';
	if (parts.length > 1) {
		// In email addresses, only the domain name should be punycoded. Leave
		// the local part (i.e. everything up to `@`) intact.
		result = parts[0] + '@';
		string = parts[1];
	}
	// Avoid `split(regex)` for IE8 compatibility. See #17.
	string = string.replace(regexSeparators, '\x2E');
	var labels = string.split('.');
	var encoded = map(labels, fn).join('.');
	return result + encoded;
}

/**
 * Creates an array containing the numeric code points of each Unicode
 * character in the string. While JavaScript uses UCS-2 internally,
 * this function will convert a pair of surrogate halves (each of which
 * UCS-2 exposes as separate characters) into a single code point,
 * matching UTF-16.
 * @see `punycode.ucs2.encode`
 * @see <https://mathiasbynens.be/notes/javascript-encoding>
 * @memberOf punycode.ucs2
 * @name decode
 * @param {String} string The Unicode input string (UCS-2).
 * @returns {Array} The new array of code points.
 */
function ucs2decode(string) {
	var output = [];
	var counter = 0;
	var length = string.length;
	while (counter < length) {
		var value = string.charCodeAt(counter++);
		if (value >= 0xD800 && value <= 0xDBFF && counter < length) {
			// It's a high surrogate, and there is a next character.
			var extra = string.charCodeAt(counter++);
			if ((extra & 0xFC00) == 0xDC00) {
				// Low surrogate.
				output.push(((value & 0x3FF) << 10) + (extra & 0x3FF) + 0x10000);
			} else {
				// It's an unmatched surrogate; only append this code unit, in case the
				// next code unit is the high surrogate of a surrogate pair.
				output.push(value);
				counter--;
			}
		} else {
			output.push(value);
		}
	}
	return output;
}

/**
 * Creates a string based on an array of numeric code points.
 * @see `punycode.ucs2.decode`
 * @memberOf punycode.ucs2
 * @name encode
 * @param {Array} codePoints The array of numeric code points.
 * @returns {String} The new Unicode string (UCS-2).
 */
var ucs2encode = function ucs2encode(array) {
	return String.fromCodePoint.apply(String, toConsumableArray(array));
};

/**
 * Converts a basic code point into a digit/integer.
 * @see `digitToBasic()`
 * @private
 * @param {Number} codePoint The basic numeric code point value.
 * @returns {Number} The numeric value of a basic code point (for use in
 * representing integers) in the range `0` to `base - 1`, or `base` if
 * the code point does not represent a value.
 */
var basicToDigit = function basicToDigit(codePoint) {
	if (codePoint - 0x30 < 0x0A) {
		return codePoint - 0x16;
	}
	if (codePoint - 0x41 < 0x1A) {
		return codePoint - 0x41;
	}
	if (codePoint - 0x61 < 0x1A) {
		return codePoint - 0x61;
	}
	return base;
};

/**
 * Converts a digit/integer into a basic code point.
 * @see `basicToDigit()`
 * @private
 * @param {Number} digit The numeric value of a basic code point.
 * @returns {Number} The basic code point whose value (when used for
 * representing integers) is `digit`, which needs to be in the range
 * `0` to `base - 1`. If `flag` is non-zero, the uppercase form is
 * used; else, the lowercase form is used. The behavior is undefined
 * if `flag` is non-zero and `digit` has no uppercase form.
 */
var digitToBasic = function digitToBasic(digit, flag) {
	//  0..25 map to ASCII a..z or A..Z
	// 26..35 map to ASCII 0..9
	return digit + 22 + 75 * (digit < 26) - ((flag != 0) << 5);
};

/**
 * Bias adaptation function as per section 3.4 of RFC 3492.
 * https://tools.ietf.org/html/rfc3492#section-3.4
 * @private
 */
var adapt = function adapt(delta, numPoints, firstTime) {
	var k = 0;
	delta = firstTime ? floor(delta / damp) : delta >> 1;
	delta += floor(delta / numPoints);
	for (; /* no initialization */delta > baseMinusTMin * tMax >> 1; k += base) {
		delta = floor(delta / baseMinusTMin);
	}
	return floor(k + (baseMinusTMin + 1) * delta / (delta + skew));
};

/**
 * Converts a Punycode string of ASCII-only symbols to a string of Unicode
 * symbols.
 * @memberOf punycode
 * @param {String} input The Punycode string of ASCII-only symbols.
 * @returns {String} The resulting string of Unicode symbols.
 */
var decode = function decode(input) {
	// Don't use UCS-2.
	var output = [];
	var inputLength = input.length;
	var i = 0;
	var n = initialN;
	var bias = initialBias;

	// Handle the basic code points: let `basic` be the number of input code
	// points before the last delimiter, or `0` if there is none, then copy
	// the first basic code points to the output.

	var basic = input.lastIndexOf(delimiter);
	if (basic < 0) {
		basic = 0;
	}

	for (var j = 0; j < basic; ++j) {
		// if it's not a basic code point
		if (input.charCodeAt(j) >= 0x80) {
			error$1('not-basic');
		}
		output.push(input.charCodeAt(j));
	}

	// Main decoding loop: start just after the last delimiter if any basic code
	// points were copied; start at the beginning otherwise.

	for (var index = basic > 0 ? basic + 1 : 0; index < inputLength;) /* no final expression */{

		// `index` is the index of the next character to be consumed.
		// Decode a generalized variable-length integer into `delta`,
		// which gets added to `i`. The overflow checking is easier
		// if we increase `i` as we go, then subtract off its starting
		// value at the end to obtain `delta`.
		var oldi = i;
		for (var w = 1, k = base;; /* no condition */k += base) {

			if (index >= inputLength) {
				error$1('invalid-input');
			}

			var digit = basicToDigit(input.charCodeAt(index++));

			if (digit >= base || digit > floor((maxInt - i) / w)) {
				error$1('overflow');
			}

			i += digit * w;
			var t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;

			if (digit < t) {
				break;
			}

			var baseMinusT = base - t;
			if (w > floor(maxInt / baseMinusT)) {
				error$1('overflow');
			}

			w *= baseMinusT;
		}

		var out = output.length + 1;
		bias = adapt(i - oldi, out, oldi == 0);

		// `i` was supposed to wrap around from `out` to `0`,
		// incrementing `n` each time, so we'll fix that now:
		if (floor(i / out) > maxInt - n) {
			error$1('overflow');
		}

		n += floor(i / out);
		i %= out;

		// Insert `n` at position `i` of the output.
		output.splice(i++, 0, n);
	}

	return String.fromCodePoint.apply(String, output);
};

/**
 * Converts a string of Unicode symbols (e.g. a domain name label) to a
 * Punycode string of ASCII-only symbols.
 * @memberOf punycode
 * @param {String} input The string of Unicode symbols.
 * @returns {String} The resulting Punycode string of ASCII-only symbols.
 */
var encode = function encode(input) {
	var output = [];

	// Convert the input in UCS-2 to an array of Unicode code points.
	input = ucs2decode(input);

	// Cache the length.
	var inputLength = input.length;

	// Initialize the state.
	var n = initialN;
	var delta = 0;
	var bias = initialBias;

	// Handle the basic code points.
	var _iteratorNormalCompletion = true;
	var _didIteratorError = false;
	var _iteratorError = undefined;

	try {
		for (var _iterator = input[Symbol.iterator](), _step; !(_iteratorNormalCompletion = (_step = _iterator.next()).done); _iteratorNormalCompletion = true) {
			var _currentValue2 = _step.value;

			if (_currentValue2 < 0x80) {
				output.push(stringFromCharCode(_currentValue2));
			}
		}
	} catch (err) {
		_didIteratorError = true;
		_iteratorError = err;
	} finally {
		try {
			if (!_iteratorNormalCompletion && _iterator.return) {
				_iterator.return();
			}
		} finally {
			if (_didIteratorError) {
				throw _iteratorError;
			}
		}
	}

	var basicLength = output.length;
	var handledCPCount = basicLength;

	// `handledCPCount` is the number of code points that have been handled;
	// `basicLength` is the number of basic code points.

	// Finish the basic string with a delimiter unless it's empty.
	if (basicLength) {
		output.push(delimiter);
	}

	// Main encoding loop:
	while (handledCPCount < inputLength) {

		// All non-basic code points < n have been handled already. Find the next
		// larger one:
		var m = maxInt;
		var _iteratorNormalCompletion2 = true;
		var _didIteratorError2 = false;
		var _iteratorError2 = undefined;

		try {
			for (var _iterator2 = input[Symbol.iterator](), _step2; !(_iteratorNormalCompletion2 = (_step2 = _iterator2.next()).done); _iteratorNormalCompletion2 = true) {
				var currentValue = _step2.value;

				if (currentValue >= n && currentValue < m) {
					m = currentValue;
				}
			}

			// Increase `delta` enough to advance the decoder's <n,i> state to <m,0>,
			// but guard against overflow.
		} catch (err) {
			_didIteratorError2 = true;
			_iteratorError2 = err;
		} finally {
			try {
				if (!_iteratorNormalCompletion2 && _iterator2.return) {
					_iterator2.return();
				}
			} finally {
				if (_didIteratorError2) {
					throw _iteratorError2;
				}
			}
		}

		var handledCPCountPlusOne = handledCPCount + 1;
		if (m - n > floor((maxInt - delta) / handledCPCountPlusOne)) {
			error$1('overflow');
		}

		delta += (m - n) * handledCPCountPlusOne;
		n = m;

		var _iteratorNormalCompletion3 = true;
		var _didIteratorError3 = false;
		var _iteratorError3 = undefined;

		try {
			for (var _iterator3 = input[Symbol.iterator](), _step3; !(_iteratorNormalCompletion3 = (_step3 = _iterator3.next()).done); _iteratorNormalCompletion3 = true) {
				var _currentValue = _step3.value;

				if (_currentValue < n && ++delta > maxInt) {
					error$1('overflow');
				}
				if (_currentValue == n) {
					// Represent delta as a generalized variable-length integer.
					var q = delta;
					for (var k = base;; /* no condition */k += base) {
						var t = k <= bias ? tMin : k >= bias + tMax ? tMax : k - bias;
						if (q < t) {
							break;
						}
						var qMinusT = q - t;
						var baseMinusT = base - t;
						output.push(stringFromCharCode(digitToBasic(t + qMinusT % baseMinusT, 0)));
						q = floor(qMinusT / baseMinusT);
					}

					output.push(stringFromCharCode(digitToBasic(q, 0)));
					bias = adapt(delta, handledCPCountPlusOne, handledCPCount == basicLength);
					delta = 0;
					++handledCPCount;
				}
			}
		} catch (err) {
			_didIteratorError3 = true;
			_iteratorError3 = err;
		} finally {
			try {
				if (!_iteratorNormalCompletion3 && _iterator3.return) {
					_iterator3.return();
				}
			} finally {
				if (_didIteratorError3) {
					throw _iteratorError3;
				}
			}
		}

		++delta;
		++n;
	}
	return output.join('');
};

/**
 * Converts a Punycode string representing a domain name or an email address
 * to Unicode. Only the Punycoded parts of the input will be converted, i.e.
 * it doesn't matter if you call it on a string that has already been
 * converted to Unicode.
 * @memberOf punycode
 * @param {String} input The Punycoded domain name or email address to
 * convert to Unicode.
 * @returns {String} The Unicode representation of the given Punycode
 * string.
 */
var toUnicode = function toUnicode(input) {
	return mapDomain(input, function (string) {
		return regexPunycode.test(string) ? decode(string.slice(4).toLowerCase()) : string;
	});
};

/**
 * Converts a Unicode string representing a domain name or an email address to
 * Punycode. Only the non-ASCII parts of the domain name will be converted,
 * i.e. it doesn't matter if you call it with a domain that's already in
 * ASCII.
 * @memberOf punycode
 * @param {String} input The domain name or email address to convert, as a
 * Unicode string.
 * @returns {String} The Punycode representation of the given domain name or
 * email address.
 */
var toASCII = function toASCII(input) {
	return mapDomain(input, function (string) {
		return regexNonASCII.test(string) ? 'xn--' + encode(string) : string;
	});
};

/*--------------------------------------------------------------------------*/

/** Define the public API */
var punycode = {
	/**
  * A string representing the current Punycode.js version number.
  * @memberOf punycode
  * @type String
  */
	'version': '2.1.0',
	/**
  * An object of methods to convert from JavaScript's internal character
  * representation (UCS-2) to Unicode code points, and back.
  * @see <https://mathiasbynens.be/notes/javascript-encoding>
  * @memberOf punycode
  * @type Object
  */
	'ucs2': {
		'decode': ucs2decode,
		'encode': ucs2encode
	},
	'decode': decode,
	'encode': encode,
	'toASCII': toASCII,
	'toUnicode': toUnicode
};

/**
 * URI.js
 *
 * @fileoverview An RFC 3986 compliant, scheme extendable URI parsing/validating/resolving library for JavaScript.
 * @author <a href="mailto:gary.court@gmail.com">Gary Court</a>
 * @see http://github.com/garycourt/uri-js
 */
/**
 * Copyright 2011 Gary Court. All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without modification, are
 * permitted provided that the following conditions are met:
 *
 *    1. Redistributions of source code must retain the above copyright notice, this list of
 *       conditions and the following disclaimer.
 *
 *    2. Redistributions in binary form must reproduce the above copyright notice, this list
 *       of conditions and the following disclaimer in the documentation and/or other materials
 *       provided with the distribution.
 *
 * THIS SOFTWARE IS PROVIDED BY GARY COURT ``AS IS'' AND ANY EXPRESS OR IMPLIED
 * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
 * FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL GARY COURT OR
 * CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
 * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
 * ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
 * NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF
 * ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 *
 * The views and conclusions contained in the software and documentation are those of the
 * authors and should not be interpreted as representing official policies, either expressed
 * or implied, of Gary Court.
 */
var SCHEMES = {};
function pctEncChar(chr) {
    var c = chr.charCodeAt(0);
    var e = void 0;
    if (c < 16) e = "%0" + c.toString(16).toUpperCase();else if (c < 128) e = "%" + c.toString(16).toUpperCase();else if (c < 2048) e = "%" + (c >> 6 | 192).toString(16).toUpperCase() + "%" + (c & 63 | 128).toString(16).toUpperCase();else e = "%" + (c >> 12 | 224).toString(16).toUpperCase() + "%" + (c >> 6 & 63 | 128).toString(16).toUpperCase() + "%" + (c & 63 | 128).toString(16).toUpperCase();
    return e;
}
function pctDecChars(str) {
    var newStr = "";
    var i = 0;
    var il = str.length;
    while (i < il) {
        var c = parseInt(str.substr(i + 1, 2), 16);
        if (c < 128) {
            newStr += String.fromCharCode(c);
            i += 3;
        } else if (c >= 194 && c < 224) {
            if (il - i >= 6) {
                var c2 = parseInt(str.substr(i + 4, 2), 16);
                newStr += String.fromCharCode((c & 31) << 6 | c2 & 63);
            } else {
                newStr += str.substr(i, 6);
            }
            i += 6;
        } else if (c >= 224) {
            if (il - i >= 9) {
                var _c = parseInt(str.substr(i + 4, 2), 16);
                var c3 = parseInt(str.substr(i + 7, 2), 16);
                newStr += String.fromCharCode((c & 15) << 12 | (_c & 63) << 6 | c3 & 63);
            } else {
                newStr += str.substr(i, 9);
            }
            i += 9;
        } else {
            newStr += str.substr(i, 3);
            i += 3;
        }
    }
    return newStr;
}
function _normalizeComponentEncoding(components, protocol) {
    function decodeUnreserved(str) {
        var decStr = pctDecChars(str);
        return !decStr.match(protocol.UNRESERVED) ? str : decStr;
    }
    if (components.scheme) components.scheme = String(components.scheme).replace(protocol.PCT_ENCODED, decodeUnreserved).toLowerCase().replace(protocol.NOT_SCHEME, "");
    if (components.userinfo !== undefined) components.userinfo = String(components.userinfo).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_USERINFO, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
    if (components.host !== undefined) components.host = String(components.host).replace(protocol.PCT_ENCODED, decodeUnreserved).toLowerCase().replace(protocol.NOT_HOST, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
    if (components.path !== undefined) components.path = String(components.path).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(components.scheme ? protocol.NOT_PATH : protocol.NOT_PATH_NOSCHEME, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
    if (components.query !== undefined) components.query = String(components.query).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_QUERY, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
    if (components.fragment !== undefined) components.fragment = String(components.fragment).replace(protocol.PCT_ENCODED, decodeUnreserved).replace(protocol.NOT_FRAGMENT, pctEncChar).replace(protocol.PCT_ENCODED, toUpperCase);
    return components;
}

function _stripLeadingZeros(str) {
    return str.replace(/^0*(.*)/, "$1") || "0";
}
function _normalizeIPv4(host, protocol) {
    var matches = host.match(protocol.IPV4ADDRESS) || [];

    var _matches = slicedToArray(matches, 2),
        address = _matches[1];

    if (address) {
        return address.split(".").map(_stripLeadingZeros).join(".");
    } else {
        return host;
    }
}
function _normalizeIPv6(host, protocol) {
    var matches = host.match(protocol.IPV6ADDRESS) || [];

    var _matches2 = slicedToArray(matches, 3),
        address = _matches2[1],
        zone = _matches2[2];

    if (address) {
        var _address$toLowerCase$ = address.toLowerCase().split('::').reverse(),
            _address$toLowerCase$2 = slicedToArray(_address$toLowerCase$, 2),
            last = _address$toLowerCase$2[0],
            first = _address$toLowerCase$2[1];

        var firstFields = first ? first.split(":").map(_stripLeadingZeros) : [];
        var lastFields = last.split(":").map(_stripLeadingZeros);
        var isLastFieldIPv4Address = protocol.IPV4ADDRESS.test(lastFields[lastFields.length - 1]);
        var fieldCount = isLastFieldIPv4Address ? 7 : 8;
        var lastFieldsStart = lastFields.length - fieldCount;
        var fields = Array(fieldCount);
        for (var x = 0; x < fieldCount; ++x) {
            fields[x] = firstFields[x] || lastFields[lastFieldsStart + x] || '';
        }
        if (isLastFieldIPv4Address) {
            fields[fieldCount - 1] = _normalizeIPv4(fields[fieldCount - 1], protocol);
        }
        var allZeroFields = fields.reduce(function (acc, field, index) {
            if (!field || field === "0") {
                var lastLongest = acc[acc.length - 1];
                if (lastLongest && lastLongest.index + lastLongest.length === index) {
                    lastLongest.length++;
                } else {
                    acc.push({ index: index, length: 1 });
                }
            }
            return acc;
        }, []);
        var longestZeroFields = allZeroFields.sort(function (a, b) {
            return b.length - a.length;
        })[0];
        var newHost = void 0;
        if (longestZeroFields && longestZeroFields.length > 1) {
            var newFirst = fields.slice(0, longestZeroFields.index);
            var newLast = fields.slice(longestZeroFields.index + longestZeroFields.length);
            newHost = newFirst.join(":") + "::" + newLast.join(":");
        } else {
            newHost = fields.join(":");
        }
        if (zone) {
            newHost += "%" + zone;
        }
        return newHost;
    } else {
        return host;
    }
}
var URI_PARSE = /^(?:([^:\/?#]+):)?(?:\/\/((?:([^\/?#@]*)@)?(\[[^\/?#\]]+\]|[^\/?#:]*)(?:\:(\d*))?))?([^?#]*)(?:\?([^#]*))?(?:#((?:.|\n|\r)*))?/i;
var NO_MATCH_IS_UNDEFINED = "".match(/(){0}/)[1] === undefined;
function parse(uriString) {
    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

    var components = {};
    var protocol = options.iri !== false ? IRI_PROTOCOL : URI_PROTOCOL;
    if (options.reference === "suffix") uriString = (options.scheme ? options.scheme + ":" : "") + "//" + uriString;
    var matches = uriString.match(URI_PARSE);
    if (matches) {
        if (NO_MATCH_IS_UNDEFINED) {
            //store each component
            components.scheme = matches[1];
            components.userinfo = matches[3];
            components.host = matches[4];
            components.port = parseInt(matches[5], 10);
            components.path = matches[6] || "";
            components.query = matches[7];
            components.fragment = matches[8];
            //fix port number
            if (isNaN(components.port)) {
                components.port = matches[5];
            }
        } else {
            //IE FIX for improper RegExp matching
            //store each component
            components.scheme = matches[1] || undefined;
            components.userinfo = uriString.indexOf("@") !== -1 ? matches[3] : undefined;
            components.host = uriString.indexOf("//") !== -1 ? matches[4] : undefined;
            components.port = parseInt(matches[5], 10);
            components.path = matches[6] || "";
            components.query = uriString.indexOf("?") !== -1 ? matches[7] : undefined;
            components.fragment = uriString.indexOf("#") !== -1 ? matches[8] : undefined;
            //fix port number
            if (isNaN(components.port)) {
                components.port = uriString.match(/\/\/(?:.|\n)*\:(?:\/|\?|\#|$)/) ? matches[4] : undefined;
            }
        }
        if (components.host) {
            //normalize IP hosts
            components.host = _normalizeIPv6(_normalizeIPv4(components.host, protocol), protocol);
        }
        //determine reference type
        if (components.scheme === undefined && components.userinfo === undefined && components.host === undefined && components.port === undefined && !components.path && components.query === undefined) {
            components.reference = "same-document";
        } else if (components.scheme === undefined) {
            components.reference = "relative";
        } else if (components.fragment === undefined) {
            components.reference = "absolute";
        } else {
            components.reference = "uri";
        }
        //check for reference errors
        if (options.reference && options.reference !== "suffix" && options.reference !== components.reference) {
            components.error = components.error || "URI is not a " + options.reference + " reference.";
        }
        //find scheme handler
        var schemeHandler = SCHEMES[(options.scheme || components.scheme || "").toLowerCase()];
        //check if scheme can't handle IRIs
        if (!options.unicodeSupport && (!schemeHandler || !schemeHandler.unicodeSupport)) {
            //if host component is a domain name
            if (components.host && (options.domainHost || schemeHandler && schemeHandler.domainHost)) {
                //convert Unicode IDN -> ASCII IDN
                try {
                    components.host = punycode.toASCII(components.host.replace(protocol.PCT_ENCODED, pctDecChars).toLowerCase());
                } catch (e) {
                    components.error = components.error || "Host's domain name can not be converted to ASCII via punycode: " + e;
                }
            }
            //convert IRI -> URI
            _normalizeComponentEncoding(components, URI_PROTOCOL);
        } else {
            //normalize encodings
            _normalizeComponentEncoding(components, protocol);
        }
        //perform scheme specific parsing
        if (schemeHandler && schemeHandler.parse) {
            schemeHandler.parse(components, options);
        }
    } else {
        components.error = components.error || "URI can not be parsed.";
    }
    return components;
}

function _recomposeAuthority(components, options) {
    var protocol = options.iri !== false ? IRI_PROTOCOL : URI_PROTOCOL;
    var uriTokens = [];
    if (components.userinfo !== undefined) {
        uriTokens.push(components.userinfo);
        uriTokens.push("@");
    }
    if (components.host !== undefined) {
        //normalize IP hosts, add brackets and escape zone separator for IPv6
        uriTokens.push(_normalizeIPv6(_normalizeIPv4(String(components.host), protocol), protocol).replace(protocol.IPV6ADDRESS, function (_, $1, $2) {
            return "[" + $1 + ($2 ? "%25" + $2 : "") + "]";
        }));
    }
    if (typeof components.port === "number" || typeof components.port === "string") {
        uriTokens.push(":");
        uriTokens.push(String(components.port));
    }
    return uriTokens.length ? uriTokens.join("") : undefined;
}

var RDS1 = /^\.\.?\//;
var RDS2 = /^\/\.(\/|$)/;
var RDS3 = /^\/\.\.(\/|$)/;
var RDS5 = /^\/?(?:.|\n)*?(?=\/|$)/;
function removeDotSegments(input) {
    var output = [];
    while (input.length) {
        if (input.match(RDS1)) {
            input = input.replace(RDS1, "");
        } else if (input.match(RDS2)) {
            input = input.replace(RDS2, "/");
        } else if (input.match(RDS3)) {
            input = input.replace(RDS3, "/");
            output.pop();
        } else if (input === "." || input === "..") {
            input = "";
        } else {
            var im = input.match(RDS5);
            if (im) {
                var s = im[0];
                input = input.slice(s.length);
                output.push(s);
            } else {
                throw new Error("Unexpected dot segment condition");
            }
        }
    }
    return output.join("");
}

function serialize(components) {
    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

    var protocol = options.iri ? IRI_PROTOCOL : URI_PROTOCOL;
    var uriTokens = [];
    //find scheme handler
    var schemeHandler = SCHEMES[(options.scheme || components.scheme || "").toLowerCase()];
    //perform scheme specific serialization
    if (schemeHandler && schemeHandler.serialize) schemeHandler.serialize(components, options);
    if (components.host) {
        //if host component is an IPv6 address
        if (protocol.IPV6ADDRESS.test(components.host)) {}
        //TODO: normalize IPv6 address as per RFC 5952

        //if host component is a domain name
        else if (options.domainHost || schemeHandler && schemeHandler.domainHost) {
                //convert IDN via punycode
                try {
                    components.host = !options.iri ? punycode.toASCII(components.host.replace(protocol.PCT_ENCODED, pctDecChars).toLowerCase()) : punycode.toUnicode(components.host);
                } catch (e) {
                    components.error = components.error || "Host's domain name can not be converted to " + (!options.iri ? "ASCII" : "Unicode") + " via punycode: " + e;
                }
            }
    }
    //normalize encoding
    _normalizeComponentEncoding(components, protocol);
    if (options.reference !== "suffix" && components.scheme) {
        uriTokens.push(components.scheme);
        uriTokens.push(":");
    }
    var authority = _recomposeAuthority(components, options);
    if (authority !== undefined) {
        if (options.reference !== "suffix") {
            uriTokens.push("//");
        }
        uriTokens.push(authority);
        if (components.path && components.path.charAt(0) !== "/") {
            uriTokens.push("/");
        }
    }
    if (components.path !== undefined) {
        var s = components.path;
        if (!options.absolutePath && (!schemeHandler || !schemeHandler.absolutePath)) {
            s = removeDotSegments(s);
        }
        if (authority === undefined) {
            s = s.replace(/^\/\//, "/%2F"); //don't allow the path to start with "//"
        }
        uriTokens.push(s);
    }
    if (components.query !== undefined) {
        uriTokens.push("?");
        uriTokens.push(components.query);
    }
    if (components.fragment !== undefined) {
        uriTokens.push("#");
        uriTokens.push(components.fragment);
    }
    return uriTokens.join(""); //merge tokens into a string
}

function resolveComponents(base, relative) {
    var options = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var skipNormalization = arguments[3];

    var target = {};
    if (!skipNormalization) {
        base = parse(serialize(base, options), options); //normalize base components
        relative = parse(serialize(relative, options), options); //normalize relative components
    }
    options = options || {};
    if (!options.tolerant && relative.scheme) {
        target.scheme = relative.scheme;
        //target.authority = relative.authority;
        target.userinfo = relative.userinfo;
        target.host = relative.host;
        target.port = relative.port;
        target.path = removeDotSegments(relative.path || "");
        target.query = relative.query;
    } else {
        if (relative.userinfo !== undefined || relative.host !== undefined || relative.port !== undefined) {
            //target.authority = relative.authority;
            target.userinfo = relative.userinfo;
            target.host = relative.host;
            target.port = relative.port;
            target.path = removeDotSegments(relative.path || "");
            target.query = relative.query;
        } else {
            if (!relative.path) {
                target.path = base.path;
                if (relative.query !== undefined) {
                    target.query = relative.query;
                } else {
                    target.query = base.query;
                }
            } else {
                if (relative.path.charAt(0) === "/") {
                    target.path = removeDotSegments(relative.path);
                } else {
                    if ((base.userinfo !== undefined || base.host !== undefined || base.port !== undefined) && !base.path) {
                        target.path = "/" + relative.path;
                    } else if (!base.path) {
                        target.path = relative.path;
                    } else {
                        target.path = base.path.slice(0, base.path.lastIndexOf("/") + 1) + relative.path;
                    }
                    target.path = removeDotSegments(target.path);
                }
                target.query = relative.query;
            }
            //target.authority = base.authority;
            target.userinfo = base.userinfo;
            target.host = base.host;
            target.port = base.port;
        }
        target.scheme = base.scheme;
    }
    target.fragment = relative.fragment;
    return target;
}

function resolve(baseURI, relativeURI, options) {
    var schemelessOptions = assign({ scheme: 'null' }, options);
    return serialize(resolveComponents(parse(baseURI, schemelessOptions), parse(relativeURI, schemelessOptions), schemelessOptions, true), schemelessOptions);
}

function normalize(uri, options) {
    if (typeof uri === "string") {
        uri = serialize(parse(uri, options), options);
    } else if (typeOf(uri) === "object") {
        uri = parse(serialize(uri, options), options);
    }
    return uri;
}

function equal(uriA, uriB, options) {
    if (typeof uriA === "string") {
        uriA = serialize(parse(uriA, options), options);
    } else if (typeOf(uriA) === "object") {
        uriA = serialize(uriA, options);
    }
    if (typeof uriB === "string") {
        uriB = serialize(parse(uriB, options), options);
    } else if (typeOf(uriB) === "object") {
        uriB = serialize(uriB, options);
    }
    return uriA === uriB;
}

function escapeComponent(str, options) {
    return str && str.toString().replace(!options || !options.iri ? URI_PROTOCOL.ESCAPE : IRI_PROTOCOL.ESCAPE, pctEncChar);
}

function unescapeComponent(str, options) {
    return str && str.toString().replace(!options || !options.iri ? URI_PROTOCOL.PCT_ENCODED : IRI_PROTOCOL.PCT_ENCODED, pctDecChars);
}

var handler = {
    scheme: "http",
    domainHost: true,
    parse: function parse(components, options) {
        //report missing host
        if (!components.host) {
            components.error = components.error || "HTTP URIs must have a host.";
        }
        return components;
    },
    serialize: function serialize(components, options) {
        var secure = String(components.scheme).toLowerCase() === "https";
        //normalize the default port
        if (components.port === (secure ? 443 : 80) || components.port === "") {
            components.port = undefined;
        }
        //normalize the empty path
        if (!components.path) {
            components.path = "/";
        }
        //NOTE: We do not parse query strings for HTTP URIs
        //as WWW Form Url Encoded query strings are part of the HTML4+ spec,
        //and not the HTTP spec.
        return components;
    }
};

var handler$1 = {
    scheme: "https",
    domainHost: handler.domainHost,
    parse: handler.parse,
    serialize: handler.serialize
};

function isSecure(wsComponents) {
    return typeof wsComponents.secure === 'boolean' ? wsComponents.secure : String(wsComponents.scheme).toLowerCase() === "wss";
}
//RFC 6455
var handler$2 = {
    scheme: "ws",
    domainHost: true,
    parse: function parse(components, options) {
        var wsComponents = components;
        //indicate if the secure flag is set
        wsComponents.secure = isSecure(wsComponents);
        //construct resouce name
        wsComponents.resourceName = (wsComponents.path || '/') + (wsComponents.query ? '?' + wsComponents.query : '');
        wsComponents.path = undefined;
        wsComponents.query = undefined;
        return wsComponents;
    },
    serialize: function serialize(wsComponents, options) {
        //normalize the default port
        if (wsComponents.port === (isSecure(wsComponents) ? 443 : 80) || wsComponents.port === "") {
            wsComponents.port = undefined;
        }
        //ensure scheme matches secure flag
        if (typeof wsComponents.secure === 'boolean') {
            wsComponents.scheme = wsComponents.secure ? 'wss' : 'ws';
            wsComponents.secure = undefined;
        }
        //reconstruct path from resource name
        if (wsComponents.resourceName) {
            var _wsComponents$resourc = wsComponents.resourceName.split('?'),
                _wsComponents$resourc2 = slicedToArray(_wsComponents$resourc, 2),
                path = _wsComponents$resourc2[0],
                query = _wsComponents$resourc2[1];

            wsComponents.path = path && path !== '/' ? path : undefined;
            wsComponents.query = query;
            wsComponents.resourceName = undefined;
        }
        //forbid fragment component
        wsComponents.fragment = undefined;
        return wsComponents;
    }
};

var handler$3 = {
    scheme: "wss",
    domainHost: handler$2.domainHost,
    parse: handler$2.parse,
    serialize: handler$2.serialize
};

var O = {};
var isIRI = true;
//RFC 3986
var UNRESERVED$$ = "[A-Za-z0-9\\-\\.\\_\\~" + (isIRI ? "\\xA0-\\u200D\\u2010-\\u2029\\u202F-\\uD7FF\\uF900-\\uFDCF\\uFDF0-\\uFFEF" : "") + "]";
var HEXDIG$$ = "[0-9A-Fa-f]"; //case-insensitive
var PCT_ENCODED$ = subexp(subexp("%[EFef]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%[89A-Fa-f]" + HEXDIG$$ + "%" + HEXDIG$$ + HEXDIG$$) + "|" + subexp("%" + HEXDIG$$ + HEXDIG$$)); //expanded
//RFC 5322, except these symbols as per RFC 6068: @ : / ? # [ ] & ; =
//const ATEXT$$ = "[A-Za-z0-9\\!\\#\\$\\%\\&\\'\\*\\+\\-\\/\\=\\?\\^\\_\\`\\{\\|\\}\\~]";
//const WSP$$ = "[\\x20\\x09]";
//const OBS_QTEXT$$ = "[\\x01-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]";  //(%d1-8 / %d11-12 / %d14-31 / %d127)
//const QTEXT$$ = merge("[\\x21\\x23-\\x5B\\x5D-\\x7E]", OBS_QTEXT$$);  //%d33 / %d35-91 / %d93-126 / obs-qtext
//const VCHAR$$ = "[\\x21-\\x7E]";
//const WSP$$ = "[\\x20\\x09]";
//const OBS_QP$ = subexp("\\\\" + merge("[\\x00\\x0D\\x0A]", OBS_QTEXT$$));  //%d0 / CR / LF / obs-qtext
//const FWS$ = subexp(subexp(WSP$$ + "*" + "\\x0D\\x0A") + "?" + WSP$$ + "+");
//const QUOTED_PAIR$ = subexp(subexp("\\\\" + subexp(VCHAR$$ + "|" + WSP$$)) + "|" + OBS_QP$);
//const QUOTED_STRING$ = subexp('\\"' + subexp(FWS$ + "?" + QCONTENT$) + "*" + FWS$ + "?" + '\\"');
var ATEXT$$ = "[A-Za-z0-9\\!\\$\\%\\'\\*\\+\\-\\^\\_\\`\\{\\|\\}\\~]";
var QTEXT$$ = "[\\!\\$\\%\\'\\(\\)\\*\\+\\,\\-\\.0-9\\<\\>A-Z\\x5E-\\x7E]";
var VCHAR$$ = merge(QTEXT$$, "[\\\"\\\\]");
var SOME_DELIMS$$ = "[\\!\\$\\'\\(\\)\\*\\+\\,\\;\\:\\@]";
var UNRESERVED = new RegExp(UNRESERVED$$, "g");
var PCT_ENCODED = new RegExp(PCT_ENCODED$, "g");
var NOT_LOCAL_PART = new RegExp(merge("[^]", ATEXT$$, "[\\.]", '[\\"]', VCHAR$$), "g");
var NOT_HFNAME = new RegExp(merge("[^]", UNRESERVED$$, SOME_DELIMS$$), "g");
var NOT_HFVALUE = NOT_HFNAME;
function decodeUnreserved(str) {
    var decStr = pctDecChars(str);
    return !decStr.match(UNRESERVED) ? str : decStr;
}
var handler$4 = {
    scheme: "mailto",
    parse: function parse$$1(components, options) {
        var mailtoComponents = components;
        var to = mailtoComponents.to = mailtoComponents.path ? mailtoComponents.path.split(",") : [];
        mailtoComponents.path = undefined;
        if (mailtoComponents.query) {
            var unknownHeaders = false;
            var headers = {};
            var hfields = mailtoComponents.query.split("&");
            for (var x = 0, xl = hfields.length; x < xl; ++x) {
                var hfield = hfields[x].split("=");
                switch (hfield[0]) {
                    case "to":
                        var toAddrs = hfield[1].split(",");
                        for (var _x = 0, _xl = toAddrs.length; _x < _xl; ++_x) {
                            to.push(toAddrs[_x]);
                        }
                        break;
                    case "subject":
                        mailtoComponents.subject = unescapeComponent(hfield[1], options);
                        break;
                    case "body":
                        mailtoComponents.body = unescapeComponent(hfield[1], options);
                        break;
                    default:
                        unknownHeaders = true;
                        headers[unescapeComponent(hfield[0], options)] = unescapeComponent(hfield[1], options);
                        break;
                }
            }
            if (unknownHeaders) mailtoComponents.headers = headers;
        }
        mailtoComponents.query = undefined;
        for (var _x2 = 0, _xl2 = to.length; _x2 < _xl2; ++_x2) {
            var addr = to[_x2].split("@");
            addr[0] = unescapeComponent(addr[0]);
            if (!options.unicodeSupport) {
                //convert Unicode IDN -> ASCII IDN
                try {
                    addr[1] = punycode.toASCII(unescapeComponent(addr[1], options).toLowerCase());
                } catch (e) {
                    mailtoComponents.error = mailtoComponents.error || "Email address's domain name can not be converted to ASCII via punycode: " + e;
                }
            } else {
                addr[1] = unescapeComponent(addr[1], options).toLowerCase();
            }
            to[_x2] = addr.join("@");
        }
        return mailtoComponents;
    },
    serialize: function serialize$$1(mailtoComponents, options) {
        var components = mailtoComponents;
        var to = toArray(mailtoComponents.to);
        if (to) {
            for (var x = 0, xl = to.length; x < xl; ++x) {
                var toAddr = String(to[x]);
                var atIdx = toAddr.lastIndexOf("@");
                var localPart = toAddr.slice(0, atIdx).replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_LOCAL_PART, pctEncChar);
                var domain = toAddr.slice(atIdx + 1);
                //convert IDN via punycode
                try {
                    domain = !options.iri ? punycode.toASCII(unescapeComponent(domain, options).toLowerCase()) : punycode.toUnicode(domain);
                } catch (e) {
                    components.error = components.error || "Email address's domain name can not be converted to " + (!options.iri ? "ASCII" : "Unicode") + " via punycode: " + e;
                }
                to[x] = localPart + "@" + domain;
            }
            components.path = to.join(",");
        }
        var headers = mailtoComponents.headers = mailtoComponents.headers || {};
        if (mailtoComponents.subject) headers["subject"] = mailtoComponents.subject;
        if (mailtoComponents.body) headers["body"] = mailtoComponents.body;
        var fields = [];
        for (var name in headers) {
            if (headers[name] !== O[name]) {
                fields.push(name.replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_HFNAME, pctEncChar) + "=" + headers[name].replace(PCT_ENCODED, decodeUnreserved).replace(PCT_ENCODED, toUpperCase).replace(NOT_HFVALUE, pctEncChar));
            }
        }
        if (fields.length) {
            components.query = fields.join("&");
        }
        return components;
    }
};

var URN_PARSE = /^([^\:]+)\:(.*)/;
//RFC 2141
var handler$5 = {
    scheme: "urn",
    parse: function parse$$1(components, options) {
        var matches = components.path && components.path.match(URN_PARSE);
        var urnComponents = components;
        if (matches) {
            var scheme = options.scheme || urnComponents.scheme || "urn";
            var nid = matches[1].toLowerCase();
            var nss = matches[2];
            var urnScheme = scheme + ":" + (options.nid || nid);
            var schemeHandler = SCHEMES[urnScheme];
            urnComponents.nid = nid;
            urnComponents.nss = nss;
            urnComponents.path = undefined;
            if (schemeHandler) {
                urnComponents = schemeHandler.parse(urnComponents, options);
            }
        } else {
            urnComponents.error = urnComponents.error || "URN can not be parsed.";
        }
        return urnComponents;
    },
    serialize: function serialize$$1(urnComponents, options) {
        var scheme = options.scheme || urnComponents.scheme || "urn";
        var nid = urnComponents.nid;
        var urnScheme = scheme + ":" + (options.nid || nid);
        var schemeHandler = SCHEMES[urnScheme];
        if (schemeHandler) {
            urnComponents = schemeHandler.serialize(urnComponents, options);
        }
        var uriComponents = urnComponents;
        var nss = urnComponents.nss;
        uriComponents.path = (nid || options.nid) + ":" + nss;
        return uriComponents;
    }
};

var UUID = /^[0-9A-Fa-f]{8}(?:\-[0-9A-Fa-f]{4}){3}\-[0-9A-Fa-f]{12}$/;
//RFC 4122
var handler$6 = {
    scheme: "urn:uuid",
    parse: function parse(urnComponents, options) {
        var uuidComponents = urnComponents;
        uuidComponents.uuid = uuidComponents.nss;
        uuidComponents.nss = undefined;
        if (!options.tolerant && (!uuidComponents.uuid || !uuidComponents.uuid.match(UUID))) {
            uuidComponents.error = uuidComponents.error || "UUID is not valid.";
        }
        return uuidComponents;
    },
    serialize: function serialize(uuidComponents, options) {
        var urnComponents = uuidComponents;
        //normalize UUID
        urnComponents.nss = (uuidComponents.uuid || "").toLowerCase();
        return urnComponents;
    }
};

SCHEMES[handler.scheme] = handler;
SCHEMES[handler$1.scheme] = handler$1;
SCHEMES[handler$2.scheme] = handler$2;
SCHEMES[handler$3.scheme] = handler$3;
SCHEMES[handler$4.scheme] = handler$4;
SCHEMES[handler$5.scheme] = handler$5;
SCHEMES[handler$6.scheme] = handler$6;

exports.SCHEMES = SCHEMES;
exports.pctEncChar = pctEncChar;
exports.pctDecChars = pctDecChars;
exports.parse = parse;
exports.removeDotSegments = removeDotSegments;
exports.serialize = serialize;
exports.resolveComponents = resolveComponents;
exports.resolve = resolve;
exports.normalize = normalize;
exports.equal = equal;
exports.escapeComponent = escapeComponent;
exports.unescapeComponent = unescapeComponent;

Object.defineProperty(exports, '__esModule', { value: true });

})));


},{}],230:[function(require,module,exports){
(function (global){(function (){

/**
 * Module exports.
 */

module.exports = deprecate;

/**
 * Mark that a method should not be used.
 * Returns a modified function which warns once by default.
 *
 * If `localStorage.noDeprecation = true` is set, then it is a no-op.
 *
 * If `localStorage.throwDeprecation = true` is set, then deprecated functions
 * will throw an Error when invoked.
 *
 * If `localStorage.traceDeprecation = true` is set, then deprecated functions
 * will invoke `console.trace()` instead of `console.error()`.
 *
 * @param {Function} fn - the function to deprecate
 * @param {String} msg - the string to print to the console when `fn` is invoked
 * @returns {Function} a new "deprecated" version of `fn`
 * @api public
 */

function deprecate (fn, msg) {
  if (config('noDeprecation')) {
    return fn;
  }

  var warned = false;
  function deprecated() {
    if (!warned) {
      if (config('throwDeprecation')) {
        throw new Error(msg);
      } else if (config('traceDeprecation')) {
        console.trace(msg);
      } else {
        console.warn(msg);
      }
      warned = true;
    }
    return fn.apply(this, arguments);
  }

  return deprecated;
}

/**
 * Checks `localStorage` for boolean values for the given `name`.
 *
 * @param {String} name
 * @returns {Boolean}
 * @api private
 */

function config (name) {
  // accessing global.localStorage can trigger a DOMException in sandboxed iframes
  try {
    if (!global.localStorage) return false;
  } catch (_) {
    return false;
  }
  var val = global.localStorage[name];
  if (null == val) return false;
  return String(val).toLowerCase() === 'true';
}

}).call(this)}).call(this,typeof global !== "undefined" ? global : typeof self !== "undefined" ? self : typeof window !== "undefined" ? window : {})
},{}],231:[function(require,module,exports){
'use strict'
module.exports = function (Yallist) {
  Yallist.prototype[Symbol.iterator] = function* () {
    for (let walker = this.head; walker; walker = walker.next) {
      yield walker.value
    }
  }
}

},{}],232:[function(require,module,exports){
'use strict'
module.exports = Yallist

Yallist.Node = Node
Yallist.create = Yallist

function Yallist (list) {
  var self = this
  if (!(self instanceof Yallist)) {
    self = new Yallist()
  }

  self.tail = null
  self.head = null
  self.length = 0

  if (list && typeof list.forEach === 'function') {
    list.forEach(function (item) {
      self.push(item)
    })
  } else if (arguments.length > 0) {
    for (var i = 0, l = arguments.length; i < l; i++) {
      self.push(arguments[i])
    }
  }

  return self
}

Yallist.prototype.removeNode = function (node) {
  if (node.list !== this) {
    throw new Error('removing node which does not belong to this list')
  }

  var next = node.next
  var prev = node.prev

  if (next) {
    next.prev = prev
  }

  if (prev) {
    prev.next = next
  }

  if (node === this.head) {
    this.head = next
  }
  if (node === this.tail) {
    this.tail = prev
  }

  node.list.length--
  node.next = null
  node.prev = null
  node.list = null

  return next
}

Yallist.prototype.unshiftNode = function (node) {
  if (node === this.head) {
    return
  }

  if (node.list) {
    node.list.removeNode(node)
  }

  var head = this.head
  node.list = this
  node.next = head
  if (head) {
    head.prev = node
  }

  this.head = node
  if (!this.tail) {
    this.tail = node
  }
  this.length++
}

Yallist.prototype.pushNode = function (node) {
  if (node === this.tail) {
    return
  }

  if (node.list) {
    node.list.removeNode(node)
  }

  var tail = this.tail
  node.list = this
  node.prev = tail
  if (tail) {
    tail.next = node
  }

  this.tail = node
  if (!this.head) {
    this.head = node
  }
  this.length++
}

Yallist.prototype.push = function () {
  for (var i = 0, l = arguments.length; i < l; i++) {
    push(this, arguments[i])
  }
  return this.length
}

Yallist.prototype.unshift = function () {
  for (var i = 0, l = arguments.length; i < l; i++) {
    unshift(this, arguments[i])
  }
  return this.length
}

Yallist.prototype.pop = function () {
  if (!this.tail) {
    return undefined
  }

  var res = this.tail.value
  this.tail = this.tail.prev
  if (this.tail) {
    this.tail.next = null
  } else {
    this.head = null
  }
  this.length--
  return res
}

Yallist.prototype.shift = function () {
  if (!this.head) {
    return undefined
  }

  var res = this.head.value
  this.head = this.head.next
  if (this.head) {
    this.head.prev = null
  } else {
    this.tail = null
  }
  this.length--
  return res
}

Yallist.prototype.forEach = function (fn, thisp) {
  thisp = thisp || this
  for (var walker = this.head, i = 0; walker !== null; i++) {
    fn.call(thisp, walker.value, i, this)
    walker = walker.next
  }
}

Yallist.prototype.forEachReverse = function (fn, thisp) {
  thisp = thisp || this
  for (var walker = this.tail, i = this.length - 1; walker !== null; i--) {
    fn.call(thisp, walker.value, i, this)
    walker = walker.prev
  }
}

Yallist.prototype.get = function (n) {
  for (var i = 0, walker = this.head; walker !== null && i < n; i++) {
    // abort out of the list early if we hit a cycle
    walker = walker.next
  }
  if (i === n && walker !== null) {
    return walker.value
  }
}

Yallist.prototype.getReverse = function (n) {
  for (var i = 0, walker = this.tail; walker !== null && i < n; i++) {
    // abort out of the list early if we hit a cycle
    walker = walker.prev
  }
  if (i === n && walker !== null) {
    return walker.value
  }
}

Yallist.prototype.map = function (fn, thisp) {
  thisp = thisp || this
  var res = new Yallist()
  for (var walker = this.head; walker !== null;) {
    res.push(fn.call(thisp, walker.value, this))
    walker = walker.next
  }
  return res
}

Yallist.prototype.mapReverse = function (fn, thisp) {
  thisp = thisp || this
  var res = new Yallist()
  for (var walker = this.tail; walker !== null;) {
    res.push(fn.call(thisp, walker.value, this))
    walker = walker.prev
  }
  return res
}

Yallist.prototype.reduce = function (fn, initial) {
  var acc
  var walker = this.head
  if (arguments.length > 1) {
    acc = initial
  } else if (this.head) {
    walker = this.head.next
    acc = this.head.value
  } else {
    throw new TypeError('Reduce of empty list with no initial value')
  }

  for (var i = 0; walker !== null; i++) {
    acc = fn(acc, walker.value, i)
    walker = walker.next
  }

  return acc
}

Yallist.prototype.reduceReverse = function (fn, initial) {
  var acc
  var walker = this.tail
  if (arguments.length > 1) {
    acc = initial
  } else if (this.tail) {
    walker = this.tail.prev
    acc = this.tail.value
  } else {
    throw new TypeError('Reduce of empty list with no initial value')
  }

  for (var i = this.length - 1; walker !== null; i--) {
    acc = fn(acc, walker.value, i)
    walker = walker.prev
  }

  return acc
}

Yallist.prototype.toArray = function () {
  var arr = new Array(this.length)
  for (var i = 0, walker = this.head; walker !== null; i++) {
    arr[i] = walker.value
    walker = walker.next
  }
  return arr
}

Yallist.prototype.toArrayReverse = function () {
  var arr = new Array(this.length)
  for (var i = 0, walker = this.tail; walker !== null; i++) {
    arr[i] = walker.value
    walker = walker.prev
  }
  return arr
}

Yallist.prototype.slice = function (from, to) {
  to = to || this.length
  if (to < 0) {
    to += this.length
  }
  from = from || 0
  if (from < 0) {
    from += this.length
  }
  var ret = new Yallist()
  if (to < from || to < 0) {
    return ret
  }
  if (from < 0) {
    from = 0
  }
  if (to > this.length) {
    to = this.length
  }
  for (var i = 0, walker = this.head; walker !== null && i < from; i++) {
    walker = walker.next
  }
  for (; walker !== null && i < to; i++, walker = walker.next) {
    ret.push(walker.value)
  }
  return ret
}

Yallist.prototype.sliceReverse = function (from, to) {
  to = to || this.length
  if (to < 0) {
    to += this.length
  }
  from = from || 0
  if (from < 0) {
    from += this.length
  }
  var ret = new Yallist()
  if (to < from || to < 0) {
    return ret
  }
  if (from < 0) {
    from = 0
  }
  if (to > this.length) {
    to = this.length
  }
  for (var i = this.length, walker = this.tail; walker !== null && i > to; i--) {
    walker = walker.prev
  }
  for (; walker !== null && i > from; i--, walker = walker.prev) {
    ret.push(walker.value)
  }
  return ret
}

Yallist.prototype.splice = function (start, deleteCount, ...nodes) {
  if (start > this.length) {
    start = this.length - 1
  }
  if (start < 0) {
    start = this.length + start;
  }

  for (var i = 0, walker = this.head; walker !== null && i < start; i++) {
    walker = walker.next
  }

  var ret = []
  for (var i = 0; walker && i < deleteCount; i++) {
    ret.push(walker.value)
    walker = this.removeNode(walker)
  }
  if (walker === null) {
    walker = this.tail
  }

  if (walker !== this.head && walker !== this.tail) {
    walker = walker.prev
  }

  for (var i = 0; i < nodes.length; i++) {
    walker = insert(this, walker, nodes[i])
  }
  return ret;
}

Yallist.prototype.reverse = function () {
  var head = this.head
  var tail = this.tail
  for (var walker = head; walker !== null; walker = walker.prev) {
    var p = walker.prev
    walker.prev = walker.next
    walker.next = p
  }
  this.head = tail
  this.tail = head
  return this
}

function insert (self, node, value) {
  var inserted = node === self.head ?
    new Node(value, null, node, self) :
    new Node(value, node, node.next, self)

  if (inserted.next === null) {
    self.tail = inserted
  }
  if (inserted.prev === null) {
    self.head = inserted
  }

  self.length++

  return inserted
}

function push (self, item) {
  self.tail = new Node(item, self.tail, null, self)
  if (!self.head) {
    self.head = self.tail
  }
  self.length++
}

function unshift (self, item) {
  self.head = new Node(item, null, self.head, self)
  if (!self.tail) {
    self.tail = self.head
  }
  self.length++
}

function Node (value, prev, next, list) {
  if (!(this instanceof Node)) {
    return new Node(value, prev, next, list)
  }

  this.list = list
  this.value = value

  if (prev) {
    prev.next = this
    this.prev = prev
  } else {
    this.prev = null
  }

  if (next) {
    next.prev = this
    this.next = next
  } else {
    this.next = null
  }
}

try {
  // add if support for Symbol.iterator is present
  require('./iterator.js')(Yallist)
} catch (er) {}

},{"./iterator.js":231}],233:[function(require,module,exports){
const { Ed25519KeyPair } = require('crypto-ld');
const jsonld = require('jsonld');
// const util = require('./rdf-sig.js');
const util = require('jsonld-signatures/lib/util.js');
const graphy = require('graphy');

module.exports = {
  Ed25519KeyPair,
  jsonld,
  util,
  graphy,
  Buffer: require('buffer').Buffer,
}

},{"buffer":74,"crypto-ld":89,"graphy":120,"jsonld":153,"jsonld-signatures/lib/util.js":137}]},{},[233])(233)
});
